// ========== 模型结构 ==========
// Cho seq2seq
@article{Cho_2014,
   title={Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation},
   url={http://dx.doi.org/10.3115/v1/D14-1179},
   DOI={10.3115/v1/d14-1179},
   journal={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher={Association for Computational Linguistics},
   author={Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
   year={2014}
}
// Sutskever seq2seq
@misc{sutskever2014sequence,
    title={Sequence to Sequence Learning with Neural Networks},
    author={Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
    year={2014},
    eprint={1409.3215},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
// ********** 模型结构 **********
// ========== seq2seq 训练方法 ==========
@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}
@misc{bengio2015scheduled,
    title={Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks},
    author={Samy Bengio and Oriol Vinyals and Navdeep Jaitly and Noam Shazeer},
    year={2015},
    eprint={1506.03099},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}
@misc{lamb2016professor,
    title={Professor Forcing: A New Algorithm for Training Recurrent Networks},
    author={Alex Lamb and Anirudh Goyal and Ying Zhang and Saizheng Zhang and Aaron Courville and Yoshua Bengio},
    year={2016},
    eprint={1610.09038},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}
@article{Zhang_2019,
   title={Bridging the Gap between Training and Inference for Neural Machine Translation},
   url={http://dx.doi.org/10.18653/V1/P19-1426},
   DOI={10.18653/v1/p19-1426},
   journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher={Association for Computational Linguistics},
   author={Zhang, Wen and Feng, Yang and Meng, Fandong and You, Di and Liu, Qun},
   year={2019}
}
// **********  seq2seq 训练方法  **********
// ========== seq2seq 解码方法 ==========
@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}
@inproceedings{boulanger2013audio,
  title={Audio Chord Recognition with Recurrent Neural Networks.},
  author={Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
  booktitle={ISMIR},
  pages={335--340},
  year={2013},
  organization={Citeseer}
}
@article{Freitag_2017,
   title={Beam Search Strategies for Neural Machine Translation},
   url={http://dx.doi.org/10.18653/v1/W17-3207},
   DOI={10.18653/v1/w17-3207},
   journal={Proceedings of the First Workshop on Neural Machine Translation},
   publisher={Association for Computational Linguistics},
   author={Freitag, Markus and Al-Onaizan, Yaser},
   year={2017}
}

// ********** seq2seq 解码方法 **********
// ========== attention ==========
@misc{bahdanau2014neural,
    title={Neural Machine Translation by Jointly Learning to Align and Translate},
    author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year={2014},
    eprint={1409.0473},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@article{luong2015effective,
  title={Effective approaches to attention-based neural machine translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  journal={arXiv preprint arXiv:1508.04025},
  year={2015}
}
@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015}
}
@article{gregor2015draw,
  title={Draw: A recurrent neural network for image generation},
  author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  journal={arXiv preprint arXiv:1502.04623},
  year={2015}
}
// ********** attention **********
// ========== pointer network ==========
@inproceedings{vinyals2015pointer,
  title={Pointer networks},
  author={Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
  booktitle={Advances in neural information processing systems},
  pages={2692--2700},
  year={2015}
}
@article{gulcehre2016pointing,
  title={Pointing the unknown words},
  author={Gulcehre, Caglar and Ahn, Sungjin and Nallapati, Ramesh and Zhou, Bowen and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1603.08148},
  year={2016}
}
@article{gu2016incorporating,
  title={Incorporating copying mechanism in sequence-to-sequence learning},
  author={Gu, Jiatao and Lu, Zhengdong and Li, Hang and Li, Victor OK},
  journal={arXiv preprint arXiv:1603.06393},
  year={2016}
}
@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}
// ********** pointer network **********