<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css?v=1.0.2">























  

<link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/5.10.2/css/all.min.css">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  


<!--图片缩放插件样式-->
<link rel="stylesheet" href="/lib/zoomify/zoomify.min.css">

  <meta name="description" content="开场白&amp;emsp;&amp;emsp;略 词向量表示：word2vec&amp;emsp;&amp;emsp;课程计划如下： &amp;emsp;&amp;emsp;神经网络词嵌入学习的通用做法：定义一个模型，根据中心词 w_t 去预测上下文单词。给定 w_t 的条件下 context 的概率。  p(context|w_t) = \dots&amp;emsp;&amp;emsp;然后用损失函数判断预测的准确性，例如：  J = 1 - p(w_{-t">
<meta name="keywords" content="学习笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="2017CS224n学习笔记">
<meta property="og:url" content="http://yan624.github.io/学习笔记/2017CS224n学习笔记.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="开场白&amp;emsp;&amp;emsp;略 词向量表示：word2vec&amp;emsp;&amp;emsp;课程计划如下： &amp;emsp;&amp;emsp;神经网络词嵌入学习的通用做法：定义一个模型，根据中心词 w_t 去预测上下文单词。给定 w_t 的条件下 context 的概率。  p(context|w_t) = \dots&amp;emsp;&amp;emsp;然后用损失函数判断预测的准确性，例如：  J = 1 - p(w_{-t">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/课程计划.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/以前的低维词向量表示方法.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/skip-grams模型.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/softmax.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/attention机制.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/加入attention机制后的性能.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/more attention（coverage）.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/Recursive vs. recurrent neural network.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive neural network for training.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive neural network details.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 1.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 2.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 3.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 4.jpg">
<meta property="og:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/related work for parsing.jpg">
<meta property="og:updated_time" content="2019-10-27T07:41:33.342Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2017CS224n学习笔记">
<meta name="twitter:description" content="开场白&amp;emsp;&amp;emsp;略 词向量表示：word2vec&amp;emsp;&amp;emsp;课程计划如下： &amp;emsp;&amp;emsp;神经网络词嵌入学习的通用做法：定义一个模型，根据中心词 w_t 去预测上下文单词。给定 w_t 的条件下 context 的概率。  p(context|w_t) = \dots&amp;emsp;&amp;emsp;然后用损失函数判断预测的准确性，例如：  J = 1 - p(w_{-t">
<meta name="twitter:image" content="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/课程计划.jpg">






  <link rel="canonical" href="http://yan624.github.io/学习笔记/2017CS224n学习笔记.html">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>2017CS224n学习笔记 | 博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">
	<!--加载flower canvas-->
<script>
var pathname = window.location.pathname;
if(pathname == '/flower.html'){
	var body =  document.getElementsByTagName('body')[0];
	var canvas = document.createElement("canvas")
	canvas.setAttribute('id', 'sakura')
	// '<canvas id="sakura"></canvas>'
	body.appendChild(canvas)
}
</script>
  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">低阶炼金术士</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-常用链接">

    
    
    
      
    

    
      
    

    <a href="/常用链接" rel="section"><i class="menu-item-icon fas fa-fw fa-bookmark"></i> <br>常用链接</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签<span class="badge">19</span></a>

  </li>
        
        
        
          
            
            
            
              
              

  
  
    
  
  <li class="menu-item menu-item-categories">

    
    
    
      
    

    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类<span class="badge">22</span></a>

  </li>


            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
        
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档<span class="badge">122</span></a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/学习笔记/2017CS224n学习笔记.html">


    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	
		<link rel="stylesheet" type="text/css" href="/lib/spop/spop.min.css">
			<script type="text/javascript" src="/lib/spop/spop.min.js"></script>
			<!--判断该文章是否为学习笔记-->
			<script>
				spop({
					template: '<h4 class="spop-title">注意</h4><p style="font-size:1.15em">如文章中未弹出此窗，则没什么大问题。</p>此文章仅为博主的学习笔记，并非教学，其中可能含有理论错误。',
					group: 'tips',
					position  : 'bottom-center',
					style: 'success',
					autoclose: 5500,
					onOpen: function () {
						//这里设置灰色背景色
					},
					onClose: function() {
						//这里可以取消背景色
						spop({
							template: 'ε = = (づ′▽`)づ',
							group: 'tips',
							position  : 'bottom-center',
							style: 'success',
							autoclose: 1500
						});
					}
				});
			</script>
	

        
        
          <h1 class="post-title" itemprop="name headline">2017CS224n学习笔记

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 10:51:09" itemprop="dateCreated datePublished" datetime="2019-05-20T10:51:09+08:00">2019-05-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-10-27 15:41:33" itemprop="dateModified" datetime="2019-10-27T15:41:33+08:00">2019-10-27</time>
              
            
          </span>

          

            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/dl/" itemprop="url" rel="index"><span itemprop="name">dl</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="开场白"><a href="#开场白" class="headerlink" title="开场白"></a>开场白</h1><p>&emsp;&emsp;略</p>
<h1 id="词向量表示：word2vec"><a href="#词向量表示：word2vec" class="headerlink" title="词向量表示：word2vec"></a>词向量表示：word2vec</h1><p>&emsp;&emsp;课程计划如下：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/课程计划.jpg" alt="课程计划"></p>
<p>&emsp;&emsp;<strong>神经网络词嵌入学习的通用做法</strong>：定义一个模型，根据中心词 <script type="math/tex">w_t</script> 去预测上下文单词。给定 <script type="math/tex">w_t</script> 的条件下 context 的概率。</p>
<script type="math/tex; mode=display">
p(context|w_t) = \dots</script><p>&emsp;&emsp;然后用损失函数判断预测的准确性，例如：</p>
<script type="math/tex; mode=display">
J = 1 - p(w_{-t}|w_t), \quad  \text{-t 代表 t 周围的单词}</script><p>&emsp;&emsp;如果可以精准地根据 t 预测到这些单词，那么概率就为 1，于是损失就没有了。但通常情况下，做不到这点。<strong>所以我们应该调整词汇表示，从而使损失最小化</strong>。<br>&emsp;&emsp;下图是以前的低维词向量表示方法，2003 年 Bengio 发表的这篇现在属于开创性的论文其实并没有太多人关注，因为那时候深度学习并没有很流行。但是当这篇论文开始流行的时候，就开始大行其道了。于是 2008 年 Collobert 和 Weston 开启了一个新方向，<strong>他们觉得如果我们只想要得到好的单词表示，我们甚至不需要构建一个具有预测功能的概率语言模型（probabilistic language model），我们只需要找到一种学习单词表示的方法即可</strong>。于是 2013 年有了 word2vec 模型。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/以前的低维词向量表示方法.jpg" alt="以前的低维词向量表示方法"></p>
<p>&emsp;&emsp;word2vec 是一个软件，实际上，它里面包含很多东西。有两个用于生成词汇向量的算法（Hierarchical softamx，negative sampling），还有两套效率中等的训练方法（Skip-grams，CBOW）。<em>这里的软件应该指的不是那种可以运行 exe 文件</em>。本节只讲 skip-grams 算法，并且不会讲那两个高效的词向量生成算法，而是将一个效率极低的算法（因为比较简单且包含了基本概念）。<br>&emsp;&emsp;skip-grams 模型的概念是：在每一个估算步中，都取一个词为中心词汇，然后尝试预测它<strong>一定范围内</strong>的上下文的词汇。这个模型将定义一个概率分布：<strong>给定一个中心词汇预测某个单词在它上下文中出现的概率</strong>。如下图所示：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/skip-grams模型.jpg" alt="skip-grams模型"></p>
<p>&emsp;&emsp;我们将会选取词汇的向量表示，以让概率分布值最大化。</p>
<h2 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h2><p>&emsp;&emsp;我们需要做的是定义一个半径 m，然后从中心词汇开始到距离为 m 的位置来预测周围的词汇。这句话比较抽象，因为到这为止，你还是构建不出一个模型（优化目标）。下面先给出模型的公式，注意一撇不是求导：</p>
<script type="math/tex; mode=display">
J'(\theta) = \prod^T_{t=1} \prod_{-m \leq m, j \neq 0} p(w_{t+j}|w_t;\theta)</script><p>&emsp;&emsp;其中定义一句话有 T 个单词，word t = 1 <script type="math/tex">\dots</script> T。上式中 m 为半径窗口，j 为整个窗口之中的索引。先不看第一个累乘符号，当 t = 1 时，也就是当中心词的索引为 1 时，以 m 为半径，预测该中心词汇的上下文单词出现的概率，并将所有的概率累乘。即公式： <script type="math/tex">\prod_{-m \leq m, j \neq 0} p(w_{t+j}|w_t;\theta)</script>。而第一个累乘符号指的是，将句子中每一个字都当做一次中心词汇，然后将概率再累乘起来。当然当中心词的索引比较靠前时，可能窗口会超出句子的前部，比如 中心词汇所以为 1，而 m = 5，则需要预测 -4，-3… 的位置，这显然不可能，所以需要自己做一下处理。<br>&emsp;&emsp;公式中的 <script type="math/tex">\theta</script> 是模型唯一的参数，让上下文所有词汇出现的概率都尽可能的高，其实 <script type="math/tex">\theta</script> 就是词向量，而模型的输入就是 one-hot 表示。但是，处理概率问题是一件很不爽的事，我们要做最大化操作，实际上就是解决对数分布的问题。这样求积就会变成求和，如下所示：</p>
<script type="math/tex; mode=display">
J(\theta) = -\frac{1}{T} \sum^T_{t=1} \sum_{-m \leq m, j \neq 0} log \, p(w_{t+j}|w_t;\theta)</script><p>&emsp;&emsp;这样我们就得到了<strong>负的对数似然</strong>，上述公式就是最终版。但是这里还有一小点就是 m 其实也算是模型的参数，但是确是<strong>超参数</strong>，需要自己手动改的。所以上面说“<em>公式中的 <script type="math/tex">\theta</script> 是模型唯一的参数</em>”也没错。事实上这个模型还有很多其他的超参数，但是现在暂且视为常数。<br>&emsp;&emsp;公式前面有个负号，是因为我们要求最小化问题，而原式只能取最大值，所以取了个负号。</p>
<h3 id="确定相应的概率分布"><a href="#确定相应的概率分布" class="headerlink" title="确定相应的概率分布"></a>确定相应的概率分布</h3><p>&emsp;&emsp;那么我们具体应该怎么通过中心词汇来预测周围单词出现的概率呢？也就是说公式中的函数 p 应该是什么。其实 p 就是 softmax 函数。具体来说就是用由词向量构成的中心词汇去预测周围词汇的概率分布。下图就是 softmax 函数。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/softmax.jpg" alt="softmax"></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>&emsp;&emsp;最前面讲到需要有一个损失函数来判断预测的准确性。我们使用 cross-entropy loss。</p>
<h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><script type="math/tex; mode=display">
\begin{align}
     & \frac{\partial}{\partial v_c} log \frac{exp(u^T_o v_c)}{\sum^v_{w=1} exp(u^T_w v_c))} \\
    = & \frac{\partial}{\partial v_c} (\underbrace{log \, exp(u^T_o v_c)}_{1} - \underbrace{log \, \sum^v_{w=1} exp(u^T_w v_c)}_2) \\
     & \frac{\partial}{\partial v_c} log \, exp(u^T_o v_c) & \text{1} \\
    = & \frac{\partial}{\partial v_c} u^T_o v_c = u_o  \\
     & \frac{\partial}{\partial v_c} log \, \sum^v_{w=1} exp(u^T_w v_c) & \text{2} \\
    = & \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \frac{\partial}{\partial v_c} \sum^v_{x=1} exp(u^T_x v_c) \\
    = & \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \sum^v_{x=1} \frac{\partial}{\partial v_c} exp(u^T_x v_c) \\
    = & \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \sum^v_{x=1} exp(u^T_x v_c) \, u_x \\
    = & \sum^v_{x=1} \frac{exp(u^T_x v_c)}{\sum^v_{w=1} exp(u^T_w v_c)} \, u_x \\
    = & \sum^v_{x=1} p(x|c) u_x \\
     & u_o - \sum^v_{x=1} p(x|c) u_x & \text{合并}\\
\end{align}</script><h1 id="高级词向量表示"><a href="#高级词向量表示" class="headerlink" title="高级词向量表示"></a>高级词向量表示</h1><p>&emsp;&emsp;略。</p>
<h1 id="Word-Window分类与神经网络"><a href="#Word-Window分类与神经网络" class="headerlink" title="Word Window分类与神经网络"></a>Word Window分类与神经网络</h1><p>&emsp;&emsp;略。</p>
<h1 id="反向传播和项目建议"><a href="#反向传播和项目建议" class="headerlink" title="反向传播和项目建议"></a>反向传播和项目建议</h1><p>&emsp;&emsp;讲反向传播，略。</p>
<h1 id="依存分析"><a href="#依存分析" class="headerlink" title="依存分析"></a>依存分析</h1><h2 id="语言结构分析历史回顾"><a href="#语言结构分析历史回顾" class="headerlink" title="语言结构分析历史回顾"></a>语言结构分析历史回顾</h2><h2 id="Dependency-Grammar-and-Dependency-Structure"><a href="#Dependency-Grammar-and-Dependency-Structure" class="headerlink" title="Dependency Grammar and Dependency Structure"></a>Dependency Grammar and Dependency Structure</h2><p>&emsp;&emsp;</p>
<h1 id="Tensorflow-入门"><a href="#Tensorflow-入门" class="headerlink" title="Tensorflow 入门"></a>Tensorflow 入门</h1><p>&emsp;&emsp;略，不学 tensorflow。</p>
<h1 id="RNN和语言模式"><a href="#RNN和语言模式" class="headerlink" title="RNN和语言模式"></a>RNN和语言模式</h1><p>&emsp;&emsp;详解 RNN 很多问题。</p>
<h1 id="机器翻译和高级循环神经网络"><a href="#机器翻译和高级循环神经网络" class="headerlink" title="机器翻译和高级循环神经网络"></a>机器翻译和高级循环神经网络</h1><p>&emsp;&emsp;花了二三十分钟讲机器翻译，然后讲解各类 RNN。</p>
<h1 id="神经机器翻译和注意力模型"><a href="#神经机器翻译和注意力模型" class="headerlink" title="神经机器翻译和注意力模型"></a>神经机器翻译和注意力模型</h1><p>&emsp;&emsp;先将机器翻译，后讲 attention。</p>
<h2 id="神经机器翻译"><a href="#神经机器翻译" class="headerlink" title="神经机器翻译"></a>神经机器翻译</h2><h2 id="attention"><a href="#attention" class="headerlink" title="attention"></a>attention</h2><p>&emsp;&emsp;下图是 attention 的工作原理。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/attention机制.jpg" alt="attention机制"></p>
<ol>
<li>图中的 a 代表 score，<script type="math/tex">\bar{h}_s</script> 代表 encoder 中每个 time step 生成的隐藏状态向量，<script type="math/tex">c_t</script> 代表 attention 之后的向量；</li>
<li>首先将开始标志输入到一个 decoder，代表开始进行翻译，输出一个单词后，将该 decoder 的<strong>隐藏状态</strong>（注意是隐藏状态而不是输出值，此节课视频中有明确指出）与 encoder 中的<strong>隐藏状态</strong>进行计算得到一个 score。打分的公式为 <script type="math/tex">score(h_{t - 1}, \bar{h}_s)</script>，score 具体是什么公式可以自己定义，最简单就是向量内积，下面会细说；</li>
<li>关于 score 函数，它有多种选择，<strong>注意一点</strong>下面的 score 函数只是对<strong>一个</strong>时间步上的隐藏状态打分，<script type="math/tex">\bar{h}_s</script> 也可以是个矩阵，即一步计算所有时间步的 attention score（这做法是最好的）。以下罗列几种做法，被广泛采用（2017 年的说法，现不知）的是第二个表达式，第三个表达式的 <script type="math/tex">v_a</script> 也是一个向量参数。另外对于第三个表达式 <script type="math/tex">v_a tanh(W_a [h_t;\bar{h}_s])</script>，它不是 score function，而是 Bahdanau，不知道为什么把它放到 score function 这。<script type="math/tex; mode=display">
score(h_t, \bar{h}_s) = 
\begin{cases}
h^T_t \bar{h}_s \\
h^T_t W_a \bar{h}_s \\
v_a tanh(W_a [h_t;\bar{h}_s])
\end{cases}</script></li>
<li>将 score 送入 softmax 得到概率；</li>
<li>通过公式 <script type="math/tex">c_t = \sum_s a_t(s)\bar{h}_s</script>，将所有的向量乘上注意力分数加起来；</li>
<li>将此新向量当做下一个 decoder 的输入；</li>
</ol>
<p>&emsp;&emsp;下图是加 attention 机制和不加的区别。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/加入attention机制后的性能.jpg" alt="加入attention机制后的性能"></p>
<h2 id="coverage"><a href="#coverage" class="headerlink" title="coverage"></a>coverage</h2><p>&emsp;&emsp;coverage = more attention，想法源于计算机视觉，请看下图。神经网络读入一张图片，要求输出一段话。但是我们知道一段话不仅要描写图中的鸟，还要描写鸟旁边的事物，所以就引出了多次注意，即神经网络需要注意图中更多的地方。将这一想法引入 NLP 中，其实就是多做几次 attention，<em>注：这一想法貌似就是后来 transformer 的 multi-head attention</em>。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/more attention（coverage）.jpg" alt="more attention(coverage)"></p>
<h2 id="search"><a href="#search" class="headerlink" title="search"></a>search</h2><p>&emsp;&emsp;</p>
<h1 id="GRU及NMT的其他议题"><a href="#GRU及NMT的其他议题" class="headerlink" title="GRU及NMT的其他议题"></a>GRU及NMT的其他议题</h1><h2 id="GRUs-LSTMs"><a href="#GRUs-LSTMs" class="headerlink" title="GRUs/LSTMs"></a>GRUs/LSTMs</h2><h2 id="NMT-evaluation"><a href="#NMT-evaluation" class="headerlink" title="NMT evaluation"></a>NMT evaluation</h2><h1 id="语音处理的端对端模型"><a href="#语音处理的端对端模型" class="headerlink" title="语音处理的端对端模型"></a>语音处理的端对端模型</h1><h1 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h1><h1 id="树RNN和短语句分析"><a href="#树RNN和短语句分析" class="headerlink" title="树RNN和短语句分析"></a>树RNN和短语句分析</h1><p>&emsp;&emsp;人类语言具有嵌套结构（训练结构、树结构），如：[The man from [the company that you spoke with about [the project] yesterday]]。<br>&emsp;&emsp;那么如何使用向量来表示这些句子的语义呢？可以使用 tree RNN，如下图：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/Recursive vs. recurrent neural network.jpg" alt="Recursive vs. recurrent neural network"></p>
<blockquote>
<p>&emsp;&emsp;<strong>Tree recursive neural network 的问题在于你需要得到一个树形结构</strong>，这是一个比较大的问题。树形网络并没有火遍全球，在语言方面确实有原因喜欢这类的模型（原因后面会有讲到），但是如果你在 arxiv 里面找，人们在语言神经网络研究中所使用的的方法时，你会发现人们并不多使用树形结构模型。LSTMs 的比例几乎是其十倍之多。<br>&emsp;&emsp;这里面比较大的原因是树形递归神经网络的使用者必须构建一个树形结构。<strong>在你构建完成后，使用反向传播学习模型会是一个问题</strong>。<br>&emsp;&emsp;<a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a> 25分开始。</p>
</blockquote>
<h2 id="simple-tree-RNN"><a href="#simple-tree-RNN" class="headerlink" title="simple tree RNN"></a>simple tree RNN</h2><h3 id="树RNN的计算"><a href="#树RNN的计算" class="headerlink" title="树RNN的计算"></a>树RNN的计算</h3><p>&emsp;&emsp;那么具体如何使用树形递归神经网络计算呢？比如下图中使用向量 [3 3] 和 [8 5] 计算，输入进神经网络之后，就会输出一个向量 [8 3] 和一个分数 1.3，这个分数代表输出的向量 [8 3] 是否合理（即结构是否合理。如果不太理解什么是结构是否合理，请看下两张图以及博客内容即可理解）。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive neural network for training.jpg" alt="recursive neural network for training"></p>
<p>&emsp;&emsp;具体的做法如下图所示。应该很好理解，就不详细说明了，其中对于计算 score 的 U，我猜测可能是一个 trainable 的参数，视频中并没有详细的说明。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive neural network details.jpg" alt="recursive neural network details"></p>
<p>&emsp;&emsp;那么到了真正的实战阶段应该怎么做呢？训练一个贪心的解析器，对于单词两两组合，然后发现最前的两个单词 “The cat” 组成的短语训练之后的分数最高，然后我们将 “The cat” 看作一个成分并且尤其对应的语义 [5 2]。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 1.jpg" alt="parsing a sentence with rnn"></p>
<p>&emsp;&emsp;接下来继续重复做，请注意现在的 “The cat” 是一个成分（可看作单词），而不是两个单词。又做一遍解析之后发现 “the mat” 的分数最高。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 2.jpg" alt="parsing a sentence with rnn——2"></p>
<p>&emsp;&emsp;再将 “the mat” 看作一个成分，并拥有对应的语义。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 3.jpg" alt="parsing a sentence with rnn 3"></p>
<p>&emsp;&emsp;以此类推，我们发现 “on the mat” 的分数最高，然后发现 “sat on the mat” 的分数最高，最后就得到 “The cat sat on the mat” 的分数最高。如下图：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing a sentence with rnn 4.jpg" alt="parsing a sentence with rnn 4"></p>
<p>&emsp;&emsp;这是一棵解析树（parse tree），我们会得到这棵解析树的分数，它的分数由每个节点的分数加和得到。<strong>我们要做的就是找到由这堆节点所能组成的分数最高的解析树</strong>。<br>&emsp;&emsp;还需要一个优化目标，similar to max-margin parsing(Taskar et al. 2004), a supervised max-margin objective:</p>
<script type="math/tex; mode=display">J = \sum_i s(x_i, y_i) - \max_{y \in A(x_i)} (s(x_i, y) - \Delta(y, y_i))</script><p>&emsp;&emsp;最后我们还需要反向传播算法进行计算，这一工作早在 20 世纪 90 年代就由几个德国人做过了。Goller 和 Kuchler 提出了这个算法，并命名为 <strong>back propagation through structure</strong>.</p>
<h2 id="Syntactically-Untied-RNN"><a href="#Syntactically-Untied-RNN" class="headerlink" title="Syntactically-Untied RNN"></a>Syntactically-Untied RNN</h2><p>&emsp;&emsp;语义解绑树形递归神经网络，这被证明是构建高质量解析器的一个成功的方法。<br>&emsp;&emsp;<a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a>，50 分开始。</p>
<h2 id="Compositionality-Through-Recursive-Matrix-Vector-Spaces"><a href="#Compositionality-Through-Recursive-Matrix-Vector-Spaces" class="headerlink" title="Compositionality Through Recursive Matrix-Vector Spaces"></a>Compositionality Through Recursive Matrix-Vector Spaces</h2><p>&emsp;&emsp;<a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a>，65 分开始。</p>
<h2 id="related-work-for-parsing"><a href="#related-work-for-parsing" class="headerlink" title="related work for parsing"></a>related work for parsing</h2><p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/related work for parsing.jpg" alt="related work for parsing"></p>
<h1 id="共指解析"><a href="#共指解析" class="headerlink" title="共指解析"></a>共指解析</h1><p>&emsp;&emsp;</p>
<a id="more"></a>
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/学习笔记/" rel="tag"># 学习笔记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/zcy/深度学习算法（一）：simple NN（前馈神经网络的正反向推导）.html" rel="next" title="深度学习算法（一）：simple NN（前馈神经网络的正反向推导）">
                <i class="fa fa-chevron-left"></i> 深度学习算法（一）：simple NN（前馈神经网络的正反向推导）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/zcy/深度学习算法（二）：simple RNN 推导与理解.html" rel="prev" title="深度学习算法（二）：simple RNN 推导与理解">
                深度学习算法（二）：simple RNN 推导与理解 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="朱冲䶮">
            
              <p class="site-author-name" itemprop="name">朱冲䶮</p>
              <p class="site-description motion-element" itemprop="description">记录学习问题，积累做的 leetcode 题目</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">122</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">19</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
			  
			  <!-- 不蒜子/busuanzi -->
			  <div class="site-state-item site-state-posts">
			  	<span class="site-state-item-count">111.8k</span>
			  	<span class="site-state-item-name">总字数</span>
			  </div>
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:897538633@qq.com" title="E-Mail &rarr; mailto:897538633@qq.com" rel="noopener" target="_blank"><i class="fas fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/yan624" title="GitHub &rarr; https://github.com/yan624" rel="noopener" target="_blank"><i class="fab fa-fw fa-github"></i>GitHub</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://huaguoguo.gitee.io" title="http://huaguoguo.gitee.io" rel="noopener" target="_blank">葬爱丶华少的天下</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://lzh0928.gitee.io/" title="https://lzh0928.gitee.io/" rel="noopener" target="_blank">Mr.Liu</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#开场白"><span class="nav-number">1.</span> <span class="nav-text">开场白</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#词向量表示：word2vec"><span class="nav-number">2.</span> <span class="nav-text">词向量表示：word2vec</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化目标"><span class="nav-number">2.1.</span> <span class="nav-text">优化目标</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#确定相应的概率分布"><span class="nav-number">2.1.1.</span> <span class="nav-text">确定相应的概率分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数"><span class="nav-number">2.2.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计算"><span class="nav-number">2.3.</span> <span class="nav-text">计算</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#高级词向量表示"><span class="nav-number">3.</span> <span class="nav-text">高级词向量表示</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Word-Window分类与神经网络"><span class="nav-number">4.</span> <span class="nav-text">Word Window分类与神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#反向传播和项目建议"><span class="nav-number">5.</span> <span class="nav-text">反向传播和项目建议</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#依存分析"><span class="nav-number">6.</span> <span class="nav-text">依存分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#语言结构分析历史回顾"><span class="nav-number">6.1.</span> <span class="nav-text">语言结构分析历史回顾</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dependency-Grammar-and-Dependency-Structure"><span class="nav-number">6.2.</span> <span class="nav-text">Dependency Grammar and Dependency Structure</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Tensorflow-入门"><span class="nav-number">7.</span> <span class="nav-text">Tensorflow 入门</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN和语言模式"><span class="nav-number">8.</span> <span class="nav-text">RNN和语言模式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器翻译和高级循环神经网络"><span class="nav-number">9.</span> <span class="nav-text">机器翻译和高级循环神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经机器翻译和注意力模型"><span class="nav-number">10.</span> <span class="nav-text">神经机器翻译和注意力模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#神经机器翻译"><span class="nav-number">10.1.</span> <span class="nav-text">神经机器翻译</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#attention"><span class="nav-number">10.2.</span> <span class="nav-text">attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#coverage"><span class="nav-number">10.3.</span> <span class="nav-text">coverage</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#search"><span class="nav-number">10.4.</span> <span class="nav-text">search</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GRU及NMT的其他议题"><span class="nav-number">11.</span> <span class="nav-text">GRU及NMT的其他议题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#GRUs-LSTMs"><span class="nav-number">11.1.</span> <span class="nav-text">GRUs/LSTMs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NMT-evaluation"><span class="nav-number">11.2.</span> <span class="nav-text">NMT evaluation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#语音处理的端对端模型"><span class="nav-number">12.</span> <span class="nav-text">语音处理的端对端模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络"><span class="nav-number">13.</span> <span class="nav-text">卷积神经网络</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#树RNN和短语句分析"><span class="nav-number">14.</span> <span class="nav-text">树RNN和短语句分析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#simple-tree-RNN"><span class="nav-number">14.1.</span> <span class="nav-text">simple tree RNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#树RNN的计算"><span class="nav-number">14.1.1.</span> <span class="nav-text">树RNN的计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Syntactically-Untied-RNN"><span class="nav-number">14.2.</span> <span class="nav-text">Syntactically-Untied RNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compositionality-Through-Recursive-Matrix-Vector-Spaces"><span class="nav-number">14.3.</span> <span class="nav-text">Compositionality Through Recursive Matrix-Vector Spaces</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#related-work-for-parsing"><span class="nav-number">14.4.</span> <span class="nav-text">related work for parsing</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#共指解析"><span class="nav-number">15.</span> <span class="nav-text">共指解析</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">朱冲䶮</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.7.0</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="总访客量">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="总访问量">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  
  <script src="/js/src/scrollspy.js?v=6.7.0"></script>
<script src="/js/src/post-details.js?v=6.7.0"></script>



  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  


  


  

  <script>
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      
        // ref: https://github.com/ForbesLindesay/unescape-html
        var unescapeHtml = function(html) {
          return String(html)
            .replace(/&quot;/g, '"')
            .replace(/&#39;/g, '\'')
            .replace(/&#x3A;/g, ':')
            // replace all the other &#x; chars
            .replace(/&#(\d+);/g, function (m, p) { return String.fromCharCode(p); })
            .replace(/&lt;/g, '<')
            .replace(/&gt;/g, '>')
            .replace(/&amp;/g, '&');
        };
      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                content = unescapeHtml(content);
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url).replace(/\/{2,}/g, '/');
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x"></i></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x"></i></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  
  

  


  

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function(i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap');
      $(e).after($wrap);
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
        var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
          return $(e).text();
        }).toArray().join('\n');
        var ta = document.createElement('textarea');
        var range = document.createRange(); //For Chrome
        var sel = window.getSelection(); //For Chrome
        var yPosition = window.pageYOffset || document.documentElement.scrollTop;
        ta.style.top = yPosition + 'px'; //Prevent page scroll
        ta.style.position = 'absolute';
        ta.style.opacity = '0';
        ta.value = code;
        ta.textContent = code; //For FireFox
        ta.contentEditable = true;
        ta.readOnly = false;
        document.body.appendChild(ta);
        range.selectNode(ta);
        sel.removeAllRanges();
        sel.addRange(range);
        ta.setSelectionRange(0, code.length);
        var result = document.execCommand('copy');
        
          if (result) $(this).text('复制成功');
          else $(this).text('复制失败');
        
        ta.blur(); //For iOS
        $(this).blur();
      })).on('mouseleave', function(e) {
        var $b = $(this).find('.copy-btn');
        setTimeout(function() {
          $b.text('复制');
        }, 300);
      }).append(e);
    })
  </script>


  

  
  # 自己新增的所有 js 文件
  <script src="/lib/my-utils.js"></script>
<!--图片缩放插件-->
<script src="/lib/zoomify/zoomify.min.js"></script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- 背景插件 -->
<script src="https://cdn.bootcss.com/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
<!-- 背景图片 -->
<script>
	function generateBG(count){
		var bg_prefix = '/images/background/';
		var bg =new Array();
		for(var i = 0; i < count; i++){
			bg[i] = bg_prefix + i + '.jpg';
		}
		bg.shuffle();
		return bg;
	}
	$("body").backstretch(generateBG(11), {
		duration:90000,//1min半一换
		fade: 1500
	});
</script>
<!-- 图片缩放 -->
<script>
$('#content img').zoomify({duration: 500, });
  $('#content img').on('zoom-in.zoomify', function () {
    $('#sidebar').css('display', 'none');
  });
  $('#content img').on('zoom-out-complete.zoomify', function () {
    $('#sidebar').css('display', '');
  });
</script>

	

</body>
</html>
