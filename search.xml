<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>构建一个任务完成型对话系统（零）：调研</title>
    <url>/posts/efcdf06b.html</url>
    <content><![CDATA[<h1 id="框架">框架</h1>
<h1 id="系统架构">系统架构</h1>
<h1 id="预训练模型">预训练模型</h1>
<p>预训练模型凭借着海量的训练数据，可以获得优质的单词表征。在众多任务中取得了不错的成绩。</p>
<p>近几年，在任务导向对话中也有不少研究工作使用预训练模型，实验结果说明其前景广阔<span class="citation" data-cites="zhang2020recent">(Zhang et al. 2020)</span>。<a href="https://yan624.github.io/posts/1ff148b4.html" title="Pretraining Methods for Dialog Context Representation Learning"><span class="citation" data-cites="mehri2019pretraining">(Mehri et al. 2019)</span></a>对比四种预训练目标，其中两种为新提出的方法，期望通过这两种方法可以获得更健壮、更通用的对话上下文表征。<span class="citation" data-cites="mehri2019multi">(Mehri and Eskenazi 2019)</span>。。。</p>
<p>经过调研后，我们打算使用 TOD-BERT<a href="https://yan624.github.io/posts/ceeb7bcc.html" title="TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue"><span class="citation" data-cites="wu2020tod">(Wu et al. 2020)</span></a>，一个专用于提取任务导向对话的预训练模型。简单来说，在训练时，该模型使用两个额外符号明确地表示人机交互过程，即 <strong>[usr]</strong> 和 <strong>[sys]</strong>。这是因为人机对话与网络上的通用文本具有明显区别，人机对话的特点是一轮对话包括一条用户语句以及一条系统回复。</p>
<ul>
<li>DialoGLUE 中有写到两个专用于对话的预训练模型</li>
<li>ConveRT: Efficient and accurate conversational representations from transformers</li>
<li>Dialogue transformers</li>
</ul>
<h1 id="炼丹">炼丹</h1>
<h2 id="对输入序列特性的调研">对输入序列特性的调研</h2>
<p>近期的工作已经展示了 RNNs 可以捕获和利用层次信息方面，例如语言建模和机器翻译。相比之下，非循环结构的神经网络（CNN、Transformer）也在众多 NLP 任务中受到关注。为了比对两种结构在建模层次结构方面的能力，同时为了找到对于上述目的“循环”是否为关键因素，<span class="citation" data-cites="tran2018importance">(Tran, Bisazza, and Monz 2018)</span> 分别比对了主谓一致以及逻辑推理两项实验的结果。他们观察到在主谓一致实验中，无论难度（词距、一致因子距离）如何 LSTM 均强于 Transformer；在逻辑推理实验中，LSTM 在大部分情况下均强于 Transformer。<strong>他们认为当层次结构对任务很重要时，循环是模型的一种特性，不应该为了运行效率而牺牲它。</strong></p>
<p><span class="citation" data-cites="tang2018self">(Tang et al. 2018)</span> 却得到了与 <span class="citation" data-cites="tran2018importance">(Tran, Bisazza, and Monz 2018)</span> 不同的结果（Transformer 略优于 LSTM），在分析上述实验之后，他们发现 <span class="citation" data-cites="tran2018importance">(Tran, Bisazza, and Monz 2018)</span> 使用了迷你版的 Transformer。在做以下退化之后，他们得到了与 <span class="citation" data-cites="tran2018importance">(Tran, Bisazza, and Monz 2018)</span> 类似的结果，退化步骤为：layers(8→4)；embedding size(512→128)；head(8→2)；dropout(0.1→0.2)……</p>
<p>综上所述，在捕获层次结构的信息时，LSTM 与 Transformer 的能力应该相差无几。由于 DST 任务对层次结构信息的要求不是很高，故可以选择拥有大量预训练模型的 Transformer 结构。</p>
<div class="note warning"><p>注意：下述论文分析的是<strong>模型结构的选择以及注意力机制的运用，是否会影响对话系统使用其可用的信息</strong>。</p>
</div>
<p><span class="citation" data-cites="sankar2019neural">(Sankar et al. 2019)</span>对神经回复生成模型提出疑问：“神经语言模型是否有效地使用了对话历史？”为此他们进行实证研究，其中心假设为：<strong>如果模型对破坏他们的扰动不敏感，那么他们就很少使用某些类型的信息</strong>。令人担忧的是，他们发现：1）基于 rnn 或 Transformer 的 seq2seq 模型均对本工作中使用的扰动不敏感；2）即使做出巨大的扰动，例如随机排序或者逆序单词，二者仍旧极其地不敏感（见表 1）；3）循环模型对对话历史中的语句顺序更敏感，这表明它比 Transformer 更易于捕获对话的多样性（conversation dynamics）。</p>
<p>通过对比模型困惑度的增衰，他们观察到：1）在大多数例子中，模型困惑度只有微小的变化，这表明他们远没有使用其可用的所有信息；2）Transformers 对单词重排序不敏感，<u>这意味着其可以学习词袋类型的表征</u>？；3）观察 Only Last 一列，seq2seq_lstm_att 和 transformers 比普通 seq2seq 使用更多对话历史的信息；4）虽然 Transformers 收敛更快并能够达到更低的测试集困惑度，但是他们似乎没有捕获对话的多样性。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/构建一个任务完成型对话系统/Do%20Neural%20Dialog%20Systems%20Use%20the%20Conversation%20History%20Effectively-An%20Empirical%20Study-PPL.png" alt="PPL" /></p>
<h2 id="如何表示对话历史">如何表示对话历史</h2>
<div class="note warning"><p>值得注意的是，以往很多工作构建的是 session-level DST，此类模型在每一轮都会重新预测完整的对话状态。在这种情况下，对话历史就是一件必需品，这是因为其中包含了以往的用户目标。如果不提供对话历史，模型就无法提取完整的对话状态。而对于 turn-level DST 模型，对话历史则是不必要的。</p>
</div>
<p>传统 DST 模型一般将完整的对话历史作为编码器的输入。虽然可以将对话历史视为补充信息，但是其中也夹杂着大量的无用特征，致使其成为模型的负担（例如无法捕获优秀的特征、增加计算成本等），这种数据稀疏性的问题严重地阻碍当前多领域 DST 的发展<span class="citation" data-cites="zhu2020efficient">(Zhu et al. 2020)</span>。因此很有必要探索一种对话历史的全新表示方式，它应该同时拥有简练以及富含历史信息的特点。</p>
<p>如果对 DST 任务有所了解，自然而然地可以想到对话状态就是一个清晰、紧凑且富含信息的抽象表征<span class="citation" data-cites="zeng2020multi">(Zeng and Nie 2020)</span>。目前已经有一些工作<span class="citation" data-cites="kim2019efficient zhu2020efficient zeng2020multi">(Kim et al. 2019; Zhu et al. 2020; Zeng and Nie 2020)</span>使用前一轮的对话状态表示对话历史，他们大多将对话状态表示为序列的形式，然后将其拼接至序列的头部或者末尾。不过由于对话状态由所有槽值对组成，将其转换成序列之后会得到一段相对较长的字符串，例如 120 个字符。上述的做法无疑会增加输入序列的长度，也会成为模型提取特征的负担。在科研领域，目前对此种弊端没有过多的研究。</p>
<h2 id="如何使用对话历史">如何使用对话历史</h2>
<ul>
<li>Sharp Nearby, Fuzzy Far Away How Neural Language Models Use Context</li>
</ul>
<h2 id="如何提取对话状态的特征">如何提取对话状态的特征</h2>
<p><span class="citation" data-cites="zhu2020efficient">(Zhu et al. 2020)</span></p>
<p><span class="citation" data-cites="zeng2020multi">(Zeng and Nie 2020)</span> 认为使用基于 self-attention 的方法建立字符与字符之间的联系，会促成不合理的连接，导致后期的错误推理。为此，他们使用图结构对对话状态进行表示，提出了对话状态图（dialog state graph），并使用 relational-GCN 对其编码，然后将其融入进 Transformer。</p>
<h1 id="数据集">数据集</h1>
<ul>
<li>STAR: A Schema-Guided Dialog Dataset for Transfer Learning</li>
<li>RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling</li>
<li>JDDC</li>
</ul>
<table>
<thead>
<tr class="header">
<th>名称</th>
<th>数据集地址</th>
<th>论文笔记</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://arxiv.org/pdf/1810.00278.pdf" target="_blank" rel="noopener">MultiWOZ2.0</a> <a href="https://openreview.net/forum?id=Cd2icZgvbxD" target="_blank" rel="noopener">2.1</a> <a href="https://arxiv.org/pdf/2007.12720" target="_blank" rel="noopener">2.2</a> <a href="https://arxiv.org/pdf/2010.05594.pdf" target="_blank" rel="noopener">2.3</a></td>
<td><a href="https://github.com/budzianowski/multiwoz" target="_blank" rel="noopener">github</a></td>
<td></td>
</tr>
<tr class="even">
<td><a href="https://arxiv.org/pdf/1909.05855.pdf" target="_blank" rel="noopener">SGD dataset and baseline</a> <a href="https://arxiv.org/pdf/2002.01359.pdf" target="_blank" rel="noopener">DSTC8</a></td>
<td><a href="https://github.com/google-research-datasets/dstc8-schema-guided-dialogue" target="_blank" rel="noopener">github</a></td>
<td><a href="https://yan624.github.io/posts/72340bc.html">笔记</a></td>
</tr>
</tbody>
</table>
<p>随着近几年虚拟助理对多领域对话的需求，目前已经有多个团队发布了诸多多领域的任务对话数据集。其中，MultiWOZ<span class="citation" data-cites="budzianowski2018multiwoz eric2019multiwoz">(Budzianowski et al. 2018; Eric et al. 2019)</span>（谷歌团队）是最先被提出的。其它的多领域数据集还有：M2M、Taskmaster、CrossWOZ(cn)。<mark class="label default">多领域数据集</mark></p>
<p>任务导向型对话系统在经过几年的发展（2018-2019）后，由于谷歌团队认为当前对话系统还具有以下的一些挑战，他们在 2019 年又提出模式引导的多领域任务对话数据集（The Schema-Guided Dialogue Dataset，<strong>SGD</strong>）<span class="citation" data-cites="rastogi2019towards">(Rastogi et al. 2019)</span>。<mark class="label primary">SGD</mark> <a id="more"></a></p>
<blockquote><p>虚拟助理（谷歌助手、Alex、Siri）需要为横跨多个领域的一系列服务或者 api 提供一个对话接口，其所支持的服务可能具有重叠的功能，并且还有部分服务可能没有训练数据。而现有公开的任务导向对话数据集还不足以解决以上的挑战，这主要是因为这些数据集只覆盖了少量的领域，且假定每个领域都有一个静态的本体。</p>
</blockquote>
<p>谷歌团队在 2020 年（7 月左右）发布了 MultiWOZ2.2<span class="citation" data-cites="zang2020multiwoz">(Zang et al. 2020)</span>，它是一个改进的版本，<span class="citation" data-cites="zang2020multiwoz">(Zang et al. 2020)</span>在 MultiWOZ2.1 上识别并修正了 17.3% 的对话状态标注错误（四种不同类型的误差以及状态更新的不一致）。同时，他们使用任务导向对话模式<span class="citation" data-cites="rastogi2019towards">(Rastogi et al. 2019)</span>重新定义了本体，将槽位分为可分类以及不可分类两种类别，对于不可分类槽位不再提供候选值，例如酒店名称，火车出发时间。此外，为了使得模型能够处理不可分类槽位，同时为了符合近期模型的规范，还引入跨度（span）标签。以往通常会使用字符串在用户语句中探测它的跨度，然而这种做法会增加数据处理的成本。最后他们还提出了三个基线模型，分别为：TRADE、SGD-baseline 以及 DS-DST。<mark class="label success">MultiWOZ2.2</mark></p>
<p>在 MultiWOZ 中，5 个领域（hotel，train，restaurant，attraction，taxi）<span class="citation" data-cites="wu2019transferable">(Wu et al. 2019)</span>包含大量对话，其它的领域只具有少量的对话，并且其中有 2 个领域（hospital，police）只出现在训练集中。</p>
<p>2020 年 10 月 又发布了 MultiWOZ2.3<span class="citation" data-cites="han2020multiwoz">(Han et al. 2020)</span>。</p>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-budzianowski2018multiwoz">
<p>Budzianowski, Pawel, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić. 2018. “Multiwoz-a Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling.” <em>arXiv Preprint arXiv:1810.00278</em>.</p>
</div>
<div id="ref-eric2019multiwoz">
<p>Eric, Mihail, Rahul Goel, Shachi Paul, Adarsh Kumar, Abhishek Sethi, Peter Ku, Anuj Kumar Goyal, Sanchit Agarwal, Shuyang Gao, and Dilek Hakkani-Tur. 2019. “MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines.” <em>arXiv Preprint arXiv:1907.01669</em>.</p>
</div>
<div id="ref-han2020multiwoz">
<p>Han, Ting, Ximing Liu, Ryuichi Takanobu, Yixin Lian, Chongxuan Huang, Wei Peng, and Minlie Huang. 2020. “MultiWOZ 2.3: A Multi-Domain Task-Oriented Dataset Enhanced with Annotation Corrections and Co-Reference Annotation.” <em>arXiv Preprint arXiv:2010.05594</em>.</p>
</div>
<div id="ref-kim2019efficient">
<p>Kim, Sungdong, Sohee Yang, Gyuwan Kim, and Sang-Woo Lee. 2019. “Efficient Dialogue State Tracking by Selectively Overwriting Memory.” <em>arXiv Preprint arXiv:1911.03906</em>.</p>
</div>
<div id="ref-mehri2019multi">
<p>Mehri, Shikib, and Maxine Eskenazi. 2019. “Multi-Granularity Representations of Dialog.” <em>arXiv Preprint arXiv:1908.09890</em>.</p>
</div>
<div id="ref-mehri2019pretraining">
<p>Mehri, Shikib, Evgeniia Razumovskaia, Tiancheng Zhao, and Maxine Eskenazi. 2019. “Pretraining Methods for Dialog Context Representation Learning.” <em>arXiv Preprint arXiv:1906.00414</em>.</p>
</div>
<div id="ref-rastogi2019towards">
<p>Rastogi, Abhinav, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav Khaitan. 2019. “Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dialogue Dataset.” <em>arXiv Preprint arXiv:1909.05855</em>.</p>
</div>
<div id="ref-sankar2019neural">
<p>Sankar, Chinnadhurai, Sandeep Subramanian, Christopher Pal, Sarath Chandar, and Yoshua Bengio. 2019. “Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study.” <em>arXiv Preprint arXiv:1906.01603</em>.</p>
</div>
<div id="ref-tang2018self">
<p>Tang, Gongbo, Mathias Müller, Annette Rios, and Rico Sennrich. 2018. “Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures.” <em>arXiv Preprint arXiv:1808.08946</em>.</p>
</div>
<div id="ref-tran2018importance">
<p>Tran, Ke, Arianna Bisazza, and Christof Monz. 2018. “The Importance of Being Recurrent for Modeling Hierarchical Structure.” <em>arXiv Preprint arXiv:1803.03585</em>.</p>
</div>
<div id="ref-wu2020tod">
<p>Wu, Chien-Sheng, Steven Hoi, Richard Socher, and Caiming Xiong. 2020. “Tod-Bert: Pre-Trained Natural Language Understanding for Task-Oriented Dialogues.” <em>arXiv Preprint arXiv:2004.06871</em>.</p>
</div>
<div id="ref-wu2019transferable">
<p>Wu, Chien-Sheng, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, and Pascale Fung. 2019. “Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems.” <em>arXiv Preprint arXiv:1905.08743</em>.</p>
</div>
<div id="ref-zang2020multiwoz">
<p>Zang, Xiaoxue, Abhinav Rastogi, Srinivas Sunkara, Raghav Gupta, Jianguo Zhang, and Jindong Chen. 2020. “Multiwoz 2.2: A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines.” <em>arXiv Preprint arXiv:2007.12720</em>.</p>
</div>
<div id="ref-zeng2020multi">
<p>Zeng, Yan, and Jian-Yun Nie. 2020. “Multi-Domain Dialogue State Tracking Based on State Graph.” <em>arXiv Preprint arXiv:2010.11137</em>.</p>
</div>
<div id="ref-zhang2020recent">
<p>Zhang, Zheng, Ryuichi Takanobu, Qi Zhu, Minlie Huang, and Xiaoyan Zhu. 2020. “Recent Advances and Challenges in Task-Oriented Dialog Systems.” <em>Science China Technological Sciences</em>. Springer, 1–17.</p>
</div>
<div id="ref-zhu2020efficient">
<p>Zhu, Su, Jieyu Li, Lu Chen, and Kai Yu. 2020. “Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue State Tracking.” <em>arXiv Preprint arXiv:2004.03386</em>.</p>
</div>
</div>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>survey</tag>
      </tags>
  </entry>
  <entry>
    <title>Pretraining Methods for Dialog Context Representation Learning</title>
    <url>/posts/1ff148b4.html</url>
    <content><![CDATA[<div class="note warnnign"><p>2020.11.2：暂时记那么多，以后如果有用到，再继续看这篇论文。</p>
</div>
<h1 id="预训练目标">预训练目标</h1>
<p>本节提出四种无监督预训练目标，其中包括<strong>两种</strong>可以捕获更好对话上下文表征的<strong>新方法</strong>。四种训练目标分别为下条语句检索（Next-Utterance Retrieval，<strong>NUR</strong>）、下条语句生成（Next-Utterance Generation，<strong>NUG</strong>）、掩码语句检索（Masked-Utterance Retrieval，<strong>MUR</strong>）以及语句不一致识别（Inconsistency Identification，<strong>InI</strong>），其中 MUR 以及 InI 为新提出的方法。</p>
<p>本文定义：</p>
<ol type="1">
<li>健壮（strong）表征：在整个对话历史上捕获语篇层面（discourse-level）的信息，在语句中捕获语句层面（utterance-level）的信息。</li>
<li>通用（general）表征：在多种下游任务中都能表现出更好的性能。</li>
<li>任意 T 轮的对话片段为：<span class="math inline">\(c = [u_1, \cdots, u_T]\)</span>。</li>
<li>可观测对话回复集合为：<span class="math inline">\(R = {r_1, \cdots, r_M}\)</span>。</li>
</ol>
<a id="more"></a>
<h2 id="next-utterance-retrieval">Next-Utterance Retrieval</h2>
<p>给定一个对话上下文，NUR 的目标是选择 <span class="math inline">\(k\)</span> 个候选回复中正确的下一条语句。NUR 可以被看作类似于语言建模，只不过分割的原子单位是语句而不是单词。</p>
<p><em>有点类似于计算余弦相似度，然后取交叉熵，具体的算法略。详见原论文。</em></p>
<h2 id="next-utterance-generation">Next-Utterance Generation</h2>
<p>NUG 基于过去的对话历史生成下一条语句。seq2seq 模型被用于预训练，并被证明可以学到对下游任务有用的表征。</p>
<p>在训练时使用了层级的 encoder-decoder。尽管在预训练时使用了 decoder，但是在下游任务中只使用了层级上下文 encoder。</p>
<p><em>公式略。详见原论文。</em></p>
<h2 id="masked-utterance-retrieval">Masked-Utterance Retrieval</h2>
<p>与 NUR 类似，</p>
<p>就像之前说的，NUR 可以被视作语言建模，那么 MUR 可以被视作 BERT 提出的 MLM。区别在于被掩盖的原子单位是语句而不是单词。</p>
<p><strong>意义：MUR 类似于 MLM，这会迫使模型让每个输入符号保持分布式上下文表征。通过掩盖整条语句，而不是输入符号，可以使得 MUR 学会为每条语句产生健壮的表征。</strong></p>
<h2 id="inconsistency-identification">Inconsistency Identification</h2>
<p>InI 的任务是在对话历史中找到不一致的语句。具体来说，给定一段对话上下文，然后随机地替换其中的一条语句，与 MUR 类似，InI 需要找到不一致的语句。</p>
<p>InI 的流程为：给定替换语句的索引 <span class="math inline">\(t\)</span>，InI 的目标是训练一个可以识别出该位置 <span class="math inline">\(t\)</span> 的模型。</p>
<p><strong>意义：明确地为对话的连贯性进行建模，这既可以促进每个独立语句的局部表征，又可以助长对话上下文的全局表征。</strong></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>hexo博客插件安装</title>
    <url>/posts/ca8a0039.html</url>
    <content><![CDATA[<h1 id="安装的插件">安装的插件</h1>
<p>打开 git，将当前目录切换到你的博客目录。使用 <code>npm ls -dept 0</code> 即可查看，所有你安装的 hexo 插件。但是以防万一，我还是在下面记录了一下（<strong>主要是我自己下载的插件，hexo 自带的不算</strong>）。</p>
<table>
<thead>
<tr class="header">
<th>插件名</th>
<th>版本号</th>
<th>状态</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>hexo-cli</em></td>
<td>3.1.0</td>
<td>必装插件</td>
</tr>
<tr class="even">
<td>hexo-abbrlink</td>
<td>2.0.5</td>
<td>-</td>
</tr>
<tr class="odd">
<td>hexo-filter-flowchart</td>
<td>1.0.4</td>
<td>-</td>
</tr>
<tr class="even">
<td>hexo-filter-mermaid-diagrams</td>
<td>1.0.5</td>
<td>-</td>
</tr>
<tr class="odd">
<td>hexo-generator-calendar</td>
<td>0.01</td>
<td>-</td>
</tr>
<tr class="even">
<td>hexo-optimize</td>
<td>2.5.1</td>
<td>优化网页加载速度</td>
</tr>
<tr class="odd">
<td><em>hexo-renderer-kramed</em></td>
<td>-</td>
<td>已废弃</td>
</tr>
<tr class="even">
<td>hexo-renderer-mathjax</td>
<td>0.6.0</td>
<td>-</td>
</tr>
<tr class="odd">
<td>hexo-renderer-pandoc</td>
<td>0.3.0</td>
<td>-</td>
</tr>
<tr class="even">
<td>hexo-symbols-count-time</td>
<td>0.7.0</td>
<td>-</td>
</tr>
<tr class="odd">
<td>hexo-tag-echarts3</td>
<td>1.1.2</td>
<td>-</td>
</tr>
<tr class="even">
<td><em>hexo-wordcount</em></td>
<td>6.0.1</td>
<td>已废弃</td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h1 id="开启mathjax插件">开启mathjax插件</h1>
<p>百度了一圈最后还是没有解决问题，因为其他的博客都说要去<code>/node_modules/hexo-renderer-kramed/lib/renderer.js</code>文件修改源代码，但是我压根没有这个文件，hexo-renderer-kramed这个文件夹不存在。</p>
<p>最后还是自己试出来了，步骤如下： 1. 安装kramed。hexo 默认的渲染引擎是 marked，但是 marked 不支持 mathjax。所以要卸载它。 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">uninstall</span> hexo-renderer-marked <span class="comment">--save</span></span><br><span class="line">npm <span class="keyword">install</span> hexo-renderer-kramed <span class="comment">--save</span></span><br></pre></td></tr></table></figure> <!-- more --></p>
<ol start="2" type="1">
<li><p>停用hexo-math，然后安装 hexo-renderer-mathjax 包。其实我也不知道怎么判断自己有没有在使用hexo-math。总而言之卸载就行了，管它存不存在。 <figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">uninstall</span> hexo-math <span class="comment">--save</span></span><br><span class="line">npm <span class="keyword">install</span> hexo-renderer-mathjax <span class="comment">--save</span></span><br></pre></td></tr></table></figure></p></li>
<li><p>开启mathjax，在next主题文件夹里，具体路径：/themes/next/_config.yml 你只需要把enable属性改为true即可 <figure class="highlight oxygene"><table><tr><td class="code"><pre><span class="line"># Math Equations Render Support</span><br><span class="line">math:</span><br><span class="line">  enable: <span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">  # <span class="keyword">Default</span>(<span class="keyword">true</span>) will load mathjax/katex script <span class="keyword">on</span> demand</span><br><span class="line">  # That <span class="keyword">is</span> it only render those page who <span class="keyword">has</span> `mathjax: <span class="keyword">true</span>` <span class="keyword">in</span> Front Matter.</span><br><span class="line">  # <span class="keyword">If</span> you <span class="keyword">set</span> it <span class="keyword">to</span> <span class="keyword">false</span>, it will load mathjax/katex srcipt EVERY PAGE.</span><br><span class="line">  per_page: <span class="keyword">true</span></span><br><span class="line"></span><br><span class="line">  engine: mathjax</span><br><span class="line">  #engine: katex</span><br><span class="line"></span><br><span class="line">  # hexo-rendering-pandoc (<span class="keyword">or</span> hexo-renderer-kramed) needed <span class="keyword">to</span> full MathJax support.</span><br><span class="line">  mathjax:</span><br><span class="line">    enable: <span class="keyword">true</span></span><br><span class="line">    # Use <span class="number">2.7</span>.<span class="number">1</span> <span class="keyword">as</span> <span class="keyword">default</span>, jsdelivr <span class="keyword">as</span> <span class="keyword">default</span> CDN, works everywhere even <span class="keyword">in</span> China</span><br><span class="line">    cdn: <span class="comment">//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML</span></span><br><span class="line">    # <span class="keyword">For</span> direct link <span class="keyword">to</span> MathJax.js <span class="keyword">with</span> CloudFlare CDN (cdnjs.cloudflare.com)</span><br><span class="line">    #cdn: <span class="comment">//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML</span></span><br><span class="line"></span><br><span class="line">    # See: https:<span class="comment">//mhchem.github.io/MathJax-mhchem/</span></span><br><span class="line">    #mhchem: <span class="comment">//cdn.jsdelivr.net/npm/mathjax-mhchem@3</span></span><br><span class="line">    #mhchem: <span class="comment">//cdnjs.cloudflare.com/ajax/libs/mathjax-mhchem/3.3.0</span></span><br><span class="line"></span><br><span class="line">  # hexo-renderer-markdown-it-plus (<span class="keyword">or</span> hexo-renderer-markdown-it <span class="keyword">with</span> markdown-it-katex plugin) needed <span class="keyword">to</span> full Katex support.</span><br><span class="line">  katex:</span><br><span class="line">    # Use <span class="number">0.7</span>.<span class="number">1</span> <span class="keyword">as</span> <span class="keyword">default</span>, jsdelivr <span class="keyword">as</span> <span class="keyword">default</span> CDN, works everywhere even <span class="keyword">in</span> China</span><br><span class="line">    cdn: <span class="comment">//cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.css</span></span><br><span class="line">    # CDNJS, provided <span class="keyword">by</span> cloudflare, maybe the best CDN, but <span class="keyword">not</span> works <span class="keyword">in</span> China</span><br><span class="line">    #cdn: <span class="comment">//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css</span></span><br><span class="line"></span><br><span class="line">    copy_tex:</span><br><span class="line">      # See: https:<span class="comment">//github.com/KaTeX/KaTeX/tree/master/contrib/copy-tex</span></span><br><span class="line">      enable: <span class="keyword">false</span></span><br><span class="line">      copy_tex_js: <span class="comment">//cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.js</span></span><br><span class="line">      copy_tex_css: <span class="comment">//cdn.jsdelivr.net/npm/katex@0/dist/contrib/copy-tex.min.css</span></span><br></pre></td></tr></table></figure></p></li>
<li>最后一步，修改/themes/next/layout/_layou.swig文件 将如下代码添加到该文件
</body>
<p>标签的上面一行 <figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="params">&lt;script type="text/x-mathjax-config"&gt;</span></span><br><span class="line">MathJax.Hub.Config(&#123;</span><br><span class="line">	<span class="comment">//下面的HTML-CSS和SVG用于在小屏幕上，数学公式可以自动换行，我测试过后发现无效，但是貌似有人可以。</span></span><br><span class="line">	<span class="string">"HTML-CSS"</span>: &#123; </span><br><span class="line"><span class="symbol">		linebreaks:</span> &#123; </span><br><span class="line"><span class="symbol">			automatic:</span> true </span><br><span class="line">		&#125; </span><br><span class="line">	&#125;,SVG: &#123;</span><br><span class="line"><span class="symbol">		linebreaks:</span> &#123; </span><br><span class="line"><span class="symbol">			automatic:</span> true </span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,menuSettings: &#123;</span><br><span class="line"><span class="symbol">		zoom:</span> <span class="string">"None"</span></span><br><span class="line">	&#125;,</span><br><span class="line"><span class="symbol">	showMathMenu:</span> false,</span><br><span class="line"><span class="symbol">	jax:</span> [<span class="string">"input/TeX"</span>,<span class="string">"output/CommonHTML"</span>],</span><br><span class="line"><span class="symbol">	extensions:</span> [<span class="string">"tex2jax.js"</span>],</span><br><span class="line"><span class="symbol">	TeX:</span> &#123;</span><br><span class="line"><span class="symbol">		extensions:</span> [<span class="string">"AMSmath.js"</span>,<span class="string">"AMSsymbols.js"</span>],</span><br><span class="line"><span class="symbol">		equationNumbers:</span> &#123;</span><br><span class="line"><span class="symbol">			autoNumber:</span> <span class="string">"AMS"</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;,tex2jax: &#123;</span><br><span class="line"><span class="symbol">		inlineMath:</span> [[<span class="string">"\\("</span>, <span class="string">"\\)"</span>]],</span><br><span class="line"><span class="symbol">		displayMath:</span> [[<span class="string">"\\["</span>, <span class="string">"\\]"</span>]]</span><br><span class="line">	&#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="params">&lt;/script&gt;</span></span><br><span class="line"><span class="params">&lt;script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/<span class="number">2.7</span><span class="number">.1</span>/MathJax.js?config=TeX-MML-AM_CHTML"&gt;</span><span class="params">&lt;/script&gt;</span></span><br></pre></td></tr></table></figure></p></li>
</ol>
<p>1-3步参考<a href="https://www.jianshu.com/p/523e806d6681" target="_blank" rel="noopener">如何在hexo中支持Mathjax</a> 4步参考<a href="http://npm.taobao.org/package/hexo-renderer-kramed" target="_blank" rel="noopener">hexo-renderer-kramed</a></p>
<ol start="5" type="1">
<li>2020.06.14 更新：注意，NexT v8 声明 hexo-renderer-kramed 已经停止维护，所以可以改用 hexo-renderer-pandoc，具体可以参考官方文档。</li>
</ol>
<h1 id="开启流程图插件">开启流程图插件</h1>
<p>hexo 本身不支持绘制流程图，但是可以使用以下命令安装插件来实现此功能。 <figure class="highlight processing"><table><tr><td class="code"><pre><span class="line">npm install --<span class="built_in">save</span> hexo-<span class="built_in">filter</span>-flowchart</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/bubkoo/hexo-filter-flowchart" target="_blank" rel="noopener">插件地址</a>，语法可以<a href="https://cloud.tencent.com/developer/article/1142260" target="_blank" rel="noopener">在这</a>找到，一个简单的例子： <figure class="highlight coq"><table><tr><td class="code"><pre><span class="line">(\`乘<span class="number">3</span>)flow</span><br><span class="line">st=&gt;start: Start|<span class="type">past</span>:&gt;http://www.google.com[blank]</span><br><span class="line">e=&gt;<span class="keyword">end</span>: <span class="keyword">End</span>:&gt;http://www.google.com</span><br><span class="line">op1=&gt;operation: My Operation|<span class="type">past</span></span><br><span class="line">op2=&gt;operation: Stuff|<span class="type">current</span></span><br><span class="line">sub1=&gt;subroutine: My Subroutine|<span class="type">invalid</span></span><br><span class="line">cond=&gt;condition: Yes</span><br><span class="line">or No?|<span class="type">approved</span>:&gt;http://www.google.com</span><br><span class="line">c2=&gt;condition: Good idea|<span class="type">rejected</span></span><br><span class="line">io=&gt;inputoutput: catch something...|<span class="type">request</span></span><br><span class="line"></span><br><span class="line">st-&gt;op1(<span class="built_in">right</span>)-&gt;cond</span><br><span class="line">cond(yes, <span class="built_in">right</span>)-&gt;c2</span><br><span class="line">cond(no)-&gt;sub1(<span class="built_in">left</span>)-&gt;op1</span><br><span class="line">c2(yes)-&gt;io-&gt;e</span><br><span class="line">c2(no)-&gt;op2-&gt;e</span><br><span class="line">(\`乘<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="开启echarts插件">开启echarts插件</h1>
<p>详见教程<a href="https://kchen.cc/2016/11/05/echarts-in-hexo/" target="_blank" rel="noopener">在 Hexo 中插入 ECharts 动态图表</a> 由于特殊需要，要给 echarts 添加一个 id，所以需要改一下源码。 找到 <code>node_modules/hexo-tag-echarts3/index.js</code>。将 <code>echartsMaps()</code> 函数改为： <figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line">function echartsMaps(<span class="built_in">args</span>, <span class="built_in">content</span>) &#123;</span><br><span class="line">    <span class="built_in">var</span> template = fs.readFileSync(filePath).toString(),</span><br><span class="line">        options = &#123;&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">content</span>.<span class="built_in">length</span>) &#123;</span><br><span class="line">        <span class="built_in">var</span> options = <span class="built_in">content</span>;</span><br><span class="line">    &#125;</span><br><span class="line">	_id = <span class="built_in">args</span>[<span class="number">0</span>] || 'echarts' + ((Math.<span class="built_in">random</span>() * <span class="number">9999</span>) | <span class="number">0</span>)</span><br><span class="line">    <span class="built_in">return</span> <span class="symbol">_</span>.template(template)(&#123;</span><br><span class="line">        id: _id,</span><br><span class="line">        option: options,</span><br><span class="line">        <span class="built_in">height</span>: <span class="built_in">args</span>[<span class="number">1</span>] || <span class="number">400</span>,</span><br><span class="line">        <span class="built_in">width</span>: <span class="built_in">args</span>[<span class="number">2</span>] || '<span class="number">85</span><span class="symbol">%</span>'</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 然后在写代码时，只需要这样 <code>{百分号 echarts id 400 '85%' 百分号}</code> 写就行了。</p>
<h1 id="页面加载速度优化">页面加载速度优化</h1>
<div class="note danger"><p>该插件确实可以增加不少的加载速度，但是问题也挺多。除了以下的一个问题，我还遇到了一个，就是在 next 主题中，左侧的作者信息栏悬浮的位置有问题。</p>
<p>在用了一天之后，还是决定不用它了。</p>
</div>
<p>使用 <a href="https://github.com/next-theme/hexo-optimize" target="_blank" rel="noopener">hexo-optimize</a> 可以极大地提升页面加载速度，但是有个缺点，页面中的 icon 可能会加载失败。</p>
<p>解决办法可以参考 <a href="https://github.com/theme-next/hexo-filter-optimize/issues/2" target="_blank" rel="noopener">github issue</a>。但是总的来说，目前并没有自动化的解决办法。</p>
<p>在使用 hexo g 等操作时，该插件会导致运行异常缓慢。此外，在本地服务器打开时修改博客，博客刷新的速度也会异常缓慢。</p>
<p>解决办法依旧在上面提到的 issue 中有过讨论，后来官方也给出了解决办法：设置 <code>export NODE_ENV=development</code>。</p>
<p>具体来说，在本地调试时，开启 <code>export NODE_ENV=development</code> 从而设置为开发环境，此时 hexo-optimize 将被禁用。注意该 <code>NODE_ENV</code> 是一个临时变量，如果需要部署到云端，只需要将 git 终端关闭，再重新打开即可取消开发环境的设置。</p>
<p>可以使用以下代码测试是否开启开发环境。 <figure class="highlight crmsh"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>. <span class="keyword">node</span> <span class="title"></span></span><br><span class="line"><span class="title">2</span>. console.log(process.env.NODE_ENV)</span><br></pre></td></tr></table></figure></p>
<p>正常情况应该会输出： <figure class="highlight actionscript"><table><tr><td class="code"><pre><span class="line">development</span><br><span class="line"><span class="literal">undefined</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title>hexo博客优化</title>
    <url>/posts/83186147.html</url>
    <content><![CDATA[<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title>hexo博客美化</title>
    <url>/posts/a3e48ca.html</url>
    <content><![CDATA[<h1 id="修改博客透明度">修改博客透明度</h1>
<p>一般来说大家都在博客里放一个背景图片，但是大部分时候博文都是很长的，导致背景图片无法全部地显示出来。所以很有必要为博文设置一个透明度，使得背景图片若隐若现。</p>
<p>在博客根目录的 <code>_data</code> 文件夹中，新建 <code>styles.styl</code> 在其中写入：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 上半部分的侧边栏 */</span></span><br><span class="line"><span class="selector-class">.header-inner</span>&#123;</span><br><span class="line">	<span class="attribute">background</span>: <span class="built_in">rgba</span>(255, 255, 255, 0.82)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/* 下半部分的侧边栏 */</span></span><br><span class="line"><span class="selector-class">.sidebar-inner</span>&#123;</span><br><span class="line">	<span class="attribute">background</span>: <span class="built_in">rgba</span>(255, 255, 255, 0.82)</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.content-wrap</span>&#123;</span><br><span class="line">	<span class="attribute">background</span>: <span class="built_in">rgba</span>(255, 255, 255, 0.779);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你没有下半部分的侧边栏（next 主题好像可以选择关闭），那么可以删除 <code>.sidebar-inner</code>。</p>
<h1 id="樱花特效">樱花特效</h1>
<p>详见 <a href="https://cangshui.net/2372.html" target="_blank" rel="noopener">网页樱花飘落特效（JS 实现）</a></p>
<div class="note danger"><p><strong>注意</strong>：此特效与不蒜子插件在某些特殊情况下存在冲突。目前 Next 支持将自定义的文件提取出来放在 <code>_data</code> 文件夹中。如果把加载樱花特效的 js 代码放在 <code>_data/footer.swig</code> 文件的末尾，则处于页脚部分的不蒜子统计不显示。</p>
<p><strong>解决办法</strong>：那行代码别放在文件的末尾就行了。</p>
</div>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title>Towards Scalable Multi-Domain Conversational Agents: The Schema-Guided Dataset</title>
    <url>/posts/72340bc.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/1909.05855.pdf" target="_blank" rel="noopener">论文地址</a></p>
<p>诸如谷歌助手、Alex 以及 Siri 之类的虚拟助手为横跨多个领域的一系列服务或者 API 提供了一个对话接口。这些系统需要支持越来越多的服务，它们可能具有重叠的功能。而且这些服务中的一部分没有可用的训练数据集。<strong>现在公开的任务导向对话数据集不足以解决以上挑战，这是因为他们只覆盖了少量的领域，并且假定每个领域都有一个固定的本体。</strong></p>
<p>本文提出了 SGD 数据集（16k 条多领对话横跨 16 个领域）。我们的数据集<strong>在规模上超过了现存的所有任务导向对话语料库</strong>，同时也强调了与构建大规模虚拟助手相关的挑战。它为<strong>语言理解、槽填充、对话状态追踪以及回复生成</strong>提供了一个具有挑战的测试平台。</p>
<p>同时，我们<strong>为任务导向对话提出了一个模式引导的范式</strong>。其中，模型在一组<strong>动态的</strong>意图和槽位上进行预测，使用它们的自然语言描述作为输入。这使得单个对话系统可以轻松地支持多种服务，并且有助于不依赖额外的训练数据整合新的服务。</p>
<p>在此范式基础上，我们发布了一个对话状态追踪模型，该模型能够在新的 APIs 上进行 zero-shot 泛化，并且在常规的配置中具有竞争力。</p>
</div>
<h1 id="the-schema-guided-dialogue-dataset">The Schema-Guided Dialogue Dataset</h1>
<p>在训练集、验证集以及测试集中有包含 20 个领域，具体信息罗列在表 2 中。我们在这些领域上创建总计 45 个服务或 api 的综合实现。我们的模拟器框架与这些服务进行交互以此生成对话大纲，它是对话语义的结构化表征。然后我们使用了众包的步骤来解释这些大纲的自然语言语句。我们新颖的众包步骤保留了从模拟器获得的所有标注，并且在对话收集之后不需要任何额外的标注。本节，我们将描述详细的步骤，然后对收集的数据进行分析。 <a id="more"></a></p>
<div class="note info"><p>此节是描述数据收集的步骤，不做翻译。下面做简要的概述。</p>
</div>
<ol type="1">
<li>Services and APIs：定义一个服务的协议（模式）由意图和槽位及其额外约束组成。
<ul>
<li>使用 SQL 引擎实现所有服务。为了反映现实世界中的服务以及 api 中的约束，我们施加了一些限制：
<ol type="1">
<li>不暴露某些槽位的所有候选值，例如日期、时间，将它们定义为<strong>不可分类槽位</strong>。</li>
<li>并且确保验证集中有相当一部分<strong>槽值</strong>不存在于训练集中，以此评估模型处理新槽值的能力。（博主注：这是否意味着不可分类槽位也可以使用分类模型？而不是指针神经网络？因为可分类槽位的槽值都很具体，例如性别只有男女，不需要进行隐藏）</li>
<li>某些槽位被视作<strong>可分类槽位</strong>，例如性别、人数、一周的天数。</li>
</ol></li>
<li><strong>服务调用限制</strong>：现实世界中用户只能调用有限的槽位组合，例如在“预定酒店”这项服务中，用户不被允许使用日期搜索酒店，他最少提供一个酒店的地址。然而现存的数据集允许使用任意组合的槽位调用服务，从而产生实际服务或者 api 不支持的流程。</li>
</ul></li>
<li>Dialogue Simulator Framework：生成对话大纲</li>
<li>Dialogue Paraphrasing：对话翻译</li>
</ol>
<h2 id="数据集分析">数据集分析</h2>
<h1 id="the-schema-guided-approach">The Schema-Guided Approach</h1>
<p>虚拟助理旨在支持网络上的大量服务。一个可行的方式是为助理定义一个巨大的统一模式，使得可以集成不同的服务供应商。<strong>然而，很难提出一个覆盖所有案例的通用模式。</strong>拥有一个通用的模式也会使开发人员集成有限服务变得复杂。<strong>我们建议使用模式引导的方法作为一种替代方案，以便新服务和 api 的集成。</strong></p>
<p>在我们提出的方法中，每一项服务都提供了一种模式，其中罗列了支持的槽位和意图，以及它们的自然语言描述（图 1 展示了一个例子）。这些描述被用于获取模式中元素的语义表征。基于这些模式元素，助理使用一个统一的模型进行预测，其中不包含特定领域或者服务的参数。</p>
<p>使用单个模型有助于在有关联的服务之间获得更好的表征以及传递公共知识。<strong>这是因为模型使用模式元素的语义表征作为输入</strong>，它可以与未经训练的未知服务或者 api 之间建立连接。同时它也能灵活地适应诸如新增意图或者槽位之类的更改。</p>
<h1 id="zero-shot-dialogue-state-tracking">Zero-shot Dialogue State Tracking</h1>
<p>我们为 zero-shot schema-guided DST 提出一个基于模式以及预训练模型的简易原型模型。</p>
<h2 id="model">Model</h2>
<p>我们使用一个模型在所有的服务以及领域中执行预测。我们首先将所有的语句、槽位以及可分类槽位的槽值（模式中所呈现的）编码为嵌入表征。由于不同的模式有不同数量的槽位和意图，所以使用模式元素的嵌入进行预测。这与现存的模型相比有所不同，它们在一个固定的模式上进行预测，并且无法跨领域进行知识共享。它们也无法适应模式的改变，需要使用新的标注数据进行重新训练。</p>
<ol type="1">
<li><strong>Schema Embedding</strong> 这个组件用于获取每个服务模式中意图、槽位、可分类槽位的槽值的表征。表 3 展示了用于嵌入的每个元素的序列对。这些序列对被输入进 BERT 中，然后输出值 <span class="math inline">\(u_{CLS}\)</span> 被用作模式的嵌入，如图 6 所示。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/SGD模式嵌入序列对.jpg" alt="SGD模式嵌入序列对" /> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/BERT%20encoder编码SGD序列对.png" alt="BERT encoder编码SGD序列对" /></li>
<li><strong>Utterance Encoding</strong> 与 Chao and Lane (2019)（BERT-DST） 类似，我们使用 BERT 编码用户的语句以及前一条系统语句，以此获得语句对的嵌入表征 <span class="math inline">\(u=u_{CLS}\)</span> 以及字符级的表征 <span class="math inline">\(t_1, t_2, \cdots, t_M\)</span>，其中 <span class="math inline">\(M\)</span> 代表两句的字符总数。通过使用一组投影（projection），语句以及模式的嵌入均被用于进行模型预测。</li>
<li><strong>Projection</strong> 令 <span class="math inline">\(x, y \in \mathbb{R}^d\)</span>。对于任务 <span class="math inline">\(K\)</span>，定义 <span class="math inline">\(l = \mathcal{F}_K(x,y,p)\)</span> 作为将 <span class="math inline">\(x,y\)</span> 转换为 <span class="math inline">\(l \in \mathbb{R}^p\)</span> 的映射，公式如下所示。其中 <span class="math inline">\(h_1, h_2 \in \mathbb{R}^d\)</span>，<span class="math inline">\(W^K_i\)</span> 和 <span class="math inline">\(b^K_i\)</span> 是可训练的参数。<span class="math inline">\(A\)</span> 是激活函数。我们参考 BERT，使用 <code>gelu</code> 函数。 <span class="math display">\[
\begin{align}
 h_1 &amp; = A(W^K_1 x + b^K_1) \\
 h_2 &amp; = A(W^K_2 (y \oplus h_1) + b^K_2) \\
 l &amp; = W^K_3 h_2 + b^K_3 \\
\end{align}
\]</span></li>
<li><strong>Active Intent</strong> 对于一个给定的服务，active intent 代表用户请求以及系统正在实现的意图。如果服务当前没有在处理意图，那么为值为 <code>NONE</code>。令 <span class="math inline">\(i_0 \in \mathbb{R}^d\)</span> 为“NONE”意图的可训练参数。我们定义意图网络为： <span class="math display">\[
l^j_{int} = \mathcal{F}_{int}(u, i_j, 1), \quad 0 \le j \le I
\]</span> 使用一个 softmax 将 <span class="math inline">\(l^j_{int}\)</span> 归一化为在所有 <span class="math inline">\(I\)</span> 个意图以及“NONE”意图上的概率分布。<strong>在推理阶段，我们预测最大概率的意图是 active intent。</strong></li>
<li><strong>Requested Slots</strong> 对于有些槽位，用户会在当前语句中请求它们的槽值。映射函数 <span class="math inline">\(\mathcal{F}_{req}\)</span> 预测第 <span class="math inline">\(j^{th}\)</span> 个槽位的 <span class="math inline">\(l^j_{req}\)</span>，它被 sigmoid 归一化到 <span class="math inline">\([0,1]\)</span> 之间。在推理阶段，所有分数 <span class="math inline">\(&gt; 0.5\)</span> 的槽位被预测为 requested： <span class="math display">\[
l^j_{req} = \mathcal{F}_{req}(u, s_j, 1), \quad 1 \le j \le S
\]</span></li>
<li><strong>User Goals</strong> 我们将用户目标定义为<strong>对话上下文中的用户约束，上下文中包含从第一轮到当前轮为止的语句</strong>。与在每轮用户语句之后预测全部的用户目标不同，我们预测当前轮和前一轮用户目标的差集。在推理阶段，对预测出的结果更新至用户目标中，以生成最新的用户目标。 我们将预测步骤分为两步：首先对于每个槽位，使用 softmax 归一化得到一个大小为 3 的分布，其代表槽位的状态，分别为 <span class="math inline">\(none, dontcare, active\)</span>。<span class="math inline">\(none\)</span> 代表值不改变，<span class="math inline">\(dontcare\)</span> 代表槽位填入特殊值 <span class="math inline">\(dontcare\)</span>，<span class="math inline">\(active\)</span> 代表进入第二步。 在第二步中，公式 7 计算可分类槽位的槽值。对于不可分类的槽位，使用公式 8 和 9 生成跨度（span）。 <span class="math display">\[
\begin{align}
l^j_{status} &amp; = \mathcal{F}_{status}(u, s_j, 3), \quad 1 \le j \le S &amp; \tag{6} \\
l^{j,k}_{value} &amp; = \mathcal{F}_{value}(u, v^k_j, 1), \quad 1 \le j \le V^k, 1 \le k \le C &amp; \tag{7} \\
l^{j,k}_{start} &amp; = \mathcal{F}_{start}(t_k, s^n_j, 1), \quad 1 \le j \le N, 1 \le k \le M &amp; \tag{8} \\
l^{j,k}_{end} &amp; = \mathcal{F}_{end}(t_k, s^n_j, 1), \quad 1 \le j \le N, 1 \le k \le M &amp; \tag{9} \\
\end{align}
\]</span></li>
</ol>
<h2 id="evaluation">Evaluation</h2>
<ol type="1">
<li>Active Intent Accuracy</li>
<li>Requested Slot F1</li>
<li>Average Goal Accuracy</li>
<li>Joint Goal Accuracy</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>TOD-BERT: Pre-trained Natural Language Understanding for Task-Oriented Dialogue</title>
    <url>/posts/ceeb7bcc.html</url>
    <content><![CDATA[<div class="note primary"><p>本文总结：</p>
<ol type="1">
<li>观点：通用的预训练模型对任务导向的对话任务没什么帮助，故研发了 TOD-BERT</li>
<li>选择与 BERT 类似的架构预训练 TOD-BERT，即 BERT-base uncased model（12L 12A 768H）</li>
<li>在 byte-pair embeddings 加入了两个特殊符号：<span class="math inline">\([USR], [SYS]\)</span></li>
<li>使用 MLM loss 和 RCL 两个函数训练模型
<ul>
<li>MLM 与 BERT 略有不同，TOD-BERT 会在训练时动态执行掩盖、替换。其他详见下面的章节</li>
<li>RCL 是一个新颖的做法，详见具体章节</li>
</ul></li>
</ol>
</div>
<div class="note info"><p>通用文本和任务导向对话之间语言模式的根本差异，导致了现存的预训练语言模型实际上没什么用。本文为语言模型统一了九种人人交互以及多轮的任务导向对话数据集。</p>
<p>为了在预训练阶段更好地对对话行为进行建模，我们在 MLM（Masked Language Modeling）中引入了“用户”和“系统”符号。</p>
</div>
<a id="more"></a>
<h1 id="预训练所使用的数据集以及建模方法">预训练所使用的数据集以及建模方法</h1>
<p>本文的目的是证明以下的假设：对于任务导向的下游任务而言，使用<strong>任务导向语料预训练得到的自监督语言模型</strong>可以比<strong>现存的预训练模型</strong>学到更好的表征。并且需要强调的是：我们最关心的不是 1）我们的预训练模型能否在每个下游任务上得到 SOTA 结果，这是因为目前最好的模型都是建立在预训练模型上（博主注：这些模型可能借助了预训练模型的威力）。2）我们的模型能否简单地替代它们。</p>
<p>我们收集并整合了九种人人交互以及多轮的任务导向对话语料，以此训练任务导向对话 BERT（Task-oriented Dialog BERT，TOD-BERT）。</p>
<p>与 BERT 类似的是：我们将 TOD-BERT 定义为 MLM 并且使用 deep bidirectional Transformer 编码器。与 BERT 不同的是：TOD-BERT 为用户和系统引入了两个特殊符号，以此对对应的对话行为建模。在预训练阶段，结合回复选择任务中的 contrastive objective function 捕获回复的相似性。</p>
<p>九种语料分别为： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/模型/TOD-BERT九种语料.png" alt="TOD-BERT九种语料" /></p>
<h1 id="tod-bert">TOD-BERT</h1>
<p>我们基于 BERT 的架构使用两种损失函数训练 TOD-BERT，分别为：掩码语言模型（Masked Language Model，MLM）loss 和回复对比损失（response contrastive loss，RCL）。值得注意的是，我们所使用的数据集也可以预训练其他任意的预训练模型结构。<strong>而我们选择 BERT 是因为，它是近年来在 NLP 研究中被广泛使用的模型。</strong>我们使用了 BERT-base uncased model，拥有 12 层和 12 个注意力头架构，以及 768 个隐藏状态。</p>
<p>为了捕获发言者的信息以及语句中潜在的交互行为，我们在 byte-pair embeddings<span class="citation" data-cites="mrkvsic2016neural">(Mrkšić et al. 2016)</span>中增加了两个特殊符号：<span class="math inline">\([USR], [SYS]\)</span>。我们将二者加在每一句话的前面，然后将所有语句拼接成一句话。</p>
<p>例如有 <span class="math inline">\(D=\{S_1, U_1, \cdots, S_N, U_N\}\)</span>，那么输入就可以被处理为“<span class="math inline">\([SYS] S_1 [USR] U_1 \cdots\)</span>”。</p>
<h2 id="mlm">MLM</h2>
<p>MLM 是类 BERT 架构的通用预训练策略，它随机采样输入序列，并将被选择到的字符替换为特殊符号 <span class="math inline">\([MASK]\)</span>。MLM loss 函数是预测被掩盖符号的交叉熵函数。在原始的实现中，随机掩盖以及替换只在开始被执行一次，并在训练期间一直保持。<strong>然而，我们在进行批训练时动态地执行符号掩盖</strong>。<strong>TOD-BERT 直接被 BERT（一组不错的初始参数）初始化</strong>，然后进一步地在那些任务导向语料上进行微调。MLM loss 函数为：</p>
<p><span class="math display">\[
L_{mlm} = - \sum^M_{m=1} \log P(x_m)
\]</span></p>
<p>其中 M 是被掩盖字符的数量。<span class="math inline">\(P(x_m)\)</span> 是符号 <span class="math inline">\(x_m\)</span> 在整个词表大小上被预测出的概率。</p>
<h2 id="response-contrastive-loss">Response contrastive loss</h2>
<p>RCL 可以被用于对话语言建模上，这是因为它不需要任何额外的人工标注。使用 RCL 预训练有一系列的优势：1）可以学到 <span class="math inline">\([CLS]\)</span> 更好的表征；2）鼓励模型捕捉潜在的对话顺序、结构信息以及回复相似度。</p>
<p>与原本的 NSP 优化目标不同，我们应用了 dual-encoder 方法并且模拟了多重负采样。</p>
<ol type="1">
<li>首先，取出一个批次的对话 <span class="math inline">\({D_1, \cdots, D_b}\)</span>，然后随机选择第 t 轮切分对话。例如，<span class="math inline">\(D_1\)</span> 可以被切为两部分，上下文 <span class="math inline">\(\{S^1_1, U^1_1, \cdots, S^1_t, U^1_t\}\)</span> 和回复 <span class="math inline">\(\{S^1_{t+1}\}\)</span>。最后使用 TOD-BERT 编码所有语句。</li>
<li>得到上下文矩阵 <span class="math inline">\(C \in \mathbb{R}^{b \times d_B}\)</span> 以及回复矩阵 <span class="math inline">\(R \in \mathbb{R}^{d \times d_B}\)</span>（回复矩阵来自 <span class="math inline">\([CLS]\)</span>）。我们将来自同一批次的其他回复视作被随机选择的负样本。那么 RCL 目标函数为： <span class="math display">\[
\begin{align}
 L_{rcl} &amp; = - \sum^b_{i=1} log M_{i,i} \\
 M &amp; = Softmax(CR^T) \in \mathbb{R}^{b \times b} 
\end{align}
\]</span></li>
<li>增加批次大小到一个量级，会在下游任务上获得更好的性能，尤其是对于回复选择。批次大小是一个超参数，由于可能会受限于硬件，我们还尝试了其他采样策略，但是没有看到明显的提升。</li>
</ol>
<h2 id="总览">总览</h2>
<p>预训练损失函数是 <span class="math inline">\(L_{mlm}\)</span> 和 <span class="math inline">\(L_{rcl}\)</span> 的加权和，在我们的试验里，只是简单地相加。</p>
<p>我们没有使用 warm-up 直接逐渐减少学习率。</p>
<p>我们使用 AdamW 并且在所有层以及注意力的权重上加上 0.1 dropout。</p>
<p>使用了 GELU。</p>
<h1 id="下游任务">下游任务</h1>
<p>在本文中，我们关心的是与 BERT 相比，使用 TOD-BERT 是否能够展示出任意的优势。所以在下游任务上微调时，我们避免在结构的顶层加上过多的额外组件。并且为了公平起见，我们使用同样的结构以及类似的参数量。</p>
<p>我们选择了几项重要的任务导向下游任务用于评估，分别为：intent recognition, dialogue state tracking, dialogue act prediction, and response selection。</p>
<div class="note info"><p>以下只介绍对话状态追踪</p>
</div>
<h2 id="dialogue-state-tracking">Dialogue state tracking</h2>
<div class="note "><p>此节不做翻译，以下为博主的理解。</p>
<p>TOD-BERT 所使用的对话状态追踪算法应该属于 NBT 那类，让第 <span class="math inline">\(j\)</span> 个槽位的所有槽值与用户语句进行一一判别，以此判断该槽位的槽值有没有被用户提及。他们没有用到近几年提出的 span 方法。</p>
<p>那么生成第 <span class="math inline">\(j\)</span> 个槽位的第 <span class="math inline">\(i\)</span> 个槽值的概率的公式为：</p>
<p><span class="math display">\[
S^j_i = Sim(G_j(F(X)), F(v^j_i)) \in \mathbb{R}^1
\]</span></p>
<p>其中 <span class="math inline">\(Sim\)</span> 代表余弦相似度函数，<span class="math inline">\(G_j\)</span> 代表第 <span class="math inline">\(j\)</span> 个槽位的映射函数，<span class="math inline">\(F\)</span> 代表预训练模型，<span class="math inline">\(v^j_i\)</span> 代表第 <span class="math inline">\(j\)</span> 个槽位的第 <span class="math inline">\(i\)</span> 个槽值。此外，使用 <span class="math inline">\([CLS]\)</span> 的表征作为函数 <span class="math inline">\(F\)</span> 的输出。</p>
</div>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-mrkvsic2016neural">
<p>Mrkšić, Nikola, Diarmuid O Séaghdha, Tsung-Hsien Wen, Blaise Thomson, and Steve Young. 2016. “Neural Belief Tracker: Data-Driven Dialogue State Tracking.” <em>arXiv Preprint arXiv:1606.03777</em>.</p>
</div>
</div>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>pre-trained model</tag>
      </tags>
  </entry>
  <entry>
    <title>DST论文笔记（2020—至今）</title>
    <url>/posts/5286f9c6.html</url>
    <content><![CDATA[<h1 id="multi-domain-dialogue-state-tracking-based-on-state-graph">Multi-Domain Dialogue State Tracking based on State Graph</h1>
<div class="tabs" id="graph-dst"><ul class="nav-tabs"><li class="tab active"><a href="#graph-dst-1">总结</a></li><li class="tab"><a href="#graph-dst-2">论文笔记</a></li></ul><div class="tab-content"><div class="tab-pane active" id="graph-dst-1"><div class="note primary">
<ol type="1">
<li>
现有工作的缺陷：1）以往的工作只是简单地将前一轮的对话状态和当前语句拼接起来，然后使用 self-attention 建立它们之间的关联。但是 attention 机制也许会关注到一些不合理（spurious）的连接，导致进行错误的推理。2）CSFN-DST 与该文工作类似，但是它只考虑了一个边（edge）类型以及三个节点类型——领域（domain）、槽位（slot）、域槽对（domain, slot）。
</li>
<li>
研究目的：处理对话状态中元素的共现信息以及人类对话中过渡联系（transition relation）。<em>作者没细说过渡是什么意思，我认为是在对话过程中不同领域之间的切换。</em>
</li>
<li>
研究目标/贡献：1）提出 dialog state graph；2）处理多关系图中有许多相异槽值的问题。
</li>
<li>
研究方法：1）图中领域和槽值相连，边为槽位。此外如果两个领域同时出现在对话状态中，则创建一条共现边（co-occurrence edge）以此连接二者。2）使用 relational-GCN 编码对话状态图。3）图中几乎所有槽值用“placeholder”填充。
</li>
<li>
<strong>总结</strong>：<strong>1）</strong>CSFN-DST 只是构建了普通的边，其代表领域和槽位之间的关联，而 Grapha-DST 的边特指槽位。<strong>2）</strong>经过消融实验验证了，状态图确实可以为基于 self-attention 的隐式图（implicit graph）提供补充信息。<strong>3）</strong>该文的做法比之 CSFN-DST 确实要先进不少，从表面上看二者是在做相同的工作，但是我认为实际上 CSFN-DST 编码的是协议图，而 Graph-DST 编码的是图结构的对话状态。<strong>4）</strong><em>这样构建图，是否做了太多的约束？导致数据处理困难？</em>
</li>
</ol>
<p>
<strong>模型架构</strong> 将 Transformer 最后几层的 Block 改为 graph-enhanced Transformer（该文实验中为最后一层）。其运算流程为（如图右侧所示）：将前一层的输出作为当前层 multi-head self-attention 的输入进而得到上下文输出，此时使用捕获的 [SLOT] 特征填充槽值，然后使用 relational-GCN 更新节点表征，并且将更新后的表征与 [slot] 融合，最后再继续执行 Transformer block 的其余流程。通过上述算法将 relational-GCN 融入 Transformer 中。<strong>需要注意的是，输入中也包含了对话状态，它们以串联的形式连接，其主要实现对话状态和当前语句的交互，而对话状态图主要捕获模式之间的联系。</strong>二者的作用不同。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/Graph-DST.png" alt="Graph-DST" />
</p>
</div></div><div class="tab-pane" id="graph-dst-2"><div class="note info">
<p>
经过对 DST 中 open-vocabulary 分类的调研，发现现存的方法通常将前一轮的对话状态和对话历史拼接在一起，然后将其作为 BiTransformer 的输入。模型依靠 Transformer 的 self-attention 机制将对话状态和语句中的符号连接起来。但是 <strong>attention 机制也许会关注到一些不合理的连接，导致后续错误的推理</strong>。
</p>
<p>
<strong>本文提出构造一个对话状态图（dialog state graph）</strong>，其中，来自上一轮对话状态中的领域（domain）、槽位（slot）以及槽值（value）被恰当地连接起来。如图 1 所示。使用 relational-GCN（关系图卷积网络）对其编码，它被融合进 Transformer 中。
</p>
</div>
<p>可以将基于双向 self-attention 的方法视为图神经网络，其输入为每个字符都相连的图，无论它们在对话历史还是对话状态中，都可以通过 attention 被连接。<strong>这种图结构对 DST 很有帮助</strong>。例如，给定酒店“名称”和出租车“出发地”的图，attention 可以建立它们之间的关联，这意味着我们可以推断出出租车的出发地和酒店名称相同。<strong>然而 Transformer 所使用的图通常拥有大量节点，attention 可能会连接两个与对话无关的节点，从而导致错误推理</strong>。</p>
<p>图需要同时表现对话历史中的关键实体和强连接（strong connection）。强连接不仅依赖于对话历史，还需要引导对话。例如，用户预订火车的时候，通常还会预订酒店，前者通常自然地会影响后者（自然过渡，natural transition）。因此应该在图中创建强连接。<strong><font color='red'>这种自然过渡在以往的研究常常被忽略</font></strong>。</p>
<p>在构建图时，除了必要的节点（node）和边（edge），还创建了一种特殊的边。如果有两个领域同时出现在对话状态中，则创建一种共现边（co-occurrence edge）以此连接二者。</p>
<p>为了有效地利用该图，需要解决以下两个问题：</p>
<ol type="1">
<li>为了聚合多关系图的节点信息，使用了 relational-GCN。</li>
<li>对于将所有槽值表现在图中，是不切实际的（因为太多且有些没有被预定义）。为此，图中的槽值节点均被定义为一个占位符，并且不为它们创建嵌入，而是使用对应 Transformer 的隐藏状态输出，即 <span class="math inline">\([SLOT]\)</span> 位置。最终，将这种基于图的推理与常用的 Transformer encoder 融合了起来。</li>
</ol>
<p><strong>以下将首先定义模型的形式表示，然后介绍对话状态图的结构，最后描述如何将对话状态图融入 Transformer。</strong></p>
<h2 id="method">Method</h2>
<p>定义一场 <span class="math inline">\(T\)</span> 轮的对话为 <span class="math inline">\(\{(D_1 S_1), \cdots, (D_T, S_T)\}\)</span>，其中 <span class="math inline">\(D_t\)</span> 代表第 <span class="math inline">\(t\)</span> 轮的系统语句和用户语句，<span class="math inline">\(S_t\)</span> 代表当前轮的对话状态。定义 <span class="math inline">\(S_t\)</span> 为 <span class="math inline">\((d_j, s_j, v_j)|1 \le j \le J\)</span>，其中 <span class="math inline">\(J\)</span> 为域槽对的总量，也就是说 <span class="math inline">\(S_t\)</span> 记录的是所有域槽对。如果域槽对的槽值为空，则 <span class="math inline">\(v_j\)</span> 为 <span class="math inline">\(NULL\)</span>。</p>
<p>DST 的目标是给定 <span class="math inline">\(\{(D_1 S_1), \cdots, (D_{t-1}, S_{t-1}), (D_t)\}\)</span>，预测 <span class="math inline">\(S_t\)</span>。该文采用 SOM-DST 的思想，只输入 <span class="math inline">\(D_{t-1}, D_T, S_{T-1}\)</span>。由于该文只是关注状态图的利用，所以模型也采用 SOM-DST 的结构。下面先介绍一下 SOM-DST 的框架。</p>
<h3 id="对话状态图的结构">对话状态图的结构</h3>
<p><strong>给定 <span class="math inline">\(S_{t-1} = \{(d_j, s_j, v_j)|1 \le j \le J\}\)</span>，对于每个 <span class="math inline">\((d_j, s_j, v_j)\)</span>，使得领域节点 <span class="math inline">\(d_j\)</span> 和槽值节点 <span class="math inline">\(v_j\)</span>（placeholder）以槽位边（slot edge）相连</strong>。其中槽位边是单向的，共现边是双向的。<strong>每个领域节点以及槽位边都有它们对应的嵌入</strong>。</p>
<p>以往的工作通常假设域槽对之间是无关的。该文则编码 domain-domain，slot-slot，domain-slot 的共现关系，这可能对 DST 有所帮助。此外，由于在 MultiWOZ 中存在过多的槽值（4500），因此该文假定它们没有被预定义，图中每个槽值节点几乎都是“placeholder”占位符。它不属于图节点嵌入，这些位置将会被动态地填入对应的 self-attention 输出，即 <span class="math inline">\([SLOT]\)</span> 位置。</p>
<h3 id="graph-enhanced-transformer">Graph-enhanced Transformer</h3>
<ol type="1">
<li><mark class="label success">multi-head attn</mark> 如图 2 右侧所示，第 <span class="math inline">\(l-1\)</span> 层的输出 <span class="math inline">\(H^{t-1}=[h^{l-1}_{cls}, \cdots, h^{l-1}_{sl_J}, \cdots]\)</span> 被输入进 multi-head self-attention layer，那么上下文表征 <span class="math inline">\(C^l=[c^l_{cls}, \cdots, c^l_{sl_J}, \cdots]\)</span> 可以由以下公式计算得到： <span class="math display">\[
\begin{align}
C^l &amp; = Concat(head_1, \cdots, head_h) \\
head_j &amp; = softmax(\frac{Q_j K^T_j}{\sqrt{d_k}}) V_j
\end{align}
\]</span></li>
<li><mark class="label warning">relational-GCN</mark> 将得到的 <span class="math inline">\([SLOT]\)</span> 表征填充各槽值（而不是原有位置槽值的表征），其余节点用词向量初始化。（<em>个人觉得有点奇怪，直接填入 placeholder 的表征不就行了？</em>）接下来，使用relational-GCN 更新节点表征。例如，对于一个领域节点 <span class="math inline">\(d\)</span>： <span class="math display">\[g^l_d = f(W_S(e_d - e_S) + \sum_{(v, sl) \in N(d)} W_O(c^l_v - e_{sl}) + \sum_{d&#39; \in N(d)} (W_I + W_O)(e_{d&#39;} - e_{co}))
\]</span></li>
<li>fusion</li>
</ol></div></div></div>
<a id="more"></a>
<h1 id="dialogue-state-tracking-with-explicit-slot-connection-modeling">Dialogue State Tracking with Explicit Slot Connection Modeling</h1>
<div class="tabs" id="dst-sc"><ul class="nav-tabs"><li class="tab active"><a href="#dst-sc-1">总结</a></li><li class="tab"><a href="#dst-sc-2">论文笔记</a></li></ul><div class="tab-content"><div class="tab-pane active" id="dst-sc-1"><div class="note primary">
<ol type="1">
<li>
现有工作的缺陷：
</li>
<li>
研究目的：
</li>
<li>
研究目标/贡献：-
</li>
<li>
研究方法：
</li>
<li>
<strong>总结</strong>：
</li>
</ol>
<p>
<strong>模型结构</strong> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/DST-SC模型架构.png" alt="DST-SC模型架构" />
</p>
</div></div><div class="tab-pane" id="dst-sc-2"><div class="note info">
<p>
在多领域场景下，用户经常通过省略（ellipsis）、指代（reference）来表达某些其它领域槽位提到的槽值。为了解决这种现象，我们提出了 DST-SC（Dialogue State Tracking with Slot Connections）模型。
</p>
</div>
<div class="note">
<p>
以下为博主的思考，并非翻译、阅读笔记。这是因为这篇论文的思想与 TripPy 类似，而在之前我已经阅读过 TripPy 的论文。
</p>
</div>
<p>仔细看了一下之后发现与 TripPy 所提出机制的一部分很像，都是为了处理省略、共指而生的。区别是 DST-SC 使用的 encoder-decoder 模型，它在生成槽值时，始终使用 soft-gated copy mechanism。</p>
<p>具体来说，在解码时，使用一个门控 <span class="math inline">\(g_1\)</span> 合并了对话历史的概率分布和词表概率分布，得到了 <span class="math inline">\(P_{gen}\)</span> 概率分布。其次使用另一个门控 <span class="math inline">\(g_2\)</span> 合并了 <span class="math inline">\(P_{gen}\)</span> 和 <span class="math inline">\(P_{vc}\)</span>，得到了最终的概率分布 <span class="math inline">\(P\)</span>。使用该概率分布即可解码得到当前时间步的单词。其中概率分布 <span class="math inline">\(P_{vc}\)</span> 是从上一轮的对话状态中计算得到的。</p>
<p>总的来说，他们延续了 TRADE 的做法，在此基础上，又额外加了一层 soft-gated copy mechanism。</p>
<p>不过我个人不怎么喜欢这种 encoder-decoder 的做法。在我的实验中，我还是使用了 TripPy 的做法。</p></div></div></div>
<h1 id="credit-coarse-to-fine-sequence-generation-for-dialogue-state-tracking">CREDIT: Coarse-to-Fine Sequence Generation for Dialogue State Tracking</h1>
<div class="note info"><p>提出了 CoaRsE-to-fine DIalogue state Tracking(CREDIT) 模型。以前的方法通常将对话状态定义为独立的三元组 <span class="math inline">\((domain, slot, value)\)</span>，而本文将 DST 转化为序列生成问题。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/CREDIT模型架构.png" alt="CREDIT模型架构" /></p>
</div>
<h1 id="efficient-context-and-schema-fusion-networks-for-multi-domain-dialogue-state-tracking">Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue State Tracking</h1>
<div class="tabs" id="csfn-dst"><ul class="nav-tabs"><li class="tab active"><a href="#csfn-dst-1">总结</a></li><li class="tab"><a href="#csfn-dst-2">论文笔记</a></li></ul><div class="tab-content"><div class="tab-pane active" id="csfn-dst-1"><div class="note primary">
<ol type="1">
<li>
现有工作的缺陷：由于<strong>域槽对数量</strong>以及<strong>对话长度</strong>的增加，数据稀疏性（data sparsity）的问题成了多领域 DST 的主要障碍。
</li>
<li>
研究目的：1）缓解数据稀疏性的问题；2）考虑不同域槽对之间的关联（<em>算是对 schema 进行了初步的编码</em>）。
</li>
<li>
研究目标/贡献：1）使用前一轮对话状态表示对话历史；2）提出模式图，并对其编码。
</li>
<li>
研究方法：1）提出了 Schema Graph 并实现了一个基本模型 context and schema fusion networks (CSFN-DST)，其主要修改了 Transformer 的 Multi-head Attention 机制。具体只是使用一个邻接矩阵实现。
</li>
<li>
<strong>总结</strong>：<strong>1）</strong>可以将 CSFN-DST 视为一种全新的域槽对表示方式，不过我觉得这好像没有利用到知识图谱的优势。此外虽然作者列出了 Graph Neural Network 的相关工作，但是并没有使用 GNN 去提取特征。<strong>2）</strong>虽然最后他们讨论了在输入中是否需要更多上下文信息的问题，但是他们在消融实验中只是额外加入上一轮的对话语句。个人认为这个实验不足以证明论文中提到的观点，即只使用当前轮的系统语句、用户语句和上一轮的对话状态是有效的。这是因为上下文信息太少了，起码再多加几轮，然后做一个对比。<strong>3）该文作者与我的想法类似，也认为 dontcare 这个槽位是比较有挑战的子任务。</strong>
</li>
</ol>
<p>
<strong>模型结构</strong> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/CSFN-DST模型架构.png" alt="CSFN-DST模型架构" />
</p>
</div></div><div class="tab-pane" id="csfn-dst-2"><div class="note info">
<p>
在多领域 DST 中，由于候选状态数量以及对话长度的增加，数据稀疏性的问题成了一个主要的障碍。为了高效地编码对话上下文，我们使用了前一轮<font style="color:red"><strong>预测出的</strong></font>对话状态以及当前轮的对话语句作为 DST 的输入。（博主注：数据的稀疏性指的是候选状态过多但是大部分是无意义的；对话长度增加但是大部分语句也是无意义的。为了处理这一问题，该文打算使用上一轮的对话状态近似对话上下文）
</p>
<p>
此外为了考虑不同域槽对之间的关联，还开发了包含先验知识的协议图（schema graph）。
</p>
<p>
本文提出了一个新颖的上下文与协议融合的网络（context and schema fusion network）。
</p>
</div>
<p>CSFN-DST 使用系统回复 <span class="math inline">\(A_t\)</span>，用户语句 <span class="math inline">\(U_t\)</span> 以及前一轮的对话状态 <span class="math inline">\(B_{t-1}\)</span> 作为模型的输入。<strong>在训练阶段，直接使用真实值 <span class="math inline">\(B_{t-1}\)</span>，但是在推理阶段，使用预测出的对话状态。</strong></p>
<p><strong>Schema Graph</strong>：为了将不同域槽对之间的联系考虑进去，并且将它们作为一种额外的输入以此引导上下文编码，我们将它们表示为 schema graph（协议图谱） <span class="math inline">\(G=(V, E)\)</span>，<span class="math inline">\(V\)</span> 代表结点（node），<span class="math inline">\(E\)</span> 代表边（edge）。如下图所示。协议图中一共有领域、槽位以及域槽对三种结点，以及在不同结点之间的四种类型无向边。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/CSFN-DST协议图.png" alt="CSFN-DST协议图" /></p>
<h2 id="输入嵌入">输入嵌入</h2>
<p><strong>Dialogue Utterance</strong> <span class="math inline">\(X = [CLS] \oplus A_t \oplus ; \oplus U_t \oplus [SEP]\)</span>，输入嵌入由词向量，片段嵌入（segment embedding）以及位置嵌入组成。</p>
<p><strong>Previous Dialogue State</strong> 用上一轮的对话状态来表示历史对话，表示为 <span class="math inline">\(B_{t-1} = [CLS] \oplus R^1_{t-1} \oplus \cdots \oplus R^K_{t-1}\)</span>，其中 <span class="math inline">\(K\)</span> 为 <span class="math inline">\(B_{t-1}\)</span> 中的三元组数量。每个三元组都被表示为一个序列，即 <span class="math inline">\(R = d \oplus - \oplus s \oplus - \oplus v\)</span>。其中，所有的符号都会被表示为单词，例如 pricereange -&gt; price range，dontcare -&gt; dont care。</p>
<p><strong>Schema Graph</strong> 所有的节点按如下形式排列：<span class="math inline">\(G = d_1 \oplus \cdots \oplus d_M \oplus s_1 \oplus \cdots \oplus s_N \oplus o_1 \oplus \cdots \oplus o_J\)</span>。每一个节点嵌入都由对应的 domain/slot/domain-slot 词向量初始化，图谱中的位置编码被省略。图谱中的边被表示为邻接矩阵 <span class="math inline">\(A^G\)</span>，其中要么为 1 要么为 0。为了强调不同类型节点的边在计算时是不一样的，我们利用节点类型得到了片段嵌入。</p>
<h2 id="context-and-schema-fusion-network">Context and Schema Fusion Network</h2>
<p><strong>Graph-based Multi-head Attention</strong> 对 Transformer 进行了改造。在执行 Multi-head Attention 时，额外使用邻接矩阵 <span class="math inline">\(A^G \in \mathbb{R}^{|Y| \times |Z|}\)</span> 作为 mask。</p>
<p><strong>Context- and Schema-Aware Encoding</strong> CSFN 与 Transformer 类似，也是由多层的神经网络组成的，每层的输出都是下一层的输入。具体可以公式化为：</p>
<p><span class="math display">\[
\begin{align}
    I_{GG} &amp; = GraphMultiHead_{\Theta_{GG}}(H^G_i, H^G_i, A^G) \\
    E_{GX} &amp; = MultiHead_{\Theta_{GX}}(H^G_i, H^{X_t}_i) \\
    E_{GB} &amp; = MultiHead_{\Theta_{GB}}(H^G_i, H^{B_{t-1}}_i) \\
    C_G &amp; = LayerNorm(H^G_i + I_{GG} + E_{GX} + E_{GB}) \\
    H^G_{i+1} &amp; = LayerNorm(C_G + FFN(C_G))
\end{align}
\]</span></p>
<p>其中 <span class="math inline">\(FFN\)</span> 代表两层全连接层以及在它们之间的一个 ReLU 激活函数。即 <span class="math inline">\(FFN(x) = max(0, xW_1 + b_1)W_2 + b_2\)</span>。</p>
<p>类似地，可以计算出 <span class="math inline">\(H^{X_t}_i, H^{B_{t-1}}_i\)</span>。不过有一点需要注意，Graph-based Multi-head Attention 并不是总是会被使用，详见原论文的 Appendix A。</p>
<h2 id="state-prediction">State Prediction</h2>
<p>与 TRADE 一样，将槽位类型分类 <span class="math inline">\(\{none, dontcare, ptr\}\)</span>。其中由于协议图中包含了域槽对，所以只需要在 CSFN 中取出所有域槽对的表征即可，进一步预测槽位的类别，即模型架构图中的深蓝色部分。</p>
<p>如果槽位类型为 <span class="math inline">\(ptr\)</span> 则使用 soft-based copy mechanism 生成槽值。</p>
<h2 id="使用bert">使用BERT</h2>
<p>如果使用 BERT 初始化词向量以及 CSFN 的所有参数，会提升大约 2 个百分点。</p>
<h2 id="结果分析">结果分析</h2>
<p>5.5.1 节中讨论了是否需要更多的上下文，并且做了实验。在额外增加上一轮的语句 <span class="math inline">\(X_{t-1}\)</span> 之后，得到了略差的准确率，所以得出结论：只编码当前的语句以及上一轮的对话状态会更高效。</p></div></div></div>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>SDT</tag>
      </tags>
  </entry>
  <entry>
    <title>强化学习入门（整理）</title>
    <url>/posts/25dd0342.html</url>
    <content><![CDATA[<div class="note info"><p>由于本人发现，相较于机器学习或者深度学习来说，在国内几乎找不到多少关于强化学习或者深度强化学习的资料，也没有太多学习路线的帖子，所以这里记录一下我的入门经历。</p>
<p>另外，由于本人并不是主修强化学习，我只是遇到了需要使用强化学习的场景（对话系统）。目前我只需要尽可能地实现那个模块即可，所以我也只是选取了 Q-learning 作为我的工具。所以本篇到目前为止（2020.09.27）只涉及 Q-learning 的入门，包括 Deep Q Network。</p>
</div>
<div class="note warning"><p>本人是零基础入门，在学习 Q-learning 之前，只知道什么是马尔可夫假设，不知道马尔科夫决策过程。所以以下的资料应该对初学者很友好。</p>
</div>
<h1 id="入门资料">入门资料</h1>
<div class="note info"><p>莫烦的教程中有几个小型试验可以拿来做一下，Q-learning 就差不多算入门了。然后他的视频还继续介绍了 DQN，可以算做一个基础的视频。到此为止算是基本上对 Q-learning 有了一定的了解。</p>
<p>注意，对于 1. Q-learning 所提供的资料来说，我反复地按 123 的顺序观看了三四遍，最后才勉强看懂。</p>
</div>
<ol type="1">
<li>Q-learning
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/27711452" target="_blank" rel="noopener">来！让我们一步步走进 Q-learning</a>：这个教程从零开始讲解 Q-learning，但是在讲到 1/4 时（大致在《迭代求解 V 函数和 Q 函数》一节之后），感觉很乱，所以推荐看一下前 1/3 部分，有助于对 Q-learning 建立一个大致的印象。</li>
<li><a href="https://www.bilibili.com/video/BV13W411Y75P?p=14" target="_blank" rel="noopener">强化学习 Reinforcement Learning (莫烦 Python 教程)</a>：莫烦的 RL 教程，我只看了其中的 Q-lerning 教程。这是从两个实例出发的，有助于进一步建立一个直观的印象，一个对应用的印象。</li>
<li><a href="https://blog.csdn.net/itplus/article/details/9361915" target="_blank" rel="noopener">A Painless Q-learning Tutorial (一个 Q-learning 算法的简明教程)</a>：一个 Q-learning 的简单教程，其中进行了简单的数值计算，有助于了解 Q-lerning 在运算时，究竟是怎么样的过程。我认为里面的算法有点问题，但是不妨碍它是一个好教程。</li>
</ol></li>
<li>DQN
<ol type="1">
<li><a href="https://www.bilibili.com/video/BV13W411Y75P?p=14" target="_blank" rel="noopener">强化学习 Reinforcement Learning (莫烦 Python 教程)</a>：继续看完 DQN 部分。 <a id="more"></a></li>
</ol></li>
</ol>
<h1 id="强化资料">强化资料</h1>
<ol type="1">
<li>DQN
<ol type="1">
<li></li>
</ol></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>rl</category>
      </categories>
  </entry>
  <entry>
    <title>任务完成型对话系统论文调研（二）</title>
    <url>/posts/4ec51203.html</url>
    <content><![CDATA[<div class="note info"><p>本文续<a href="https://yan624.github.io/posts/e0902c9c.html">任务完成型对话系统论文调研（一）</a>。</p>
</div>
<h1 id="引言">引言</h1>
<p>任务完成型对话系统中的挑战比起之前已经有所改变。在 <span class="citation" data-cites="xu-hu-2018-end">(Xu and Hu 2018)</span> 提出使用 Ptr 缓解低频槽值提取的问题之后，两年之内涌现了许多有突破性的论文。<strong>变化的槽值</strong>已经不再是难点。 <a id="more"></a></p>
<h1 id="dst">DST</h1>
<p>本文结构与上一篇不同。删除了《独立模型与联合模型》。删除了《难点/未来的工作》一节，这是因为其中大部分难点都或多或少得到了缓解，本文将其替换为了《各项难点的处理方式》。增加了《前情提要》一节，回顾了 2020 年之前 DST 模型的做法。增加了《DSTC》一节，介绍对话状态跟踪挑战（Dialog State Tracking Challenge，DSTC）。其余章节不做变化。</p>
<table>
<thead>
<tr class="header">
<th>模型</th>
<th>槽值生成方法</th>
<th>槽位门控</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Graph-DST<span class="citation" data-cites="zeng2020multi">(Zeng and Nie 2020)</span></td>
<td><mark class="label success">generative</mark></td>
<td><mark class="label info">soft-gated copy</mark></td>
</tr>
<tr class="even">
<td>DST-SC<span class="citation" data-cites="ouyang-etal-2020-dialogue">(Ouyang et al. 2020)</span></td>
<td><mark class="label success">generative</mark></td>
<td><mark class="label info">soft-gated copy</mark></td>
</tr>
<tr class="odd">
<td>CSFN-DST<span class="citation" data-cites="zhu2020efficient">(Zhu et al. 2020)</span></td>
<td><mark class="label success">generative</mark></td>
<td><mark class="label info">soft-gated copy</mark></td>
</tr>
</tbody>
</table>
<div class="tabs" id="dst论文对比"><ul class="nav-tabs"><li class="tab active"><a href="#dst论文对比-1">论文介绍</a></li><li class="tab"><a href="#dst论文对比-2">论文瑕瑜</a></li></ul><div class="tab-content"><div class="tab-pane active" id="dst论文对比-1"><table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>论文</th>
<th>标签</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><a href="https://arxiv.org/abs/2010.11137" target="_blank" rel="noopener" title="20.10">Graph-DST</a></strong></td>
<td><mark class="label primary"><strong>Transformer</strong></mark> <mark class="label primary"><strong>relational-GCN</strong></mark><br />
<mark class="label success">Zeng et al., 2020</mark> <mark class="label primary">dialog state graph</mark> <mark class="label success">graph-enhanced Transformer</mark></td>
</tr>
<tr class="even">
<td><strong><a href="https://www.aclweb.org/anthology/2020.acl-main.5/" target="_blank" rel="noopener" title="20.07">DST-SC</a></strong></td>
<td><mark class="label primary"><strong>BiGRU</strong></mark><br />
<mark class="label success">Ouyang et al., 2020</mark> <mark class="label info">slot connection mechanism</mark></td>
</tr>
<tr class="odd">
<td><strong><a href="https://arxiv.org/abs/2004.03386" target="_blank" rel="noopener" title="20.04">CSFN-DST</a></strong></td>
<td><mark class="label primary"><strong>CSFN</strong></mark> <mark class="label primary"><strong>BERT</strong></mark><br />
<mark class="label success">Zhu et al., 2020</mark> <mark class="label primary">Schema Grapha</mark> <mark class="label info">Graph-based Multi-head Attention</mark></td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="dst论文对比-2"><table>
<thead>
<tr class="header">
<th style="text-align: center;">论文</th>
<th>优化的方向</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Ouyang et al., 2020</td>
<td>1）共指解析</td>
<td></td>
</tr>
<tr class="even">
<td style="text-align: center;">Zhu et al. 2020</td>
<td>1）提出了 Schema Graph；</td>
<td></td>
</tr>
</tbody>
</table></div></div></div>
<h2 id="前情提要">前情提要</h2>
<div class="note "><p>本节回顾一下 2020 年之前 DST 的做法。</p>
</div>
<p>我暂时没有阅读过远古时代如何构建 DST 模型的论文，所以对那时的做法不做分析或评价。但是据我所知，在以前都需要一个人工构建的同义词表，以此替换用户语句中的一些同义词。例如“center”和“centre”都是“中心”的意思，但是由于它们是不同单词，所以一般都需要使用同义词表对用户的输入进行预处理。然而这种构建同义词表的做法显然费时费力。</p>
<h3 id="同义词表以及误差传递的问题">同义词表以及误差传递的问题</h3>
<p>在描述如何解决标题中的难点之前，首先需要介绍另一个要点。TODS 一般由六部分组成，每一部分的输入分别是其前一部分的输出，这就导致了一个严重的问题——层级误差传递。由于神经网络或者其他的技术都无法做到百分之百的准确率，所以每一个模块的误差会被一次一次地放大。</p>
<p>为解决这一问题，<span class="citation" data-cites="henderson2014word">(Henderson, Thomson, and Young 2014)</span> <strong>舍弃了 SLU 模块</strong>，直接使用 ASR 识别出的结果作为 RNN 的输入，注意那时他们并没有使用词向量。并且，他们沿用了他们同年发表的论文中的方法——delexicalised features。简单来说就是将“槽”和“值”替换为一种标签，例如“i want chinese food”-&gt;“i want <code>&lt;value&gt;</code> <code>&lt;slot&gt;</code>”。这样做虽然可以提高模型的泛化性，但是还是需要一个人工构建的同义词表。<mark class="label default">联合模型</mark></p>
<p>2013 年下半年词向量横空出世。此后，DST 领域也开始<strong>借助词向量的优势</strong>。<span class="citation" data-cites="zilka2015incremental">(Zilka and Jurcicek 2015)</span> 额外使用了 ASR 输出的置信度分数，具体来说就是将置信度分数乘上词向量从而得到一个全新的词向量，并将其作为模型的输入（具体做法还可以改进，文中只说了将分数和词向量结合），从而作为 LSTM 的输入。然后在<strong>每一个时间步</strong>上都接 N 个线性分类层，用于在所有候选槽值上进行分类，N 代表槽位的数量。<em>博主注：说实话这中分类方式挺诡异的，因为每个时间步都要执行一次分类。但是不管怎么样，这种方式借助词向量的优势已经不需要同义词表了。</em> <mark class="label info">不再需要使用同义词表</mark></p>
<h3 id="判别式dst">判别式DST</h3>
<p>此后，<span class="citation" data-cites="mrkvsic2016neural">(Mrkšić et al. 2016)</span> 提出了 neural belief tracker（NBT），也使用了词向量，不过他们使用的词向量是自己训练的。此外最重要的是他们提出了判别式 DST，即<strong>使用槽值对的表征去与用户语句做判别，以此判断该槽值对是否被用户提及</strong>，如果是则更新对话状态，反之亦反。<strong>但是这显然包含着重大的隐患，就是有些槽值对是不可枚举的，这该如何去匹配？</strong>所以之后的模型大都在围绕两点：1）槽值不可枚举怎么办？2）有未知的槽值怎么办？<mark class="label info">判别式 DST</mark></p>
<p><span class="citation" data-cites="rastogi2017scalable">(Rastogi, Hakkani-Tür, and Heck 2017)</span> 提出了一个多领域 DST 模型，但是它是一个独立模型，这是因为它需要 SLU 模块帮助其实现 delexicalisation。<strong>他们将槽值候选集加了一项限定，即每一个槽值都会有一项分数，通过分数的排名，将候选集限定在一定的范围内，实验中选择 7 最为最大值。</strong>候选集的生成方式有多种，文中使用了外部的知识源而不是本体（因为本体通常很难构建以及访问。而知识源则很简答，可能还描述了其他方式去构建，但是时间太久了，有点忘了）。<mark class="label warning">有限候选集</mark> <mark class="label success">多领域 DST</mark></p>
<p><span class="citation" data-cites="zhong2018global">(Zhong, Xiong, and Socher 2018)</span> 使用 global-locally 自注意力机制改进了对低频槽值对的追踪。</p>
<p>另外有一个插曲是在 2015-2017 年之间，有人提出了 Pointer Network（Ptr-Nets），并且后续有许多研究人员对其进一步完善。<span class="citation" data-cites="xu-hu-2018-end">(Xu and Hu 2018)</span> 首次在 DST 中引入了 index-based Ptr，此后几乎所有的模型都是用了该方式。<mark class="label success">span-based</mark></p>
<h3 id="slot-gate和多领域dst">Slot Gate和多领域DST</h3>
<p>在之前其实已经有了多领域 DST，不过他们都是在不同的数据集之间进行实验。直到 <span class="citation" data-cites="budzianowski2018multiwoz">(Budzianowski et al. 2018)</span> 发布了 MultiWOZ 多领域任务完成型对话数据集，才涌现了一大批相对正常的多领域 DST 模型。有一点需要强调，由于已经步入多领域 DST 的时代，所以使用槽值对 <span class="math inline">\(&lt;slot, value&gt;\)</span> 的形式显然已经不具有足够的能力表示对话状态，在此之后大都使用三元组 <span class="math inline">\(&lt;domain, slot, value&gt;\)</span> 的形式来表示，而槽位一般也写作 <code>doamin-slot</code>，可以读作“域槽对”。</p>
<div class="note warning"><p>注意，NBT 是使用<strong>槽值对</strong>去与用户语句判别从而实现二元分类。而 TRADE 是使用<strong>域槽对</strong>去与用户语句做判别，从而实现三元分类得到槽位的类别，然后依靠槽位的类别再进一步去生成槽值。</p>
</div>
<p><span class="citation" data-cites="wu2019transferable">(Wu et al. 2019)</span> 提出了 TRADE 模型，沿用了 Ptr 神经网络，此外还使用 zero-shot 的训练方式使模型有能力处理未知领域中的槽位。他们将槽位分为 <span class="math inline">\(\{none, dontcare, ptr\}\)</span> 三种。<code>none</code> 代表当前所判别的槽位不包含槽值，槽值就是 <code>none</code>；<code>dontcare</code> 代表用户不关心当前所判别的槽位的具体槽值是什么，槽值就是 <code>dontcare</code>；<code>ptr</code> 代表模型需要再额外使用一个 ptr 神经网络来从用户语句中直接提取槽值。具体做法是，模型使用域槽对去和用户语句做判别，得到槽位的类别，然后根据槽位的类别进一步得到槽值。<em>博主注：这样的做法实际上会造成误差的层级传播，后面会说到。</em><mark class="label info">slot gate</mark></p>
<p><span class="citation" data-cites="zhang2019find">(Zhang et al. 2019)</span> 将槽位分为 <em>{none, dontcare, picklist-based, span-based}</em>，其中前两个和最后一个与 TRADE 中的定义一一对应。他们认为有些槽位是没必要使用 ptr 从用户语句中提取的，例如对于槽位“hotel-pricerange”，只有三个槽值 <em>{cheap, moderate, expensive}</em>。<span class="citation" data-cites="heck2020trippy">(Heck et al. 2020)</span> 将槽位分为 <em>{none, dontcare, span-based, bool-based, refer, inform}</em>。</p>
<h2 id="各项难点的处理方式">各项难点的处理方式</h2>
<ol type="1">
<li>未知的槽位：任务导向对话模式、zero-shot learning</li>
<li>未知以及不可枚举的槽值：span-based</li>
<li>未知的意图：任务导向对话模式</li>
<li>变化的系统动作：目前不知</li>
<li>数据稀缺：MultiWOZ，TaskMaster，CrossWOZ，SGD</li>
<li>计算复杂度：目前不知</li>
</ol>
<h2 id="dstc">DSTC</h2>
<p>本节介绍 DSTC1-DSTC8 数据集。</p>
<h2 id="相关工作">相关工作</h2>
<p>详见 <a href="https://yan624.github.io/posts/5286f9c6.html">DST论文笔记（2020—至今）</a>。</p>
<ol type="1">
<li><span class="citation" data-cites="zhu2020efficient">(Zhu et al. 2020)</span> 提出了 CSFN-DST（Context and Schema Fusion Network）。主要思想是将冗长的上下文改为：当前系统回复 <span class="math inline">\(A_t\)</span>，用户输入 <span class="math inline">\(U_t\)</span> 以及上一轮的对话状态 <span class="math inline">\(B_{t-1}\)</span>。作者将上一轮的对话状态视为对话历史的抽象表征，在训练时使用真实的对话状态，<font color="red"><strong>在推理阶段使用预测出的对话状态</strong></font>。此外，还将领域 <span class="math inline">\(D\)</span>，槽位 <span class="math inline">\(S\)</span> 以及域槽对 <span class="math inline">\(O\)</span> 表示图结构，并称之为协议图（schema graph）或者模式图。使用了 Graph-based Multi-head Attention 编码该协议图，实际上只是比普通的 Multi-head Attn 多了一个 mask 而已。<a class="btn" href="https://yan624.github.io/posts/5286f9c6.html#efficient-context-and-schema-fusion-networks-for-multi-domain-dialogue-state-tracking" title="Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue State Tracking"><i class="fa fa-"></i>论文笔记</a></li>
<li><span class="citation" data-cites="ouyang-etal-2020-dialogue">(Ouyang et al. 2020)</span>提出了 slot connection mechanism 用于处理省略、共指的难题，思想与 TripPy 类似，但是做法不同。具体不做阐述了。<a class="btn" href="https://yan624.github.io/posts/5286f9c6.html#dialogue-state-tracking-with-explicit-slot-connection-modeling" title="Dialogue State Tracking with Explicit Slot Connection Modeling"><i class="fa fa-"></i>论文笔记</a></li>
<li><span class="citation" data-cites="zeng2020multi">(Zeng and Nie 2020)</span> 认为以往的工作只是简单地将前一轮的对话状态和当前语句拼接起来，然后使用 self-attention 建立它们之间的关联。但是 attention 机制也许会关注到一些不合理（spurious）的连接，从而导致进行错误的推理。该文提出对话状态图（dialog state graph），以此处理对话状态中元素的共现信息以及过渡联系。使用 relational-GCN 对该图编码，然后将其融入 Transformer。<a class="btn" href="https://yan624.github.io/posts/5286f9c6.html#multi-domain-dialogue-state-tracking-based-on-state-graph" title="Multi-Domain Dialogue State Tracking based on State Graph"><i class="fa fa-"></i>论文笔记</a></li>
</ol>
<h1 id="dpl">DPL</h1>
<p>待续。</p>
<h1 id="结果对比">结果对比</h1>
<div id="dst-multiwoz2.1" style="width: 100%;height: 350px;margin: 0 auto"></div>
<script src="https://cdn.bootcdn.net/ajax/libs/echarts/5.0.0-alpha.2/echarts.common.min.js"></script>
<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('dst-multiwoz2.1'));
        // 指定图表的配置项和数据
        var option = {
	title: {text: 'MultiWOZ 2.1 结果对比'},
	tooltip: {trigger: 'axis', axisPointer: {type: 'shadow'}},
	legend: {
		type: 'scroll',
		data: ['CSFN-DST', 'DST-SC', 'Graph-DST'],
		top: 25,
	},
	toolbox: {
		orient: 'vertical',
		left: 'right',
		top: 'center',
		feature: {
			dataView: {show: true},
			magicType: {show: true, type: ['bar', 'tiled']},
			restore: {show: true},
			saveAsImage: {show: true, pixelRatio: 2}
		}
	},
    xAxis: {type: 'category', name: '--年份-->', data: ['Joint Goal Accuracy']},
    yAxis: {
		type: 'value',
		min: function (value) {
			_min = value.min - 20;
			if(_min < 0) return 0;
			else return Math.floor(_min);
		},
		max: 100
	},
    series: [
		{name: 'CSFN-DST', type: 'bar', data: [50.81],},
		{ 
            name: 'CSFN-DST',
            type: 'bar',
            data: [52.88],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'+BERT', offset: [0, 10]}
			}
		},
		{name: 'DST-SC', type: 'bar', data: [49.58],},
		{name: 'Graph-DST', type: 'bar', data: [54.85],},
	]
};
        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>
<script>
window.onload = function () {
    $('colgroup').remove()
    }
</script>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-budzianowski2018multiwoz">
<p>Budzianowski, Pawel, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić. 2018. “Multiwoz-a Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling.” <em>arXiv Preprint arXiv:1810.00278</em>.</p>
</div>
<div id="ref-heck2020trippy">
<p>Heck, Michael, Carel van Niekerk, Nurul Lubis, Christian Geishauser, Hsien-Chin Lin, Marco Moresi, and Milica Gašić. 2020. “TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking.”</p>
</div>
<div id="ref-henderson2014word">
<p>Henderson, Matthew, Blaise Thomson, and Steve Young. 2014. “Word-Based Dialog State Tracking with Recurrent Neural Networks.” In <em>Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (Sigdial)</em>, 292–99.</p>
</div>
<div id="ref-mrkvsic2016neural">
<p>Mrkšić, Nikola, Diarmuid O Séaghdha, Tsung-Hsien Wen, Blaise Thomson, and Steve Young. 2016. “Neural Belief Tracker: Data-Driven Dialogue State Tracking.” <em>arXiv Preprint arXiv:1606.03777</em>.</p>
</div>
<div id="ref-ouyang-etal-2020-dialogue">
<p>Ouyang, Yawen, Moxin Chen, Xinyu Dai, Yinggong Zhao, Shujian Huang, and Jiajun Chen. 2020. “Dialogue State Tracking with Explicit Slot Connection Modeling.” In <em>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, 34–40. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2020.acl-main.5" target="_blank" rel="noopener" class="uri">https://doi.org/10.18653/v1/2020.acl-main.5</a>.</p>
</div>
<div id="ref-rastogi2017scalable">
<p>Rastogi, Abhinav, Dilek Hakkani-Tür, and Larry Heck. 2017. “Scalable Multi-Domain Dialogue State Tracking.” In <em>2017 Ieee Automatic Speech Recognition and Understanding Workshop (Asru)</em>, 561–68. IEEE.</p>
</div>
<div id="ref-wu2019transferable">
<p>Wu, Chien-Sheng, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, and Pascale Fung. 2019. “Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems.” <em>arXiv Preprint arXiv:1905.08743</em>.</p>
</div>
<div id="ref-xu-hu-2018-end">
<p>Xu, Puyang, and Qi Hu. 2018. “An End-to-End Approach for Handling Unknown Slot Values in Dialogue State Tracking.” In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 1448–57. Melbourne, Australia: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P18-1134" target="_blank" rel="noopener" class="uri">https://doi.org/10.18653/v1/P18-1134</a>.</p>
</div>
<div id="ref-zeng2020multi">
<p>Zeng, Yan, and Jian-Yun Nie. 2020. “Multi-Domain Dialogue State Tracking Based on State Graph.” <em>arXiv Preprint arXiv:2010.11137</em>.</p>
</div>
<div id="ref-zhang2019find">
<p>Zhang, Jian-Guo, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S Yu, Richard Socher, and Caiming Xiong. 2019. “Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking.” <em>arXiv Preprint arXiv:1910.03544</em>.</p>
</div>
<div id="ref-zhong2018global">
<p>Zhong, Victor, Caiming Xiong, and Richard Socher. 2018. “Global-Locally Self-Attentive Dialogue State Tracker.” <em>arXiv Preprint arXiv:1805.09655</em>.</p>
</div>
<div id="ref-zhu2020efficient">
<p>Zhu, Su, Jieyu Li, Lu Chen, and Kai Yu. 2020. “Efficient Context and Schema Fusion Networks for Multi-Domain Dialogue State Tracking.” <em>arXiv Preprint arXiv:2004.03386</em>.</p>
</div>
<div id="ref-zilka2015incremental">
<p>Zilka, Lukas, and Filip Jurcicek. 2015. “Incremental Lstm-Based Dialog State Tracker.” In <em>2015 Ieee Workshop on Automatic Speech Recognition and Understanding (Asru)</em>, 757–62. IEEE.</p>
</div>
</div>
]]></content>
      <categories>
        <category>AI</category>
        <category>nlp</category>
      </categories>
  </entry>
  <entry>
    <title>Self-paced Curriculum Learning</title>
    <url>/posts/5bd6d30b.html</url>
    <content><![CDATA[<h1 id="总结">总结</h1>
<div class="note warning"><p>这篇论文太难懂了，可能是由于数学太差了，我一直无法理解 <span class="math inline">\(\lim_{\lambda \to 0} v^*_i = 1, \lim_{\lambda \to \infty} v^*_i = 0\)</span> 这个约束在代码里应该怎么实现，此外对于 <span class="math inline">\(v\)</span> 向量应该也是要约束在 <span class="math inline">\([0, 1]\)</span>，但是这在代码里应该怎么实现？这个向量应该会随着模型更新的，它完全有可能被更新成小于 0，或者大于 1。</p>
<p>暂且不跟进这篇论文了。</p>
</div>
<h1 id="前置背景">前置背景</h1>
<div class="note warning"><p>该论文对 curriculum learning 和 self-paced learning 做了的一点介绍，如果读者对这两个学习制度不了解，可以有选择地读一下这两个的介绍，否则应该看不懂论文中提出的算法。</p>
</div>
<p>课程式学习（Curriculum learning，CL）或者自步学习（self-paced learning，SPL）都是最近（一个 2009，一个 2010）被提出的学习制度（learning regime），灵感来源于人类和动物的学习过程，即从简单逐渐到更复杂的策略。其中，二者具有相似的学习范式，但是有着不同的学习计划。<mark class="label info">Abs</mark></p>
<p>在 CL 中，课程是由先验知识决定的，并且之后保持不变。因此其高度依赖先验知识的依赖，而忽略了对学习者的反馈（博主注：说白了就是课程由教务组制定，之后的课程保持不变，学生学习的好坏取决于教务组的能力。教务组对应于人类标注者（annotator），学生对应于模型）。在 SPL 中，课程式动态决定的，以适应学习者的学习节奏。<mark class="label info">Abstract</mark> <mark class="label info">Intro</mark> <mark class="label primary">CL 和 SPL 主要的差异在于课程的定义不同</mark></p>
<p>课程（curriculum）决定了一系列的训练样本，基本上对应着一群以学习难度升序排序的样本。</p>
<p>CL 的<strong>优点</strong>是整合不同来源的先验知识的灵活性，<strong>缺点</strong>是课程的设计已经被决定，于后续的学习无关。SPL <strong>受限于</strong>没有将先验知识整合进训练过程，导致它易于过拟合。由于它们各自都有优点，实际上很难判断谁更好。<mark class="label info">Introduction</mark></p>
<p>这些学习范式已经从经验上被证明有助于避免不良的局部极小值，并取得更好的泛化结果。（作者贴了三篇论文）<mark class="label info">Introduction</mark></p>
<p>确实。一条样本如果要简单，那么它的优化过程可能相对来说要简单。那么再优化难的样本可能就只需要花更少的时间。<mark class="label default">博主瞎猜</mark></p>
<p>关于 CL 和 SPL 具体的算法实现，可以阅读对应的论文，此处不再深入。 <a id="more"></a></p>
<h1 id="研究目标">研究目标</h1>
<h2 id="具体问题陈述">具体问题陈述</h2>
<p>作者认为 SPL 无法处理先验知识，容易造成过拟合。论文中，作者发现了 CL 和 SPL 之间缺少的连接，并且提出了一个统一的自步课程学习（self-pace curriculum learning，SPCL）框架。SPCL 是一个简明的优化问题，它既考虑了训练前的先验知识，又考虑了训练中的学习进度。与人类教育相比，SPCL 类似于“师生协作”模式，而不是 CL 的“教师驱动”或者 SPL 的“学生驱动”。<mark class="label info">Abstract</mark> <mark class="label info">Intro</mark></p>
<h2 id="解决的问题">解决的问题</h2>
<p>解决 CL 以及 SPL 的缺点。在一个统一健全的框架中，一个合理的学习范式应该同时考虑先验知识和在训练时学习到的信息。<mark class="label info">Model and Algorithm</mark></p>
<h1 id="spcl">SPCL</h1>
<h2 id="spl">SPL</h2>
<p>SPL 的优化对象： <span class="math display">\[\min_{w, v \in [0, 1]^n} \mathbb{E}(w, v, \lambda) = \sum^n_{i=1} v_i L(y_i, f(x_i, w)) - \lambda \sum^n_{i=1} v_i \tag{1}
\]</span></p>
<h2 id="模型和算法">模型和算法</h2>
<p>与 CL 类似，作者假设给定一个由权威根据先验知识定义的课程。我们可以得到以下的公式，该公式可以是同时实现 CL 和 SPL 的要求：</p>
<p><span class="math display">\[\min_{w, v \in [0, 1]^n} \mathbb{E}(w, v, \lambda, \Psi) = \sum^n_{i=1} v_i L(y_i, g(x_i, w)) + f(v; \lambda) \quad s.t. \, v \in \Psi \tag{3}
\]</span></p>
<p>其中 <span class="math inline">\(v = [v_1, v_2, \cdots, v_n]^T\)</span> 代表样本重要性的权重变量。<span class="math inline">\(f\)</span> 被称为自步函数，它控制学习计划。<span class="math inline">\(\Psi\)</span> 是一个可行的区域（博主注：这种说法比较模糊，详见《定义二：课程区域》），编码了一个预定义的课程信息。<span class="math inline">\(L\)</span> 就是指损失函数。那么一个课程在数学上可以被定义为以下几种类别。</p>
<h3 id="定义一全序课程">定义一：全序课程</h3>
<div class="note info"><p>全序课程（Total order curriculum）意味着课程表中的所有课程都呈全序状态。以下为两个名词解释，具体可以百度，此外对于名词“全序”貌似是一个数学上的定义。</p>
<ul>
<li>课程：即一个样本</li>
<li>全序：即在一个序列中，所有样本呈全序状态。而偏序指的是在一个序列中，所有样本大致呈一定的顺序。</li>
</ul>
</div>
<p>对于一个训练样本 <span class="math inline">\(X = \{x_i\}^n_{i=1}\)</span>，即一个全序课程，可以被表示为一个排序函数： <span class="math display">\[\gamma: X \to {1, 2, \cdots, n}
\]</span></p>
<p>其中 <span class="math inline">\(\gamma(x_i) &lt; \gamma(x_j)\)</span> 代表在训练时 <span class="math inline">\(x_i\)</span> 应该比 <span class="math inline">\(x_j\)</span> 更早得被学习。<span class="math inline">\(\gamma(x_i) = \gamma(x_j)\)</span> 代表对于这两个样本没有特殊的先后关系。</p>
<h3 id="定义二课程区域">定义二：课程区域</h3>
<p>基于样本 <span class="math inline">\(X = \{x_i\}^n_{i=1}\)</span>，给定一个预定义的课程 <span class="math inline">\(\gamma(\cdot)\)</span> 以及它们对应的权重变量 <span class="math inline">\(v = [v_1, \cdots, v_n]^T\)</span>。<span class="math inline">\(\Psi\)</span> 被称为课程 <span class="math inline">\(\gamma\)</span> 可行的区域，当：</p>
<ol type="1">
<li><span class="math inline">\(\Psi\)</span> 是一个非空凸集；</li>
<li>对于每一个样本对 <span class="math inline">\(x_i, x_j\)</span>，倘若 <span class="math inline">\(\gamma(x_i) &lt; \gamma(x_j)\)</span>，则 <span class="math inline">\(\lmoustache_{\Psi} v_i dv &gt; \lmoustache_{\Psi} v_j dv\)</span>。其中 <span class="math inline">\(\lmoustache_{\Psi} v_i dv\)</span> 计算 <span class="math inline">\(\Psi\)</span> 内 <span class="math inline">\(v_i\)</span> 的期望值。类似地，如果 <span class="math inline">\(\gamma(x_i) = \gamma(x_j)\)</span>，则 <span class="math inline">\(\lmoustache_{\Psi} v_i dv = \lmoustache_{\Psi} v_j dv\)</span>。</li>
</ol>
<h3 id="定义三自步函数">定义三：自步函数</h3>
<p>自步函数决定了一个学习协议。对于每一个训练样本及其对应的损失值 <span class="math inline">\(\mathcal{l} = [\mathcal{l}_1, \cdots, \mathcal{l}_n]^T\)</span>，假设 <span class="math inline">\(v = [v_1, \cdots, v_n]^T\)</span> 代表权重参数向量。<span class="math inline">\(\lambda\)</span> 控制学习进度（或者模型的“年龄”）。满足以下条件，则 <span class="math inline">\(f(v; \lambda)\)</span> 被称为自步函数：</p>
<ol type="1">
<li>当 <span class="math inline">\(v \in [0, 1]^n\)</span>， <span class="math inline">\(f(v; \lambda)\)</span> 是凸的。</li>
<li><span class="math inline">\(\lim_{\lambda \to 0} v^*_i = 1, \lim_{\lambda \to \infty} v^*_i = 0\)</span></li>
<li><span class="math inline">\(||v||_1 = \sum^n_{i=1} v_i\)</span> 相对于 <span class="math inline">\(\lambda\)</span> 增加，那么 <span class="math inline">\(\forall i \in [1, n], \, \lim_{\lambda \to 0} v^*_1 = 0, \, \lim_{\lambda \to \infty} v^*_i = 0\)</span></li>
</ol>
<p>其中 <span class="math inline">\(v^* = \arg\min_{v \in [0,1]^n} \sum v_i \mathcal{l}_i + f(v; \lambda)\)</span></p>
<h1 id="评估">评估</h1>
<h1 id="结论">结论</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>self-paced learning</tag>
        <tag>curriculum learning</tag>
      </tags>
  </entry>
  <entry>
    <title>RuntimeError: CUDA error: n illegal memory access was encountered</title>
    <url>/posts/87554a0.html</url>
    <content><![CDATA[<p>在 GPU 上训练时，报了这个错。目前为止，始终无法解决。看起来像是数据量大小引起的，之前用小数据训练没问题，改用大数据之后就报错了。但是根据查到的资料，别人在其他的情况下也有这问题。 <figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="string">RuntimeError:</span> <span class="string">transform:</span> failed to <span class="string">synchronize:</span> <span class="string">cudaErrorIllegalAddress:</span> an illegal memory access was encountered</span><br></pre></td></tr></table></figure></p>
<p>后来在网上看到了别人的讨论，有人运行了以下代码：</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="attr">CUDA_LAUNCH_BLOCKING</span>=<span class="number">1</span> python train.py</span><br></pre></td></tr></table></figure>
<p>我试了一下，然而，过了几个 epoch 之后，又报错了。不过加了 <code>CUDA_LAUNCH_BLOCKING=1</code> 之后，报的错更详细了，为： <a id="more"></a> <figure class="highlight x86asm"><table><tr><td class="code"><pre><span class="line">Traceback (most recent calls WITHOUT Sacred internals):</span><br><span class="line">  File <span class="string">"train.py"</span>, line <span class="number">98</span>, <span class="keyword">in</span> run</span><br><span class="line">    model(data_loader)</span><br><span class="line">  File <span class="string">"/home/zcy/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py"</span>, line <span class="number">550</span>, <span class="keyword">in</span> __call__</span><br><span class="line">    result = self.forward(*input, **kwargs)</span><br><span class="line">  File <span class="string">"/home/zcy/python_workspace/DSTex/model.py"</span>, line <span class="number">117</span>, <span class="keyword">in</span> forward</span><br><span class="line">    self.train_epoch(pbar_train, cur_epoch, train_batch_num, train_statistics_every)</span><br><span class="line">  File <span class="string">"/home/zcy/python_workspace/DSTex/model.py"</span>, line <span class="number">162</span>, <span class="keyword">in</span> train_epoch</span><br><span class="line">    train_perf = self.train_batch(train_data, cur_epoch)</span><br><span class="line">  File <span class="string">"/home/zcy/python_workspace/DSTex/model.py"</span>, line <span class="number">215</span>, <span class="keyword">in</span> train_batch</span><br><span class="line">    loss.backward()</span><br><span class="line">  File <span class="string">"/home/zcy/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/tensor.py"</span>, line <span class="number">198</span>, <span class="keyword">in</span> backward</span><br><span class="line">    torch.autograd.backward(self, gradient, retain_graph, create_graph)</span><br><span class="line">  File <span class="string">"/home/zcy/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/autograd/__init__.py"</span>, line <span class="number">100</span>, <span class="keyword">in</span> backward</span><br><span class="line">    allow_unreachable=True)  # allow_unreachable flag</span><br><span class="line"><span class="symbol">RuntimeError:</span> CUDA error: an illegal memory access was encountered (copy_device_to_device <span class="meta">at</span> /opt/conda/conda-bld/pytorch_1587428398394/work/aten/src/ATen/native/cuda/Copy.cu:<span class="number">61</span>)</span><br><span class="line">frame #<span class="number">0</span>: c10::Error::Error(c10::SourceLocation, <span class="keyword">std</span>::string const&amp;) + <span class="number">0x4e</span> (<span class="number">0x7f5fc5c77b5e</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libc10.so)</span><br><span class="line">frame #<span class="number">1</span>: <span class="meta">at</span>::native::copy_device_to_device(<span class="meta">at</span>::TensorIterator&amp;, bool) + <span class="number">0x861</span> (<span class="number">0x7f5fc82b12b1</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cuda.so)</span><br><span class="line">frame #<span class="number">2</span>: &lt;unknown function&gt; + <span class="number">0x240f91c</span> (<span class="number">0x7f5fc82b391c</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cuda.so)</span><br><span class="line">frame #<span class="number">3</span>: &lt;unknown function&gt; + <span class="number">0x9146ac</span> (<span class="number">0x7f5fed76d6ac</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">4</span>: &lt;unknown function&gt; + <span class="number">0x911d73</span> (<span class="number">0x7f5fed76ad73</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">5</span>: <span class="meta">at</span>::native::copy_(<span class="meta">at</span>::Tensor&amp;, <span class="meta">at</span>::Tensor const&amp;, bool) + <span class="number">0x44</span> (<span class="number">0x7f5fed76c834</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">6</span>: <span class="meta">at</span>::native::embedding_dense_backward_cuda(<span class="meta">at</span>::Tensor const&amp;, <span class="meta">at</span>::Tensor const&amp;, long, long, bool) + <span class="number">0x4bd</span> (<span class="number">0x7f5fc83fdbdd</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cuda.so)</span><br><span class="line">frame #<span class="number">7</span>: &lt;unknown function&gt; + <span class="number">0xde41dc</span> (<span class="number">0x7f5fc6c881dc</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cuda.so)</span><br><span class="line">frame #<span class="number">8</span>: &lt;unknown function&gt; + <span class="number">0xe2404c</span> (<span class="number">0x7f5fedc7d04c</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">9</span>: &lt;unknown function&gt; + <span class="number">0x28037f1</span> (<span class="number">0x7f5fef65c7f1</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">10</span>: &lt;unknown function&gt; + <span class="number">0xe2404c</span> (<span class="number">0x7f5fedc7d04c</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">11</span>: <span class="meta">at</span>::native::embedding_backward(<span class="meta">at</span>::Tensor const&amp;, <span class="meta">at</span>::Tensor const&amp;, long, long, bool, bool) + <span class="number">0x124</span> (<span class="number">0x7f5fed7ca1a4</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">12</span>: &lt;unknown function&gt; + <span class="number">0xeaefe0</span> (<span class="number">0x7f5fedd07fe0</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">13</span>: &lt;unknown function&gt; + <span class="number">0x29acffa</span> (<span class="number">0x7f5fef805ffa</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">14</span>: &lt;unknown function&gt; + <span class="number">0xee78d9</span> (<span class="number">0x7f5fedd408d9</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">15</span>: torch::autograd::generated::EmbeddingBackward::apply(<span class="keyword">std</span>::vector&lt;<span class="meta">at</span>::Tensor, <span class="keyword">std</span>::allocator&lt;<span class="meta">at</span>::Tensor&gt; &gt;&amp;&amp;) + <span class="number">0x1cd</span> (<span class="number">0x7f5fef45ef9d</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">16</span>: &lt;unknown function&gt; + <span class="number">0x2ae8215</span> (<span class="number">0x7f5fef941215</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">17</span>: torch::autograd::Engine::evaluate_function(<span class="keyword">std</span>::shared_ptr&lt;torch::autograd::GraphTask&gt;&amp;, torch::autograd::Node*, torch::autograd::InputBuffer&amp;) + <span class="number">0x16f3</span> (<span class="number">0x7f5fef93e513</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">18</span>: torch::autograd::Engine::thread_main(<span class="keyword">std</span>::shared_ptr&lt;torch::autograd::GraphTask&gt; const&amp;, bool) + <span class="number">0x3d2</span> (<span class="number">0x7f5fef93f2f2</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">19</span>: torch::autograd::Engine::thread_init(<span class="keyword">int</span>) + <span class="number">0x39</span> (<span class="number">0x7f5fef937969</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_cpu.so)</span><br><span class="line">frame #<span class="number">20</span>: torch::autograd::python::PythonEngine::thread_init(<span class="keyword">int</span>) + <span class="number">0x38</span> (<span class="number">0x7f5ff2c7e558</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/libtorch_python.so)</span><br><span class="line">frame #<span class="number">21</span>: &lt;unknown function&gt; + <span class="number">0xc819d</span> (<span class="number">0x7f5ff56e119d</span> <span class="keyword">in</span> /home/zcy/anaconda3/envs/nlp/lib/python3<span class="meta">.7</span>/site-packages/torch/lib/../../../.././libstdc++.so<span class="meta">.6</span>)</span><br><span class="line">frame #<span class="number">22</span>: &lt;unknown function&gt; + <span class="number">0x76db</span> (<span class="number">0x7f6017a0d6db</span> <span class="keyword">in</span> /lib/x86_64-linux-gnu/libpthread.so<span class="meta">.0</span>)</span><br><span class="line">frame #<span class="number">23</span>: clone + <span class="number">0x3f</span> (<span class="number">0x7f601773688f</span> <span class="keyword">in</span> /lib/x86_64-linux-gnu/libc.so<span class="meta">.6</span>)</span><br></pre></td></tr></table></figure></p>
<p>看起来有点像是张量在拷贝的时候出的错，回想起之前有人说，改一下代码就解决了，所以打算试一下他提供的代码： <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">torch<span class="selector-class">.cuda</span><span class="selector-class">.set_device</span>(&lt;device_num&gt;)</span><br></pre></td></tr></table></figure></p>
<p>简单来说，就是在你调用 <code>tensor.cuda()</code> 或者 <code>model.to(device)</code> 之后再调用上面的代码即可。<strong>更新</strong>：这方法还是不行，一会之后有报错了。</p>
<p>后来设置 <code>torch.backends.cudnn.benchmark=False</code>，也是失败了。</p>
<p>如果还是不行，可以试一下 <a href="https://github.com/pytorch/pytorch/issues/21819" target="_blank" rel="noopener">issue</a> 中各种的玄学方法。。。</p>
<p>这貌似是一个随机的错误，目前还是无解。。。</p>
<p><strong>更新</strong>：好像发现为什么了。</p>
<p>其实就是在调用交叉熵函数的时候，真实标签的值大于预测出概率分布的维度。例如，概率分布的维度是 200，而对应的标签为 205。我的场景是使用 pointer network 预测语句中的索引位置。由于数据处理失误，导致在真实标签中多加了 1。</p>
<p>注：这个 error 可能会由很多问题引起，不能保证我的解决办法对你有效。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>pytorch</category>
      </categories>
  </entry>
  <entry>
    <title>如何缓解类别不平衡</title>
    <url>/posts/10f07708.html</url>
    <content><![CDATA[<h1 id="魔改损失函数">魔改损失函数</h1>
<h2 id="focal-loss">Focal Loss</h2>
<div class="note info"><p>来源于何凯明团队的 <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Lin_Focal_Loss_for_ICCV_2017_paper.pdf" target="_blank" rel="noopener">Focal Loss for Dense Object Detection</a>。</p>
<p>本文可能有点绕，配合《<a href="https://zhuanlan.zhihu.com/p/32423092" target="_blank" rel="noopener">何恺明大神的「Focal Loss」，如何更好地理解？</a>》看可能会简单点。</p>
</div>
<p>由于 Focal Loss 是在 CV 领域提出的，本人对该领域并没有太多的了解，所以本文只关注论文中 Focal Loss 一节。</p>
<p>Focal Loss 是对 crossentropy 损失函数进行的改进，具体公式为 <span class="math inline">\(CE(p, y) = -\log(p_t)\)</span>。其中 <span class="math inline">\(p_t\)</span> 是对类别 y 的估计概率。</p>
<h3 id="balanced-cross-entropy">Balanced Cross Entropy</h3>
<p>一个解决类别不平衡的通用办法是引入一个权重因子 <span class="math inline">\(\alpha \in [0, 1]\)</span>，类别 1 是 <span class="math inline">\(\alpha\)</span>，类别 -1 是 <span class="math inline">\(1 - \alpha\)</span>。实际上，<span class="math inline">\(\alpha\)</span> 应该设置为相反的类别频率大小，或者将其视为一个超参数，在验证集上调试。那么，类似地我们可以得到 <span class="math inline">\(\alpha\)</span>-balanced CE loss： <span class="math display">\[CE(p_t) = -\alpha_t \log(p_t)
\]</span></p>
<p>论文将该损失函数做为了基线。</p>
<h3 id="focal-loss-definition">Focal Loss Definition</h3>
<div class="note info"><p>先说一下背景，现有正负类样本，负类样本非常多，正类样本非常少，我们要做的是识别出正类样本。</p>
</div>
<p>大量的 loss 由易分类的负类样本组成，并且其主导了梯度。虽然 <span class="math inline">\(\alpha\)</span> 平衡了正负类样本的重要性，但是<em>它难以区分难易样本</em>。</p>
<p>与 Balanced Cross Entropy 不同，focal loss 在 CE 中加入了一个调整因子（modulating factor）<span class="math inline">\((1 - p_t)^{\gamma}\)</span>，以及一个可调整的专注（focusing）参数 <span class="math inline">\(\gamma \ge 0\)</span>。论文中的图 1，绘制了 <span class="math inline">\(\gamma \in [0, 5]\)</span> 的 focal loss。那么 Focal Loss 可以定义为： <span class="math display">\[FL(p_t) = -(1 - p_t)^{\gamma} log(p_t)
\]</span></p>
<p>据论文中所述，<strong>focal loss 拥有两样特性</strong>：</p>
<ol type="1">
<li>当样本被误分类，同时 <span class="math inline">\(p_t\)</span> 非常小时，调整因子接近 1，那么 loss 就没有变化。如果 <span class="math inline">\(p_t\)</span> 趋向于 1，因子趋向于 0，那么易分的样本就会被降低权重。</li>
<li>专注参数 <span class="math inline">\(\gamma\)</span> 平滑地调整哪个简单样本应该被降低权重的比例。<span class="math inline">\(\gamma=0\)</span>，FL = CE。随着其加大，降低效果也就会被加大。<strong>论文发现 <span class="math inline">\(\gamma = 2\)</span> 是最好的</strong>。</li>
</ol>
<p>直觉上来讲，调整因子减少了来自易分类样本的损失贡献，并且扩大了样本接受小损失的范围。这句话好绕啊。说人话就是将选择小损失样本的范围扩大了。也就说 FL 的目的是<strong>将所有预测基本正确的样本的 loss 全部缩放，而预测基本错误的样本的 loss 保持基本不变</strong>。所以这就实现了扩大小损失样本范围的功能。</p>
<p>那么如何判断到底是基本正确还是基本错误呢？这其实与上文的“难以区分难易样本”相呼应。就是通过预测的概率 <span class="math inline">\(p_t\)</span> 来控制。如果概率接近 1，就意味着完全预测正确，那么相当于我们不再需要进行优化，也就是说将该 loss 删除。反之亦反。</p>
<p>在实践中，还会对 focal loss 进一步地魔改，即改为： <span class="math display">\[FL(p_t) = -\alpha_t (1 - p_t)^{\gamma} log(p_t)
\]</span></p>
<p>论文指出，这个变种在他们的实验中有略微的提升，但是我感觉“略微的提升”好像没什么说服力。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>liandan</category>
      </categories>
  </entry>
  <entry>
    <title>如何缓解过拟合</title>
    <url>/posts/6008fcbd.html</url>
    <content><![CDATA[<h1 id="s">s</h1>
<ul>
<li>数据层面</li>
<li>算法层面</li>
</ul>
<h1 id="参考资料">参考资料</h1>
<ul>
<li><a href="https://www.zhihu.com/question/360181480/answer/936386049" target="_blank" rel="noopener">有了提前中止防止过拟合方法为什么还需要 L1,L2,dropout 防止过拟合的方法？</a></li>
</ul>
<a id="more"></a>
]]></content>
      <categories>
        <category>AI</category>
        <category>liandan</category>
      </categories>
      <tags>
        <tag>overfitting</tag>
      </tags>
  </entry>
  <entry>
    <title>SourceChangeWarning：验证集上准确率很高，但是测试集上很低</title>
    <url>/posts/cb7d01da.html</url>
    <content><![CDATA[<p>按照国（Ge）际（Ren）惯例，这种问题的解决办法直接写在最前面。答案是，训练环境中的 pytorch 版本与测试环境中的版本不一致。 <a id="more"></a></p>
<p>今天训练一个 DST 模型，另外感到奇怪的是，在训练集上 70%+ 的 joint acc，验证集上也有 57%+。但是在测试集上只有 2%。</p>
<p>经过一系列的排查后，修复了一些 bug，但是结果还是没有变化。于是就没辙了。。。做深度学习的人都知道，神经网络模型压根就是一个黑盒子，根本无法像写 web 应用一样调试程序。</p>
<p>然后又经过一个下午的人肉排查后，私以为代码不可能出错，但是它在测试的时候就是会出问题。</p>
<p>后来突然发现我一直无视一个警告，因为之前一直感觉它没什么用。内容如下：</p>
<figure class="highlight vhdl"><table><tr><td class="code"><pre><span class="line">SourceChangeWarning: source code <span class="keyword">of</span> class <span class="symbol">'torch</span>.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object<span class="symbol">'s</span> source <span class="keyword">attribute</span> <span class="keyword">or</span> set `torch.nn.Module.dump_patches = <span class="literal">True</span>` <span class="keyword">and</span> <span class="keyword">use</span> the patch tool <span class="keyword">to</span> revert the changes.</span><br><span class="line">SourceChangeWarning: source code <span class="keyword">of</span> class <span class="symbol">'torch</span>.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object<span class="symbol">'s</span> source <span class="keyword">attribute</span> <span class="keyword">or</span> set `torch.nn.Module.dump_patches = <span class="literal">True</span>` <span class="keyword">and</span> <span class="keyword">use</span> the patch tool <span class="keyword">to</span> revert the changes.</span><br><span class="line">SourceChangeWarning: source code <span class="keyword">of</span> class <span class="symbol">'torch</span>.nn.modules.loss.NLLLoss' has changed. you can retrieve the original source code by accessing the object<span class="symbol">'s</span> source <span class="keyword">attribute</span> <span class="keyword">or</span> set `torch.nn.Module.dump_patches = <span class="literal">True</span>` <span class="keyword">and</span> <span class="keyword">use</span> the patch tool <span class="keyword">to</span> revert the changes.</span><br></pre></td></tr></table></figure>
<p>它显示源码发生了改变，但是我压根就没改过源码。经过一番排查后，我突然发现，这个警告不是提醒我，我的代码发生改变，而是 pytorch 的源码发生了变化。</p>
<p>想到这一点，就全可以解释通了。</p>
<p>由于现在是暑期，我一直用远程连接，连接着实验室的服务器。而服务器的 pytorch 代码的版本与我笔记本上的不一样！</p>
<p>服务器上的是 <code>pytorch=1.5.0, torchvision=0.6.0</code> cuda 版本，而本地的是 <code>torch=1.4.0, torchvision=0.5.0</code> cpu 版本。</p>
<p>后来我直接在服务器上测试我的模型，发现结果终于合理了。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title>将hexo迁移到其他电脑所需的操作</title>
    <url>/posts/fe4b567a.html</url>
    <content><![CDATA[<h1 id="安装必需组件">安装必需组件</h1>
<p>可以参考文章<a href="https://cczeng.github.io/2017/05/03/git/我是如何利用Github-Pages搭建起我的博客——细数一路的坑/" target="_blank" rel="noopener">《我是如何利用 Github Pages 搭建起我的博客，细数一路的坑》</a>中的安装步骤。</p>
<p>但是由于我的是将原先的 hexo 迁移到新电脑，所以有点不一样。</p>
<ol type="1">
<li><strong>首先</strong>，可以参考上文提到的文章，先安装 git 和 node.js。</li>
<li><strong>然后</strong>，切换到博客的根目录，我的是 <code>D:/hexo/blog</code>。在目录打开 git 命令行，执行 <code>npm install hexo-cli -g</code>。这是在安装 hexo，否则你无法执行 hexo 的命令。</li>
<li><strong>最后</strong>，安装以前安装过的<a href="https://yan624.github.io/posts/5d62ca7e.html">插件</a>。（PS：突然发现可能不用安装这些插件也行，因为它们本身就在你的博客里）</li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>情感回复生成论文笔记</title>
    <url>/posts/64223641.html</url>
    <content><![CDATA[<div class="note info"><p>目前所记录的论文，只截止到 2020 年。</p>
</div>
<h1 id="generating-responses-with-a-specific-emotion-in-dialog">Generating Responses with a Specific Emotion in Dialog</h1>
<ul>
<li><a href="https://yan624.github.io/posts/1d4dcf2a.html">论文笔记</a></li>
</ul>
<h1 id="affective-neural-response-generation">Affective Neural Response Generation</h1>
<ul>
<li><a href="https://yan624.github.io/posts/6ce305f0.html">论文笔记</a> <a id="more"></a></li>
</ul>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>Generating Responses with a Specific Emotion in Dialog</title>
    <url>/posts/1d4dcf2a.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://www.aclweb.org/anthology/P19-1359.pdf" target="_blank" rel="noopener">论文地址</a></p>
</div>
<h1 id="摘要以及引言">摘要以及引言</h1>
<p>人类拥有独特能力能够察觉到复杂，有细微差别的情绪，也拥有使用语言与他人交流这些体验的独特能力。尽管近些年的研究（...）提供了大量的证据，证明<strong>系统能够表达情感可以很大程度上提高用户的满意程度</strong>，但是对于制作一个产生更情绪化回复的对话系统来说，仍旧具有很大的挑战。</p>
<p>在早期的表征工作中，人工地准备一些规则，即有意地从语料库中选择一些需要的“情绪化”回复。在语料库中进行精心地调查后，这些规则由这方面的专家编写，但是这使得复杂多变的情感难以表达，并且难以很好地扩展到大型数据集。<mark class="label info">早期的情绪表征工作</mark></p>
<p>最近，seq2seq 被用于构建对话模型。ECM 也由 Zhou et al(2018) 提出解决情绪表达的问题。然而还是遭受到了不小的困难。</p>
<p>语言在情感中扮演了重要的角色。正如表 1 所示，我们发现至少有两种方式可以将情感填入单词之中。一个是明确地（<strong>explicit</strong>）使用强烈的情感词汇来描述情绪状态（emotion states），例如“anger”，“disgust”，“contentment”，“joy”，“sadness”等；另一个是增强情感表达的强度，与之前的不同，它不是通过情感词汇，而是在某种情感上含蓄地（<strong>implicit</strong>）组合各种中性词。（<strong>博主注</strong>：如果无法理解，可以看原论文中的表一，它提供了例子）</p>
<p>在本项研究中，我们提出一个情感对话系统（emotional dialogue system，<strong>EmoDS</strong>），<strong>它可以以明确或者含蓄的方式，将一种特定的情感表达到具有连贯结构的词汇中</strong>。<strong>我们使用一个基于字典的 attention 机制（lexicon-based attention mechanism）扩展 seq2seq 模型，这对使用情绪字典中的同义词替换回复中的单词有促进作用</strong>。回复生成步骤将由序列级别的情绪分类器指导，它不仅可以增强情绪表达的强度，还有助于识别不包含任何情绪单词的情绪化语句。我们还提出了一个半监督的方法去创建一个情绪字典，它是一个相对“准确”的情绪状态表征。实验结果显示了 EmoDS “厉害”。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p>先前的工作报道对话系统有情感可以增强用户的满意程度。但是所作的工作大都是人工制定的规则，它们都是由受过训练的专家进行撰写。这很难处理复杂的语句，并且很难扩展到大规模的数据集中。</p>
<p>RNN 及其在 seq2seq 中的应用，可以用于创建聊天机器人。早前的研究，也在企图避免其产生无聊、枯燥的回复。</p>
<p>最近。。。</p>
<h1 id="method">Method</h1>
<h2 id="问题定义">问题定义</h2>
<p>给定一个 <span class="math inline">\(X = {x_1, x_2, \cdots, x_M}\)</span> 和一个情绪类别 <span class="math inline">\(e\)</span>，目的是生成回复 <span class="math inline">\(Y = {y_1, y_2, \cdots, y_N}\)</span>，其中 <span class="math inline">\(x_i, y_j \in V\)</span>。<span class="math inline">\(V = V_g \cup V_e\)</span> 是一个词表，其中 <span class="math inline">\(V_g\)</span> 是通用词表，<span class="math inline">\(V_e\)</span> 是情绪字典。并且需要 <span class="math inline">\(V_g \cap V_e = \emptyset\)</span>。字典 <span class="math inline">\(V_e\)</span> 还会进一步分为 <span class="math inline">\(V^z_e\)</span>，其中的每个单词都会被划分为一个情绪类别 <span class="math inline">\(z\)</span>。</p>
<h2 id="dialogue-system-with-lexicon-based-attention-mechanism">Dialogue System with Lexicon-based Attention Mechanism</h2>
<p><em>介绍 seq2seq</em>；<em>介绍 lexicon-based attention mechanism</em>（这个实际上就是普通的 attention）；EmoDS 的架构如图 1 所示。</p>
<p><em>介绍 seq2seq 是如何做的</em>。</p>
<p>decoder 使用前一个预测单词和情绪词更新隐藏状态 <span class="math inline">\(s_j\)</span>，具体公式如下所示： <span class="math display">\[s_j = LSTM_{decoder}([Emb(y_{j-1}); e_j], s_{j-1})
\]</span></p>
<p>其中情感向量 <span class="math inline">\(e_j\)</span> 由给定类别 <span class="math inline">\(z\)</span> 的 <span class="math inline">\(V^z_e\)</span> 中的词嵌入加权和计算得到： <span class="math display">\[
\begin{align}
    e_j &amp; = \sum_k a_{jk} \cdot Emb(w^z_k) \\
    a_{jk} &amp; = \frac{exp(c_{jk})}{\sum^{T_z}_{t=1} exp(c_{jt})} \\
    c_{jk} &amp; = Sigmoid(\alpha^T h_M + \beta^T s_{j-1} + \gamma^T Emb(w^z_k))
\end{align}
\]</span></p>
<p>为了把情绪单词植入回复中，我们估计了两种概率分布。一是，给定情绪类型 <span class="math inline">\(z\)</span>，在 <span class="math inline">\(V^z_e\)</span> 中每个情绪词 <span class="math inline">\(w^e\)</span> 上计算概率分布 <span class="math inline">\(P_e(y_j = w^e)\)</span>；二是，在 <span class="math inline">\(V_g\)</span> 中所有通用词汇上计算概率分布 <span class="math inline">\(P_g(y_j = w^g)\)</span>： <span class="math display">\[
\begin{align}
    P_e(y_j = w^e) &amp; = Softmax(W_e s_j) \\
    P_g(y_j = w^g) &amp; = Softmax(W_g s_j) \\
    \sigma_j &amp; = Sigmoid(v^T s_j) \\
    y_j \sim P(y_j) &amp; = 
        \begin{bmatrix}
            \sigma_j P_e(y_j = w^e) \\ 
            (1 - \sigma_j) P_g(y_j = w^g)
        \end{bmatrix}
\end{align}
\]</span></p>
<p>其中 <span class="math inline">\(sigma_j in (0, 1)\)</span> 是一个类型选择器，控制生成通用词或情绪词的权重，<span class="math inline">\(W_e, W_g, v\)</span> 是可学习的参数。attention 机制有助于在正确的时间步上，将想要的情绪词放进回复，这使得有希望生成特定情绪的回复。每个样本的损失函数被定义为最小化交叉熵函数。</p>
<h2 id="emotion-classification">Emotion Classification</h2>
<h2 id="training-objective">Training Objective</h2>
<p>总的训练目标被分为两部分：生成损失和分类损失。即 <span class="math inline">\(L = L_{MCE} + \lambda L_{CLA}\)</span>，<span class="math inline">\(\lambda\)</span> 控制生成损失的相对重要程度，相对于分类项来说。</p>
<h2 id="diverse-decoding-algorithm">Diverse Decoding Algorithm</h2>
<p>Li et al. (2016c) 发现大多数由传统集束搜索产生的 N 个最优回复是类似的，因此我们提出一种 diverse decoding 算法来培养回复生成中的多样性。<strong>我们强制 N 个候选回复中的开头单词必须是不同的，然后模型继续通过贪婪解码策略生成回复</strong>。最终，我们选择 N 个候选回复中，情绪分数最高的回复。候选回复由 emotion classifier 进行评分。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Affective Neural Response Generation</title>
    <url>/posts/6ce305f0.html</url>
    <content><![CDATA[<h1 id="摘要以及引言">摘要以及引言</h1>
<p>现在的神经对话模型主要在词汇句法层面处理自然语言，而忽略了人与人对话中最关键的成分之一：其中的情感内容。我们在这一方向上迈出一小步，提出三种新型的方式，将情感（affective/emotional）融入 LSTM encoder-decoder 神经对话模型：<strong>1）</strong>情感词嵌入（affective word embeddings），这是认知上的设计；<strong>2）</strong>基于情感的优化函数（affect-based objective functions），增强了标准的交叉熵函数；<strong>3）</strong>用于解码的情感多样集束搜索（affectively diverse beam search）。实验表明这些技巧提高了 encoder-deocder 模型的开放域对话造诣，并且使得它能够产生富含情绪的回复，这些回复更有趣且更自然。<mark class="label info">摘要</mark></p>
<p>人机对话系统已经有了很广泛的应用，从酒店预订到情绪化虚拟助手。在基于神经网络的对话系统中，离散的单词被映射为真实值的向量，这被称为嵌入，它们捕获到了单词的抽象意义；然后基于 LSTM 的 encoder-deocder 框架根据一条或者一系列先前的语句产生回复。编码解码方向上最近的进展已经表明，它在面向任务的对话系统和开放域回复生成上都是有效的。<mark class="label info">对话系统的一般做法</mark></p>
<p>虽然现在大多数的神经对话模型可以在句法上生成格式良好的回复，但是他们脱离上下文、简短、枯燥且含糊。最近解决这些问题的一些贡献包括：diverse decoding（Li, Monroe, and Jurafsky 2016; ...），diversity-promoting objective functions（Li et al. 2016a），adversarial learning（...），latent variable modeling for diversity（...），human-in-the-loop reinforcement learning（...），online active learning（...），latent intention modeling（...），content-introduce approaches（...）。虽然这些进展有希望解决以上问题，但是我们仍旧离我们的目标很远——建造一个自动化神经助手，可以始终实现有趣的类人对话。<mark class="label info">近年解决生成语句单一的做法</mark></p>
<p>现存开放域神经对话模型的其中一个缺点是对自然语言情感建模的缺乏。在大型的对话数据集上训练时，这些模型没有捕捉到人与人交互时的情绪状态，它们通常通过单词、短语与或者情绪的选择从而表现出来。例如 seq2seq 模型中的 attention 机制可以学习得到句法级的对齐。类似地，像 Word2Vec 的词嵌入通过上下文可以学习到词向量，并且可以永久地保存低级的语义。然而，现存模型无法清楚地捕捉到情绪方面的状态。<mark class="label warning">现存模型的缺陷</mark></p>
<p>我们的目标是在开放域神经对话模型中，通过情感智能增强它们以此缓和此类问题。我们将以三种方式实现：</p>
<ol type="1">
<li>我们使用认知工程化的词汇级情感词典，将单词嵌入到三维情感空间中（...），其中情感相似的结构彼此接近。通过这种方式，随后的神经模型可以感知到单词的情感特征；</li>
<li>我们提出使用情感目标，增强标准的交叉熵损失函数，因此我们的模型将会被明确地“指导”从而产生更多的情感语句；</li>
<li>我们将情感的多样性注入进生成的回复中，回复将通过情感多样集束搜索（<strong>affectively diverse beam search</strong>）算法的解码器生成，因此我们的模型能够在解码期间有效地搜索到带有情感的回复。 <a id="more"></a></li>
</ol>
<h1 id="相关工作">相关工作</h1>
<p>由于情感认知虚拟助手能够和人类产生情感上的关系，它已经引起了学术界以及工业界的兴趣（...）。基于文本且带有情感的对话生成系统也是一个活跃的研究领域。过去的研究大多数关注的是开发基于手写模版的语音和基于文本的特征，然后利用这两点将情感融入基于检索或基于槽位的口语对话系统（SDS）中。</p>
<p>除却它们，与我们的工作最为相关的是以下两项研究：</p>
<ol type="1">
<li>Affect Language Model：</li>
<li>Emotional Chatting Machine：</li>
</ol>
<h1 id="提出的情感方法">提出的情感方法</h1>
<p>本节提出情感化的神经对话生成，它使用情感认知增强了传统的对话模型。</p>
<p>图 1 描述了模型的总体结构。我们利用一个认知工程词典（affectively engineered dictionary），在此基础上提出了三种情感对话生成策略，即情感词嵌入（<strong>affective word embeddings</strong>）、情感训练目标（<strong>affective training objectives</strong>）以及情感多样集束搜索（<strong>affectively diverse beam search</strong>）。</p>
<h2 id="affective-word-embeddings">Affective Word Embeddings</h2>
<p>正如前所述，传统的词嵌入利用共现统计的方式训练，无法捕获情感层面的状态。我们提出使用一个三维的情感空间来增强传统的词嵌入，即使用一个外部的认知工程情感词典（<strong>cognitively-engineered affective dictionary</strong>）（Warriner, Kuperman, and Brysbaert 2013）。</p>
<p>我们使用的词表包含 13915 词元化（lemmatized，词形还原，指词的基本形态）的英语单词，其中每一个都被评为三个传统上被接受的、持续的、真实的情感维度：</p>
<blockquote>
<p><strong>Valence</strong> (V, the pleasantness of a stimulus), <strong>Arousal</strong> (A, the intensity of emotion produced, or the degree of arousal evoked, by a stimulus), and <strong>Dominance</strong> (D, the degree of power/control exerted by a stimulus)</p>
</blockquote>
<p>社会学家假设 VAD 空间（也被称为 EPA 空间，即 Evaluation, Potency, and Activity，分别与 VAD 一一对应且为一个意思）构建了语言概念（跨语言且跨文化）上的语义关系；它捕捉了近 70% 的概念情感意义的差异。VAD 评分以前被用于情绪分析和移情辅导，以及其他情感计算应用。据我们所知，我们是首次将 VAD 引入对话生成领域的。</p>
<div class="note warning"><p>这是不是可以认为移情计算是情感计算的一种？</p>
</div>
<p><em>接下来介绍了 VAD。</em></p>
<h2 id="affective-loss-functions">Affective Loss Functions</h2>
<p>损失函数的思想体系与 Li et al. (2016a) 类似，但是我们关注情感层面。几个启发式的方法如下所示：</p>
<h3 id="minimizing-affective-dissonance">Minimizing Affective Dissonance</h3>
<h2 id="affectively-diverse-decoding">Affectively Diverse Decoding</h2>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>文本分类任务总结</title>
    <url>/posts/1f7446e4.html</url>
    <content><![CDATA[<h1 id="focal-loss">Focal Loss</h1>
<p><a href="https://www.zhihu.com/search?type=content&amp;q=类别不平衡应该怎么训练" target="_blank" rel="noopener">类别不平衡应该怎么训练？</a> <a id="more"></a></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>nlp</category>
      </categories>
  </entry>
  <entry>
    <title>神经网络训练技巧（二）</title>
    <url>/posts/79498a68.html</url>
    <content><![CDATA[<h1 id="前言">前言</h1>
<p>原来这篇文章应该是训练技巧的第二篇的，但是由于<a href="https://yan624.github.io/posts/8071918e.html">前一篇</a>写得跟 <font color='#DDAA00'>shi</font> 一样，并且因为那篇是我做第一个实验过程中得到的结论，就不想删了。所以后来大部分炼丹技巧都移到这了。</p>
<h1 id="参数介绍">参数介绍</h1>
<p><a href="https://www.zhihu.com/question/48282030/answer/114305326" target="_blank" rel="noopener"></a></p>
<table>
<thead>
<tr class="header">
<th>参数</th>
<th>介绍</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>--</td>
<td>-</td>
</tr>
</tbody>
</table>
<h1 id="节省时间">节省时间</h1>
<ul>
<li>一开始可以先使用小量的数据去试探出一个合适的参数范围，当后期进行精调参数时，可以考虑把验证步骤关了，以此加速模型训练过程。</li>
<li>在调参的时候没必要为了追求最高的准确率，而刻意把 epoch 调大，这都是后面确定结果的时候干的。在刚开始调参的时候，如果 val_acc 在后期（例如 10 个 epoch 之后就稳定了）一直浮动的 50% 左右，但是 <code>epoch=20</code> 的准确率比 <code>epoch=30</code> 低 4 个百分点，这是无所谓的，可以果断选择 <code>epoch=20</code>，因为节省时间最重要。等到参数调出来了，再去试最合适的 epoch。 <a id="more"></a></li>
</ul>
<h1 id="参数初始化">参数初始化</h1>
<ol type="1">
<li>LSTM 使用 orthogonal_ 初始化【2】，forget gate bias 初始化为 1<span class="citation" data-cites="jozefowicz2015empirical">(Jozefowicz, Zaremba, and Sutskever 2015)</span></li>
<li>Embedding 使用 uniform 初始化【3】</li>
<li>relu使用 kaiming(He) 初始化【4】</li>
<li>tanh 初始化推荐使用 Glorot normal【3】</li>
</ol>
<h1 id="过拟合">过拟合</h1>
<p>注意：处理过拟合，一定是模型已经调参调的差不多了才用，调参的时候可以不用。</p>
<h2 id="正则化">正则化</h2>
<ol type="1">
<li>weight decay</li>
<li>layer norm：将 norm 加在输出上，即输出后立马加上</li>
<li>dropout：加在输出层之前的那层就行了【1】</li>
</ol>
<h1 id="如何继续收敛">如何继续收敛</h1>
<div class="note danger"><p>请注意，learning rate decay 并不是处理过拟合的手段，相反，它会使得模型越来越过拟合。因为学习率衰减本质是让模型在训练集上放慢脚步继续进一步拟合。</p>
</div>
<ol type="1">
<li>learning rate decay：其中 step = 1 就是 exponential；step 只能以固定的步长进行衰减，multi-step 可以控制每步的步长。一般用 step 就行了。
<ol type="1">
<li><strong>step</strong></li>
<li>multi-step</li>
<li>exponential</li>
<li>cosine annealing with warm restart</li>
<li>warm up</li>
</ol></li>
</ol>
<h1 id="pytorch使用">pytorch使用</h1>
<ol type="1">
<li>训练的时候不要忘记加 zero_grad【5】</li>
<li>如果要加 weight decay，记得要使用 AdamW 算法，而不是 Adam</li>
</ol>
<h1 id="梯度爆炸">梯度爆炸</h1>
<ol type="1">
<li>clip_grad_norm_</li>
</ol>
<h1 id="seq2seq">seq2seq</h1>
<ol type="1">
<li>使用集束搜索（beamsearch）算法，几乎总是比贪婪搜索（gready search）要好。</li>
</ol>
<h1 id="神经网络优化的难点">神经网络优化的难点</h1>
<h1 id="玄">玄</h1>
<h2 id="可以尝试一下">可以尝试一下</h2>
<ol type="1">
<li>LSTM、GRU、BERT 可以都试一下</li>
<li>一般在训练 rnn 时，一层就足够了，但是有时可以多加几层试试</li>
<li>embedding size 可以设置小点，例如 50-300；rnn 隐藏状态可以大点，例如 256-512</li>
<li>可以试试 batch=1</li>
<li>word dropout<span class="citation" data-cites="bowman-etal-2016-generating">(Bowman et al. 2016)</span>：这个方法其实挺简单的，只需要使用以下代码即可实现，代码参考<a href="https://stackoverflow.com/questions/50174230/implementing-word-dropout-in-pytorch" target="_blank" rel="noopener">这</a>，思想参考<a href="https://www.aclweb.org/anthology/K16-1002.pdf" target="_blank" rel="noopener" title="Generating Sentences from a Continuous Space">这</a>。 <figure class="highlight sas"><table><tr><td class="code"><pre><span class="line">def word_dropout(<span class="meta">x</span>, unk, rate=0.1):</span><br><span class="line">    probs = torch.empty(<span class="meta">x</span>.shape).uniform_(0, 1)</span><br><span class="line">    <span class="meta">x</span> = torch.<span class="meta">where</span>(probs &gt; rate, <span class="meta">x</span>, torch.zeros(<span class="meta">x</span>.shape, dtype=torch.long).fill_(unk))</span><br><span class="line">    <span class="meta">return</span> <span class="meta">x</span></span><br></pre></td></tr></table></figure></li>
<li>对于 adam，学习率可以设置为 0.0003，真的是一个神奇的小数</li>
</ol>
<h2 id="玄中玄">玄中玄</h2>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    rand_seed = <span class="built_in">random</span>.randint(<span class="number">0</span>, <span class="number">99999</span>)</span><br><span class="line">    torch.manul_seed(rand_seed)</span><br><span class="line">    save(rand_seed)</span><br><span class="line">    run_model()</span><br><span class="line">    <span class="meta"># 然后去玩几天游戏</span></span><br></pre></td></tr></table></figure>
<h1 id="网络资源">网络资源</h1>
<ol type="1">
<li><a href="https://www.zhihu.com/question/41631631" target="_blank" rel="noopener">你有哪些 deep learning（rnn、cnn）调参的经验？</a></li>
<li><a href="https://www.zhihu.com/question/57828011" target="_blank" rel="noopener">你在训练 RNN 的时候有哪些特殊的 trick？</a></li>
<li><a href="https://www.zhihu.com/question/25097993" target="_blank" rel="noopener">深度学习调参有哪些技巧？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/75938932" target="_blank" rel="noopener">权重初始化</a></li>
<li><a href="https://www.zhihu.com/question/303070254" target="_blank" rel="noopener">PyTorch 中在反向传播前为什么要手动将梯度清零？</a></li>
<li><a href="https://www.zhihu.com/question/29873016/answer/77647103" target="_blank" rel="noopener">caffe 里的 clip gradient 是什么意思？</a></li>
</ol>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-bowman-etal-2016-generating">
<p>Bowman, Samuel R., Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio. 2016. “Generating Sentences from a Continuous Space.” In <em>Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning</em>, 10–21. Berlin, Germany: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/K16-1002" target="_blank" rel="noopener" class="uri">https://doi.org/10.18653/v1/K16-1002</a>.</p>
</div>
<div id="ref-jozefowicz2015empirical">
<p>Jozefowicz, Rafal, Wojciech Zaremba, and Ilya Sutskever. 2015. “An Empirical Exploration of Recurrent Network Architectures.” In <em>International Conference on Machine Learning</em>, 2342–50.</p>
</div>
</div>
]]></content>
      <categories>
        <category>AI</category>
        <category>liandan</category>
      </categories>
      <tags>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>如何选择激活函数</title>
    <url>/posts/eadec448.html</url>
    <content><![CDATA[<h1 id="概述">概述</h1>
<a id="more"></a>
<h1 id="sigmoid">Sigmoid</h1>
<h2 id="分类问题为什么用ce而不是mse">分类问题为什么用CE，而不是MSE</h2>
<p>如下分别为两个损失函数的数学形式。感觉这个问题可能有点被过分解读了，下面总结一下再网上看到的观点。 <span class="math display">\[
\begin{align}
MSE = &amp; \sum_i(y_i - \hat{y}_i)^2 \\
CE = &amp; - \sum_i y_i \cdot log(\hat{y}_i)
\end{align}
\]</span></p>
<ul>
<li>从模型实际需求的角度
<ul>
<li>MSE 关注所有类别之间的误差。类别标签虽然是 0,1,2,3... 之类的表示，但是最终都会转为 one-hot 表示。而 MSE 对真实值和预测值之间误差的计算方式是减法，所以 MSE 会关注所有类别的误差。</li>
<li>与 MSE 不同，CE 只关注正确类别的误差。由于其是乘法，所以所有的错误类别的误差都变成了 0。</li>
</ul></li>
<li>从误差上限的角度
<ul>
<li>MSE 的误差有上限，因为只是 <span class="math inline">\(y - \hat{y}\)</span>。</li>
<li>而 CE 的计算方式是 <span class="math inline">\(- y \cdot log(\hat{y})\)</span>，由于 <span class="math inline">\(\hat{y} \in [0, 1]\)</span>，则 CE 的值域为 <span class="math inline">\([0, +\inf]\)</span></li>
</ul></li>
<li>从直觉上
<ul>
<li>分类问题的标签没有空间的概念，标签 1 和标签 10 并不是说它们的差距就比标签 1 和标签 2 差距大，而 MSE 就是专门用来衡量距离的。</li>
</ul></li>
<li>从优化的角度
<ul>
<li>貌似有人说 MSE 容易导致梯度消失，主要的原因是 Sigmoid 的导数。然而我感觉不又寸。。。MSE 和 CE 的导数就差了这一项而已，这能有多大区别。。。</li>
</ul></li>
</ul>
<p>参考： 1. <a href="https://www.zhihu.com/question/319865092/answer/717476767" target="_blank" rel="noopener">为什么平方损失函数不适用分类问题？</a> 2. <a href="https://zhuanlan.zhihu.com/p/84431551" target="_blank" rel="noopener">MSE vs 交叉熵</a></p>
<h1 id="relu家族">ReLU家族</h1>
<p>ReLU 的函数是 <span class="math inline">\(a = max(0, x)\)</span>，同时它还拥有许多变体。但是如下图所示，总的来说，它就分为两类。一类是负域线性，另一类是负域非线性。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/如何选择激活值？/几种常见的激活函数.jpg" alt="几种常见的激活函数" /></p>
<p>如果你期望某个张量在不断地被计算的过程中，最后输出越小越好（接近 0），那么最好别使用 ReLU。</p>
<p>例如，我碰到了一个问题。我参考论文《<a href="https://arxiv.org/pdf/1704.01074.pdf" target="_blank" rel="noopener">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</a>》设计了一个模块，简单来说就是有一个 memory，它会在神经网络计算过程中参与运算（加减操作），当一个批次计算完毕时，我们期望这个 memory 会被释放至 0（<em>越接近越好</em>）。然后我在制作这个模块时使用了 relu 函数，我发现我的神经网络将它的权重调整的很奇怪。在进入 relu 函数之前，<span class="math inline">\(x \cdot W\)</span> 总是输出负数。我的分析是：由于 relu 函数的负域总是输出 0，而我们的要求是在处理完一个批次后，memory 需要释放至 0，所以这个模块索性就让它永远等于 0，而不会在计算过程中既有产生 memory，又有释放 memory。因为让输出 0 是一件很简单的事，神经网络只需要学习让线性变换的输出全部为负数即可。</p>
<p>为了让神经网络不那么简单就学习到我们的要求，即不要让它总是输出 0，而是希望它能有加有减，所以我使用 elu 替代了它。</p>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><a href="https://www.zhihu.com/question/59031444" target="_blank" rel="noopener">如何理解 ReLU activation function?</a></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>liandan</category>
      </categories>
      <tags>
        <tag>activation</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP疑难杂题总结</title>
    <url>/posts/f4a0fc2f.html</url>
    <content><![CDATA[<h1 id="梯度消失">梯度消失</h1>
<h2 id="simple-rnn-的缺陷">simple-RNN 的缺陷</h2>
<p>RNN一个最大的缺陷就是梯度消失与梯度爆炸问题，由于这一缺陷，使得RNN在长文本中难以训练，这才诞生了LSTM及各种变体，来源于<a href="https://zhuanlan.zhihu.com/p/44163528" target="_blank" rel="noopener">专栏</a>。梯度消失的原因：参考<a href="https://zhuanlan.zhihu.com/p/28687529" target="_blank" rel="noopener">专栏</a>。 个人的解释如下： 在 RNN 中利用 memory 的方式是一种复合函数的结构，所以在反向传播时，需要链式求导，即 <span class="math inline">\(f(g(x)) = f&#39;(g(x))·g&#39;(x)\)</span>，梯度与梯度相乘容易造成<strong>梯度消失</strong>和<strong>梯度爆炸</strong>。而在 LSTM 中，是使用加和的计算方式，所以大致解决了梯度消失的问题。 <div class="note info"><p>在 RNN 中，求导得到的表达式为连乘，而 sigmoid 的输出值在 [0-1] 之间，造成了梯度消失。当然也会造成梯度爆炸，因为激活函数不一定非是 sigmoid，换成 ReLU 输出值就会大于 1 了。 接下来我带入数字来讲解一遍，<strong>具体公式详见《<a href="https://yan624.github.io/posts/b2bd11c2.html#反向传播（BPTT）">Simple RNN 的反向传播</a>》，下面只讲求导后的函数</strong>。我们先把公式拿过来，并设 <span class="math inline">\(a^3 = 0.2\)</span>, <span class="math inline">\(a^2 = 0.1\)</span>, <span class="math inline">\(a^1 = 0.05\)</span>, <span class="math inline">\(w_{aa} = 0.07\)</span>。并且<strong>易得</strong> <span class="math inline">\(S^1 = a^1\)</span>, <span class="math inline">\(S^2 = a^2\)</span>, <span class="math inline">\(S^3 = a^3\)</span>（易得部分都不懂的，建议仔细看看文章里的公式）。 <span class="math display">\[
\frac{\partial{a^3}}{\partial{W_{aa}}} = S_3 \circ (1 - S_3) \circ
\{
    \overbrace{a^2}^{\frac{\partial{W_{aa} \cdot a^2}}{\partial{W_{aa}}}} + \overbrace{
        W_{aa} \cdot \underbrace{
            S_2 \circ (1 - S_2)[
                a^1 + W_{aa} \cdot \underbrace{
                    S_1 \circ (1 - S_1) \circ \frac{\partial{a^0}}{\partial{W_{aa}}}
                }_{\frac{\partial{a^1}}{\partial{W_{aa}}}}
            ]
        }_{\frac{\partial{a^2}}{\partial{W_{aa}}}}
    }^{\frac{\partial{a^3}}{\partial{a^2}}}
\}
\]</span> 则 <span class="math display">\[
\frac{\partial{a^3}}{\partial{W_{aa}}} = a^3 \circ (1 - a^3) \circ \{a^2 + W_{aa} \cdot a^2 \circ (1 - a^2) \circ [a^1 + 0]\}
\]</span> <em>首先需要明白一点，对于 RNN 来说，激活值 a 就是 memory。我们将设置的值带入得到 <span class="math inline">\(\frac{\partial{a^3}}{\partial{W_{aa}}} = 0.0160504\)</span>。可以发现梯度很小，而这仅仅是在序列长度为 3 的情况下。那么假设我们修改值，将 <span class="math inline">\(w_{aa}\)</span> 改为 0.7，则 <span class="math inline">\(\frac{\partial{a^3}}{\partial{W_{aa}}} = 0.016504\)</span>，将 <span class="math inline">\(w_{aa}\)</span> 改为 7，则 <span class="math inline">\(\frac{\partial{a^3}}{\partial{W_{aa}}} = 0.02104\)</span>。我们发现即使 <span class="math inline">\(w_{aa}\)</span> 的变化很大，梯度值的变化效果也不是明显。也就是说对于 <span class="math inline">\(\frac{\partial{a^3}}{\partial{W_{aa}}}\)</span>，<span class="math inline">\(W_{aa}\)</span> 这个值不是很重要，在计算梯度时，可以忽略。</em>（<strong>2020.3.2 更新</strong>：事实上 <span class="math inline">\(W_{aa}\)</span> 对梯度消失也有影响，这里没影响是因为上式嵌套结构中才出现了一个 <span class="math inline">\(W_{aa}\)</span>。刚才试了一下如果多套几个，梯度也会受到很大影响（<strong>其中对梯度消失的影响略小，主要对梯度爆炸的影响很大</strong>）） 综上所述，<del>我们发现 W 几乎无法阻止梯度越变越小。</del>激活值全都在 [0-1] 范围内，所以就产生了梯度消失——gradient vanishing。（<span class="math inline">\(W_{aa}\)</span> 也会造成影响） 对于梯度爆炸，由于激活函数是 sigmoid 激活值不可能大于 1，所以可能是 <span class="math inline">\(W_{aa}\)</span> 造成的。如果激活函数是 tanh 的话，激活值会大于 1，那么应该也会造成梯度爆炸。 对 <span class="math inline">\(W_{ax}\)</span> 是差不多的道理，只不过对于输入值 x，它本身的取值就是 [<span class="math inline">\(\infty\)</span>, <span class="math inline">\(-\infty\)</span>]，所以与 a 不同。 然而梯度消失的真正原因并不完全是这个，详见 <a href="https://yan624.github.io/·zcy/AI/nlp/NLP模型训练分析.html#LSTM解决了RNN的什么问题">LSTM 解决了 RNN 的什么问题</a> 的第二点。</p>
</div> <a id="more"></a> RNN 的 loss 是每个 timestep 上的 loss 的加和，下图显示了这种情况下是如何求导的。不过有时候 RNN 的 loss 也就最后一个 tiemstep 会有一个 loss，比如分类任务。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/深度学习算法（二）：simple%20RNN%20推导与理解/vanishing%20gradient%20problem%20details.jpg" alt="vanishing gradient problem details" /></p>
<p>参考资料： 1. <a href="https://zhuanlan.zhihu.com/p/28749444" target="_blank" rel="noopener">LSTM如何解决梯度消失问题</a> 2. <a href="https://zhuanlan.zhihu.com/p/34203833" target="_blank" rel="noopener">深入理解lstm及其变种gru</a> 3. <a href="https://www.zhihu.com/question/34878706/answer/192444888" target="_blank" rel="noopener">LSTM如何来避免梯度弥散和梯度爆炸？</a> 4. <a href="https://zhuanlan.zhihu.com/p/83496936" target="_blank" rel="noopener">人人都能看懂的LSTM介绍及反向传播算法推导（非常详细）</a></p>
<h1 id="lstm解决了rnn的什么问题">LSTM解决了RNN的什么问题</h1>
<p>解决了两点。仅为个人观点。 1. memory 机制 2. 梯度消失</p>
<h2 id="memory机制">memory机制</h2>
<p><strong>第一</strong>，RNN 受到短期记忆的影响。如果序列很长，他们将很难将信息从较早的时间步传送到后面的时间步。LSTM 通过改进 memory，可以更好地保留序列信息。 在每个时间点， RNN 都只用每个 cell 的 output 覆盖 memory 里的值，即每个 tiemstep 中的信息都会被覆盖掉。而在 LSTM 中，它会将 memory 乘上一个权重再加上 input，从而获得新的 memory。它不会每次都 forget memory，除非 forget gate 计算结果等于 0。从公式的角度看就是： <span class="math display">\[
RNN: memory_{new} = cell(memory, input) \\
LSTM: memory_{new} = a * input + b * memory \\
\]</span> cell() 代表一个简单的 sigmoid 函数，memory 与 input 可以做拼接处理，也可以 memory + input，具体自己设计。a 是 input gate 的计算结果，b 是 forget gate 的计算结果，说白了都是一个权重，可以忽略。 这样乍一看好像 RNN 和 LSTM 没什么区别，它们都是会进行一些计算，然后获得一个新的 memory。但是 RNN 的计算方式是将 memory 与 input <strong>一起</strong>输入进 neuron，从而产生一个 output，最后将这个 output 作为新的 memory。你会发现，在 RNN 中，虽然 output 是由 memory 和 input 计算得来的，但是在更新 memory 时不是采用 LSTM 的策略，而是直接用 output 将 memory 覆盖掉，<strong>这既没考虑到原 memory 的值，也没考虑当前 input 的值</strong>。而 LSTM 在覆盖 memory 时，会考虑当前 memory 以及 input 的值。<strong>理解该段的重点是：下面的 1</strong>。 1. <strong>个人理解</strong>：RNN 看似用到了原 memory 和 input，但是在实际计算时（即 cell() 函数所做的操作），由它俩 train 出来的权重矩阵只是为了使 cell() 计算的结果尽可能地接近 y，而并非在计算一个好的 memory。这里尤其要注意，cell() 函数的功能跟 memory 没关系，RNN 与 memory 有关的操作仅仅只有一步，即 <span class="math inline">\(memory_{new} = output\)</span>，它只是将以前的 memory 覆盖掉。而 LSTM 不光在更新 memory 时用到了原 memory 和 input，它里面的 3 个 gate 也都需要通过 input 计算，所以 input 对 LSTM 的输出影响很大，对 memory 的更新自然也大。 2. <strong>李宏毅机器学习视频中的说法</strong>：如果 weight 可以影响到 memory 里的值，那么这个影响会一直存在。我觉得李宏毅老师的讲解跟我的应该差不多，重点也是 LSTM 多了一个可以训练 memory 的权重。 3. memory 本质是在记忆之前所有的 input。</p>
<p>其实 forget gate 还是有几率清空 memory 的，那么为什么不直接取消 forget gate 呢？你不是要充分利用 input 吗？实际上在 LSTM 的第一个版本是没有 forget gate 的，它是后来才加上去的。甚至现在的说法是在训练 LSTM 时，不要给 forget gate 太大的权重，要让它大部分时间都是开着的，即大部分时间都不要清空 memory。如果以后训练 LSTM 时，觉得过拟合严重，可以使用 GRU，GRU 只有两个 gate（无 output gate）。（<em>引用<a href="https://www.bilibili.com/video/av10590361?p=37" target="_blank" rel="noopener">教学视频</a> 22:50 的话</em>）。</p>
<h2 id="梯度消失-1">梯度消失</h2>
<p><strong>第二</strong>，反向传播时出现的问题，以下 Q 为问题，A 为解释。 引子：如《clip gradient》一章黄框中所说，RNN 很容易出现峭壁和平原。<strong>LSTM 只解决了 gradient vanishing 的问题</strong>，没有解决 gradient explode。LSTM 使得 error surface 不那么崎岖，<strong>消除了训练时的一些平坦的地方</strong>。虽然梯度在有些地方依然崎岖，但是不会有太平坦的地方。<strong>所以在训练时可以放心的将 lr 调小</strong>，不需要担心会出现平坦的地方，导致训练过慢。 如果公司问为什么把 RNN 换成 LSTM？<del>回答 LSTM 比较潮、因为 LSTM 比较复杂。</del>回答 LSTM 可以处理 gradient vanishing 的问题。具体解释如下： <strong>Q</strong>：为什么 LSTM 可以解决 gradient vanishing 的问题？（解决梯度消失也可以说成避免 gradient 特别小（消除平原）） <strong>A</strong>：在 RNN 中利用 memory 的方式是一种复合函数的结构，所以在反向传播时，需要链式求导，梯度与梯度相乘容易造成<strong>梯度消失</strong>和<strong>梯度爆炸</strong>。关于 RNN 反向传播的求导结果可以参考《simple RNN 的缺陷》蓝色提示框。 虽然这样的求导大致已经可以解释了梯度消失的问题，但是如果仔细想想就会发现盲点。在此之前，我想先说明 RNN 家族的反向传播路径与其他的神经网络不同，它的 loss 值是每一个 timestep 的真实值 y 与输出值 的 loss 之和。<a href="https://mooc.study.163.com/learn/2001280005?tid=2001391038&amp;_trace_c_p_k2_=72573d316c3441869416d70899cdf382#/learn/content?type=detail&amp;id=2001770031" target="_blank" rel="noopener">此视频</a> 大致讲明白了这个总 loss 值到底是由哪些 loss 相加得到的。 知道了上面的前提条件，就可以很简单的理解这个盲点了，接下来我先介绍一下这个盲点是什么：<strong>参考资料 1 大致解释了这一问题</strong>，这一段可能比较绕，<strong>简单来说就是后面的 timestep（比如下图中 <span class="math inline">\(loss_4\)</span>）在反向传播时，求 <span class="math inline">\(\Delta W\)</span> 会出现梯度消失（注意 RNN 每个 timestep 的 W 都是一样），这是因为在求梯度时，函数已经复合了好几层</strong>。而对 <span class="math inline">\(loss_1\)</span> 求 W 的导数时，由于它本身就在序列的前面，函数还没有复合，所以 <span class="math inline">\(\Delta W\)</span> 的导数还没梯度消失。<strong>最后在计算总的 loss 时，是将各个阶段的梯度加起来</strong>，即使后面的 loss 会得到一个很小的的梯度 <span class="math inline">\(\Delta W\)</span>，但由于 <span class="math inline">\(loss_1\)</span> 的原因，并不会发生梯度消失。 但是事实上是会发生的，那么梯度消失从何而来呢？这是因为在求序列前几个单词的梯度时，你需要从 <span class="math inline">\(loss_4\)</span> 开始计算（<em>当然其他的 <span class="math inline">\(loss_3\)</span> 也要计算，但是原理是一样</em>），由于 <span class="math inline">\(loss_4\)</span> 中复合了好几层函数，导致诸如 <span class="math inline">\(x_1\)</span>所对应的 RNN 的梯度很小，从而产生了<strong>信息丢失</strong>。信息丢失就是 RNN 的梯度消失。 你可能会想这不还是梯度连乘导致的？确实，但是有一点需要考虑，RNN 在反向传播时，是需要传播到输入值 x 的，即词向量。而在计算梯度时，<span class="math inline">\(x_4\)</span> 所对应 RNN 肯定拥有不是很小的梯度 <span class="math inline">\(\Delta W\)</span>，这是由于此时它还没有嵌套函数，所以信息无问题。但是当反向传播到 <span class="math inline">\(x_1\)</span> 时，梯度已经很小了，由于小梯度导致 <span class="math inline">\(x_1\)</span> 无法得到很好的更新，于是产生了信息丢失，也就是说长期记忆没有回传给 <span class="math inline">\(x_1\)</span>。 <span class="math inline">\(loss_3\)</span> 以及 <span class="math inline">\(loss_2\)</span> 以此类推，不过对于 <span class="math inline">\(loss_1\)</span> 并无问题，因为它没有复合函数。 注：<strong>上两段，还参考了参考资料 3，个人认为参考资料 1 中内容并不是很完整</strong>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习500问笔记/total%20loss.jpg" alt="total loss" /></p>
<p>以上的参考资料： 1. <a href="https://www.zhihu.com/question/34878706/answer/665429718" target="_blank" rel="noopener">LSTM如何来避免梯度弥散和梯度爆炸？</a> 2. <a href="https://www.bilibili.com/video/av10590361?p=37" target="_blank" rel="noopener">李宏毅机器学习</a>) 3. <a href="https://www.bilibili.com/video/av41393758?p=8" target="_blank" rel="noopener">RNN 和语言模式</a>，19.50 开始</p>
<p>而在 LSTM 中，是使用加和的计算方式（博主注：<strong>由于我没有计算过，所以我也不是很肯定</strong>），所以大致解决了梯度消失的问题。注意我没有说解决了梯度爆炸的问题。 <div class="note success"><p>LSTM 的模型以及参数名参考<a href="https://yan624.github.io/posts/5e27260b.html#长短期记忆——Long-Short-term-Memory-LSTM">此处</a>。 <span class="math display">\[
\begin{aligned}
    LSTM: z_i &amp; = [a_{i - 1}; x_i] \\
    memory_{new} &amp; = g(z_i) * input(z_i) + memory * forget(z_i) \\
    a_i &amp; = h(g(z_i) * input(z_i) + memory * forget(z_i)) * output(z_i) \\
\end{aligned}
\]</span> 对 LSTM 的求导结果很复杂，就不写了（实际上算得我自己都乱了）。。。它的复杂结构使得它不会出现一个数被连乘，导致极小。<strong>注意 LSTM 并没有解决梯度爆炸的问题。可以结合 clipping 训练 LSTM</strong>。 参考资料： 1. <a href="https://zhuanlan.zhihu.com/p/28749444" target="_blank" rel="noopener">LSTM如何解决梯度消失问题</a> 2. <a href="https://zhuanlan.zhihu.com/p/36101196" target="_blank" rel="noopener">漫谈LSTM系列的梯度问题</a> 3. <a href="https://www.zhihu.com/question/34878706/answer/192444888" target="_blank" rel="noopener">LSTM如何来避免梯度弥散和梯度爆炸？</a> 4. <a href="https://zhuanlan.zhihu.com/p/83496936" target="_blank" rel="noopener">人人都能看懂的LSTM介绍及反向传播算法推导（非常详细）</a></p>
</div></p>
<p>其他一些思考：LSTM 虽然可以永久的记住以前的 input 信息，但是 memory 说白了就是一个权重矩阵，不可能无限制的记住任何信息。所以可以对 memory 进行一些魔改，比如 memory network 将 memory 修改成用数组存储。 那么问题来了，GRU 解决了什么问题呢？为什么过拟合严重，可以使用 GRU？详见下一章。</p>
<h2 id="其他解决梯度消失的办法">其他解决梯度消失的办法</h2>
<ol type="1">
<li>Clockwise RNN</li>
<li>Structurally Constrained Recurrent Network(SCRN)</li>
<li></li>
</ol>
<h2 id="lstm-为什么没有解决梯度爆炸">LSTM 为什么没有解决梯度爆炸？</h2>
<p>理论上，梯度爆炸也同样糟糕。但在实践上，其实我们可以直接砍一刀（原话：it turns out we can actually have a hack），这由 Thomas Mikolov 首次提出。在某种程度上是不精确的，比如说“<strong>现在你有一个很大的梯度 100，让我们把它限制在 5 吧</strong>”。这方法就结束了。你只要定义一个临界值，当梯度大于临界值时，就使梯度等于临界值。虽然不是一个数学方法，但结果表明在实践中效果不错。 参考资料： 1. <a href="https://www.bilibili.com/video/av41393758?p=8" target="_blank" rel="noopener">RNN 和语言模式</a> 49.06 - 62.38</p>
<h1 id="梯度爆炸">梯度爆炸</h1>
<p><a href="http://proceedings.mlr.press/v28/pascanu13.pdf" target="_blank" rel="noopener">此论文</a>提出了 clip gradient（以下称 clipping）<strong>解决梯度爆炸</strong>。首先看下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习500问笔记/the%20error%20surface%20is%20rough.jpg" alt="the error surface is rough" /></p>
<p>如果只看图，会发现有一个像峭壁一样的东西，它就是罪魁祸首。当我们将一个小球往前移动时，有时候正好迈过峭壁，小球得以正常移动。但是当小球碰到峭壁时，小球就会被反弹回去，导致 loss 发生剧烈变化。 从数学角度来看，那个峭壁就是梯度。<strong>需要注意的是</strong>，由于图中 z 轴标注的是 total loss，所以第一印象感觉峭壁代表 total loss，但是<strong>峭壁代表的是梯度，而不是 total loss</strong>。根据参数更新公式 <span class="math inline">\(w -= \alpha * \Delta w\)</span>，其中 <span class="math inline">\(\Delta w\)</span> 代表 w 的梯度，所以 w 的更新方向其实与梯度直接相关。<strong>当 w 不幸到达某个值时，遇到梯度极大的情况，那么不管梯度是正还是负，都会将 w 更新到一个相对很大的值，从而 loss 值也会跟着改变。注：这里其实也与 learning rate 有关，因为原本的梯度都很小，所以我们初始设置的 lr 都很大。突然梯度增大，而 lr 没有适应，一个大的梯度乘上一个大的 lr，那就更大了</strong>。 <strong>解决办法</strong>是：当 gradient 大于某个 threshold 时，就不让它大于 threshold（视频中说作者的代码中将 threshold 设置为 15，但是这个 threshold 应该是具体情况具体分析）。 <div class="note warning"><p>Q：那么是什么导致了出现梯度猛增的现象呢？ A：首先不是 sigmoid 的锅。因为已知 sigmoid 函数只会导致 gradient vanishing（梯度消失）的问题（<em><a href="https://yan624.github.io/posts/b803ed7e.html#缺陷">sigmoid 的缺陷</a>这一章说明了 sigmoid 具有梯度消失的缺陷</em>）。<del>如果是 sigmoid 同时引起梯度爆炸和梯度消失，按理说换成 ReLU 就能同时解决梯度爆炸/消失，但是将 RNN 的激活函数换成 ReLU 并没有解决问题，所以跟激活函数没什么关系</del>（<strong>博主注</strong>：删除内容是从李宏毅老师的视频上记下来的，但是现在看来可能是我理解错了。首先在根本上就错了，sigmoid 会造成梯度消失，但替换品并不是 relu，而是 tanh，其也只是减缓作用而已）。 那么怎么说明是什么导致了梯度爆炸呢？我们只需要小小地改变一个参数，然后观察 output 的变化，就能测出这个参数的 gradient 的大小。现在假设激活函数是 y = w * x，序列长度为 1000，并且第一个 timestep 的输入为 1，其他的 timestep 皆为 0，则<span class="math inline">\(1^{1000} = 1\)</span>，而 <span class="math inline">\(1.01^{1000} \approx 20000\)</span>。既然结果那么大，我们可能会想到去减小 learning rate 从而减小梯度，但是 <span class="math inline">\(0.99^{1000} \approx 0\)</span>，你又要调大 learning rate，导致 lr 调起来很麻烦，所以调不调 lr 并没有什么区别。而这里就分别出现了梯度消失和梯度爆炸。这是由于 RNN 是序列模型，它需要处理一连串的序列。前一个的输出是后一个输入，<strong>类似于蝴蝶效应，一个很小的值，经过多个函数也能被放的很大。</strong> 那么为什么可以通过观察一个参数的变化从而观察 gradient 的变化呢？很简单，例如 y = w * x，用上面的例子，第 1000 个输出会是 <span class="math inline">\(y_{1000} = w^{1000} * x\)</span>，对 w 求导得 <span class="math inline">\(\Delta w = 1000 w^{999} x\)</span>，由于 <span class="math inline">\(w^{999}\)</span> 比 <span class="math inline">\(w^{1000}\)</span> 小不了多少，所以 gradient 很大。 经过上面的例子我们就知道了问题出现的原因。当然一般情况下不会像上面序列长度有 1000 那么离谱。现在设序列长度就 40，当我们遇到一个较大的值时（比如 <span class="math inline">\(1.1^{40} = 45.26\)</span>），依旧会出现梯度爆炸的问题。 解决办法：LSTM，clipping 等。<strong>注意：LSTM 只解决了 gradient vanishing 的问题，没有解决 gradient explode。详见《<a href="#LSTM解决了RNN的什么问题">LSTM 解决了 RNN 的什么问题</a>》章节</strong>。同理 clipping 也只能解决 gradient explode 的问题，因为它能将梯度限制在一个点上（<strong>这是博主的思考，视频中并没有给出此结论</strong>）。那么我们可以结合 LSTM 和 clipping，从而同时解决梯度爆炸/消失。 综上所述，在 RNN 中，即使参数在很小一个范围内，梯度的变化也会很大。 最后还有一个问题，就是上面的例子是用 y = w * x 的例子，但是实际上，激活函数是用的 sigmoid, tanh 等，所以每个神经元的输出都永远在 [-1, 1] 中间。那么怎么会造成上面的例子中的情况呢？其实上面的例子只是一个比喻。真正的原因是反向传播时做的链式求导，它导致了梯度的连乘。详细推导见《<a href="#simple-RNN-的缺陷">simple RNN 的缺陷</a>》蓝色提示框。</p>
</div></p>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><a href="https://www.bilibili.com/video/av10590361?p=37" target="_blank" rel="noopener">P37 26: Recurrent Neural Network (Part II)</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/34203833" target="_blank" rel="noopener">深入理解lstm及其变种gru</a></li>
</ol>
<h1 id="什么时候该用梯度裁剪">什么时候该用梯度裁剪？</h1>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/32154263" target="_blank" rel="noopener">浅谈神经网络中的梯度爆炸问题</a></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>nlp</category>
      </categories>
  </entry>
  <entry>
    <title>李宏毅迁移学习视频笔记</title>
    <url>/posts/ed3332ae.html</url>
    <content><![CDATA[<h1 id="什么是迁移学习">什么是迁移学习</h1>
<p>现在手上有一些与本实验没有直接关系的数据集，那么能不能使用该数据集来帮助我们做一些事情。</p>
<p>比如说要开发一个图像识别的模型，去识别医学上的图像。这方面的数据集可能很少，但是作为图片本身来说是有很多的。比如猫狗图片也是图片。 <a id="more"></a></p>
<h1 id="概要">概要</h1>
<p>与任务有关的数据被称为 target data，与任务没有直接关系的数据被称为 source data。每种数据都有可能有标签和无标签，所以一共分四种情况。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅迁移学习视频笔记/Transfer_Learning_Overview.jpg" alt="Transfer Learning Overview" /></p>
<h2 id="都有标签">都有标签</h2>
<p>Target data 和 Source data 都具有标签。 任务定义为：Target data:<span class="math inline">\((x^t, y^t)\)</span> 和 Source data:<span class="math inline">\((x^s, y^s)\)</span>。</p>
<h3 id="fine-tuning">Fine-tuning</h3>
<p>最常见以及最简单的做法是微调。<strong>Fine-tuning 在乎的是在 Target data 上的性能好不好，如果在 Source data 上的性能坏掉就算了。</strong>（25:00） 但是通常 Tartget data 的量是很少的，因为如果量多的话，直接当一般的机器学习方法来做就行了。总而言之，一般 Source data 的量会有很多。此外 Target data 很少，大概只有几个样本一般叫做 <strong>One-shot learning</strong>。 例如，Target data 是音频数据，并且是特定用户的声音，而 Source data 是许多人的声音。这里的处理方式是使用 Source data 来训练一个模型，然后使用 Target data 来微调。<strong>但是这可能会有个问题，当你使用 Target data 继续训练时，整个模型可能会坏掉。</strong> 接下里介绍一些可能能够解决的技巧： - Conservative Training：比如在语音辨识的任务中，使用 Source data 训练一个神经网络，这些数据都随处可见。但是你的 Target data 可能是用户特定的声音，可能只有 5 句、10 句。当然如果直接使用 Target data 训练模型肯定也是不行的，注意这个模型已经是之前使用 Source data 预训练的模型。（<em>李宏毅老师没说为什么。</em>）所以我们在微调的时候，需要加入一些正则化约束。通常我们会加 L1 和 L2，但是在 Consertive Training 中我们会加不同的正则化。总而言之，<strong>我们需要使得两个模型之间的输出时接近的，或者模型参数是接近的</strong>。（<em>具体怎么做，他也没说</em>。） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅迁移学习视频笔记/Conservative_Training.jpg" alt="Conservative Training" /> - Layer Transfer： 把模型中某几个 layer 拿出来，直接复制到新的模型中。1）然后使用 Target data 只训练自己定义的那几层 layer（<strong>防止过拟合</strong>）；2）当然如果你有足够多的 Target data，你也可以微调整个模型。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅迁移学习视频笔记/Layer_Transfer.jpg" alt="Layer Transfer" /> + 那么哪些 layer 应该被 transfer 呢？ * Speech：通常拷贝最后几层，然后重新训练 input 的那层。因为在语音识别中，人的发音均有不同，而模型的前几层可能与人的发音（浅层信息）有关。后几层可能与特定的人无关（深层信息）。 * Image：通常拷贝前几层，然后重新训练后几层。因为在机器视觉里，前几层可能捕获的是图片的浅层信息，而这些信息每个人看到的几乎都是一样。后面几层可能是深度的信息，每个任务需要的信息可能都是不同的。</p>
<h3 id="multitask-learning">Multitask Learning</h3>
<p>Multitask Learning 在乎的是在两个数据集上是否做得都好。 假设现在两个不同任务使用的是同样的 feature 的话（<em>图左</em>）。在叠几层神经网络后，在某一层分成两个任务做。那么这两个任务在前几层是共用特征的。所以在做 Multitask Learning 时，需要确定两个任务是否具有共通性，是否可以共用前几个 layer。 甚至现在有一些更疯狂的做法（<em>图右</em>）。模型的输入都可能没有办法共同学习，但是可以把两个特征输入进同一个模型，然后仅在某几层共享它们的特征。就算 task A 和 B 的输入特征完全不一样，但是只要你觉得在中间某几层有几个共同的地方，你还是可以用 Multitask Learning。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅迁移学习视频笔记/Multitask_Learning.jpg" alt="Multitask Learning" /></p>
<p>Multitask Learning 比较成功的案例是多语言语音识别。</p>
<h3 id="progressive-neural-network">Progressive Neural Network</h3>
<h2 id="source-data有标签">Source data有标签</h2>
<p>任务定义为：Source data:<span class="math inline">\((x^s, y^s)\)</span>，Target data:<span class="math inline">\((x^t)\)</span>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅迁移学习视频笔记/Source_data_with_label.jpg" title="Source data with label" alt="Source data with label" /></p>
<h3 id="domain-adversarial-training">Domain-adversarial training</h3>
<h3 id="zero-shot-learning">Zero-shot learning</h3>
]]></content>
      <categories>
        <category>notes</category>
        <category>transfer-learning</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>transfer learning</tag>
      </tags>
  </entry>
  <entry>
    <title>CS330：multitask learning and meta learning</title>
    <url>/posts/743b4b10.html</url>
    <content><![CDATA[<div class="note info"><p>视频来自 <a href="https://www.bilibili.com/video/BV15t4y127V1" target="_blank" rel="noopener" class="uri">https://www.bilibili.com/video/BV15t4y127V1</a>。视频于 12:25 正式开始。</p>
</div>
<h1 id="简介和概览">简介和概览</h1>
<p>本视频从 30:10 开始介绍多任务学习，之前都是在做简单的介绍。 首先如何定义任务（task）？给定数据集 <span class="math inline">\(\mathcal{D}\)</span> 以及损失函数 <span class="math inline">\(\mathcal{L}\)</span>，然后使用它们训练模型 <span class="math inline">\(f_{\theta}\)</span>。<em>这是目前的简单定义，课程后期会更严谨地进行定义。</em> 所以不同的任务会根据，1）不同的对象（different objects）比如一个任务是对猫分类，另一个任务是对杯子分类；2）不同的人（different people），对不同的人进行不同的预测；3）不同的目标（different objective）等进行变化。 <a id="more"></a></p>
<h2 id="批判性的假设">批判性的假设</h2>
<p>坏消息：<strong>不同的任务需要共享一些结构，如果你做不到这一点，那么你最好还是将它们拆开来，用原始的单任务学习方法。</strong> 好消息：<strong>许多任务都可以共享结构，即使它们在表面上看不出来可以共享结构，甚至可以是看起来毫无关联的任务。</strong></p>
<h2 id="非正式的问题定义">非正式的问题定义</h2>
<p>多任务学习问题：相比于独立地学习，学习所有的任务可以更快速以及更熟练。 元学习问题：给定先前任务上数据或者经验，在学习一个新任务时会更迅速并且/或者更熟练。 <strong>之后的课程会更形式化地进行定义</strong>。 视频中（38:00）的观点，transfer learning 更像是 multi-task learning 和 meta learning 的结合版。 视频中还有一个观点，<strong>多任务学习难道不是就是一个单任务学习吗</strong>？我们把所有的数据集拼接在一起 <span class="math inline">\(\mathcal{D} = \sum \mathcal{D}_i\)</span>，不就只剩一个数据集了？然后将所有的损失函数求和 <span class="math inline">\(\mathcal{L} = \sum \mathcal{L_i}\)</span>，不就是一个损失函数了？ 结论是这是可行的！但是我们可以做得更好。</p>
<h2 id="为什么要在现在研究多任务学习">为什么要在现在研究多任务学习？</h2>
<p>事实上 20 多年前就有人在研究了，1997 Caruana 提出了 Multitask Learning。事实上，早在 1992 年，Bengio 就提出了一种类似的思想。</p>
<h1 id="多任务学习和元学习基础">多任务学习和元学习基础</h1>
<ol type="1">
<li>Concatenation-based conditioning</li>
<li>Addive conditioning</li>
<li>Multi-head architecture</li>
<li>Multiplicative conditioning</li>
<li>More complex choice...</li>
</ol>
]]></content>
      <categories>
        <category>notes</category>
        <category>multi-task</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>multi-task learning</tag>
      </tags>
  </entry>
  <entry>
    <title>EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems</title>
    <url>/posts/b764c538.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/2003.02958.pdf" target="_blank" rel="noopener">论文地址</a>，作者为 Zandie et al.，发表于 2020 年。</p>
</div>
<h1 id="摘要以及引言">摘要以及引言</h1>
<p>理解情绪并且对此作出回复是对话系统最大的挑战之一。本轮提出 EmpTransfo，一个多头 Transformer 架构，用于创建一个移情对话系统。EmpTransfo 利用用于语言生成的一流预训练模型（例如 OpenAI-GPT），不过可以使用不同的大小。我们展示了利用历史的情绪以及其他的元数据（metadata）可以提高生成对话的质量。我们使用一个具有挑战性的语言语料库进行的实验结果表明，我们提出的方法在 Hit@1 以及 PPL（Perplexity）上优于其他模型。</p>
<p>人类拥有独特的能力，能够使用细微的情绪通过自然语言交流。大多数现存的对话系统关注语言生成以及提高生成语言的质量。尽管它们也很重要，但是移情的能力是进行高质量对话必不可少的一环。</p>
<p>近来，NLP 取得了巨大的成功，但是结合类似情绪（emotion）以及上下文知识仍旧是一个挑战。</p>
<p>尽管用于大多数传统对话系统的语料库通常是大规模的，但是它们缺乏特殊性，不包含情绪，主题，人格等原数据。基于通用语料库训练出来的系统导致对话助手无法理解情绪，缺乏人格并且趋向于产生通用的回复，例如“我不知道”。因此有必要创建一个带有更多上下文信息的数据集。例如 DAILYDIALOG 包含情绪，主题，动作。 <a id="more"></a></p>
<h1 id="related-work">Related Work</h1>
<p>。</p>
<h1 id="方法">方法</h1>
<p>预训练模型 nb。本文使用 GPT。</p>
<h2 id="empathetic-dialog-generation">Empathetic Dialog Generation</h2>
<p>假设在两个代理之间的对话中，每一个代理的每一轮对话都被称为“语句”（utterance）。因此一场对话由一系列的语句组成。一般化为，有 <span class="math inline">\(n\)</span> 条<strong>语句</strong> <span class="math inline">\(U = \{u_1, u_2, \cdots, u_n\}\)</span>，并且对于任何一句语句 <span class="math inline">\(i\)</span> 有 <span class="math inline">\(N_i\)</span> 个<strong>符号</strong>（token），即 <span class="math inline">\(U_i = \{t_1, t_2, \cdots, t_{N_i}\}\)</span>。对于每一条语句，也有一个<strong>情绪</strong>与之对应 <span class="math inline">\(E = \{e_1, e_2, \cdots, e_n\}\)</span>。<mark class="label danger">任务定义</mark></p>
<p>在我们的数据集中，一个样本是 <span class="math inline">\(u_1, u_2, \cdots, u_{T-1}, u_{next}\)</span>，其中 <span class="math inline">\(u_{next}\)</span> 可以代表下一条真实语句，也可以是来自一组 distractor <span class="math inline">\(U&#39;_T\)</span> 中的一个 distractor。一个 distractor 是来自数据集中的一条随机的语句。同理，如果序列对应的情绪为 <span class="math inline">\(\{e_1, e_2, \cdots, e_{T-1}, e_{next}\}\)</span>，那么 <span class="math inline">\(e_{next}\)</span> 就是下一条语句正确的情绪 <span class="math inline">\(e_T\)</span> 或者来自一组 distractor <span class="math inline">\(E&#39;_T\)</span> 中的一个 distractor。一个 distractor 是来自所有情绪集合中的一个随机情绪。<mark class="label warning">实验中数据集的结构</mark></p>
<p>我们的模型将序列输入进 Transformer。然后将输出喂入三个前馈神经网络头（three feed-forwad linear heads），负责生成下一个情绪，下一条句子，下一个符号。我们使用 12 层的架构，但是它可以被扩展，或者减小大小。接下来，我们定义这三个不同的头以及它们对应 loss 函数。<mark class="label info">模型计算步骤</mark></p>
<h3 id="language-modeling-head">Language modeling head</h3>
<p>语言建模的任务是，给定一个符号序列作为上下文，去预测下一个符号是什么。如果一个符号序列的下一条正确语句是 <span class="math inline">\(U_T = \{t_1, t_2, \cdots, t_N\}\)</span>，下一个符号的条件概率为： <span class="math display">\[P(t_i | t_1, \cdots, t_{i-1}) = softmax(h * W_1)
\]</span> <span class="math inline">\(h\)</span> 是 Transformer 上一个隐藏层的输出，<span class="math inline">\(W_1\)</span> 是符号嵌入矩阵，是可学习的。loss 函数定义为： <span class="math display">\[\mathcal{L}(U_T) = - \sum^N_{i=1} logP(t_i | t_1, \cdots, t_{i-1})
\]</span> 需要注意的是，语言模型的 loss 不在下一条句子的 distractor <span class="math inline">\(U&#39;_T\)</span> 上训练。</p>
<h2 id="next-utterance-prediction-head">Next utterance prediction head</h2>
<p>跟随 BERT（Devlin et al., 2018）的做法，在 next utterance prediction 中，我们尝试训练一个模型以实现在对话中预测下一条语句的功能。模型将学习区分正确语句和来自 distractor 中的语句。更具体来说，我们创建了一个分类器来计算下一条语句的概率： <span class="math display">\[P_u(a|u_1, u_2, \cdots, u_{T-1}) = softmax(h_1 * W_2)
\]</span> <span class="math inline">\(a\)</span> 被定义为： <span class="math display">\[
a = \begin{cases}
    1 &amp; \text{$u_{next} = u_T$} \\ 
    0 &amp; \text{$u_{next} \in U&#39;_T$}
\end{cases}
\]</span> <span class="math inline">\(h_1\)</span> 是来自 Transformer decoder 最后一个符号的隐藏状态，<span class="math inline">\(W_2\)</span> 是权重矩阵，是可学习的。然后 loss 函数被定义为： <span class="math display">\[\mathcal{L}_2(U_{1:T}) = -logP_u(a|u_1, u_2, \cdots, u_{T-1})
\]</span> <strong>博主注</strong>：<em>预测下一条语句是否正确的公式似乎有错误。因为它的输入仅仅是对话上下文，没有包含 distractor，这如何区分？所以这个公式我觉得应该是 <span class="math inline">\(P_u(a|u_1, u_2, \cdots, u_T) = softmax(h_1 W_2)\)</span></em></p>
<h2 id="next-emotion-prediction-head">Next emotion prediction head</h2>
<p>与 Next utterance prediction 类似，模型训练出来后用于区分正确的下一个情绪。</p>
<p><strong>本实验分别设计了带有和不带有 Next emotion prediction head 作为对比。</strong></p>
<h2 id="loss">Loss</h2>
<p>最后的 loss 是上述 3 个任务的 loss 的加和 <span class="math inline">\(\mathcal{L}_{total} = c_1 \mathcal{L_1} + c_2 \mathcal{L_2} + c_3 \mathcal{L_3}\)</span>。<span class="math inline">\(c_1, c_2, c_3\)</span> 在实验时调整。</p>
<h2 id="input-representation">Input Representation</h2>
<p>我们使用 DIALYDIALOG 数据集，它的每一句话都有情绪和动作所标注，同时整一场对话由一个主题所标注。表 ？（论文中的数字标错了，其实是表 1）展示了一个对话样本。由 4 句话组成，其中红色并且标注了 d 的语句时 distractor。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Towards Persona-Based Empathetic Conversational Models</title>
    <url>/posts/3b2a2032.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/2004.12316.pdf" target="_blank" rel="noopener">论文地址</a>，作者为 Zhong et al.，发表于 2020 年。 这论文现在叫 Endowing Empathetic Dialogue Systems with Personas。</p>
</div>
<h1 id="摘要以及引言">摘要以及引言</h1>
<p>移情对话模型已经在很多领域被证明能够提高用户的满意度和改进任务的结果。在心理学上，persona 被证明与 personality 高度关联，进而影响移情（博主注：<em>我实在不知道 persona 和 personality 有什么区别</em>）。此外，经我们的实证分析也认为 persona 在移情对话中扮演者重要的角色。为此，我们提出了一个 persona-based 移情对话的新任务，并<strong><u>首次</u>对 persona 在移情反应上的影响进行了实证研究</strong>。具体而言，我们<strong><u>首次</u>提出了一个用于 persona-based 移情对话的新的大规模多领域数据集 P</strong>ersona-based <strong>E</strong>mpathetic <strong>C</strong>onversion（<strong>PEC</strong>）。然后我们还提出了 <strong>CoBERT</strong>，一个基于 BERT 的高效回复检索模型，在我们的数据集上获得了一流的性能（<strong>博主吐槽</strong>：<em>你们自己首次提出的数据集，当然是一流的</em>）。最后做了总结。值得注意的是我们的结果展示出，<strong>当 CoBERT 在移情对话上训练而不是非移情对话上训练时，persona 能够提高移情回复的效果</strong>。 移情（empathy），严格来讲是情感共情（affective empathy），指的是用合适的情感（emotion）对他人的精神状态做出回应的能力。 当产生移情回应时，大多数现存的研究都没有考虑 persona。XiaoIce 有，但是她的 persona 是不可配置的，因此很难满足各种人类的需求。 <a id="more"></a></p>
<h1 id="related-work">Related Work</h1>
<p><strong>Empathetic Conversational Models</strong>：尽管对神经对话模型由越来越多的研究，但是在使对话具有移情的特性上依旧只有很少的关注，直到现在（<strong><em>一堆参考论文</em></strong>），可能是由于移情对话数据的缺少。Rashkin et al.(2019) 提出了首个移情对话数据集 EmpatheticDialogues（ED）。 <strong>Persona-based Conversational Models</strong>：今年，浮现的研究趋势是个性化的对话模型（personalizing conversational models）（<strong><em>一堆参考论文</em></strong>）。 <strong>Retrieval-based Conversational Models</strong>：……</p>
<h1 id="the-pec-dataset">The PEC dataset</h1>
<p>本节介绍采集过程和PEC 数据集的统计。</p>
<h2 id="data-source">Data Source</h2>
<p>我们从两个 reddit 的标签（<em>类似一个吧</em>） happy 和 offmychest（吐槽/吐苦水）收集移情对话。我们选择这两个标签，是因为他们发的内容具有迥异的情绪，并且他们的评论比之随意的对话，明显更有移情效果。</p>
<h2 id="conversation-collection">Conversation Collection</h2>
<p>Reddit 上的讨论是以线程的形式组织的，每个线程有一个帖子以及直接或者间接的评论。每一个线程都是一棵树（tree）的形式。因此，如果给定一个带有 <span class="math inline">\(n\)</span> 个节点的线程，我们可以提取出 <span class="math inline">\(n-1\)</span> 条对话。我们随机地将对话分割为 8:1:1。</p>
<h2 id="persona-collection">Persona Collection</h2>
<p>略，看不懂。</p>
<h2 id="data-processing">Data Processing</h2>
<p>对于每次对话，我们保留最多 6 条最近的轮数。我们过滤对话以确保：<strong>1）</strong>每条帖子在 2-90 个单词；<strong>2）</strong>每条评论在 2-30 个单词（帖子的标题通常长于评论。在 <em>happy</em> 上 87% 的帖子少于 90 个单词，82% 的评论少于 30 个单词。在 <em>offmychest</em> 上 24% 的帖子少于 90 个单词，59% 的评论少于 30 个单词）；<strong>3）</strong>所有的发言者最少有一个 persona 语句；<strong>4）</strong>the last speaker is different from the first speaker in each conversation（<em>看不懂</em>）。</p>
<h2 id="data-annotations">Data Annotations</h2>
<p>略。</p>
<h2 id="comparisions-with-related-datasets">Comparisions with Related Datasets</h2>
<p>表 4 呈现了 PEC 和相关数据集的比较情况。</p>
<h1 id="our-cobert-model">Our CoBERT Model</h1>
<p>本节介绍提出的模型，如图 2 所示。</p>
<h2 id="任务定义">任务定义</h2>
<p>给定对话数据集 <span class="math inline">\(\mathcal{D}\)</span>，由 N 条格式为 <span class="math inline">\((X, P, y)\)</span> 的对话组成。其中 <span class="math inline">\(X = \{X_1, X_2, \cdots, X_{n_X}\}\)</span> 表示 <span class="math inline">\(n_X\)</span> 条上下文语句，<span class="math inline">\(P = \{P_1, P_2, \cdots, P_{n_P}\}\)</span> 表示回复者的 <span class="math inline">\(n_P\)</span> 条 persona 语句，<span class="math inline">\(y\)</span> 表示 <span class="math inline">\(X\)</span> 的回复。the task of response selectioncan be formulated as learning a function <span class="math inline">\(f(X, P, y)\)</span> that assigns the highest score to the true candidate <span class="math inline">\(y\)</span> and lower scores to negative candidates given <span class="math inline">\(X\)</span> and <span class="math inline">\(P\)</span>。在推理阶段，训练好的模型选择候选列表中分数最高的语句。</p>
<h2 id="bert表征">BERT表征</h2>
<p>在输入 BERT 之前，将所有上下文语句拼接成一个单一的文本语句。由于 persona 语句没有顺序可言，所以我们将随机顺序的 persona 语句拼接起来。在 context，persona 和 response 输入进 BERT encoder 之后，我们获取了他们的向量表征 <span class="math inline">\(X \in \mathbb{R}^{m \times d}, P \in \mathbb{R}^{q \times d} and Y \in \mathbb{R}^{n \times d}\)</span>，<span class="math inline">\(d\)</span> 代表 BERT 的嵌入大小，<span class="math inline">\(m, q, n\)</span> 分别代表 context, persona, response 的序列长度。注意，不同的 segment id 用于区分上下文中 Speaker 和 Respondent 的话语。</p>
<h2 id="hop-1-co-attention">Hop-1 Co-attention</h2>
<p>给定 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span>，我们使用 co-attention（Lu et al., 2016）来学习 first order mathcing 信息。具体来讲，我们先计算单词之间的类同（word-word affinity）矩阵 <span class="math inline">\(A_{XY} \in \mathbb{R}^{m \times n}\)</span>： <span class="math display">\[A_{XY} = XY^T
\]</span> 然后计算上下文与回复之间的（context-to-response）attention <span class="math inline">\(A_{X2Y} \in \mathbb{R}^{m \times n}\)</span>，回复和上下文之间的（response-to-context）attention <span class="math inline">\(A_{Y2X} \in \mathbb{R}^{n \times m}\)</span>： <span class="math display">\[
\begin{align}
    A_{X2Y} &amp; = softmax(A_{XY}) \\
    A_{Y2X} &amp; = softmax(A^T_{XY}) \\
\end{align}
\]</span> softmax 计算第二个维度。最终，我们获得了 attended context 表征 <span class="math inline">\(X&#39; = A_{X2Y} Y \in \mathbb{R}^{m \times d}\)</span> 以及 attended response 表征 <span class="math inline">\(Y&#39;_X = A_{Y2X} X \in \mathbb{R}^{n \times d}\)</span>。 为了聚合 first order matching 信息，并提取 discriminative 特征，我们对 <span class="math inline">\(X&#39;\)</span> 和 <span class="math inline">\(Y&#39;_X\)</span> 沿着序列维度进行 max-pooling，得到 <span class="math inline">\(X&#39;_{max} \in \mathbb{R}^d\)</span> 和 <span class="math inline">\(Y&#39;_{X,max} \in \mathbb{R}^d\)</span>。</p>
<h2 id="hop-2-co-attention">Hop-2 Co-attention</h2>
<h2 id="loss">Loss</h2>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>I kown the feeling: Learning to converse with empathy</title>
    <url>/posts/bfd3a550.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://openreview.net/pdf?id=HyesW2C9YQ" target="_blank" rel="noopener">论文地址</a>，论文作者为 Rashkin et al.，发表于 2018 年。本文发布了一个情绪对话数据集。</p>
<p>我突然发现作者还有<a href="https://arxiv.org/pdf/1811.00207.pdf" target="_blank" rel="noopener">另一篇论文</a>，与这篇几乎一模一样。</p>
</div>
<h1 id="摘要与引言">摘要与引言</h1>
<p>对话代理的一个挑战是识别交谈对象的感受并且相应地做出回应，这一领域难做的原因是缺少合适、公开、可用的情绪（emotion）、对话（dialogue）数据集。本文提出一个新的移情对话生成（empathetic dialogue generation）任务以及一个移情对话数据集。与其他仅在大规模互联网对话数据上训练的模型相比，本实验表明使用此数据集训练的对话模型，由人类评测后被认为更具有同情心，同时在其他的指标上也有所改进（如 BLEU）。 <a id="more"></a></p>
<h1 id="related-work">Related Work</h1>
<p>对情绪的良好反应需要全面覆盖人类的表达。现有多种<strong>协议</strong>企图组织出一个情绪谱（spectrum of emotions），包括从来自生物反应的少数<strong>基本情绪</strong>（Ekman, 1992; Plutchik, 1984），到从上下文状态推理出的大规模<strong>细微情绪</strong>（Skerry &amp; Saxe, 2015）。<strong>我们融合多种标注协议的情绪</strong>，有一点需要注意，在对话场景中，仅从一个情景中就能推断出的情绪是很重要的。</p>
<p>分布式表征在当前一流的情绪分类模型中是其核心（一些论文），例如 emojis or hashtags，它们都采集自 twitter 上的公共媒体内容。<strong>SEMEVAL2019 EmoContext</strong> 挑战也是使用对话数据探测三种基本情绪。虽然公开的对话数据具有自发性（而非诱导性）数据的<strong>优点</strong>，但是它还有两个<strong>缺点</strong>：1）<em>总的来说就是人们在公开的平台上总是表达更完美的自己，在私下才会表达更强烈的负面情绪</em>；2）Twitter 通常限制为 140 个字符，这并不适用于一般的对话。本项工作试图产生覆盖情绪更平衡的内容，这更接近我们的终极目标，即培养出一种能够对任何情绪做出反应的对话。</p>
<p><em>一些相关工作</em></p>
<h1 id="taking-about-personal-situations">Taking about personal situations</h1>
<p>我们考虑一个开放域一对一的对话背景，即两个人在某种情形下交流，一人在谈论另一人身上发生的事。这导致一种给定感觉的体验。<mark class="label info">介绍数据集的构成</mark></p>
<h2 id="emotional-situation-grounding">Emotional situation grounding</h2>
<p>每个对话都基于一种<strong>情境（situation）</strong>。在给定情绪标签的情况下，参与者写下这一<strong>情境</strong>。图 2 罗列出了 32 种情绪类别，<strong>该集合的灵感来以前的数据集</strong>（<em>一些论文</em>），我们将它们整合到了一起。</p>
<h2 id="speaker-and-listener">Speaker and Listener</h2>
<p>写下情境描述的人（Speaker）开始一场对话。另一个对话参与者（Listener）通过 Speaker 所说的内容意识到潜在的<strong>情境</strong>，并作出回复。文中的模型是在 Listener 回应 Speaker 的环境下（<strong>博主注</strong>：即 Speaker 的输入已知，需要生成 Listener 的回复）进行测试的。但是该数据集也可以被用于为 Speaker 生成对话。</p>
<h2 id="采集细节">采集细节</h2>
<p>雇佣了 810 名美国工作者。每一对工作者被要求：<strong>1）</strong>分别选择一个情绪词（emtion word）并且描述他们体会到的一个情景（situation）；<strong>2）</strong>分别对每一个情景进行一场对话。</p>
<h2 id="任务设置">任务设置</h2>
<p>任务的第一阶段，要求工作者根据情绪标签用 1-3 句话描述一个情境。平均每个情境描述 19.8 个字。第二阶段，两名工作者互相聊天。每次对话被限制为 4-8 句长（平均每次对话 4.31 句），平均每条语句长 15.2 个字。 并且确保了情绪平衡的覆盖。</p>
<h2 id="empatheticdialogues-dataset-statistics">EMPATHETICDIALOGUES dataset statistics</h2>
<p>包含 24850 条对话，收集自 810 个不同的参与者，它们将可以通过 ParlAI 在网上公开可用。对话大于被分割为 80% 训练集，10% 验证集，10% 测试集，实际为 19533/2770/2547。<mark class="label default">数据集的比例</mark></p>
<h1 id="empathetic-dialogue-generation">Empathetic Dialogue Generation</h1>
<p>本节描述我们的数据集是怎么能够使得普通的闲聊模型更具同情心（empathetic）的，与其他现存模型不同，它能够生成更具有移情能力的回复。我们让模型扮演 Listener 的角色来训练和评估模型。<strong>在测试阶段，对话模型可以访问对话前一句的句子，但是不能访问情绪词提示（例如“proud”），也不能访问由 Speaker 生成的情境描述</strong>。<strong>博主注</strong>：<em>这可能是因为在真实的场景下，无法获取到用户的情绪，也无法得到情境。此外这是否意味着训练和评估的时候可以访问？</em>给定 <span class="math inline">\(n\)</span> 句之前的对话语句，定义为对话上下文 <span class="math inline">\(x\)</span>，并拼接以及标记成 <span class="math inline">\(x_1, \cdots, x_m\)</span>。然后是生成的目标（target）回复 <span class="math inline">\(\bar{y}\)</span>，我们的模型最大化目标回复的似然估计 <span class="math inline">\(p(\bar{y} | x)\)</span>。我们分别调查了生成和检索（retrieval）的设置。</p>
<h2 id="基本架构">基本架构</h2>
<p>模型基于 Transformer。</p>
<p><strong>Retrieval</strong>：给定一个候选回复的大型集合 <span class="math inline">\(Y\)</span>，让模型去选择最好的那个 <span class="math inline">\(y^*\)</span>。我们首先在基于 Transformer 的检索架构（<a href="https://arxiv.org/pdf/1804.07754.pdf" target="_blank" rel="noopener" title="Learning semantic textual similarity from conversations">Yang et al., 2018</a>）上做实验。我们也在 BERT 上做了实验。<strong>在训练的时候，我们将来自同一批次的所有语句作为候选回复，批次大小设置为 512，这样可以给模型更多负例。</strong>（BERT 用了 256）。在推理的时候，我们选择了三个候选回复集合，它们收集自：ED 训练集中的所有回复语句 <span class="math inline">\(Y^ED\)</span>；DailyDialog 中的所有语句 <span class="math inline">\(Y^DD\)</span>；一百万条语句 <span class="math inline">\(Y^R\)</span>，它们来自拥有 17 亿条数据的 Reddit 对话数据集。</p>
<p><strong>Generation</strong>：Transformer decoder 使用 encoder 的输出去预测一系列单词 <span class="math inline">\(y\)</span>，最小化生成序列 <span class="math inline">\(\bar{y}\)</span> 的负对数似然。在推理阶段，我们使用来自 <a href="https://arxiv.org/pdf/1610.02424.pdf" target="_blank" rel="noopener">Vijayakumar et al. (2016)</a> 的 diverse beam search。</p>
<p><strong>Training Details</strong>：先使用 17 亿的 Reddit 对话数据进行预训练，使用 Transformer 或者 BERT-base 从头开始训练。<em>具体参数参考论文，不做赘述</em>。Transformer 使用 Fasttext 预训练词向量，对于 BERT，使用在 BooksCorpus 和 English Wikipedia 上预训练出来的词向量。</p>
<h2 id="利用来自ed的训练数据">利用来自ED的训练数据</h2>
<p>基于检索的模型依赖候选对象。我们的数据明确地指定需要有同情心，以一对一对话的背景，这意味着不同于用于预训练的 Reddit 对话数据集，这些领域的候选对象也许比通用的对话更适合移情反应。<strong>因此，我们的实验直接将 ED 候选对象直接放入在推理时使用的候选池中，而<u>不对 ED 进行微调</u></strong>。<mark class="label info">检索模型的候选池还使用了 ED 数据</mark></p>
<p>对基于检索的模型和基于生成的模型我还使用微调过的预训练模型，去预测下一条句子，其中对话上下文是前 4 句话的窗口，这是我们数据集中对话的平均长度。在文章中，使用此方法的模型被称为 “File-Tuned” 模型。<strong>除了模型中的预训练步骤，此微调步骤会在所有建构中被一直使用，直到模型收敛</strong>。<mark class="label danger">使用 ED 进行微调</mark></p>
<h1 id="adding-information-from-external-predictor">Adding Information From External Predictor</h1>
<p>许多现存的模型已经在监督任务上训练好了，这些模型也许与移情回复有关。例如预测 tweets 的 emoji 标签。这些模型与我们的基础架构的表征结合，也许可以取得收益。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>dataset</tag>
      </tags>
  </entry>
  <entry>
    <title>情感计算论文笔记</title>
    <url>/posts/ebc36368.html</url>
    <content><![CDATA[<div class="note info"><p>目前所记录的论文，只截止到 2020 年。</p>
</div>
<h1 id="towards-persona-based-empathetic-conversational-models">Towards Persona-Based Empathetic Conversational Models</h1>
<ul>
<li><a href="https://yan624.github.io/posts/3b2a2032.html">论文笔记</a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/CoBERT.jpg" alt="CoBERT 结构图" /> <a id="more"></a></li>
</ul>
<h1 id="emptransfo-a-multi-head-transformer-architecture-for-creating-empathetic-dialog-systems">EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems</h1>
<ul>
<li><a href="https://yan624.github.io/posts/b764c538.html">论文笔记</a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/EmpTransfo.jpg" alt="EmpTransfo" /></li>
</ul>
<h1 id="caire-an-empathetic-neural-chatbot">CAiRE: An Empathetic Neural Chatbot</h1>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/CAiRE.jpg" title="CAiRE" /></p>
<ul>
<li><strong>Language Model Pre-training</strong>：使用 GPT，在大型文本语料库 BooksCorpus 上进行预训练，可以使得模型能够捕获对话跨度足够大的上下文信息。</li>
<li><strong>Persona Dialogue Pre-training</strong>：现存的移情对话数据集相对较小，仅在这数据集上进行微调可能会限制模型在闲聊时的所拥有的话题。为了增强 CAiRE 在闲聊时的能力，参照 Wolf et al., 2019 的迁移学习策略，我们先在 PersonaChat 上对模型进行预训练。该预训练步骤给予 CAiRE 一个 persona，因此提高了模型的参与度和一致性。</li>
<li><strong>Empathetic Dialogue Fine-tuning</strong>：使用 EmpatheticDialogues。在训练的时候给出 speaker 的情绪标签，但是在评估时，不给出。
<ul>
<li><strong>Fine-tuning Detail</strong>
<ul>
<li>为了完全利用在 PersonaChat 上预训练的效果，我们自定义了 CAiRE 的 persona 语句：<em>&quot;my name is caire&quot;, &quot;i want to help humans to make a better world&quot;, &quot;i am a good friend of humans&quot;</em>（<strong>博主注</strong>：<em>这些语句代表着 CAiRE 的人物定位</em>）。照着 Wolf et al., 2019 的微调协议，我们首先拼接了自定义 persona，对话历史以及回复（distractor）。使用了特殊符号，并且所有的嵌入都是由位置嵌入，词嵌入和对话状态嵌入相加而成。前两个是 Transformer 所需，对话状态嵌入帮助 CAiRE 对对话的体系结构建模，同时用于区分 persona 语句，对话上下文语句和回复。表征输入进 Transformer 后生成上下文表征，我们将最后一个符号定义为 <span class="math inline">\(SEN\)</span>，回复（distractor）之前的符号定义为 <span class="math inline">\(EMO\)</span>。</li>
<li>为了<strong>优化回复预测的目标对象</strong>，在每一个训练步，我们从其他对话中采样出一个 distractor 来对抗真实的回复。然后将 SEN 表征输入一个线性层，区分是否为真实的回复，然后得到 cross-entropy <span class="math inline">\(\mathcal{L}_S\)</span>。</li>
<li>为了<strong>优化回复的语言模型的目标对象</strong>，我们用真实回复的上下文表征去预测下一个回复的符号，然后使用 cross-entropy 计算语言模型的 loss <span class="math inline">\(\mathcal{L}_L\)</span>。</li>
<li>为了<strong>使 CAiRE 探测到对话伙伴的情绪</strong>，我们在训练阶段新增了一个对话情绪探测优化目标。我们将 EMO 作为当前对话状态的摘要，然后将其输入进线性映射层，去预测 32 个情绪的分数。cross-entropy 被用于计算情绪类别的 loss <span class="math inline">\(\mathcal{L}_E\)</span></li>
<li>最终，我们在最后的 loss 函数上进行微调：<span class="math inline">\(\mathcal{L} = \alpha \mathcal{L}_L + \mathcal{L}_S + \mathcal{L}_E\)</span></li>
</ul></li>
</ul></li>
</ul>
<h1 id="moel-mixture-of-empathetic-listeners">MoEL: Mixture of Empathetic Listeners</h1>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/MoLE.jpg" title="MoLE" /></p>
<ul>
<li>以前的移情对话系统研究大多数关注的是给定某个情绪，生成一个回复。然而要使得系统具有移情能力，更重要的是需要理解用户的情绪以及合适的回复。本文提出一个 end-to-end 方法，用于对移情对话系统建模，即 Mixture of Empathetic Listeners（<strong>MoEL</strong>）。我们的模型<strong>首次捕获了用户的情绪并且输出一个情绪分布</strong>。
<ul>
<li>目前移情对话回复生成主要有两条线：<strong>1）</strong>多任务方法，联合训练一个模型，预测用户当前的情绪状态以及基于此状态合适的回复；<strong>2）</strong>调节对某一固定情绪的回复生成。</li>
</ul></li>
<li><strong>Mixture of Empathetic Listeners</strong>：对话上下文是一组来自 Speaker 和 listener 的交替语句，表示为 <span class="math inline">\(\mathcal{C} = \{U_1, S_1, U_2, S_2, \cdots, U_t\}\)</span>，speaker 每句话的情绪状态表示为 <span class="math inline">\(Emo = \{e_1, e_2, \cdots, e_t\}, \, \forall e_i \in \{1, \cdots, n\}\)</span>。<strong>我们的模型旨在追踪上下文中 speaker 的情绪状态 <span class="math inline">\(e_t\)</span>，并且生成一个移情回复 <span class="math inline">\(S_t\)</span></strong>。总的来说，如图 1 所示，MoEL 由三个组件组成：emtion tracker, emotion-aware listeners and meta listener。<strong>1）</strong>emtion tracker 编码 <span class="math inline">\(\mathcal{C}\)</span> 以及计算用户情绪的分布。<strong>2）</strong>emotion-aware listeners <strong>独立地</strong>关注上述分布并计算它们自己的分布。<strong>3）</strong>最后，meta listener 采用来自 emotion-aware listeners 的加权表征，然后生成最终的语句。<mark class="label primary">模型架构</mark> <mark class="label danger">任务定义和介绍模型计算流程</mark>
<ul>
<li><strong>Embedding</strong>：定义上下文嵌入为 <span class="math inline">\(E^C \in \mathbb{R}^{|V| \times d_{emb}}\)</span>，回复的嵌入为 <span class="math inline">\(E^R \in \mathbb{R}^{|V| \times d_{emb}}\)</span>。在多轮对话中，模型能够区分不同的轮数是至关重要的。因此我们在输入中加入了对话状态的嵌入，这被用于使 encoder 能够区分 speaker 或者 listener 的语句（Wolf et al., 2019）。此外还加入了位置编码，所以上下文嵌入表示为 <span class="math inline">\(E^C(C) = E^W(C) + E^P(C) + E^D(C)\)</span>。<span class="math inline">\(E^W\)</span> 代表词向量，<span class="math inline">\(E^P\)</span> 代表位置编码，<span class="math inline">\(W^D\)</span> 代表对话状态（<em>对话状态指的是什么，请参考 Wolf et al., 2019</em>）。</li>
<li><strong>Emotion Tracker</strong>：此模块使用标准的 Transformer。首先拼接所有对话轮数，使用 <span class="math inline">\(E^C\)</span> 将所有符号映射为向量表征。然后开始编码。类似 BERT，为了计算输出张量的加权和，我们在每一个输入序列的开头增加了一个 query 符号 <span class="math inline">\(QRY\)</span>。将 Transformer 的编码器表示为 <span class="math inline">\(TRS_{Enc}\)</span>，那么对应上下文表征如下所示，<span class="math inline">\(H \in \mathbb{R}^{L \times d_{model}}\)</span>，其中 L 是序列长度。 <span class="math display">\[H = TRS_{Enc}(E^C([QRY; C]))
  \]</span> 那么我们可以定义符号 <span class="math inline">\(QRY\)</span> 最后的表征为：<span class="math inline">\(q = H_0, q \in \mathbb{R}^{d_{model}}\)</span>，然后它被用于生成情绪的分布。</li>
<li><strong>Emotion Aware Listeners</strong>：这主要由 <strong>1）</strong>shared listener（学习每个情绪的共享信息）；<strong>2）</strong>n 个独立的 Transformer decoder（学习在给定一个特定的情绪状态下，做出合适的反应）组成。我们定义 listeners 的集合为：<span class="math inline">\(L = [TRS^0_{Dec}, \cdots, TRS^n_{Dec}]\)</span>。每个情绪回复表征为： <span class="math display">\[V_i = TRS^i_{Dec}(H, E^R(r_{0:t-1}))
  \]</span> <span class="math inline">\(TRS^i_{Dec}\)</span> 指的是第 i 个 listener，包括 shared listener。在概念上，我们希望 shared listener 的输出是一个通用表征，可以帮助模型捕获对话上下文。而每个 empathetic listener 的职责是学习怎样用某种情绪进行回复。<strong>为了使模型拥有这些行为，我们根据用户的情绪分布给不同的 empathetic listener 分配了不同的权重，但是给 shared listener 分配固定的权重 1</strong>。（这个权重在最后加权和的时候用）
<ul>
<li>构建了一个 Key-Value Memory Network（Miller et al., 2016），用于为 listener 分配不同的权重。</li>
</ul></li>
<li><strong>Meta Listener</strong>：最后，该组件使用的是另一个 Transformer decoder，它进一步地转换了 listeners 的表征并且生成了最后的回复语句。<strong>直觉是每个 listener 专门针对某种情绪，meta listener 收集多个 listener 的意见，并产生最终的回复。</strong>此模块的公式定义类似。</li>
</ul></li>
</ul>
<h1 id="i-kown-the-feeling-learning-to-converse-with-empathy">~I kown the feeling: Learning to converse with empathy</h1>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/ED.png" title="ED" /></p>
<ul>
<li><a href="https://yan624.github.io/posts/bfd3a550.html">论文笔记</a></li>
</ul>
<h1 id="towards-empathetic-open-domain-conversation-models-a-new-benchmark-and-dataset">~Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset</h1>
<p>同上一篇论文，它们是一样的。</p>
<h1 id="emotional-chatting-machine-emotional-conversation-generation-with-internal-and-external-memory">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</h1>
<ul>
<li><a href="https://yan624.github.io/posts/e5ce1f40.html">论文笔记</a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/ECM.jpg" alt="ECM" /></li>
<li>他们的模型定义为 <span class="math inline">\(P(Y|X, e) = \prod^m_{t=1} P(y_t | y_{&lt;t}, X, e)\)</span>，Y 是回复，X 是用户输入，e 是情绪类别的嵌入（<strong>该论文假定 e 已经预先给定</strong>）。直观来说就是在给定用户输入语句和<strong>待生成回复</strong>的情绪类别（emotion categories）的条件下，生成回复（<em>当然这几乎是不切实际的，因为你无法预先知道机器的回复需要附带什么样的情绪，所以这个类别 <span class="math inline">\(e\)</span> 我该分配什么情绪？《Affective Neural Response Generation》也这么认为</em>）。</li>
<li>ECM 的工作流程是：<strong>1）</strong>在训练步骤，将语料输入情绪分类器，得到情绪，于是原语料变为 (post, response, emtion) 形式的三元组；<strong>2）</strong>在推理过程中，post 被输入进 ECM 以生成给予不同情绪类别的回复（<strong>博主注</strong>：此文章不可控制生成回复的情绪类别，只能为每一种情绪类别都生成一句合适的回复。比如说现在系统中定义了 5 种情绪类别，现在用户很悲伤，需要机器生成“安慰”的语句。但是 ECM 做不到，它只能遍历所有的情绪类别，然后为每一种类别生成一句回复）。</li>
<li><strong>Emotion Category Embedding</strong> 提取情绪类别的嵌入。</li>
<li><strong>Internal Memory</strong> 使用词向量，GRU 隐藏状态和上下文向量的拼接版进行计算。先使用 sigmoid 函数分别计算 read gate 和 write gate 的状态 <span class="math inline">\(g^r_t \, g^w_t\)</span>，然后 <span class="math inline">\(g^r_t\)</span> 使用<strong>对应元素相乘的乘法（element-wise multiplication）</strong>从 Internal Memory <span class="math inline">\(M^I_{e,t}\)</span> 中提取一定量的记忆 <span class="math inline">\(M^I_{r,t}\)</span>（都是玄学，意会就行，不用试图理解），<span class="math inline">\(M^I_{r,t}\)</span> 将与拼接版向量同时被喂入 GRU。最后 GRU 生成的隐藏状态 <span class="math inline">\(s_t\)</span> 通过 <span class="math inline">\(g^w_t\)</span> 提取出一定的记忆 <span class="math inline">\(M^I_{e,t+1}\)</span> 写入 Internal Memory。受到心理学上的启发，情绪化回应是相对短暂的，所以<strong>凭借此 Internal Memory 记录用户交谈过程中的短暂情绪变化</strong>。之前说到该记忆状态 <span class="math inline">\(M^I\)</span> 会与拼接后的向量同时输入进 GRU，这就意味着<strong>该情绪记忆会影响解码过程</strong>。特别地，该记忆模块不同于其他的记忆模块，如 LSTM，当解码过程结束后，<strong>记忆模块中的状态应该衰减至 0</strong>，这代表着情绪被机器完全地表达出来。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/ECM：Internal%20Memory.jpg" alt="Internal Memory" /></li>
<li><strong>External Memory</strong> 通过 GRU 的隐藏状态 <span class="math inline">\(s_t\)</span> 计算下一个单词概率。单词的概率分布由两部分组成，一是情绪词表的概率分布，二是通用词表的概率分布，二者拼接后通过此拼接的概率分布计算下一个单词的概率。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/情感计算论文笔记/ECM：External%20Memory.jpg" alt="External Memory" /></li>
</ul>
<h1 id="transfertransfo-a-transfer-learning-approach-for-neural-network-based-conversational-agents">TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents</h1>
<div class="note warning"><p>此论文不算是情感计算的论文，由于上述有几篇论文用到了这论文的一些方法，所以这里也加进去了。</p>
</div>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>affective computing</tag>
      </tags>
  </entry>
  <entry>
    <title>情感计算论文调研</title>
    <url>/posts/db974a7a.html</url>
    <content><![CDATA[<div class="note warning"><p>2020.10.24 留：本文未完成。</p>
</div>
<h1 id="introduction">Introduction</h1>
<p>情感计算（affective computing），移情计算（empathetic computing）。 <a id="more"></a></p>
<h1 id="related-work">Related Work</h1>
<div class="tabs" id="情感计算论文对比"><ul class="nav-tabs"><li class="tab active"><a href="#情感计算论文对比-1">论文介绍</a></li><li class="tab"><a href="#情感计算论文对比-2">论文瑕瑜</a></li></ul><div class="tab-content"><div class="tab-pane active" id="情感计算论文对比-1"><table>
<colgroup>
<col style="width: 23%" />
<col style="width: 23%" />
<col style="width: 28%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th>论文</th>
<th style="text-align: center;">模型</th>
<th>标签</th>
<th style="text-align: center;">评价指标</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#Towards-Persona-Based-Empathetic-Conversational-Models" title="Endowing Empathetic Dialogue Systems with Personas"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/2004.12316.pdf" target="_blank" rel="noopener" title="20.06"><i class="fa fa-"></i>论文</a> Zhong et al., 2020</td>
<td style="text-align: center;">BERT</td>
<td><mark class="label primary">移情计算</mark> <mark class="label primary">PEC</mark> <mark class="label danger">Co-attention</mark></td>
<td style="text-align: center;"><mark class="label success">R#k</mark> <mark class="label success">MRR</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#EmpTransfo-A-Multi-head-Transformer-Architecture-for-Creating-Empathetic-Dialog-Systems" title="EmpTransfo: A Multi-head Transformer Architecture for Creating Empathetic Dialog Systems"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/2003.02958.pdf" target="_blank" rel="noopener" title="20.03"><i class="fa fa-"></i>AAAI</a> Zandie et al., 2020</td>
<td style="text-align: center;">GPT2</td>
<td><mark class="label primary">移情计算</mark> <mark class="label primary">DailyDialog</mark> <mark class="label success">multi-task learning</mark> <strong><mark class="label info">Three Head</mark></strong></td>
<td style="text-align: center;"><mark class="label info">perplexity(PPL)</mark> <mark class="label success">Hit#1</mark> <mark class="label success">BLEU</mark> <mark class="label success">F1</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#caire-an-empathetic-neural-chatbot" title="CAiRE: An Empathetic Neural Chatbot"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1907.12108.pdf" target="_blank" rel="noopener" title="19.07"><i class="fa fa-"></i>AAAI</a> Lin et al., 2019a</td>
<td style="text-align: center;">GPT</td>
<td><mark class="label primary">移情计算</mark> <mark class="label primary">EmpatheticDialogues</mark> <mark class="label primary">PersonaChat</mark> <mark class="label success">multi-task learning</mark></td>
<td style="text-align: center;"><mark class="label info">PPL</mark> <mark class="label success">AVG BLEU</mark> <mark class="label success">EMO ACC</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#MoEL-Mixture-of-Empathetic-Listeners" title="MoEL: Mixture of Empathetic Listeners"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1908.07687.pdf" target="_blank" rel="noopener" title="ijcnlp 19.08"><i class="fa fa-"></i>ACL</a> Lin et al., 2019b</td>
<td style="text-align: center;">Transformer</td>
<td><mark class="label primary">移情计算</mark> <mark class="label primary">EmpatheticDialogues</mark> <strong><mark class="label success">Emotion Tracker</mark></strong> <strong><mark class="label info">Emotion Aware Listener</mark></strong> <strong><mark class="label danger">Meta Listener</mark></strong> <mark class="label warning">Mixture Of Expert</mark> <mark class="label default">response comparison</mark> <mark class="label default">listener analysis</mark> <mark class="label default">visualize Emotion Dist</mark></td>
<td style="text-align: center;"><mark class="label success">BLEU</mark> <mark class="label primary">Relevance</mark> <mark class="label primary">Fluency</mark> <mark class="label primary">Empathy</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#I-kown-the-feeling-Learning-to-converse-with-empathys" title="I kown the feeling: Learning to converse with empathy"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://openreview.net/pdf?id=HyesW2C9YQ" target="_blank" rel="noopener" title="18.09"><i class="fa fa-"></i>ICLR</a> <font color='blue'>rashkin et al., 2018</font><a class="btn" href="https://arxiv.org/abs/1811.00207" target="_blank" rel="noopener" title="18.11"><i class="fa fa-"></i>ACL</a> 2019</td>
<td style="text-align: center;">Transformer / BERT</td>
<td><mark class="label primary">移情计算</mark> <mark class="label primary">EmpatheticDialogues</mark></td>
<td style="text-align: center;"><mark class="label info">PPL</mark> <mark class="label success">P#1,100</mark> <mark class="label success">AVG BLEU</mark> <mark class="label primary">Fluency</mark> <mark class="label primary">Empathy</mark> <mark class="label primary">Relevance</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html##Emotional-Chatting-Machine-Emotional-Conversation-Generation-with-Internal-and-External-Memory" title="Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1704.01074.pdf" target="_blank" rel="noopener" title="17.04"><i class="fa fa-"></i>AAAI</a> Zhou et al., 2017</td>
<td style="text-align: center;">GRU</td>
<td><mark class="label primary">情感计算</mark> <mark class="label primary">ESTC</mark> <strong><mark class="label info">Emotion Category Embedding</mark></strong> <strong><mark class="label success">Internal Memory</mark></strong> <strong><mark class="label primary">External Memory</mark></strong> <mark class="label warning">emotion accuracy</mark> <strong><mark class="label danger">loss function</mark></strong></td>
<td style="text-align: center;"><mark class="label info">PPL</mark> <mark class="label success">EMO ACC</mark> <mark class="label success">Content</mark> <mark class="label success">Emotion</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#TransferTransfo-A-Transfer-Learning-Approach-for-Neural-Network-Based-Conversational-Agents" title="TransferTransfo: A Transfer Learning Approach for Neural Network Based Conversational Agents"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1901.08149.pdf" target="_blank" rel="noopener" title="19.01"><i class="fa fa-"></i>AAAI</a> Wolf et al., 2019</td>
<td style="text-align: center;">Transformer</td>
<td></td>
<td style="text-align: center;"><mark class="label success">Hits#1</mark> <mark class="label success">F1</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/ebc36368.html#btn"><i class="fa fa-"></i>笔记</a><a class="btn" href="#url"><i class="fa fa-"></i>论文</a></td>
<td style="text-align: center;">-------</td>
<td>----------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td>---------------------</td>
<td style="text-align: center;">粗体代表有启发的论文</td>
<td>粗体代表有启发的思想</td>
<td style="text-align: center;">----------------</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="情感计算论文对比-2"><table>
<colgroup>
<col style="width: 23%" />
<col style="width: 52%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th>论文</th>
<th>实现的功能</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Zhong et al., 2020</td>
<td></td>
<td><strong>1）</strong>通过二分类，选取候选回复</td>
</tr>
<tr class="even">
<td>Zandie et al., 2020</td>
<td><strong>1）</strong>使用 GPT-2 进行预训练；<strong>2）</strong>LM head 可以预测下一条语句；<strong>3）</strong>NUP head 预测下一条语句是否与输入语句匹配；<strong>4）</strong>NEP head 预测下一条语句的情绪；<strong>4）</strong>词嵌入的用法与 Transformer 类似</td>
<td><strong>1）</strong>为了使用合适的情绪进行回复，需要使用到<strong>情绪</strong>、<strong>动作</strong>和<strong>主题</strong>等元信息（<em>作者自己这么认为的</em>）；</td>
</tr>
<tr class="odd">
<td>Lin et al., 2019a</td>
<td><strong>1）</strong>使用 GPT 在 BooksCorpus 上预训练；<strong>2）在 PersonaChat 上进行预训练</strong>；<strong>3）使用三句话赋予 CAiRE 一个人物定位</strong>；<strong>4）</strong>SEN 预测 distractor 是否为真实回复；<strong>5）</strong>LM 生成回复；<strong>6）</strong>EMO 预测对话上下文的情绪。</td>
<td><strong>1）</strong></td>
</tr>
<tr class="even">
<td>Lin et al., 2019b</td>
<td><strong>1）Emotion Tracker 追踪对话上下文中的情绪</strong>；<strong>2）Emotion Aware Listeners 分别监听 36 种情绪以及一种通用情绪的信息</strong>；<strong>3）Meta Listener 收集多个 Listener 的意见，并产生最终的回复</strong>。</td>
<td><strong>1）</strong>需要为每种情绪都分配一个监听器，未免有些不灵活；</td>
</tr>
<tr class="odd">
<td>rashkin et al., 2018</td>
<td><strong>1）</strong>提出了 EmpatheticDialogues 数据集；<strong>2）</strong>提出了 Pre-trained、Fine-tuned、EmoPrepend-k、TopicPrepend-k、<em>Multi-task</em> 和 <em>Ensem-DM</em> 基线模型</td>
<td></td>
</tr>
<tr class="even">
<td>Zhou et al. 2017</td>
<td><strong>1）</strong>使用情绪分类器对数据集进行自动标注；<strong>2）</strong>给定用户的输入，通过 embed 层和两个 Memory 组件，能够根据不同的情绪类别，生成特定的情绪化语句；<strong>3）外部记忆通过为情感词和通用词分配不同的概率，从而生成更优质的回复</strong></td>
<td><strong>1)</strong>在编码过程中，输入需要包含待生成语句的情绪（emotion） <span class="math inline">\(e\)</span>，这是不现实的，因为在实际应用中，你并不知道返回的语句需要包含什么情绪</td>
</tr>
<tr class="odd">
<td>-----------------</td>
<td>粗体代表不错的想法</td>
<td>斜体代表在以后的论文中此缺点大致已被解决</td>
</tr>
</tbody>
</table></div></div></div>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1704.01074.pdf" target="_blank" rel="noopener">Zhou et al. 2017</a> 提出了 <strong>Emotional Chatting Machine</strong>（<strong>ECM</strong>），该模型不可控制<u style="text-decoration-style: wavy;">生成回复</u>的情绪类别。比如说现在系统中定义了 5 种情绪类别，现在用户很悲伤，需要机器生成 “安慰” 的语句。但是 ECM 做不到，它只能遍历所有的情绪类别，然后为每一种类别生成一句回复。<br />
<strong>请注意，由于此论文为 2017 年提出，此时并没有支持 ECM 训练的数据集，所以他们先在 NLPCC2013 和 NLPCC2014 的一个情绪分类数据集上训练了一个情绪分类器（emotion classifier） ，然后使用这个分类器对 STC 数据集进行自动标注，从而生成一个全新的带有情绪的数据集。他们称之为 ESTC，不过由于自动标注，必不可免地拥有噪声。</strong><br />
<strong>Emotion Category Embedding</strong> 提取情绪类别的嵌入。<strong>Internal Memory</strong> 记录用户交谈过程中的短暂情绪变化，该模块中的情绪状态向量 <span class="math inline">\(M^I\)</span> 会影响解码过程。特别地，其不同于其他模型的记忆模块，当解码过程结束后，记忆模块中的状态应该衰减至 0，这代表着情绪被机器完全地表达出来。<strong>External Memory</strong> 通过对情感词（emotion words）和通用词（generic words）分配不同的生成概率，从而生成进一步情绪词。由于内部情绪状态和被挑选出的单词之间并不具有明显的关系，而有些词汇可以很好的表达出感情，例如 awesome，所以需要一个外部记忆模块控制这些情绪词。（<strong>博主注</strong>：<em>原论文中并没有写明 Internal Memory（下称 IM） 和 External Memory（下称 EM） 的具体用法，但是我认为 IM 应该是配合着 GRU 使用，它是 GRU 的输入之一，同时 GRU 也会影响 IM 的状态。而 EM 是在 GRU 生成隐藏状态 <span class="math inline">\(s_t\)</span> 后使用的，EM 用于进一步完善所生成单词的概率分布。</em>）<br />
另外此文的 loss function 设计的很有启发性。</li>
<li><a href="https://arxiv.org/abs/1811.00207" target="_blank" rel="noopener">Rashkin et al., 2018</a> 提出了一个数据集 <strong>EmpatheticDialogues</strong>，以及提出了 Pre-trained、Fine-tuned、EmoPrepend-k、TopicPrepend-k、<em>Multi-task</em> 和 <em>Ensem-DM</em> 基线模型。</li>
<li><a href="https://arxiv.org/pdf/1908.07687.pdf" target="_blank" rel="noopener">Lin et al., 2019b</a> 提出了 <strong>MoLE</strong> 架构，在 EmpatheticDialogues 数据集上进行训练,使得其可以生成移情回复。它主要由三大组件组成：<strong>1）</strong>emotion tracker 编码上下文信息 <span class="math inline">\(\mathcal{C}\)</span>，同时计算用户潜在情绪的分布；<strong>2）</strong>emotion-aware listeners 独立地关注上述的分布，并计算自己的分布；<strong>3）</strong>meta listener 采用各个 emotion-aware listener 的加权表征，然后相加为一个表征，并生成最终的回复。。其中 emotion-aware listeners 还包含 shared listener 和 <span class="math inline">\(n\)</span> 个独立的 empathetic listener，shared listener 捕获通用信息，empathetic listener 捕获其对应情绪的信息。</li>
<li><a href="https://arxiv.org/pdf/1907.12108.pdf" target="_blank" rel="noopener">Lin et al., 2019a</a> 提出了一个对话代理 <strong>CAiRE</strong>。首先使用 GPT 预训练模型，其中 GPT 已经在大型文本语料库 BooksCorpus 上进行了预训练。其次由于现存的移情对话数据集相对较小，仅在这数据集上进行微调，模型在闲聊时所拥有的话题可能会有相对的局限。为了增强 CAiRE 在闲聊时的能力，参考 Wolf et al., 2019 的迁移学习策略，先在 PersonChat 上对模型进行预训练，<strong>此时的预训练不同于之前的预训练。该步的训练使得 CAiRE 拥有一种人格，而之前的预训练是使 CAiRE 拥有理解语言的能力</strong>。 另外为了完全利用在 PersonaChat 上预训练的效果，他们自定义了三条 CAiRE 的人物定位（persona）语句。这些语句代表着 CAiRE 的人物定位。</li>
<li><a href="https://arxiv.org/pdf/2003.02958.pdf" target="_blank" rel="noopener">Zandie et al., 2020</a> 提出了 <strong>EmpTransfo</strong> 架构。他们将序列输入进 Transformer（GPT-2）中得到特征，然后将特征分别输入给三个头，即 Language modeling head（<strong>LM</strong>），Next utterance prediction head（<strong>NUP</strong>）和 Next emotion prediction head（<strong>NEP</strong>）。LM 生成回复语句，与 CAiRERE 类似，NUP 预测干扰项是否为正确回复（<em>感觉这个模块有点问题，可能公式写错了</em>），NEP 预测回复语句所带有的情绪。其中 NUP 是参考了 BERT 的做法。</li>
<li><a href="https://arxiv.org/pdf/2004.12316.pdf" target="_blank" rel="noopener">Zhong et al., 2020</a> 提出了 <strong>Persona-based Empathetic Conversation</strong>（<strong>PEC</strong>）数据集，提供一个基线，并且证明 persona 对移情回复有着提升性能的效果。他们提出的模型的做法是：对 <span class="math inline">\(X, P, y\)</span> 分别使用 BERT 提取向量表征，然后使用 Co-attention 机制配上 max-pooling 提取特征。最后将所有向量拼接后做 dot 运算，得到一个值，从而判断某一个候选回复是否为合适的回复。其中 <span class="math inline">\(X\)</span> 是对话上下文，<span class="math inline">\(P\)</span> 是 persona 语句（<em>用于提升性能</em>，<strong>博主注</strong>：<em>我不太懂这个 persona 是什么意思</em>），<span class="math inline">\(y\)</span> 是候选回复。所以这个模型的运行方式是，<strong>用 <span class="math inline">\(X\)</span> 对每一个候选回复 <span class="math inline">\(y\)</span> 做点积得到一个分数，然后选取分数最高的候选回复返回</strong>。</li>
</ol>
<h2 id="论文笔记">论文笔记</h2>
<p><a href="https://yan62.github.io/posts/ebc36368.html" target="_blank" rel="noopener">情感计算论文笔记</a></p>
<h1 id="dataset">Dataset</h1>
<!-- CS = CrowdSource -->
<table>
<caption>Emotion</caption>
<thead>
<tr class="header">
<th>简称</th>
<th>数据集名称</th>
<th>来源</th>
<th>类型</th>
<th>语言</th>
<th>公开</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="#" title="2020.04">PEC</a></td>
<td><a href="https://arxiv.org/pdf/2004.12316.pdf" target="_blank" rel="noopener" title="Towards Persona-Based Empathetic Conversational Models">Persona-based Empathetic Conversations</a></td>
<td>Reddit</td>
<td>persona + empathy</td>
<td>en</td>
<td>是？</td>
</tr>
<tr class="even">
<td><a href="https://github.com/facebookresearch/EmpatheticDialogues" target="_blank" rel="noopener" title="2018.11">ED</a></td>
<td><a href="https://arxiv.org/abs/1811.00207" target="_blank" rel="noopener" title="Towards Empathetic Open-domain Conversation Models: a New Benchmark and Dataset">EmpatheticDialogues</a></td>
<td>CS</td>
<td>empathy</td>
<td>en</td>
<td>是</td>
</tr>
<tr class="odd">
<td><a href="#" title="2018.09">PCR</a></td>
<td><a href="https://arxiv.org/pdf/1809.01984.pdf" target="_blank" rel="noopener" title="Training Millions of Personalized Dialogue Agents">persona-based conversations from Reddit</a></td>
<td>Reddit</td>
<td>persona</td>
<td>en</td>
<td>否</td>
</tr>
<tr class="even">
<td><a href="https://github.com/claude-zhou/MojiTalk" target="_blank" rel="noopener" title="2018.06">none</a></td>
<td><a href="https://www.aclweb.org/anthology/P18-1104.pdf" target="_blank" rel="noopener" title="MOJITALK: Generating Emotional Responses at Scale">MojiTalk</a></td>
<td>Twitter</td>
<td>emotion</td>
<td>en</td>
<td>是</td>
</tr>
<tr class="odd">
<td><a href="http://yanran.li/dailydialog" target="_blank" rel="noopener" title="2017.10">none</a></td>
<td><a href="https://arxiv.org/pdf/1710.03957.pdf," target="_blank" rel="noopener" title="DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset">Dailydialog</a></td>
<td>various websites</td>
<td>emotion + topic + action</td>
<td>en</td>
<td>是</td>
</tr>
<tr class="even">
<td>--</td>
<td><a href="http://tcci.ccf.org.cn/conference/2014/dldoc/evatask1.pdf" target="_blank" rel="noopener">Emotion Analysis in Chinese Weibo Texts</a></td>
<td>weibo</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<caption>Persona</caption>
<thead>
<tr class="header">
<th>简称</th>
<th>数据集名称</th>
<th>来源</th>
<th>类型</th>
<th>语言</th>
<th>公开</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="#" title="2020.04">PEC</a></td>
<td><a href="https://arxiv.org/pdf/2004.12316.pdf" target="_blank" rel="noopener" title="Towards Persona-Based Empathetic Conversational Models">Persona-based Empathetic Conversations</a></td>
<td>Reddit</td>
<td>persona + empathy</td>
<td>en</td>
<td>是？</td>
</tr>
<tr class="even">
<td><a href="https://github.com/fannn1217/persona.chatbot" target="_blank" rel="noopener" title="2018.06">PC</a></td>
<td><a href="https://www.aclweb.org/anthology/P18-1205.pdf" target="_blank" rel="noopener" title="Personalizing Dialogue Agents: I have a dog, do you have pets too?">PersonaChat</a></td>
<td>CS</td>
<td>persona</td>
<td>en</td>
<td>是</td>
</tr>
</tbody>
</table>
<h1 id="情感分析">情感分析</h1>
<div class="note "><p>这个领域说实话挺乱的，有叫 sentiment analysis（情感分析）/sentiment classification 的，也有叫 emotion classification（情绪分类）/emotion analysis/emotion detection 的。不过这两种任务实际上有一点不同，sentiment analysis 分析的是消极积极的程度，一般是二分类，但是也有多分类的。比如说在影评的时候，如果满分是 10 分，那么就是十分类问题。而 emotion classification 是对语句所包含的情绪进行分类，例如喜悦、快乐、满足、幸福、恐惧、悲伤等等等等。虽然说有点不一样，但是说白了都是对于情感/情绪的一个分类问题。</p>
<p>总而言之，简单来说，喜怒哀乐是 emotion，消极中性积极是 sentiment。【2】</p>
<p>说实话，在中文中，情绪和情感这两个词其实一般没有很大的区别。但是在中英文互翻的时候就有问题了，比如 sentiment analysis，我觉得叫<strong>情绪分析</strong>更为贴切。个人认为情感是人类对事物的某种表达，它常常有多种类别，例如喜怒哀乐等，这些都是人类经过长时的积淀而产生的。但是情绪更像是瞬发的表达，正如影评分类之类的任务，并不会包含过多的情感，更多是情绪。例如电影好不好看，菜好不好吃，这些都是瞬时的【3】。虽然本文的主要关注点是情感计算，本来想使用 emotion classification 这个名词，但是由于 <strong>sentiment analysis</strong> 使用较广，并且名词是在太多，所以避免语义上的问题，下文仅使用名词“<strong>情感分析</strong>”。</p>
</div>
<div class="note info"><p>本人在网络上找到了一些综述性质的文章，并将其中的几篇引用较高的论文拿出来做一项总结【1，4】。本文将总结几篇情感分析的论文。</p>
</div>
<h2 id="相关工作">相关工作</h2>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><a href="https://github.com/declare-lab/awesome-sentiment-analysis" target="_blank" rel="noopener">awesome-sentiment-analysis</a></li>
<li><a href="https://www.zhihu.com/question/391603553/answer/1282552321" target="_blank" rel="noopener">深度学习中的情感分析（sentiment）和情绪分析 (emotion) 的区别是什么？</a></li>
<li><a href="https://www.zhihu.com/question/24325522" target="_blank" rel="noopener">在心理学上，「情绪」与「情感」之间有何异同？</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/58707338" target="_blank" rel="noopener">「情感分析领域」简单调研</a></li>
</ol>
<h1 id="情感回复生成">情感回复生成</h1>
<h2 id="related-work-1">Related Work</h2>
<div class="tabs" id="情感回复生成论文对比"><ul class="nav-tabs"><li class="tab active"><a href="#情感回复生成论文对比-1">论文介绍</a></li><li class="tab"><a href="#情感回复生成论文对比-2">论文瑕瑜</a></li></ul><div class="tab-content"><div class="tab-pane active" id="情感回复生成论文对比-1"><table>
<thead>
<tr class="header">
<th>论文</th>
<th style="text-align: center;">模型</th>
<th>标签</th>
<th style="text-align: center;">评价指标</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/64223641.html#generating-responses-with-a-specific-emotion-in-dialog" title="Generating Responses with a Specific Emotion in Dialog"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://www.aclweb.org/anthology/P19-1359.pdf" target="_blank" rel="noopener" title="19.07"><i class="fa fa-"></i>ACL</a> Song et al., 2019</td>
<td style="text-align: center;">-------</td>
<td>----------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/64223641.html#affective-neural-response-generation" title="Affective Neural Response Generation"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1709.03968.pdf" target="_blank" rel="noopener" title="17.09"><i class="fa fa-"></i>Springer</a> Asghar et al., 2017</td>
<td style="text-align: center;">-------</td>
<td>----------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/64223641.html#btn"><i class="fa fa-"></i>笔记</a><a class="btn" href="#url"><i class="fa fa-"></i>论文</a></td>
<td style="text-align: center;">-------</td>
<td>----------</td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td>---------------------</td>
<td style="text-align: center;">粗体代表有启发的论文</td>
<td>粗体代表有启发的思想</td>
<td style="text-align: center;">----------------</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="情感回复生成论文对比-2"><table>
<thead>
<tr class="header">
<th>论文</th>
<th>实现的功能</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Song et al., 2019</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Asghar et al., 2017</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>-----------------</td>
<td>粗体代表不错的想法</td>
<td>斜体代表在以后的论文中此缺点大致已被解决</td>
</tr>
</tbody>
</table></div></div></div>
<h3 id="论文笔记-1">论文笔记</h3>
<p><a href="https://yan624.github.io/posts/64223641.html">情感回复生成论文笔记</a>。</p>
<h2 id="参考资料-1">参考资料</h2>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/146648319" target="_blank" rel="noopener">赛尔笔记 | 对话中的情感分析与生成简述</a></li>
<li><a href="https://github.com/declare-lab/awesome-sentiment-analysis" target="_blank" rel="noopener">awesome-sentiment-analysis</a></li>
</ol>
]]></content>
      <categories>
        <category>AI</category>
        <category>nlp</category>
      </categories>
      <tags>
        <tag>affective computing</tag>
      </tags>
  </entry>
  <entry>
    <title>Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</title>
    <url>/posts/e5ce1f40.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/1704.01074.pdf" target="_blank" rel="noopener">论文地址</a>，论文作者为 Zhou, Hao, et al.，发表于 2017 年。</p>
</div>
<h1 id="论文概要与引言">论文概要与引言</h1>
<p>想要对话系统或者对话助手取得成功，对情绪的感知和表达是一个关键因素。本文提出 <strong>Emotional Chatting Machine</strong>（<strong>ECM</strong>），可产生带有情绪的回复，而不仅仅是合乎情理且语法准确的内容。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p>目前在大规模对话生成中并没有工作提出情绪因素，但是有一些可控变量文本生成的研究。例如，基于语言的某一种属性（观点，时态等）生成语句。</p>
<ol type="1">
<li>提出一个可以根据语言某些特性来生成语句的生成模型，例如情绪和时态（sentiment and tenses）</li>
<li>Affect Language Model 可以根据上下文词汇和感情类别（context words and affect categories）生成文本</li>
<li>与语法信息合作，为一个文档生成评论，使用了情绪和主题的因素（sentiment and topics）。</li>
</ol>
<p>本文的工作与先前工作有两个方面不同：</p>
<ol type="1">
<li>以前的工作高度依赖语言学工具或者自定义的参数，但是我们的模型完全是数据驱动的，不依赖任何人工调整</li>
<li>以前的工作没有对交互过程中的输入和输出中包含的多种情绪建模，反而使生成的文本简单地延续了上下文中的情绪</li>
</ol>
<h1 id="ecm">ECM</h1>
<h2 id="背景encoder-decoder框架">背景：encoder-decoder框架</h2>
<p>略。</p>
<h2 id="任务定义和概要">任务定义和概要</h2>
<p>此问题定义为：给定一个 <strong>post</strong> <span class="math inline">\(X = (x_1, x_2, \cdots, x_n)\)</span> 以及一个<strong>待生成的回复</strong>的情绪类别 <span class="math inline">\(e\)</span>，目标是生成一个回复 <span class="math inline">\(Y = (y_1, y_2, \cdots, y_m)\)</span>，它与情绪类别 <span class="math inline">\(e\)</span> 相关联。本质上来讲，模型估计概率：<span class="math inline">\(P(Y|X, e) = \prod^m_{t=1} P(y_t | y_{&lt;t}, X, e)\)</span>。情绪类别包括 {Angry, Disgust, Happy, Like, Sad, Other}，继承自一个 <a href="http://tcci.ccf.org.cn/conference/2014/dldoc/evatask1.pdf" target="_blank" rel="noopener">Chinese emotion classification challenge</a> 任务。</p>
<p>在我们的问题陈述中，因为情绪是高度主观的，所以<strong>我们假定待生成回复的情绪类别已经预先给定</strong>。给定一个 post，一句回复也许有多种情绪合适，这取决于回复者的态度。与以往的研究相比，psot 和 response 之间情感的灵活交互时一个重要区别。先前工作的做法是生成一个与输入句子相同情绪的回复，情绪无法做到灵活变换。</p>
<p>因此，由于这种主观的情绪回复，我们选择关注核心问题的解决，即给定一个 post 和一个待回复的情绪类别，生成一句情绪化的回复。注意，有多种方式能够使聊天机器人对一句回复选择一个情绪类别。一种是<strong>给予机器人一种人格或者一些背景知识</strong>；另一种是<strong>使用训练数据从而在给定 post 的情绪的情况下，找到最常见的回复的情绪类别，然后将它作为回复附带的情绪</strong>。此方法由于反应了人们的普遍情绪，所以是合理的。<strong>这将留给未来的工作</strong>。<mark class="label info">赋予机器人能够生成带有情绪的回复的能力</mark></p>
<p>基于上一节的生成框架，提出了 ECM。<strong>第一</strong>，因为情绪类别是一个对情绪表达的高度抽象，ECM 嵌入情绪类别并且将其词向量喂入 decoder。<strong>第二</strong>，我们假定在解码期间，有一个内在的情绪状态，为了捕获到状态模糊的改变以及为了动态地平衡语法状态和情绪状态之间的权重，ECM 采用一个内部记忆模块（internal memory module）。<strong>第三</strong>，情绪显示的表达是通过外部记忆模块（external memory module）显示地选择一个通用（非情绪）或情绪词汇来建模的。<mark class="label primary">ECM的基本介绍</mark></p>
<p>ECM 的总览如图 1 所示。在<strong>训练步骤</strong>，处理过的回复对语料库被喂入一个情绪分类器，然后 ECM 在三元组（posts，responses and emotion）形式的回复的情绪标签上训练。在<strong>推理过程</strong>，post 被喂入 ECM 以生成基于不同情绪类别的情绪化回复。<mark class="label primary">ECM 的流程</mark></p>
<h2 id="emotion-category-embedding">Emotion Category Embedding</h2>
<p>因为一个情绪类别（例如 Angry，Disgust，Happy）是情绪表达的高度抽象，在回复生成上对情绪建模的最直观的方式是将待生成的回复的情绪类别作为额外输入。每一个情绪标签都是真实数值，一个低维的向量。对于每一个情绪类别 <span class="math inline">\(e\)</span>，我们都随机初始化为 <span class="math inline">\(v_e\)</span>，然后在训练阶段中学习。情绪嵌入，词嵌入以及上下文向量被喂入 decoder，然后更新 decoder 的状态 <span class="math inline">\(s_t\)</span>：<mark class="label primary">训练情绪类别的嵌入</mark> <span class="math display">\[s_t = GRU(s_{t-1}, [c_t; e(y_{t-1}); v_e])
\]</span></p>
<h2 id="internal-memory">Internal Memory</h2>
<p>上一节提出的方法是相对静态的：情绪类别嵌入不会在生成步骤中改变，这个也许牺牲了语句在语法上的准确性，由 <a href="https://arxiv.org/pdf/1704.06851.pdf" target="_blank" rel="noopener">Ghosh et al. 2017</a> 提出。受到心理学上成果的启发，情绪化回应是相对短暂的，是涉及到变化的并且是在情绪化回应中的动态情绪状态，因此我们设计了一个<strong>内部记忆模块去捕获在解码过程中情绪的动态变化</strong>。如下所示，我们模拟了情绪表达的过程：<strong>1）</strong>在解码过程开始之前，每一个类别都有一个内部情绪状态；<strong>2）</strong>每一个时间步，情绪状态都会有一定程度的衰减；<strong>3）</strong>一旦解码步骤完成，情绪状态应该衰减至 0，这意味着情绪被完全地表达出来了。</p>
<p>内部记忆模块的详细过程如图 2 所示。每一个时间步 <span class="math inline">\(s\)</span>，ECM 通过输入（前一个解码出的单词 <span class="math inline">\(e(y_{t-1})\)</span> 的词向量）、前一个解码状态 <span class="math inline">\(s_{t-1}\)</span>和当前上下文向量 <span class="math inline">\(c_t\)</span>，去计算一个 <strong>read gate</strong> <span class="math inline">\(g^r_t\)</span>。<strong>write gate</strong> <span class="math inline">\(g^w_t\)</span> 基于解码状态 <span class="math inline">\(s_t\)</span> 计算。read gate 和 write gate 如下定义： <span class="math display">\[
\begin{align}
    g^r_t &amp; = sigmoid(W^r_g [e(y_{t-1}); s_{t-1}; c_t]) \\
    g^w_t &amp; = sigmoid(W^w_g s_t)
\end{align}
\]</span> 然后 read 和 write gate 各自被用于读取和写入内部记忆。因此，情绪状态在每个时间步都会根据一定量（通过 <span class="math inline">\(g^w_t\)</span>）被擦除。尤其最后一个时间步，内部情绪状态将会衰减至 0。这一过程将由以下公式定义，其中 <span class="math inline">\(otimes\)</span> 代表矩阵对应元素相乘运算。 <span class="math display">\[
\begin{align}
    M^I_{r, t} &amp; = g^r_t \otimes M^I_{r, t} \\
    M^I_{e, t+1} &amp; = g^w_t \otimes M^I_{e, t} \\
\end{align}
\]</span> GRU 根据前一个生成的目标词 <span class="math inline">\(e(y_{t-1})\)</span>，前一个解码的隐藏状态 <span class="math inline">\(s_{t-1}\)</span>，上下文向量 <span class="math inline">\(c_t\)</span> 和更新过的情绪状态 <span class="math inline">\(M^I_{r,t}\)</span> 生成状态 <span class="math inline">\(s_t\)</span>，如下所示： <span class="math display">\[s^t = GRU(s_{t-1}, [c_t; e(y_{t-1}); M^I_{r, t}])
\]</span> 然后根据这个状态 <span class="math inline">\(s_t\)</span> 就可以通过 softmax 函数计算出生成单词的分布 <span class="math inline">\(o_t\)</span>。</p>
<h2 id="external-memory">External Memory</h2>
<p>在内部记忆模块中，<strong>内部情绪状态和被挑选出的单词之间的相互关系不是很清楚并且不是可直接观测</strong>。因为情感的表达和句子中情感词是显而易见的，例如 <em>lovely</em> 和 <em>awesome</em> 与通用词汇（非情感词，例如 <em>person</em>，<em>day</em>）相比携带了强烈的感情，所以我们提出了外部记忆模块，<strong>通过对情感词（emotion words）和通用词（generic words）分配不同的生成概率，从而对清晰的情感表达建模</strong>。因此模型可以从情感词汇表或者通用词汇表中选择地生成词汇。</p>
<p>带着外部机遇模块的编码器如图 3 所示。给定当前状态 <span class="math inline">\(s_t\)</span>，在情绪词表上计算出 emotion softmax <span class="math inline">\(P_e(y_t = w_e)\)</span> 和 generic softmax <span class="math inline">\(P_g(y_t = w_g)\)</span>，它们分别读取自情绪词表（emotion vocabulary）和通用词表（generic vocabulary）。type selector <span class="math inline">\(\alpha_t\)</span> 控制是否生成情绪或者通用词汇。最终通过两个概率分布的拼接向量计算出下一个单词的概率。该过程可由下公式描述： <span class="math display">\[
\begin{align}
    \alpha_t &amp; = sigmoid((v_u)^T s_t) \\
    P_g(y_t = w_g) &amp; = softmax(W^o_g s_t) \\
    P_e(y_t = w_e) &amp; = softmax(W^o_e s_t) \\ 
    y_t \sim o_t = P(y_t) &amp; = \begin{bmatrix} (1 - \alpha_t) P_g(y_t = w_g) \\ \alpha_t P_e(y_t = w_e) \end{bmatrix} \\
\end{align}
\]</span> 其中 <span class="math inline">\(\alpha_t \in [0,1]\)</span> 是一个标量，用以平衡情绪词 <span class="math inline">\(w_e\)</span> 和通用词 <span class="math inline">\(w_g\)</span> 之间的选择。<em>其他符号望文生义就不说了</em>。</p>
<h2 id="loss-function">Loss Function</h2>
<p>loss function 由三部分组成，一个用于内部记忆，强制使得内部记忆状态在最后一个解码步衰减至 0；另一个用于外部记忆，约束情感词或者通用词的选择。定义为： <span class="math display">\[L(\theta) = -\sum^m_{t=1} p_t log(o_t) - \sum^m_{t=1} q_t log(\alpha_t) + \|M^I_{e,m}\|
\]</span> <span class="math inline">\(M^I_{e,m}\)</span> 是最后一个时间步 m 的内部解码状态， <span class="math inline">\(\alpha_t\)</span> 是选择情绪词还是通用词的概率，<span class="math inline">\(q_t \in {1, 2}\)</span> 是选择情绪词还是通用词的真实值。所以第一项是预测下一个词的 loss，第二项被用于监督情绪词和通用词选择的概率的 loss，第三项被用于确保在解码完成时，内部隐藏状态被全部表达出来。</p>
<h1 id="数据准备">数据准备</h1>
<p>由于没有现成的数据支持 ECM 的训练，所以我们先在 NLPCC 的情绪分类数据集上训练一个情绪分类器（emotion classifier），然后使用这个分类器标注 STC 对话数据集（Shang, Lu, and Li 2015），这样来构建我们自己的数据集。数据准备主要有两步：</p>
<ol type="1">
<li>构建情绪分类器：我们在 NLPCC 的数据集上训练了多个模型，然后选择了一个做好的用做自动标注。数据集选择 NLPCC2013 和 NLPCC2014 的情绪分类任务挑战。数据收集自微博，由人工标注成 8 个情绪分类。移除了低频的情绪（Fear（1.5%），Surprise（4.4%））之后，我们还剩 6 个。我们选择了 lexicon-based classifier (Liu 2012)，RNN，LSTM，Bi-LSTM 等模型。实验证明 Bi-LSTM 是最好的。</li>
<li>标注 STC 数据集的情绪：我们使用 Bi-LSTM 对 STC 进行标注。这样就获得了情绪标签数据集，我们称之为 ESTC。尽管 ESTC 由于自动标注有很多噪声，但是实际上足够训练了（-.-真的吗？）。未来我们将研究分类误差是怎么样影响回复生成的。</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>画UML等的配色</title>
    <url>/posts/350f36a6.html</url>
    <content><![CDATA[<h1 id="系统架构图">系统架构图</h1>
<h2 id="说明">说明</h2>
<p><strong>圆角方形</strong>代表一个模块。<strong>“圆角方形（主）”</strong>代表重要的模块，<strong>“圆角方形（辅）”</strong>代表重要模块中的子模块，<strong>“圆角方形（层）”</strong>代表多个模块组合成的某一层，例如“业务层”，“应用层”。<strong>“圆角方形（数据）”</strong>代表各种数据，例如数据库数据，图数据，知识图谱等。</p>
<h2 id="配色1">配色1</h2>
<p>背景色：#171717</p>
<p>圆角方形背景色（主）：#61649f（山梗紫）</p>
<p>圆角方形背景色（辅）：#a7a8bd（淡蓝紫）</p>
<h2 id="配色2">配色2</h2>
<p>背景色：白色</p>
<p>圆角方形背景色（主）：#5dbe8a（蔻梢绿），#b9dec9（竹篁绿）</p>
<p>圆角方形背景色（辅）：#f4ce69（炒米黄），#f9e9cd（米色），#fbeee2（淡米粉），#5cb3cc（碧青），#93d5dc（清水蓝），#e3b4b8（鼠鼻红）</p>
<p>圆角方形背景色（层）：#1ba784（竹绿）</p>
<p>圆角方形背景色（数据）：#10aec2（甸子蓝） <a id="more"></a></p>
<h2 id="一个栗子">一个栗子</h2>
<p>背景色：白色</p>
<p>圆角方形背景色（主）：#5dbe8a（蔻梢绿）</p>
<p>圆角方形背景色（辅）：#5cb3cc（碧青），#f4ce69（炒米黄） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/画UML等的配色/智能对话系统架构.png" alt="智能对话系统架构" /></p>
]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>配色</tag>
      </tags>
  </entry>
  <entry>
    <title>【机器学习算法】无监督学习</title>
    <url>/posts/70c86b65.html</url>
    <content><![CDATA[<h1 id="section"></h1>
<a id="more"></a>
]]></content>
  </entry>
  <entry>
    <title>神经网络训练技巧（tricks）</title>
    <url>/posts/8071918e.html</url>
    <content><![CDATA[<div class="note default"><p><mark class="label success">gradient clipping</mark> <mark class="label primary">learning rate decay</mark> <mark class="label info">dropout</mark> <mark class="label info">tensorboardX</mark> <mark class="label primary">过拟合/欠拟合</mark></p>
</div>
<h1 id="技巧">技巧</h1>
<p><span class="citation" data-cites="jozefowicz2015empirical">(Jozefowicz, Zaremba, and Sutskever 2015)</span> 发现在 LSTM 的 forget gate 上的 bais 设置为 1，可以缩小 LSTM 和 GRU 之间的差距。（题外话：该论文还很好地解释了梯度消失出现的原因）下面是解释：</p>
<blockquote><p>许多应用将 SLTM 的遗忘门随机地使用一个很小的值进行初始化，这在大多数应用上都能够正常工作。但是这种初始化实际上将遗忘门（<strong>博主注</strong>：注意是遗忘门，而不是遗忘门偏差）设置成了 0.5。这就在每一个时间步，由于 0.5 这个因素，引入了一个梯度消失的问题。当模型特别需要长期依赖时，就会导致出现问题。<mark class="label warning">为什么会使得遗忘门变成0.5？</mark></p>
<p>这个问题可以简单地将遗忘门的偏差设置为一个较大的数值，从而得以解决，例如 1 或 2。通常将其设为接近 1 的值，从而启动 gradient flow。这个观点早已经被 Gers et al.(2000) 提出，但是很多从业者都不知道这点，所以我们再次强调。</p>
<p>如果遗忘门的偏差没有正确初始化，我们可能会错误地得出结论：LSTM 无法学习解决具有远程依赖性的问题。然而根据上面的观点，事实并非如此。</p>
</blockquote>
<div class="note warning"><p>值得注意得一点是，<span class="citation" data-cites="jozefowicz2015empirical">(Jozefowicz, Zaremba, and Sutskever 2015)</span> 认为 GRU 作为 LSTM 的变种，与 LSTM 一样，仍然难以证明其 cell 是否设计得合理。并且据实验发现，<strong>基于普通的初始化方式</strong>，其几乎在所有任务上胜过 LSTM。但是正如之前所述，只要 LSTM 的 forget get bias 被初始化为 1，它们之间的差距几乎相当。</p>
<p>博主注：那么也就是说 GRU 的优点只有比 LSTM 的运行速度快一点</p>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-jozefowicz2015empirical">
<p>Jozefowicz, Rafal, Wojciech Zaremba, and Ilya Sutskever. 2015. “An Empirical Exploration of Recurrent Network Architectures.” In <em>International Conference on Machine Learning</em>, 2342–50.</p>
</div>
</div>
</div>
<h1 id="调参的步骤以及经验">调参的步骤以及经验</h1>
<div class="note info"><p><a href="https://www.bilibili.com/video/BV1Ux411S7rk?p=13" target="_blank" rel="noopener">李宏毅深度学习</a> 大致地讲解了调参技巧，不过现在都是人尽皆知的方法了。</p>
</div>
<p>根据本人经历，记录调参的方法。</p>
<h2 id="最初的超参数">最初的超参数</h2>
<p>首先你需要固定自己的 epoch 以及 batch size，然后使用尽可能大的学习率（learning rate，lr），使得你的模型在训练集上拟合的不错，即 loss 值达到可以接受的程度，并且准确率或者你的其他指标达到不错的水平。<strong>一般我将 batch size 选为 128，epoch 选为 100。</strong>如果初步调试后无法得到一个好的结果，可以根据需求略微地调整这三个参数。<mark class="label danger">三个最重要的参数</mark></p>
<p>得到一个不错的效果意味着你的模型本身没有存在很大的问题。<strong>但是</strong>由于取的是尽可能大的 lr，那么你的模型在验证集上的结果可能差的离谱！这不要紧，因为之后还要调整各个超参数，此步仅仅是找 lr。最后有一点，如果经过长期调试，在训练集上均无法得到一个好的结果，那么得检查一下代码或者数据处理的是否有问题。<mark class="label primary">验证模型是否有问题，同时得到合适的学习率</mark></p>
<p>要牢记一点，<strong>超参数的好坏一定要在验证集上做评定，并且最好保证在训练集上的性能不受太大影响</strong>。此外，<strong>在尝试合适的学习率时，可以把验证步骤关了，因为此时的验证精度没什么用。这样做可以加快训练速度。</strong><mark class="label info">一些小技巧</mark></p>
<p>现在假设你最终使用一套 <code>(lr, epoch, batch_size)</code> 的超参数，在训练集上得到一个还不错的结果。那么可以进行下一阶段，选取合适的 batch size（<em>注意此步《最初的超参数》是用来选择 lr 的，epoch 和 batch size 仅仅是一个根据经验固定的值</em>）。详见下节《<a href="#batch-size的选择">batch size的选择</a>》。 <div class="note warning"><p>如果在训练集上的结果还不错，那么在验证集上的结果应该不会差到训练不起来的地步。此时可以通过调整上述三个超参数使性能提高，注意，稍微调一下就行。一般来说应该不需要调整。</p>
</div></p>
<h2 id="batch-size的选择">batch size的选择</h2>
<p>在看了参考文献 1 之后，我对目前我正在做的模型做了几个小实验。我以前以为 batch size 对模型的影响不大，我认为只要 batch size 设置得足够大，只要有足够大的 epoch，模型总能收敛。但是在做了这几个实验之后，我发现 batch size 似乎能够影响模型的性能。</p>
<h3 id="几个小实验">几个小实验</h3>
<p>下图是几个实验的结果，图有点乱，但是其实很好分析。只需要记住一点，曲线在上方的都是 train BLEU，曲线在下方的都是 val BLEU。训练集上的性能比验证集上的高，这很正常。</p>
<p>此实验，其他超参数均固定，epoch 可以暂且无视。先看上方的三条线，灰色的超参数为 <code>(lr, epoch, batch_size) = (0.001, ?, 64)</code>，而蓝红分别为 <code>(0.0003, ?, 32)</code> 和 <code>(0.0003, ?, 16)</code>。可见 batch size 为 64 的模型训练集上的 BLEU 指标比不上其它的模型。下方的验证集同理。还有一点，图中 batch size 为 32 的模型收敛要慢，这是因为 lr 不合理，设置为 0.0005 可能更合理。那么对于此任务来说，这两组参数可能都是一个不错的选择。但是我倾向于 <code>batch size=32</code> 的，因为它训练的速度更快，毕竟时间就是生命。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/不同超参数之间，性能的对比.svg" alt="不同超参数之间，性能的对比" /></p>
<p>下面给出所有实验的对比，发现还是那两组的性能最好。橙色那条线是 <code>(0.001, ?, 128)</code>。此外我还试了 <code>(0.002, ?, 128)</code>，但是这组实验直接烂掉了，模型早早地拟合完毕，但是训练集上的 BLEU 连 50% 都没。由于已知增加 batch size 的同时需要加大 lr，由上述的两种实验可知，该任务参数的上限可能就是 <code>(0.001, ?, 128)</code>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/不同超参数之间，性能的对比2.svg" alt="不同超参数之间，性能的对比2" /></p>
<p>由上述实验可知，batch size 和 lr 还是对模型的性能有影响的。并且二者对模型的影响是具有相互作用的。这是因为在 loss function 中，唯二的超参数就是 batch size 和 lr【<a href="https://zhuanlan.zhihu.com/p/64864995" target="_blank" rel="noopener">1</a>】，其他的超参数是都在神经网络里。上述的实验只是一个大概的实验，其中的变化太多，无法选择到一组完美的组合，但是还是可以有经验可循的。<strong>加大 batch size 就要加大 lr，减小 batch size 就要减小 lr，而且可以以对应倍数进行改变</strong>【<a href="https://zhuanlan.zhihu.com/p/64864995" target="_blank" rel="noopener">1</a>，<a href="https://arxiv.org/pdf/1706.02677.pdf" target="_blank" rel="noopener">2</a>，<a href="https://arxiv.org/pdf/1705.08741.pdf" target="_blank" rel="noopener">3</a>】。</p>
<p>假设经过《<a href="#调参的步骤以及经验">调参的步骤以及经验</a>》之后，现在你的超参数为 <code>(0.001, 100, 64)</code>。那么你接下来可选的超参数组合为：<code>(0.002, 100, 128), (0.0005, 100, 32), (0.00025, 100, 16)</code>。具体的参数值可以按照自己的习惯进行改写，例如 0.00025 可以改成 0.0003。</p>
<p>总而言之，知道这一点之后，有关 lr 和 batch size 的调整就不需要像无头苍蝇一样乱调了。可以选定大概 5 组参数，直接放在服务器上训练。然后选择一个最合适的范围，再进行微小的调整。或者如果嫌麻烦，可以直接选择 5 组里最好的。</p>
<h3 id="总结">总结</h3>
<p>上述的实验只是做个补充，总的来说： 1. 大的 batch size 可以减少训练时间，模型更稳定（<em>关于模型更稳定这点，我没有在论文里读到过，只是取自【<a href="https://zhuanlan.zhihu.com/p/64864995" target="_blank" rel="noopener">1</a>】</em>）。因为批次越大，所需要迭代的次数就要少，训练速度肯定要快。 2. batch size 不是越大越好</p>
<h3 id="参考资料">参考资料</h3>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/64864995" target="_blank" rel="noopener">【AI 不惑境】学习率和 batchsize 如何影响模型的性能？</a></li>
<li><a href="https://arxiv.org/pdf/1706.02677.pdf" target="_blank" rel="noopener">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</a></li>
<li><a href="https://arxiv.org/pdf/1705.08741.pdf" target="_blank" rel="noopener">Train longer, generalize better: closing the generalization gap in large batch training of neural networks</a></li>
</ol>
<h2 id="如何处理过拟合">如何处理过拟合</h2>
<p>参考《过拟合处理》</p>
<h2 id="loss-值并不能作为判断模型性能的指标">loss 值并不能作为判断模型性能的指标</h2>
<p>有一个让我印象深刻的案例，我发现验证集上的 loss 值很高，但是在验证集上的准确率还不错。我认为<strong>loss 值并不能作为判断模型性能的指标</strong>。</p>
<p>例如我的实验，在训练集上 loss 值的大小收敛到 [0.1, 1]，但是在验证集上 loss 值高达 [25, 50]，所以在最开始我一直认为模型在验证集上的性能肯定极差。现在假设以 acc 作为评分指标，在训练集上可能有 60%+，而在验证集上我猜测连 1% 都没有。由于这种错误的思维，其实我并没有编写计算 acc 的代码，因为我觉得这个模型有问题，所以我懒得耗费时间编这个代码。</p>
<p>最后我受不了了，编写了计算 acc 的代码，发现两个数据集上的性能居然类似，大致分别为 68% 和 48%。下面是基于直觉的分析，假设我们的目标多分类任务，预测 <code>['我', '是', '鱼']</code>。</p>
<p>由于在训练集上的 loss 值很低，所以自然而然地可以想到它的预测水平要高，假设预测 <code>'我'</code> 的概率为 0.9，那么对应的损失值为 <span class="math inline">\(-\log(0.9)\)</span>（负对数似然）。而在验证集上，假设预测 <code>'我'</code> 的概率为 0.6，那么对应的损失值为 <span class="math inline">\(-\log(0.6)\)</span>。可以看出显然验证集上的损失值要大得多，但是他们的结果是一样的，都预测正确了。注：这里的损失值其实相差还是不大，但是对于语言生成任务来说，损失值是要累加的，假设一句话有 30 个字，那么累加之后，差距就大了。</p>
<h2 id="gpu内存不够以及随机采样">GPU内存不够以及随机采样</h2>
<p>如果你实验室的机器不好，打算使用随机采样的方法使得在小样本上测试超参数。<strong>那么请记得 train/val/test 的比例一定要与原数据集的比例一样</strong>。数据集一般都是由制作者划分好比例的，比如你得到的数据集 train/val/test 的数据量为 12472/900/900。现在你想只训练 6600 条数据，以此提高找到超参数的效率，那么你必须做到以下几点：</p>
<p>按照比例缩放：<span class="math inline">\(\frac{6600}{12472} \approx 0.529\)</span>，那么你所取得的 val/test 数据集合一定要是 <span class="math inline">\(0.529 \times 900 \approx 476\)</span> 条。简单来说，你从总的训练集中取多少比例，也要到验证集和测试集里按这个比例取。不能“<em>哦，总共就 900 份，我不如都算作验证集吧</em>”，<strong>这样会导致数据的分布极其的不平衡</strong>！试想一下，数据的制作者肯定会尽量使得三份数据集的分布尽可能的接近，并且其中的句子肯定也是长短不一的。结果你从训练集中随机取出 6000 份，导致了这些数据的分布和原来不一样，一个直观的解释就是模型无法捕获长句子的信息，因为你的新训练集和训练集中长句子所占的比例不一样。而你还偏偏用原来那个分布的验证集！</p>
<p>一定要使用随机采样的方法！不要直接使用 python 的切片！否则也会导致你的数据集分布不平衡。使用 python 内置的 <code>random.choice()</code> 可以很简单地实现随机采样。</p>
<h2 id="关于adam的一个bug">关于Adam的一个bug</h2>
<p>如果需要对模型使用权重衰减的策略，<strong>在 Pytorch 中不要使用 Adam 算法，有 bug</strong>。听说目前流行的深度学习框架都有 bug。请改用 AdamW 算法。甚至在一开始就可以选择 AdamW，因为 Adam 和 AdamW 是一样的，区别仅仅是在权重衰减步骤上有所不同。</p>
<h1 id="对于如何融合两个向量的思考">对于如何融合两个向量的思考</h1>
<p>在训练神经网络时，有些情况会有两个张量，但是网络的输入只有一个。例如在训练 Bi-LSTM 时，会分别得到正向以及逆向的输出。这两个张量的特征我们都需要利用到，那么该如何融合它们的特征呢？</p>
<p>常用的做法就是<strong>1）直接相加</strong>；<strong>2）或者拼接两个张量</strong>。</p>
<p><strong>个人比较喜欢第二种方法</strong>，因为我自学习神经网络开始，一直将一个向量的各个维度视作数据的各个特征。而张量拼接的做法，直观上来看，其实就是<strong>将两个张量的特征合并</strong>。个人认为这更符合我的逻辑。反之，张量相加好像体现不出特征的奇妙之处。</p>
<p>当然这样做也各有优缺点，<strong>张量拼接的方式导致了维度倍增</strong>，而相加的方式还是维持原来的维度。但是张量拼接之后可以接一个前馈神经网络（甚至可以接多层感知机，让网络更深），进行降维。总得来说，张量拼接的方式虽然使得维数倍增，但是现在这个年代，这个维数也可以接受，只要的维数不是高的离谱就行。同时<strong>方法 2 后接一个前馈神经网络</strong>，这又进一步<strong>对两个张量进行了特征提取</strong>，用一句话形容就是“取其精华，去其糟粕”。前馈网络对张量的降维可以理解为删去了无用的特征。</p>
<p>其次，方法 1 和方法 2 其实也是类似的。一般方法二需要接一个线性变换，即 <span class="math inline">\(C = f(\begin{pmatrix}M \\ N\end{pmatrix})\)</span>。而方法一可以公式化为：<span class="math inline">\(D = \begin{pmatrix}1 &amp; 1\end{pmatrix} \cdot \begin{pmatrix}M \\ N\end{pmatrix} + 0\)</span>。说白了就是方法一相比于方法二，权重是 1，偏差是 0。也就是说方法一的做法<strong>没有利用神经网络自动为两个张量分配合适的权重</strong>。</p>
<p>最后，其实还有另一个做法。先对两个张量做一次线性变换，再相加。这其实和方法二完全一样，观察下式。实际上，<span class="math inline">\(W_c b_c\)</span> 都可以拆成两个折半的矩阵/向量，例如 <span class="math inline">\(W_c = \begin{pmatrix}W_{c_1} &amp; W_{c_2} \end{pmatrix}\)</span>。拆开之后就是 <span class="math inline">\(C = f(M) + F(N)\)</span>，这其实就是先进行线性变换再相加。 <span class="math display">\[
f(x) = W \cdot x + b \\
C = f(\begin{pmatrix}M \\ N\end{pmatrix}) = W_c \cdot \begin{pmatrix}M \\ N\end{pmatrix} + b_c
\]</span></p>
<h2 id="参考资料-1">参考资料</h2>
<ol type="1">
<li><a href="https://www.zhihu.com/question/389912594/answer/1178054600" target="_blank" rel="noopener">神经网络中对需要 concat 的特征进行线性变换然后相加是否好于直接 concat?</a></li>
<li>以后有机会再补充</li>
</ol>
<h1 id="过拟合处理">过拟合处理</h1>
<div class="note warning"><p>奇怪的事写在前面。</p>
<p>我碰到了一种情况，训练集上拟合的很好（loss 约为 1），但是在验证集上很差（loss 约为 280+）。不断地调整代码以及更换学习率，得到的效果均不明显。</p>
<p>我给出其中一种可能：<strong>两种数据集的分布不一样</strong>。例如我的问题，在给定 10000 条训练集样本和 900 条验证集样本的情况下。由于 NLP 任务句子不等长的特性，所以我选择先将句子排序使得同一批次中的数据等长，注意我没有选择填充 <code>&lt;PAD&gt;</code> 这种方法。</p>
<p>然后<strong>我取了 6600 条训练集样本，在取验证集样本时，由于它的数据量较小，所以我全要了，问题就出在这</strong>。我的训练集样本是取的 [1400: 8000]，所以这个区间内的句子长度比较平均，由于我事先排序的原因，所以极短的句子和极长的句子我都没取到。但是原验证集和原训练集的分布是一样的！所以 900 条验证集中包含了极长的句子和极短的句子，这导致了现在的两个数据集分布不一样了！<strong>解决办法是使用随机采样</strong>。<em>不要排序之后直接切片获得数据，而是应该是先随机采样，再排序</em>。</p>
<p>但是处理完之后结果依旧很烂！现在正在调试学习率。待续，后面补充。</p>
</div>
<p>当过拟合时，可以考虑以下的方法，过拟合的另一种说法是高方差（high variance）。</p>
<h2 id="增加数据集的大小">增加数据集的大小</h2>
<p>如下图所示，紫红色和蓝色曲线是验证集上的 loss。蓝色曲线意味着我从 4400 条数据增加到了 6600 条。明显可以看到过拟合略有缓解。但是训练集上的 loss 增加了，灰色那条线是增加数据量后的训练集 loss。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/add_more_data.svg" title="增加更多的数据" alt="增加更多的数据" /></p>
<p>下图也是一个例子，相比于上个模型还训练的有问题，这个模型已经训练的还可以了。可以看到红色曲线比蓝色的要平缓一点，因为数据集增加，训练集上的 loss 会相应增加。再看上面的橙色和深蓝色，深蓝色是增加数据量之后的 loss 曲线，略微降低。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/add%20more%20data2.svg" alt="增加更多的数据2" /> ## 加大批次大小或减小模型复杂度 如下图所示，中间的两条橙色和蓝色曲线是批次大小从 128 增加到 224 的结果。橙色曲线为 val loss，可以看到橙色曲线相比于上面那条蓝色的 val loss，已经略有下降，这代表着过拟合的程度略有降低。而中间的蓝色曲线代表 train loss，相比于下面的灰色 train loss 曲线有些许上升，这代表着模型在训练集上的泛化能力有所下降。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/more_larger_batch_size.svg" alt="加大批次大小" /></p>
<p>下图为减小隐藏状态的例子，中间的绿色以及红色曲线是隐藏状态从 512 减到 400 的结果，可以看到验证集上的 loss 略有下降（略微的缓解过拟合），训练集上的 loss 略有上升。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/reduce_hidden_size.svg" alt="减小隐藏状态大小" /></p>
<h2 id="learning-rate-decay">learning rate decay</h2>
<p>Q：在什么时候需要使用 learning rate decay？</p>
<p>A：网上资源不多，还是自己总结吧。在此实验中，加入 learning rate decay 后，准确率略有提升。</p>
<h2 id="正则化">正则化</h2>
<h2 id="dropout">Dropout</h2>
<p>一般设置为 0.5。在 Pytorch 中代表神经网络中某一层的神经元的输出有 0.5 的概率为 0。其他的深度学习框架不保证一样。</p>
<p>参考资料： 1. <a href="https://zhuanlan.zhihu.com/p/38200980" target="_blank" rel="noopener">深度学习中Dropout原理解析</a></p>
<h2 id="label-smoothing">label smoothing</h2>
<h1 id="集成学习ensemble">集成学习Ensemble</h1>
<h1 id="可视化训练结果">可视化训练结果</h1>
<p>以前一直用 matplotlib 来画图，现在用了 tensorboardX 之后，感觉人瞬间就爽了，以下为教程。无法启动看 2，启动后网页无法显示看 3，代码不会写看 1。</p>
<p>参考资料： 1. <a href="https://tensorboardx.readthedocs.io/en/latest/tutorial.html#what-is-tensorboard-x" target="_blank" rel="noopener">官方文档</a> 2. <a href="https://blog.csdn.net/qq_40605167/article/details/95761885" target="_blank" rel="noopener">tensorboard OSError: [Errno 22] Invalid argument错误处理</a> 3. <a href="https://blog.csdn.net/weixin_44135282/article/details/86156961" target="_blank" rel="noopener">tensorboard生成的网址打不开的解决方法</a> 4. <a href="https://blog.csdn.net/bigbennyguo/article/details/87956434" target="_blank" rel="noopener">详解PyTorch项目使用TensorboardX进行训练可视化</a></p>
<h1 id="其他的调参经验">其他的调参经验</h1>
<h2 id="拟合异常分析">拟合异常分析</h2>
<h3 id="val-loss上升val-acc也上升">val loss上升，val acc也上升</h3>
<div class="note warning"><p>这里的 acc 只是一种比较抽象的说法，换成 BLEU 等指标也是可以的。</p>
</div>
<p>使用 seq2seq 训练一个对话模型时，发现 val loss 始终很高，用尽了办法也没办法让它下去。train loss 一般都在 0.x - 3 之间，BLEU 也在 80%-90% 之间。但是 val loss 就是大概在 80 以上，而 BLEU 在 30 % 左右。在下面几个章节的图片中可以明显的看到二者的 gap 非常大。</p>
<h4 id="参考资料-2">参考资料</h4>
<ol type="1">
<li><a href="https://www.zhihu.com/question/318399418/answer/1202932315" target="_blank" rel="noopener">验证集 loss 上升，准确率却上升该如何理解？</a> <a id="more"></a></li>
</ol>
<h3 id="训练集和验证集的性能或者loss相差巨大">训练集和验证集的性能或者loss相差巨大</h3>
<p>此问题与下一章《train acc很大，gap非常大》的问题类似，或者说完全一样。无论怎么调整参数或者加什么正则化方法，都无法使得验证集 loss 减小，或者准确率上升。这意味着需要增加数据集，其他的方法都不管用。具体看下图，我增加了大约已被数据集后，黄色验证集曲线（7872 条数据）比绿色验证集曲线(4000 条)下降很多。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/加大数据集后，val_loss明显下降.svg" alt="加大数据集后，val_loss明显下降" /></p>
<h4 id="train-acc很大gap非常大">train acc很大，gap非常大</h4>
<p>在训练过程中出现了一种情况，train acc 94% 左右，但是 val acc 只有 24% 左右，test acc 也是 24% 左右。很多人认为这是<strong>过拟合</strong>状态，因为模型在训练集上拟合的很好，但在验证集上拟合的不好，这两者之间的 gap 很大。也就是<strong>高方差</strong>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/train%20acc很大，gap也很大.svg" alt="train acc很大，gap也很大" /></p>
<p>以下是对此现象的分析： 1. 再增加 <strong>epoch</strong> 已经没用了，因为该模型的参数已经很好的拟合了数据集，使得准确率接近 100%。 <blockquote class="blockquote-center">
<i class="fa fa-quote-left"></i>
<p>说明训练集中的几乎所有信息（不论是对泛化有用的信息还是训练集中的噪声）都全部被模型学习到了。（<a href="https://www.zhihu.com/question/65200055" target="_blank" rel="noopener">来源</a>）</p>

<i class="fa fa-quote-right"></i>
</blockquote></p>
<ol start="2" type="1">
<li>改变（无论增大还是缩小） rnn 的<strong>隐藏状态</strong>也不会有很大改善了。比如说此文章的模型，我尝试选择隐藏状态大小为 (100, 115, 125, 128)，结果如下所示，可以看到增加减少隐藏状态大小，对 train acc 根本无影响，对 val acc 也只有一点影响： <blockquote class="blockquote-center">
<i class="fa fa-quote-left"></i>
<table>
<thead>
<tr class="header">
<th>hidden size</th>
<th>batch</th>
<th>train acc</th>
<th>val acc</th>
<th>test acc</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>32</td>
<td>94.42%</td>
<td>20.74%</td>
<td>21.28%</td>
</tr>
<tr class="even">
<td>115</td>
<td>32</td>
<td>94.42%</td>
<td>22.80%</td>
<td>23.72%</td>
</tr>
<tr class="odd">
<td>125</td>
<td>32</td>
<td>94.42%</td>
<td>24.95%</td>
<td>24.78%</td>
</tr>
<tr class="even">
<td>128</td>
<td>32</td>
<td>94.42%</td>
<td>21.20%</td>
<td>22.58%</td>
</tr>
<tr class="odd">
<td>125</td>
<td>128</td>
<td>98.47%</td>
<td>19.13%</td>
<td>20.37%</td>
</tr>
</tbody>
</table>

<i class="fa fa-quote-right"></i>
</blockquote> <div class="note info"><p>但是我认为这种情况<strong>不算过拟合</strong>（暂时不看 <code>batch=128</code> 那组）。因为过拟合指的是模型在训练集上过度地拟合了数据特征，于是在验证集上出现个比较离群的数据样本，就会得到很差的结果。 如果把训练集拥有的特征集合定义为 A，验证集拥有的特征集合定义为 B，那么 <span class="math inline">\(C=A \cap B, D = A \cup B - C\)</span>，其中 C 代表的是未被神经网络拟合的很小的一部分特征，D 代表的是已经被神经网络拟合的特征（注：这里的拟合并不一定要完全的拟合，在拟合线的附近即可）。神经网络要做的是同时拟合 A 与 B 的所有特征。 但是随着 epoch 的增加，A 中的所有特征肯定被拟合的越来越好，而 B 中有些已经被拟合的特征却越来越远离拟合线，所以导致了 C 中的特征越来越多。（可以通过逻辑回归来先思考，验证集数据原本在拟合线附近，但是增加 epoch 或者增加网络参数等操作导致过拟合，原本在拟合线附近的数据点反而偏离了） <strong>所以训练集和验证集中的数据的分布应该是这样的：训练集和验证集中有很多数据分布类似（对应即使过拟合 val acc 也不会下降到 0%），但是两个数据集中有些数据只有部分特征的分布是类似的（对应于过拟合），最后两个数据集汇总有一部分数据完全无关联（对应于不管怎么拟合，val acc 始终不可能到 100%）。</strong> 话说回来文中的情况，明显训练集和验证集的 acc 到达顶部之后一直处于平稳的状态，增加 epoch 或者增加网络参数都没有使得 acc 增加或下降，这就意味这 C 中的特征没有变化。 <strong>所以这种情况应该是这样的：训练集和验证集中的数据有少量是类似的（对应于 val acc 拥有 20+%），其余大部分，可能有超过 60% 的数据都没有关联（对应于不管怎么训练 val acc 始终只有 20+%），最后有两个数据集中一小部分数据可能有部分特征重叠（对应于随着 epoch 的增加，val acc 有略微的波动）。</strong></p>
</div></li>
</ol>
<p>对这种情况，一般出现在利用随机采样快速训练模型，只需要加大数据量就行了。所以以后再用小数据量训练时只需要将参数调整到满意的地步就不需要再继续调整了，直接换大数据量。 最后对于 <code>batch = 128</code> 的那组，train acc 上升了，其他的下降了，有过拟合嫌疑，但是幅度不是很大。</p>
<h2 id="loss与acc之间的关系">loss与acc之间的关系</h2>
<p><a href="https://www.zhihu.com/question/264892967/answer/833656253" target="_blank" rel="noopener">深度学习中 loss 和 accuracy 的关系？</a></p>
<h2 id="关于epoch">关于epoch</h2>
<p>如果你调试了很多参数之后，模型在<strong>训练集</strong>上的性能没有很大改善，<strong>可以尝试大幅度增加 epoch</strong>。当然你也可以在一开始就使用很大的 epoch。因为有些模型很奇怪，可能 loss 曲线已经很平滑了，但是在某个 epoch 之后，loss 值突然暴跌。例如，下图是训练了一段时间的 loss 值，我卡了四五天，一直以为 loss 不会下降了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/smooth_loss.svg" alt="smooth loss" /></p>
<p>但是当你加大 epoch 之后，突然发现它又开始下降了。（注：这两条曲线有点不一样，是因为我略微地调整了代码，但是这已经足够说明问题了。经过我的实验，这里的 loss 值下降与我的代码调整无关） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/slumping_loss.svg" alt="slumping loss" /></p>
<p>这可能不太明显，我们把它缩放一下，发现真的又开始下降了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/scaled_slumping_loss.svg" alt="scaled slumping loss" /></p>
<h2 id="加大lrtrain-loss不一定更快收敛">加大lr，train loss不一定更快收敛</h2>
<p>我有碰到一个情况，<strong>加大学习率后，训练集上的 loss 反而下降的更慢了！</strong>图片我放在了下面，其中深蓝色的曲线代表着学习率是要大的那个模型。我的猜测是，学习率加大后，在某一个时间段的 epoch 中，模型一直在尝试走到山底，但是由于学习率过大，导致它一直来回振荡。而学习率小点，就正好一脚跨下去了。从图中也可以发现，在一开始，大学习率的模型确实要下降的快点，但是后来被小学习率的模型反超了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/增加lr，loss反而下降更慢.svg" alt="增加 lr，loss 反而下降更慢" /></p>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-jozefowicz2015empirical">
<p>Jozefowicz, Rafal, Wojciech Zaremba, and Ilya Sutskever. 2015. “An Empirical Exploration of Recurrent Network Architectures.” In <em>International Conference on Machine Learning</em>, 2342–50.</p>
</div>
</div>
]]></content>
      <categories>
        <category>AI</category>
        <category>liandan</category>
      </categories>
      <tags>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>一些常用的pytorch技巧</title>
    <url>/posts/6e48825d.html</url>
    <content><![CDATA[<div class="note default"><p><mark class="label info">pytorch</mark> <mark class="label warning">zero grad</mark> <mark class="label success">改变tensor形状</mark> <mark class="label primary">矩阵乘法</mark> <mark class="label info">loss function</mark> <mark class="label danger">pytorch nn</mark> <mark class="label success">操作张量</mark></p>
</div>
<div class="note warning"><p>本文只记录框架层面的使用。关于深度学习层面的研究记录在 <a href="https://yan624.github.io/·zcy/AI/nlp/神经网络训练技巧（tricks）.html">神经网络训练技巧（tricks）</a>。</p>
</div>
<h1 id="viewreshape和resize_">view、reshape和resize_</h1>
<p><strong>结论写在前面</strong>：张量连续，使用 <code>view()</code>（此为多数情况）；张量不连续，则使用 <code>reshape()</code>。<code>resize_()</code> 最好不要使用。注意，在张量不连续的情况下，非要使用 <code>view()</code> 也可以，但是要先调用 <code>contiguous()</code> 方法，使得张量连续，但是此方法会返回一个新的张量，浪费时间空间。 <strong>共同点</strong>：这些方法都可以改变 pytorch 中 tensor 的形状，但是它们略有不同。</p>
<ol type="1">
<li>view()：只能改变连续的（contiguous）张量，且返回的张量与原张量的数据是共享的。在张量不连续的情况下，硬要使用此方法，需要在使用之前使用 <code>tensor.contiguous()</code>。</li>
<li>reshape()：对张量是否连续无要求，且<strong>可能</strong>返回的原张量的拷贝（这个“可能”是字面意思，开发者指出，你永远无法预先知道返回的张量是否为拷贝版本。参考 <a href="https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa" target="_blank" rel="noopener">stackoverflow 回答</a>）。</li>
<li>resize_()：与上述二者有较大差别，此方法可以无视原张量的形状，进行随意变化。如果元素的数量大于原张量的元素数量，那么底层的存储大小会进行调整，即会进行扩容。小于，则存储空间不做变化。参考《<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor.resize_" target="_blank" rel="noopener">pytorch 文档</a>》。 <div class="note warning"><p>这是一个底层的方法，大多数情况可以使用 <code>view()</code> 或者 <code>reshape()</code>。想要使用自定义步长改变张量内置的大小，请使用 <code>set_()</code>。总而言之，就是最好不要用这个方法。</p>
</div> <a id="more"></a></li>
</ol>
<h2 id="不连续的张量的说明">不连续的张量的说明</h2>
<p>如果对 tensor 使用 <code>transpose</code>，<code>permute</code> 等操作会使该 tensor 在内存中变得不再连续。例如，以下代码在使用 <code>view()</code> 方法后会报出 <code>RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.</code> 的错误。 <div class="note info"><p>至于为什么 pytorch 有这种“连续的”设定，这就要从 pytorch 的底层讲起了，又是要几条博客才能解释（ps：关键是我也不懂），不过可以参考《<a href="https://zhuanlan.zhihu.com/p/64551412" target="_blank" rel="noopener">PyTorch 中的 contiguous</a>》。</p>
</div></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">tensor = torch.Tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>]])</span><br><span class="line"># 正常输出</span><br><span class="line">print(tensor.transpose(<span class="number">1</span>, <span class="number">0</span>).reshape(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(tensor.permute(<span class="number">1</span>, <span class="number">0</span>).reshape(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(tensor.T.reshape(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"># 报错</span><br><span class="line">print(tensor.transpose(<span class="number">1</span>, <span class="number">0</span>).view(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(tensor.permute(<span class="number">1</span>, <span class="number">0</span>).view(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">print(tensor.T.view(<span class="number">2</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<h2 id="contiguous的解释">contiguous()的解释</h2>
<p>此外，运行以下代码可以得出非连续张量在使用 <code>contiguous()</code> 后会返回一个新的张量，它会重新开辟一块内存，并按照行优先一维展开顺序重新存储原张量。取自 <a href="https://zhuanlan.zhihu.com/p/64551412" target="_blank" rel="noopener">PyTorch 中的 contiguous#为什么需要 contiguous ？</a>。 <figure class="highlight autohotkey"><table><tr><td class="code"><pre><span class="line">tensor1 = torch.Tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">8</span>, <span class="number">9</span>, <span class="number">0</span>]])</span><br><span class="line">tensor2 = tensor1.transpose(<span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line"># 转置前后，张量并无区别</span><br><span class="line">print(tensor1.dat<span class="built_in">a_ptr</span>() == tensor2.dat<span class="built_in">a_ptr</span>())# <span class="literal">True</span></span><br><span class="line"># 对连续张量（tensor1）使用 contiguous() 是无意义的，无论是否转置都是同一个张量</span><br><span class="line">tensor3 = tensor1.contiguous()</span><br><span class="line">print(tensor3.dat<span class="built_in">a_ptr</span>() == tensor2.dat<span class="built_in">a_ptr</span>(), tensor3.dat<span class="built_in">a_ptr</span>() == tensor1.dat<span class="built_in">a_ptr</span>())# <span class="literal">True</span> <span class="literal">True</span></span><br><span class="line"># 对非连续张量（tensor2）使用会返回一个新的张量，无论是否转置都不是同一个张量</span><br><span class="line">tensor4 = tensor2.contiguous()</span><br><span class="line">print(tensor4.dat<span class="built_in">a_ptr</span>() == tensor2.dat<span class="built_in">a_ptr</span>(), tensor4.dat<span class="built_in">a_ptr</span>() == tensor1.dat<span class="built_in">a_ptr</span>())# <span class="literal">False</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><a href="https://blog.csdn.net/qq_39507748/article/details/105381089" target="_blank" rel="noopener">pytorch 学习笔记五：pytorch 中 reshape、view 以及 resize 之间的区别</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/64551412" target="_blank" rel="noopener">PyTorch 中的 contiguous</a></li>
<li><a href="https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa" target="_blank" rel="noopener">What's the difference between reshape and view in pytorch?</a></li>
</ol>
<h1 id="矩阵乘法">矩阵乘法</h1>
<p>pytorch 拥有多种矩阵乘法计算的函数，包括但不限于 <code>torch.mul()</code>，<code>torch.dot()</code>，<code>torch.mm()</code>，<code>torch.bmm()</code>，<code>torch.matmul()</code>。</p>
<h2 id="矩阵相乘">矩阵相乘</h2>
<p><code>torch.dot()</code> 属于向量点积。</p>
<p><code>torch.mm()</code>，<code>torch.bmm()</code>，<code>torch.matmul()</code> 都属于矩阵相乘。</p>
<ol type="1">
<li>torch.mm()：二维矩阵相乘，它只能处理二维矩阵，对于其它维度需要使用 <code>torch.matmul()</code>。注意：如果你需要计算一个矩阵和一个向量的乘法，那么这个向量在框架角度来讲要是二维的。也就是说向量的 shape=(x, 1)，而不能是 shape=(x, )。</li>
<li>torch.bmm()：与 <code>torch.mm()</code> 一样，只能处理二维矩阵，但是它被用于计算具有批次这个维度的矩阵，也就是说相乘的两个矩阵实际上是三维的。例如矩阵 <span class="math inline">\(A_{32 \times 3 \times 4}\)</span> 和 <span class="math inline">\(B_{32 \times 4 \times 3}\)</span>，其中 32 是它们的批次大小，32 之后的维度还是要按照矩阵相乘的规则。<strong>它在神经网络计算中被频繁使用，因为数据通常都是被一批一批得输入进神经网络。注意，<code>torch.bmm()</code> 只是一个特例（带有批次属性的二维矩阵），如果需要计算高维矩阵的相乘，必须使用 <code>torch.matmul()</code>。</strong> <div class="note info"><p>注意，<code>torch.bmm()</code> 的输入只能是 3 维，它不能进行广播。广播矩阵相乘请使用 <code>torch.matmul()</code>。</p>
</div></li>
<li>torch.matmul()：执行的乘法操作取决于输入张量的维度。
<ol type="1">
<li>如果都是 1 维，则点乘；</li>
<li>如果都是 2 维，则计算二维矩阵相乘；</li>
<li>如果第一个张量是 1 维，第二个是 2 维，则广播第一个张量，进行二维矩阵相乘计算；</li>
<li>如果第一个张量是 2 维，第二个是 1 维，则计算矩阵 * 向量；</li>
<li>如果二者至少都是 1 维，且至少一个参数是 N 维（N &gt; 2）。非矩阵的维度将被广播，矩阵维度一般指每个张量的最后一至两位。如 shape=(1, 2, 3, 4) 和 shape=(1, 4, 3)，最后两位是矩阵维度；shape=(1, 2, 3, 4) 和 shape=(4)，第一个张量的最后两位和第二个张量的最后一位就是矩阵维度。</li>
</ol></li>
</ol>
<p>综上，其实没有高维矩阵相乘的概念，一直都是在做矩阵-矩阵/向量乘法，张量中其他的维度只被用于广播。</p>
<h2 id="矩阵对应元素相乘">矩阵对应元素相乘</h2>
<p><code>torch.mul()</code> 是对应元素的乘法，例如 <span class="math inline">\(\begin{pmatrix}1\end{pmatrix}\)</span>。它主要分为两种情况：</p>
<ol type="1">
<li>张量乘标量：这个很好理解，就是一个张量乘上一个数字。</li>
<li>张量乘张量：对应元素相乘，<strong>如果两个张量的形状不同，则需要满足能够广播的前提</strong>。如果不满足，则报错。张量广播的机制具体看下面的章节。</li>
</ol>
<h2 id="广播机制">广播机制</h2>
<p>设现有张量 A，B。广播机制分为两种情况：1）张量的维度不同；2）张量的维度相同。</p>
<p>本来想写的，但是博客<a href="https://blog.csdn.net/littlehaes/article/details/103807303" target="_blank" rel="noopener">《pytorch 中的广播机制》</a>中已经写明白了。此外这些都是经验之说，我在实践过程中发现 A.ndim &lt; B.ndim 也可以进行计算。以后看比较权威的书之后，再来更新吧。</p>
<p>但是有一点比较清楚，广播机制只有 <code>torch.mat.mul()</code> 支持。</p>
<h2 id="参考资料-1">参考资料</h2>
<ol type="1">
<li><a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener">pytorch 官方文档</a></li>
<li><a href="https://pytorch.org/docs/stable/torch.html" target="_blank" rel="noopener">pytorch 中的广播机制</a></li>
</ol>
<h1 id="pytorch-loss-function">pytorch loss function</h1>
<p>pytorch 的多元分类 loss 有 CrossEntropyLoss 和 NLLLoss。NLLLoss 全称 Negative Log Likelihood Loss，说白了就是求对数概率并取负，我们从函数图像就可以理解。模型输出的概率分布在 0-1 之间，log 函数的 0-1 区间正好全是负数，所以要加上一个负号，让 loss 值为正数。显而易见，概率越接近 1，loss 值越小。接下来描述一下这两个函数。 1. CrossEntropyLoss = LogSoftmax + NLLLoss； 2. CrossEntropyLoss 中已经附带了 log_softmax 操作，所以如果你想省事，那么直接将输出向量输入 CrossEntropyLoss 即可； 3. 如果使用 NLLLoss，那么在使用 NLLLoss 之前，还需要经过一层 LogSoftmax。</p>
<p>需要注意一点，我感觉网上很多人也没有理解什么是 CrossEntropyLoss，导致很多人都被误导了。首先 nll 的公式如下：</p>
<p><span class="math display">\[
nll\_loss = -\log(pred)
\]</span></p>
<div class="note warning"><p>nll loss 可以有多种表达方式，我把在网上看到的公式都罗列一下。</p>
<p>以下的公式与 crossentropy 一样。（实际上公式就是一样的，只不过在概念上有点不同，由于输出值 y 是 one hot 形式，为 0 时，就相当于没有加，最后的结果就是上面的公式） <span class="math display">\[
nll\_loss = -\sum^n_{i=1} y_i log(pred_i) = -log(pred)
\]</span> 这里的 class 就是指第几个标签，它不是 one hot 表示形式。大家会发现这里少了一个 log 函数，实际上 pred 是使用 log_softmax 函数计算之后的结果。 <span class="math display">\[
nll\_loss = -pred[class]
\]</span></p>
</div>
<p>CrossEntropyLoss 公式如下： <span class="math display">\[
crossentropy\_loss = -\sum^n_{i=1} y_i log(pred_i)
\]</span> <del>无法理解的原因之一是，在学机器学习的时候，大家都知道啥是 crossentropy，后来在学多元分类时，开始分 binary_crossentropy 和 crossentropy。这点大家都能理解，但是到看到 NLLLoss 时，就开始懵逼了。</del></p>
<p><del>由于 CrossEntropyLoss = LogSoftmax + NLLLoss，在 crossentropy 的公式中貌似没有出现 softmax（更没有 log_softmax），所以开始懵了，无法理解其中的 LogSoftmax 是干啥的。</del></p>
<p>首先我要解释一点 CrossEntropyLoss 是 LogSoftmax 和 NLLLoss 两个步骤之和，之前说的“+”号，并非是数学意义上的加号。也就是说，CrossEntropyLoss 就比 NLLLoss 多做了一步 LogSoftmax（<strong>博主注</strong>：<em>个人认为实际上只是多做了一步 softmax，说多做了一步 log_softmax，是因为站在 pytorch 框架的角度</em>）。</p>
<p>其次，对于真实输出值 y 来说，无非就是 0 和 1（注意多元分类也只有 0 和 1），并且根据上述 crossentropy 的公式。实际上公式可以化简为以下所示，其中的 m 代表真实值为 1 的索引。 <span class="math display">\[
crossentropy\_loss = -\sum^n_{i=1} y_i log(pred_i) = -log(pred_m)
\]</span> 请注意这里的 <span class="math inline">\(pred_m\)</span>。我们都知道在进行分类问题时，我们需要将输出结果置于 0-1 之间，对于二元分类我们使用 sigmoid 函数，对于多元分类我们使用 softmax（到这开始有内味了）。由于分类问题都是要这么做的，所以将 softmax 这个函数放到公式 <span class="math inline">\(crossentropy\_loss = -log(pred_m)\)</span> 中，我们惊奇的发现 crossentropy 函数变成了 log_softmax（最前面的负号暂时不看）。即 crossentropy + softmax = -log_softmax。 <div class="note warning"><p>请始终留意，pred 是一个向量通过 softmax/log_softmax 计算之后的值。</p>
</div></p>
<p>最后你会发现这样还是不对。<span class="math inline">\(nll\_loss = -log(pred)\)</span>，之前说 CrossEntropyLoss = <strong>LogSoftmax</strong> + NLLLoss，我把 log_softmax 放到 nll 里，变成了 <span class="math inline">\(LogSoftmax + NLLLoss = -log(log(pred))\)</span>，怎么多了一个 log？实际上 nll 的公式应该以 <span class="math inline">\(nll\_loss = -pred[class]\)</span> 为准，你会发现这个公式中没有 log 函数。这样将 logsoftmax 放入 nll loss 中，就正好是 crossentropy 了。</p>
<p>那么你就会问 nll 明明是 Negative Log Liklihood，log 不见了，这不就是名存实亡了？</p>
<p><strong>这可能是因为 pytorch 想要简化操作，才这么设置的，别的框架可能并不是这样。简而言之，pytorch 框架中，nll loss 的公式是 -pred。crossentropy 的公式是 logsoftmax + nll loss，即 nll(log_softmax(output))</strong></p>
<p><strong>也就是说，如果神经网络的最后一层输出是 logsoftmax，那么就使用 nll loss（上一段 nll loss 那个 pred 就是通过 log_softmax 的输出值）。如果最后一层只是输出，偷懒不想写 logsoftmax，那么就使用 crossentropy loss（上一段 crossentropy 中的 output 就是一个普通的神经网络输出）。</strong></p>
<h2 id="顺便一提kldivloss">顺便一提KLDivLoss</h2>
<p><a href="https://www.cnblogs.com/charlotte77/p/5392052.html" target="_blank" rel="noopener">【原】浅谈KL散度（相对熵）在用户画像中的应用</a> 暂时还没用过这个 loss，简单来说，是用来比较两个概率分布之间的信息熵差异，如 AB 两组群体，有对某一商品的总消费分布 P 和群体人数的分布 Q，可以计算 PQ 之间的信息熵差异，从而获得 AB 两组群体对该商品的偏爱程度。</p>
<h2 id="参考资料-2">参考资料</h2>
<ol type="1">
<li><a href="http://blog.leanote.com/post/lee-romantic/crossentry" target="_blank" rel="noopener">CrossEntropyLoss和NLLLoss的理解</a></li>
<li><a href="https://www.cnblogs.com/ranjiewen/p/10059490.html" target="_blank" rel="noopener">Pytorch之CrossEntropyLoss() 与 NLLLoss() 的区别</a></li>
<li><a href="https://blog.csdn.net/m0_38133212/article/details/88087206" target="_blank" rel="noopener">CrossEntropyLoss与NLLLoss的总结</a></li>
<li><a href="https://www.cnblogs.com/marsggbo/p/10401215.html" target="_blank" rel="noopener">Pytorch里的CrossEntropyLoss详解</a></li>
</ol>
<h1 id="pytorch中的神经网络">pytorch中的神经网络</h1>
<h2 id="lstm">LSTM</h2>
<p>关于 nn.LSTM 的用法：如果不想手动初始化隐藏状态，而是想让 pytorch 帮你初始化，那么就只需要填入输入值即可。举个例子，下面代码框中的代码所输入的自然语句是 ['how are you', 'i'm fine']。 其中输入值 x 的形状为 (seq_len, batch_size, input_size)，对应上面的例子就是 (3, 2, 300)，代表序列长度为 3（因为上面的两句话的最大长度为 3），批量大小为 2，词向量维度为 300。需要注意的是：<strong>pytorch 会根据你输入的序列长度</strong>（输入的张量必须是一样长的，参差不齐的张量无法输入，当然了，你也无法创建出这样的张量）<strong>自动地在时间步上做计算，不需要你写一个循环，然后依次输入每一个单词的词向量。</strong> <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">cell = nn.<span class="constructor">LSTM(<span class="params">input_size</span>, <span class="params">hidden_size</span>, <span class="params">num_layers</span>)</span></span><br><span class="line">output, (a, m) = cell(x)</span><br></pre></td></tr></table></figure></p>
<h1 id="张量操作">张量操作</h1>
<h2 id="expand">expand()</h2>
<p><code>expand()</code> 函数按照你想要的大小扩充 tensor，并且<strong>返回一个新的 tensor</strong>。注意它是 tensor 的成员方法，并且你所想要新 tensor 的维度必须与原 tensor 的维度相同。例如，原 tensor.shape=(3, 1)，那么你可以扩大为 (3, 4)，但是你不能扩大为 (3, 1, 1)，当然更不能为 (3, 1, 4)。举个例子： <figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">x = torch.Tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])</span><br><span class="line"># (<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">print(x.shape)</span><br><span class="line">y = x.expand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"># (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">print(y.shape)</span><br><span class="line"># error</span><br><span class="line">x.expand(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="optimizer.zero_grad">optimizer.zero_grad()</h1>
<p>在 pytorch 中，为什么要在每个循环之初调用这个方法？因为 pytorch 把计算的每个梯度都累加起来，并不会每迭代一次就将梯度清零。这样做看起来令人费解，并反常理。但是实际上这样做可以做更多神奇的操作，比如</p>
<ul>
<li><a href="https://www.zhihu.com/question/303070254" target="_blank" rel="noopener" class="uri">https://www.zhihu.com/question/303070254</a></li>
</ul>
<p>还有，试想本来你想运行 batch_size=1024，但是由于电脑太差，只能运行 batch_size=256 的批次数据。那么只需要每循环两次调用一次 zero_grad() 即可。 参考：</p>
<ol type="1">
<li><a href="https://blog.csdn.net/u011959041/article/details/102760868" target="_blank" rel="noopener">pytorch中为什么要用 zero_grad() 将梯度清零</a></li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>pytorch</tag>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>科研中用到的python技巧</title>
    <url>/posts/119cad78.html</url>
    <content><![CDATA[<h1 id="迭代器">迭代器</h1>
<a id="more"></a>
<h2 id="参考资料">参考资料</h2>
<ol type="1">
<li><a href="https://blog.csdn.net/cadi2011/article/details/90487199" target="_blank" rel="noopener">Python 之__iter__函数，很重要的知识点</a></li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title>Pointer Networks</title>
    <url>/posts/d7a5fd2b.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/1506.03134.pdf" target="_blank" rel="noopener">论文地址</a>，作者是 Vinyals et al.，发表于 2015 年。</p>
</div>
<h1 id="摘要">摘要</h1>
<p>提出一个新的神经结构来学习输出序列的条件概率，输出元素是在输入序列中对应位置的离散标记。</p>
<p>由于输出的每一步都与输入的长度有关，但是输入的长度是可变的，所以现有方法 seq2seq 和神经图灵机都无法简单地解决这问题。可变长度序列的排序，各种组合优化的问题都属于此类。我们的模型<strong>使用 attention 机制来解决这种输出字典可变大小的问题</strong>。 <a id="more"></a></p>
<h1 id="引言">引言</h1>
<p>RNN 在序列上学习函数已经用了超过 30 年。然而，它们的架构有一定的局限性，<strong>输入和输出只能是固定的</strong>。最近，<strong>引入的 seq2seq 范式移除了这些限制</strong>。Bahdanau et. al. 使用 <strong>attention 机制进一步优化来自输入的额外上下文信息</strong>，以此增强 decoder。 尽管如此，这些方法仍旧需要固定的词典。由于这些限制，我们无法直接地将这些框架应用在输出字典的大小取决于输入序列长度的问题上。本文，我们提出 Pointer Networks（Ptr-Nets），它可以解决三种组合优化问题：<code>computing planar convex hulls, Delaunay triangulations and the symmetric planar Travelling Salesman Problem (TSP)</code>。</p>
<h1 id="模型">模型</h1>
<p>先回顾一下 seq2seq model 和 attention 机制，它们是我们工作的基线。</p>
<h2 id="seq2seq-model">seq2seq model</h2>
<p>给定一个训练对 <span class="math inline">\((\mathcal{P}, \mathcal{C}^{\mathcal{P}})\)</span>，seq2seq 模型使用一个带参数的模型（带参数 <span class="math inline">\(\theta\)</span> 的 RNN）计算条件概率 <span class="math inline">\(p(\mathcal{C}^{\mathcal{P}} | \mathcal{P}; \theta)\)</span> 以此估计概率链式法则，即： <span class="math display">\[p(\mathcal{C}^{\mathcal{P}} | \mathcal{P}; \theta) = \prod^{m(\mathcal{P})}_{i=1} p(\mathcal{C}_i | \mathcal{C}_1, \cdots, \mathcal{C}_{i-1}, \mathcal{P}; \theta) \tag{1}
\]</span> 其中 <span class="math inline">\(\mathcal{P} = \{P_1, \cdots, P_n\}\)</span>，<span class="math inline">\(\mathcal{C} = \{C_1, \cdots, C_{m(\mathcal{P})}\}\)</span>。模型参数在训练集上最大化条件概率： <span class="math display">\[\theta^{\star} = \arg \max_{\theta} \sum_{\mathcal{P}, \mathcal{C^{\mathcal{P}}}} \log p(\mathcal{C}^{\mathcal{P}} | \mathcal{P}; \theta) \tag{2}
\]</span></p>
<h2 id="content-based-input-attention">Content Based Input Attention</h2>
<h2 id="ptr-net">Ptr-Net</h2>
<p>我们现在描述一个非常简化版的 attention 模型，它能使得我们解决上面提到的难题。我们使用 attention 机制建模 <span class="math inline">\(p(\mathcal{C}_i | \mathcal{C}_1, \cdots, \mathcal{C}_{i-1}, \mathcal{P})\)</span>： <span class="math display">\[
\begin{align}
    u^i_j &amp; = v^T tanh(W_1 e_j + W_2 d_i) \quad j \in (1, \cdots, n) \\
    p(\mathcal{C}_i | \mathcal{C}_1, \cdots, \mathcal{C}_{i-1}, \mathcal{P}) &amp; = softmax(u^i)
\end{align}
\]</span> 然后，不同于 attention 机制，<strong>我们不混合编码状态 <span class="math inline">\(e_j\)</span></strong> 以此将信息带到 decoder 中，而是<strong>使用 <span class="math inline">\(u^i_j\)</span> 作为指针，指出输出元素</strong>。 <strong>我们还注意到，我们的方法特别针对输出是离散的并且与输入中的位置相对应的问题。</strong></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>Ptr</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中各种优化算法的学习笔记</title>
    <url>/posts/bbe4416e.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://ruder.io/optimizing-gradient-descent/index.html" target="_blank" rel="noopener">各种优化算法比较</a></p>
</div>
<h1 id="mini-batch梯度下降">Mini-batch梯度下降</h1>
<div class="note primary"><p>Q：为什么Mini-batch比普通的梯度下降快？</p>
</div>
<p>普通的梯度下降——vanilla gradient descent，是将整个数据集同时做运算，而Mini-batch梯度下降算法是以一组为单位，分别进行梯度下降，所有组执行完毕后再进行下一次迭代。</p>
<p>假设现在有m个样本。 <span class="math display">\[
X = \begin{pmatrix}x^1&amp;x^2&amp;x^3&amp;\cdots&amp;x^m\end{pmatrix}\\
Y = \begin{pmatrix}y^1&amp;y^2&amp;x^3&amp;\cdots&amp;y^m\end{pmatrix}\\
\]</span> 使用Mini-batch，假设每1000个样本为一组： <span class="math display">\[
X = \begin{pmatrix}\underbrace{x^1\cdots x^{1000}}_{X^{\{1\}}} &amp; \underbrace{x^{1001}\cdots x^{2000}}_{X^{\{2\}}} &amp; \cdots&amp;\underbrace{\cdots x^m}_{X^{\{t\}}}\end{pmatrix}\\
Y = \begin{pmatrix}\underbrace{y^1\cdots y^{1000}}_{Y^{\{1\}}} &amp; \underbrace{y^{1001}\cdots y^{2000}}_{Y^{\{2\}}} &amp; \cdots&amp;\underbrace{\cdots y^m}_{Y^{\{t\}}}\end{pmatrix}\\
\]</span> 如果使用代码实现就是类似下面这样的伪代码： <figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> t = <span class="number">1</span>, ..., t</span><br><span class="line">	forwardprop <span class="keyword">on</span> X^&#123;t&#125;</span><br><span class="line">	compute cost</span><br><span class="line">	backprop <span class="keyword">to</span> compute grads</span><br><span class="line">	update weights <span class="keyword">and</span> bais</span><br></pre></td></tr></table></figure> for循环完成之后就完成了神经网络的第一次迭代。 <a id="more"></a></p>
<h2 id="理解mini-batch">理解mini-batch</h2>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/Mini-batch和普通梯度下降的区别.jpg" alt="Mini-batch和普通梯度下降的区别" /> 1. 如果将batch设为m，那它就是普通的梯度下降算法。 2. 如果将batch设为1，就叫做随机梯度下降——SGD 3. batch在1到m之间就是mini-batch</p>
<p>SGD和普通梯度下降的区别，“+”代表代价最小点。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/SGD和vanilla%20gradient%20descent的区别.jpg" alt="SGD和vanilla gradient descent的区别" /> SGD和mini-batch的区别。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/SGD和mini-batch的区别.jpg" alt="SGD和mini-batch的区别" /></p>
<p><strong>应该记住的有：</strong></p>
<ol type="1">
<li>普通梯度下降、mini-batch和SGD之间的区别就是执行一次参数更新所需的样本数量不同。</li>
<li>你需要自己调整学习速率<span class="math inline">\(\alpha\)</span>。</li>
<li>当mini-batch的量调整良好时，它通常优于普通梯度下降和SGD（尤其是在训练集特别大时）。</li>
</ol>
<h2 id="mini-bacth实现步骤">mini-bacth实现步骤</h2>
<ol type="1">
<li>打乱数据。创建一个打乱数据之后的副本，其中X和Y的每一列都代表一个训练样本。注意X和Y是同步地随机打乱样本，即X中第<span class="math inline">\(i^{th}\)</span>个样本和Y中第<span class="math inline">\(i^{th}\)</span>标签在打乱之后还是是对应的。此步骤确保样本被随机地分割到不同的mini-batches中。下图是步骤示意图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/mini-batch第一步打乱数据.jpg" alt="mini-batch第一步打乱数据" /></li>
<li>切分。将打乱数据后的XY切分进<code>mini_batch_size</code>大小（下图是64）的mini-batches中。不过注意训练样本的数量并不总能被<code>mini_batch_size</code>整除。最后的mini-batch可能要小点，但是不需要担心这点。使用<code>math.floor()</code>向上取整即可。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/mini-batch第二步切分.png" alt="mini-batch第二步切分" /></li>
</ol>
<h2 id="一些经验">一些经验</h2>
<p>如果小数据量（大约小于2000）的话，<strong>只</strong>执行步骤1即可；如果样本数目较大，执行步骤1和步骤2，一般将batch设置在64~512之间，考虑到电脑的内存设置和使用方式，batch的大小设置为2的次方，代码的运行速度会比较快；</p>
<h1 id="指数加权平均">指数加权平均</h1>
<p>为了更好地理解其他优化算法，需要使用到指数加权平均。这章介绍一下它。</p>
<p>Exponentially weighted averages，在统计学中被称为指数加权移动平均——Exponentially weighted moving averages。</p>
<p>指数加权平均有一个公式：<span class="math inline">\(V_t = \beta * V_{t-1} + (1- \beta) * \theta_t\)</span>，<span class="math inline">\(V_0 = 0\)</span>，其目的是使用<span class="math inline">\(V_t\)</span>代替<span class="math inline">\(\theta_t\)</span>。<span class="math inline">\(V_t\)</span>可视为<strong>约等于</strong><span class="math inline">\(\frac{1}{1 - \beta}\)</span>个样本的平均值。这里可能会有疑问，为什么<span class="math inline">\(V_t\)</span>可视为约等于<span class="math inline">\(\frac{1}{1 - \beta}\)</span>个样本的平均值？将 <span class="math inline">\(1 - \beta\)</span> 除到等式左边，可以看到 <span class="math inline">\(\frac{1}{1 - \beta} V_t \approx \theta_t\)</span>。</p>
<p>下图中的数据为伦敦一年之间的温度，来源于吴恩达的深度学习视频，可以看到其中的数据十分杂乱，也就是常在网络上看到别人所说的“噪点”多。我们可以使用<strong>指数加权平均</strong>来画出一条线，就是下图的红线，来代表温度变化的趋势，这样会使得更容易让人类理解和观察。</p>
<p>下图中的<span class="math inline">\(\beta\)</span>为0.9。而<span class="math inline">\(\frac{1}{1 - 0.9} = 10\)</span>，所以<span class="math inline">\(V_t\)</span>代表过去<em>十天</em>内的平均温度。如果<span class="math inline">\(\beta\)</span>为0.98，那么<span class="math inline">\(V_t\)</span>代表过去<em>五十</em>天内的平均温度 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/指数加权平均例子.jpg" alt="指数加权平均例子" /> 下图是不同<span class="math inline">\(\beta\)</span>值的对比。注意到一点，绿色（<span class="math inline">\(\beta\)</span>=0.98）的线比红色的线要平坦一点，这是因为你多平均了几天的温度，所以这根线波动更新、更平坦。但是缺点是曲线进一步向右移，拟合的不是很好。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/不同beta值的对比.jpg" alt="不同beta值的对比" /> 现在看到了平均了10天和50天温度的曲线，现在试试<span class="math inline">\(\beta=0.5\)</span>，也就是只平均两天的温度。由于只平均了两天的温度，数据太少，所以曲线有更多的噪声，更有可能出现异常值。但是这个曲线能更快适应温度变化。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/beta值等于0.5的指数加权平均.jpg" alt="beta值等于0.5的指数加权平均" /></p>
<h2 id="理解其作用">理解其作用</h2>
<div class="note primary"><p>略。至今看不懂。</p>
</div>
<h2 id="偏差修正">偏差修正</h2>
<p>之前的曲线其实都是理想状态下的，回想绿色的曲线是50天内的温度平均值。但是其实绿色曲线会是紫色曲线那样的轨迹。初始化<span class="math inline">\(V_0=0\)</span>，原数据中<span class="math inline">\(\theta_0 = 40\)</span>，所以其实<span class="math inline">\(V_1 = 0.02 * 40 = 8\)</span>，从而绿色曲线的起点实际上很低。因为起点并没有计算50天内的温度平均，我们默认将<span class="math inline">\(V_0\)</span>初始化为0。</p>
<p>我们可以用下图右边的公式将其修正。算出<span class="math inline">\(V_t\)</span>后再做如下计算：<span class="math inline">\(\frac{V_t}{1 - \beta^t}\)</span>，其中<span class="math inline">\(\beta\)</span>的上标t是指<strong>t次方</strong>。</p>
<p>另外由于t越大，<span class="math inline">\(\beta^t\)</span>的值越接近0，所以对后面的值几乎没影响。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/指数加权平均偏差修正.jpg" alt="指数加权平均偏差修正" /></p>
<h1 id="优化算法总结">优化算法总结</h1>
<table>
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="header">
<th>算法</th>
<th>介绍</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>SGD</td>
<td>问：为什么 SGD 比 batch gradient descent 快？答：因为 SGD 可以使用极小的 epoch 更新多次权重，而 BGD 必须要大 epoch 才可以。详见<a href="https://www.zhihu.com/question/40892922" target="_blank" rel="noopener">此处</a></td>
</tr>
<tr class="even">
<td> </td>
<td><strong>优点</strong>：<br /> 1）在损失函数是凸函数的情况下能够保证收敛到一个较好的全局最优解；2）数据量过大时，batch 方法可以减少机器压力，从而更快地收敛；3）当训练集有很多冗余时（类似的样本出现多次），batch方法收敛更快。<br /> <strong>缺点</strong>：<br />1）<span class="math inline">\(\alpha\)</span> 是一个定值，它的选取直接决定了解的好坏，过小会导致收敛太慢，过大会导致震荡而无法收敛到最优解；2）对于非凸问题，只能收敛到局部最优，并且没有任何摆脱局部最优的能力（一旦梯度为0就不会再有任何变化）；3）更新方向完全依赖当前的 batch</td>
</tr>
<tr class="odd">
<td>Momentum</td>
<td>累积梯度，充当动量，注：虽然 Momentum 和 RMSprop 类似，但是实际上在计算上并不一样， RMSprop 要多一个除以 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span> 的步骤，且没有偏差修正这一步骤</td>
</tr>
<tr class="even">
<td> </td>
<td><strong>优点</strong>：1）一定程度上缓解了 SGD 收敛不稳定的问题，并且有一定的摆脱局部最优的能力（即如同一个滚轮下坡一样，它拥有惯性，在到达鞍点时不会立即停止，会因为惯性再向前一点距离，从而可能离开此鞍点）。<br /> <strong>缺点</strong>：1）多了一个超参数需要调整，它的选取同样会影响到结果。</td>
</tr>
<tr class="odd">
<td>RMSprop</td>
<td>通过除以 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span> 减小波动幅度从而收敛更快</td>
</tr>
<tr class="even">
<td> </td>
<td><strong>优点</strong>：1）不需要手动调整学习率，可以自动调整。</td>
</tr>
<tr class="odd">
<td>Adam</td>
<td><strong>优点</strong>：1）结合 Momentum 和 RMSProp，稳定性好，同时相比于 Adagrad 不用存储全局所有的梯度，适合处理大规模数据。<br /> <strong>缺点</strong>：1）有三个超参数需要调整</td>
</tr>
<tr class="even">
<td>Adagrad</td>
<td>RMSProp 的简化版<br /> <strong>适用场景</strong>：Adagrad非常适合处理稀疏数据（如 one-hot）</td>
</tr>
<tr class="odd">
<td> </td>
<td><strong>优点</strong>：1）不需要手动调节 <span class="math inline">\(\alpha\)</span>，它会发生自适应的变化。<br /> <strong>缺点</strong>：1）学习率单调递减，在迭代后期可能导致学习率变得特别小而导致收敛及其缓慢。</td>
</tr>
<tr class="even">
<td>Adadelta</td>
<td>Adadelta 是 Adagrad 的一种扩展算法，以处理Adagrad学习速率单调递减的问题。RMSprop 可以算作 Adadelta 的一个特例</td>
</tr>
<tr class="odd">
<td> </td>
<td><strong>优点</strong>：1）不需要手动调整学习率，可以自动调整；2）不需要手动设置<strong>初始</strong> <span class="math inline">\(\alpha\)</span>。<br /> <strong>缺点</strong>：1）后期容易在小范围内产生震荡</td>
</tr>
<tr class="even">
<td>-----------</td>
<td><a href="https://blog.csdn.net/gangyin5071/article/details/81810358#11-sgd" target="_blank" rel="noopener">机器学习各优化算法的简单总结</a><br /> <a href="http://ruder.io/optimizing-gradient-descent/" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms</a> <br /> <a href="https://arxiv.org/abs/1609.04747" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms ARXIV</a> <br /> <a href="https://blog.csdn.net/google19890102/article/details/69942970" target="_blank" rel="noopener">An overview of gradient descent optimization algorithms 中文翻译</a></td>
</tr>
</tbody>
</table>
<p>凸优化与非凸优化： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/凸优化与非凸优化.jpg" alt="凸优化与非凸优化" /></p>
<h1 id="动量梯度下降momentum">动量梯度下降——Momentum</h1>
<p>Momentum改进自SGD，让每一次的参数更新方向不仅取决于当前位置的梯度，还受到上一次参数更新方向的影响。 不管是普通的梯度下降、mini-batch、SGD 还是其他的什么，都是通过 <span class="math inline">\(W -= \alpha * dW\)</span> 来更新权重。但是在动量梯度下降中，使用到了<strong>指数加权平均</strong>。尤其是针对mini-batch算法，因为mini-batch算法抖动过大，上面的章节介绍了mini-batch的梯度下降误差曲线，指数加权平均正好可以解决。 可以观察下图发现，梯度下降的波动比较大，也就是噪点较多，我们可以使用指数加权平均来减少噪点。下面的公式就是用其减少了梯度dW和db。下式中还对指数加权平均进行了优化，使用了<strong>偏差修正</strong>。 <span class="math display">\[
    \begin{cases}
        compute\ dW, db\\
        V_{dW} = \beta * (V_{dW})_{prev} + (1 - \beta) * dW,\quad V_{db} = \beta * (V_{db})_{prev} + (1 - \beta) * db\\
        V^{corrected}_{dW} = \frac{V_{dW}}{1 - \beta^t},\quad V^{corrected}_{db} = \frac{V_{db}}{1 - \beta^t} \\
        W -= \alpha * V^{corrected}_{dW}\\
        b -= \alpha * V^{corrected}_{db}\\
    \end{cases}
\]</span> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/梯度下降示意图.jpg" alt="梯度下降示意图" /></p>
<p>在梯度下降时的这种波动减慢了下降的速度，无法使用更大的学习速率。因为梯度已经很大了，如果使用更大的学习速率，可能梯度直接爆炸了，直接无法收敛。为了避免摆动过大需要使用较小的学习速率。 还可以从另一种角度看待。我们希望在纵轴上学习的慢点，我们希望摆动小点，不就是希望纵轴小点吗。而在横轴上我们又希望学习的快点，因为我们希望越快接近中心越好。 这个<a href="https://www.bilibili.com/video/av10590361/?p=18" target="_blank" rel="noopener">视频</a>讲的直观一点，可以参考一下，从36:00开始看，虽然讲的是RMSprop但是讲的原理跟Momentum的原理一样。</p>
<h2 id="补充">补充</h2>
<p>在课后练习中有更详细的说明，在此补充一下。 &gt;Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will &quot;oscillate&quot; toward convergence. Using momentum can reduce these oscillations.</p>
<p>大致意思就是使用Momentum可以使得mini-batch的振荡更小，观察下图。。。说实话我并没有观察出什么，不知道Coursera是怎么想的。我把此图的提示贴出来： &gt;Figure 3: The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence v and then take a step in the direction of v .</p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/机器学习中的各种优化算法/mini-batch使用Momentum后.png" alt="mini-batch使用Momentum后" /> &gt;Momentum takes into account the past gradients to smooth out the update. We will store the 'direction' of the previous gradients in the variable v . Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of v as the &quot;velocity&quot; of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill.</p>
<p>Momentum考虑到了之前的梯度，从而用其来缓和参数更新。我们将前一次梯度的“方向”存进变量v。后续不翻译了。</p>
<h1 id="均方根传播rmsprop">均方根传播——RMSprop</h1>
<div class="note primary"><p>问题：对梯度做平方，且 <span class="math inline">\(S_{dW}\)</span> 的计算公式是加法（即修改过的指数加权平均），那么 <span class="math inline">\(S_{dW}\)</span> 岂不是会越来越大？不就意味着动量越来越大，到最后停不下来了？</p>
<p><strong>当然不是，可以减小</strong>。设 <span class="math inline">\(dW_1 = 15 \quad S_{dW1} = 20 \quad \beta = 0.9 \quad dW_2 = 2\)</span>，则 <span class="math inline">\(S_{dW2} = 0.9 * 20 + (1 - 0.9) * 15 = 19.5\)</span>，而 <span class="math inline">\(S_{dW3} = 0.9 * 19.5 + (1 - 0.9) * 2 = 17.75\)</span>。比较 <span class="math inline">\(S_{dW1} \, S_{dW2} \, S_{dW3}\)</span> = 20 19.5 17.75，明显在下降，比较 <span class="math inline">\(dW_1 \, dW_2\)</span> 发现梯度减少引起得 <span class="math inline">\(dS\)</span> 减少。</p>
<p><strong>RMSProp 的本质</strong>是：在梯度大的地方，减小 <span class="math inline">\(\alpha\)</span>（即陡坡则减小步伐）；在梯度小的地方，增大 <span class="math inline">\(\alpha\)</span>（即缓坡则增大步伐）。解释如下：</p>
<p>RMSProp的更新公式为： <span class="math display">\[
    \begin{cases}
        S_{dW} = \beta_2 * (S_{dW})_{prev} + (1 - \beta_2) * (dW)^2 \\
        W -= \alpha * \frac{dW}{\sqrt{S_{dW}} + \epsilon} \\
    \end{cases}
\]</span> 对于 <span class="math inline">\(W -= \alpha * \frac{dW}{\sqrt{S_{dW}} + \epsilon}\)</span> 来说，其实就是普通的权重更新公式多除以一个 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span>。而由于 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span> 是梯度的累加，故为简便起见，将 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span> 看作梯度（Q：为什么可以将这个视为梯度？A：<span class="math inline">\(\sqrt{S_{dW}}\)</span> 是对梯度 dW 的类似累加操作，开个根号后差不多就是梯度）。</p>
<p>我们知道在<strong>陡坡</strong>处梯度大，我们需要<strong>减小步伐</strong>，要不然容易一步迈长了，而减小步伐的意思就是减小 <span class="math inline">\(\alpha\)</span>。</p>
<p>假设现在陡坡处梯度为 100，那么就是将原本的梯度下降公式多除以了 100（因为我们已将 <span class="math inline">\(\sqrt{S_{dW}} + \epsilon\)</span> 视为梯度）。是不是梯度越大，则分母越大？分母越大则意味着 <span class="math inline">\(\alpha\)</span> 越小。</p>
<p>反之，<strong>缓坡</strong>梯度小，我们就需要<strong>增大步伐</strong>，假设梯度为 0.1，那么就代表将原本的权重更新公式除以 0.1。分母越小，则 <span class="math inline">\(\alpha\)</span> 越大。</p>
</div>
<p>Root mean square prop.</p>
<p>一个类似Momentum的算法，没必要死记公式，略。<a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=48e14d97b8284ad0b4e8d32be2605c3d#/learn/content?type=detail&amp;id=2001702124" target="_blank" rel="noopener">视频地址</a>。</p>
<p>或者<a href="https://www.bilibili.com/video/av10590361/?p=18" target="_blank" rel="noopener">另一个参考视频</a>，36:00开始。</p>
<p><strong>RMSprop 没有使用偏差修正。</strong>但是在 Adam 中的 RMSprop 使用了偏差修正。 <span class="math display">\[
    \begin{cases}
        compute\ dW, db\\
        S_{dW} = \beta_2 * (S_{dW})_{prev} + (1 - \beta_2) * (dW)^2,\quad S_{db} = \beta_2 * (S_{db})_{prev} + (1 - \beta_2) * (db)^2\\
        W -= \alpha * \frac{dW}{\sqrt{S_{dW}} + \epsilon}\\
        b -= \alpha * \frac{db}{\sqrt{S_{db}} + \epsilon}\\
    \end{cases}
\]</span> 在更新 W 和 b 时的算法与之前的 Momentum 算法略微不同。另外为了防止 dW 和 db 等于 0，导致分母为 0，所以在分母加了一个极小值<span class="math inline">\(\epsilon\)</span>，在 Keras 中取了 1e-7， 吴恩达老师说 1e-8 是个不错的选择。</p>
<p><strong>RMSprop 算法也是使用了指数加权平均算法。</strong>并且还结合了 Adagrad。 <div class="note info"><p>对于理解 RMSprop。<strong>可以观察出 RMSprop 和 Momentum 长得有点像，但是这两个算法的具体关系暂时不清楚</strong>。并且 RMSprop 其实还有简化版的算法，叫做 Adagrad。之前对这些优化算法（Momentum, RMSprop, Adam 等）的理解都是<em>改变 W 和 b 的大小从而使得梯度下降更快</em>。但是又今天看了一遍<a href="https://www.bilibili.com/video/av10590361/?p=18" target="_blank" rel="noopener">李宏毅老师的视频</a>，发现还有其他的理解。其实这些算法都在<strong>改变学习速率的大小</strong>。</p>
<p>比如 RMSprop 算法，观察<span class="math inline">\(W -= \alpha * \frac{dW}{\sqrt{S_{dW}} + \epsilon}\)</span>，我们可以改写成<span class="math inline">\(W = W - \frac{\alpha}{\sqrt{S_{dW}} + \epsilon} * dW\)</span>。看dW之前的那项<span class="math inline">\(\frac{\alpha}{\sqrt{S_{dW}} + \epsilon}\)</span>实际上就是对学习速率<span class="math inline">\(\alpha\)</span>乘上了<span class="math inline">\(\frac{1}{\sqrt{S_{dW}} + \epsilon}\)</span>。</p>
<p>所以对RMSprop的理解是：<strong>如果梯度过大<span class="math inline">\(\frac{\alpha}{\sqrt{S_{dW}} + \epsilon}\)</span>就会相对减小，如果梯度过小<span class="math inline">\(\frac{\alpha}{\sqrt{S_{dW}} + \epsilon}\)</span>就会相对增大</strong>。因为其实<span class="math inline">\(S_{dW}\)</span>就是 dW 算出来的，而梯度过大就是 dW 过大，dW过大就是<span class="math inline">\(S_{dW}\)</span>过大。一个很大的数取倒数，这个数就变很小了。梯度过小同理。</p>
<p>而为什么梯度过大就要是学习速率<span class="math inline">\(\alpha\)</span>变小呢？因为梯度过大就是说梯度较为陡峭，可以想象一座陡峭的山，如果跨一大步是不是直接掉下去了？而掉在哪是未知的，很有可能掉到最低点的前面，这样大概率是回不到最低点的（或者是极小值点）。而如果<span class="math inline">\(\alpha\)</span>小点就很好了，因为可以一小步一小步的走，最终可能会走到极小值点（或者最小值点）。梯度过小同理。平原地方肯定要大跨步走，你小步伐走要走到什么时候才能走到极小值点？</p>
<p><strong>另外 RMSprop 可以算是 Adagrad 算法的改进版，但是这二者的具体关系未知。</strong></p>
</div></p>
<h1 id="优化算法历史介绍">优化算法历史介绍</h1>
<blockquote>
<p>在深度学习的历史中，有不少学者，包括许多知名学者，提出了优化算法并解决了一些问题。但之后这些算法被指出并不能一般化，并不能适用于多种神经网络。</p>
<p>时间久了，深度学习圈子里的人开始多少有点质疑全新的优化算法。</p>
<p>但是RMSprop和Adam是少有的经受住人们考验的两种算法。已被证明适用于不同的深度学习结构。</p>
</blockquote>
<h1 id="adam">Adam</h1>
<p>全称：Adaptive Moment Estimation</p>
<p>这里的 RMSprop 使用了偏差修正。</p>
<p><strong>Adam 算法是 Momentum 和 RMSprop 结合起来的算法。</strong>Momentum算法解决算法在纵轴上波动过大的问题，它可以使用类似于物理中的动量来累积梯度。而RMSprop可以在横轴上收敛速度更快同时使得波动的幅度更小。所以将两种算法结合起来表现可能会更好。</p>
<div class="note primary"><p>我的理解是 RMSprop 算法也算是在累计梯度。所以我感觉只使用 RMSprop 和使用 Adam 差不多。</p>
</div>
<p><span class="math display">\[
\begin{array}{l}
    compute\ dW, db\\
    V_{dW} = \beta_1 * V_{dW} + (1 - \beta_1) * dW,\quad V_{db} = \beta_1 * V_{db} + (1 - \beta_1) * db\\
    S_{dW} = \beta_2 * S_{dW} + (1 - \beta_2) * (dW)^2,\quad S_{db} = \beta_2 * S_{db} + (1 - \beta_2) * (db)^2\\
    V^{corrected}_{dW} = \frac{V_{dW}}{1 - \beta_1},\quad V^{corrected}_{db} = \frac{V_{db}}{1 - \beta_1}\\
    S^{corrected}_{dW} = \frac{S_{dW}}{1 - \beta_2},\quad S^{corrected}_{db} = \frac{S_{db}}{1 - \beta_2}\\
    W -= \alpha * \frac{V^{corrected}_{dW}}{\sqrt{S^{corrected}_{dW}} + \epsilon}\\
    b -= \alpha * \frac{V^{corrected}_{db}}{\sqrt{S^{corrected}_{db}} + \epsilon}\\
\end{array}
\]</span> <a href="https://arxiv.org/pdf/1412.6980.pdf" target="_blank" rel="noopener">adam paper</a>在这。</p>
<h2 id="超参数的选择">超参数的选择</h2>
<ol type="1">
<li><span class="math inline">\(\alpha\)</span>需要自行调整。</li>
<li><span class="math inline">\(\beta_1\)</span>一般设置为0.9，计算<span class="math inline">\(dW\)</span>。</li>
<li><span class="math inline">\(\beta_2\)</span>Adam的作者推荐0.999，计算<span class="math inline">\((dW)^2\)</span>。</li>
<li><span class="math inline">\(\epsilon\)</span>其实不是很重要，但是Adam作者推荐设置为<span class="math inline">\(10^{-8}\)</span>。其实不设置也可以，并不会影响算法的性能。</li>
</ol>
<p>所以在该算法中其实只要调整<span class="math inline">\(\alpha\)</span>就够了，其他的参数也可以调整，但是一般不调整。</p>
<h2 id="adam是否还需要调节学习率">adam是否还需要调节学习率？</h2>
<p><a href="https://arxiv.org/pdf/1705.08292.pdf" target="_blank" rel="noopener">The Marginal Value of Adaptive Gradient Methods in Machine Learning</a></p>
<h1 id="其他的学习速率衰减算法">其他的学习速率衰减算法</h1>
<h2 id="adagrad">Adagrad</h2>
<p>让学习率适应参数，对于出现次数较少的特征，我们对其采用更大的学习率，对于出现次数较多的特征，我们对其采用较小的学习率。因此，Adagrad非常适合处理稀疏数据。</p>
<p><a href="https://www.bilibili.com/video/av10590361/?p=6" target="_blank" rel="noopener">李宏毅 Adagrad 参考视频</a>，从06:30开始。</p>
<p><a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=48e14d97b8284ad0b4e8d32be2605c3d#/learn/content?type=detail&amp;id=2001702125" target="_blank" rel="noopener">吴恩达深度学习——学习速率衰减</a></p>
<h1 id="优化算法总结-1">优化算法总结</h1>
<table>
<thead>
<tr class="header">
<th><strong>optimization method</strong></th>
<th><strong>accuracy</strong></th>
<th><strong>cost shape</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Gradient descent</td>
<td>79.7%</td>
<td>oscillations</td>
</tr>
<tr class="even">
<td>Momentum</td>
<td>79.7%</td>
<td>oscillations</td>
</tr>
<tr class="odd">
<td>Adam</td>
<td>94%</td>
<td>smoother</td>
</tr>
</tbody>
</table>
<h1 id="优化算法实战">优化算法实战</h1>
<p>在实践中，可能可以先使用 Adam 让模型快速收敛，然后使用 SGD 让模型跑出更好的效果。</p>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/32338983" target="_blank" rel="noopener">Adam 那么棒，为什么还对 SGD 念念不忘 (3)—— 优化算法的选择与使用策略</a></li>
</ol>
<!-- hexo-renderer-pandoc 有问题，如果表格中的内容过多，会自动生成 colgroup 标签 -->
<script>
    $('colgroup').remove()
</script>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>4me</tag>
        <tag>优化算法</tag>
      </tags>
  </entry>
  <entry>
    <title>SLU论文笔记（？-2019）</title>
    <url>/posts/81299a9a.html</url>
    <content><![CDATA[<h1 id="a-bi-model-based-rnn-semantic-frame-parsing-model-for-intent-detection-and-slot-filling">A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling</h1>
<ul>
<li><a href="https://yan624.github.io/·论文笔记/dilogue/task-oriented/59.%20A%20Bi-model%20based%20RNN%20Semantic%20Frame%20Parsing%20Model%20for%20Intent%20Detection%20and%20Slot%20Filling.html">论文笔记</a></li>
<li>对 ID 和 SF 分别使用了一个模型，但是<strong>共享了两个模型的隐藏状态</strong>。论文中描述到，以前的研究经常把 ID 和 SF 当做两个任务来看，这次这篇论文将这两个任务交互起来当做一个任务看待。但是我认为 joint model 这种做法已经是将两个任务当做一个看了，毕竟它们共享了一个模型提取的信息，只是在解码时使用不同的模型。
<ul>
<li>对于解码而言，论文分别使用了 encoder-decoder 结构和纯粹的 encoder 结构，最后是 encoder-decoder 性能略高。 <a id="more"></a></li>
</ul></li>
</ul>
<h1 id="a-self-attentive-model-with-gate-mechanism-for-spoken-language-understanding">A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding</h1>
<p>大多数现存的联合学习模型仅考虑表面的参数共享，而不是语义级的。本文使用新的 self-attentive 模型和 gate mechanism（门控机制）全面地利用槽位与意图之间的语义关联。</p>
<ul>
<li>图 1 显示了我们模型的总览。第一层将输入序列映射为向量，向量由字级别和字母级别（由 CNN 获得）的向量拼接而成，这个合并的向量将用于接下来的层。在序列标注中，上下文信息在很多场景下都很有用，本文使用一种方法在每个时间步使用上下文特征。具体来说，<strong>使用 self-attention 获取上下文向量</strong>，然后 BiRNN 使用这个向量产生隐藏状态。最后一步使用意图增强（intent-augmented）的门控机制去匹配槽位标签。最终，在门控机制之上再加上 softmax 层，用于分类。
<ul>
<li><strong>Embedding Layer</strong>：我们首先将单词 <span class="math inline">\(w = (w_1, w_2, \cdots, w_T)\)</span> 转换为词级别的嵌入 <span class="math inline">\(E^w = [e^w_1, e^w_2, \cdots, e^w_T]\)</span> 和字母级别的嵌入 <span class="math inline">\(E^c = [e^c_1, e^c_2, \cdots, e^c_T]\)</span>。尽管 GloVe 和 Word2vec 词向量已经能够满足很多 NLP 任务，但是字母级别的信息能够提供一些更细微的知识（例如语素）。一些语素相关的词在向量空间中更接近，这对识别槽位标签很有帮助。同时字母级别的词向量也有利于缓解 OOV 问题。本文关注 <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/viewPaper/12489" target="_blank" rel="noopener">Kim et al., 2016</a> 使用的 character-aware convolution layer。 ……</li>
<li><strong>Self-Attention</strong>：</li>
<li><strong>BiLSTM</strong>：</li>
<li><strong>Intent-Augmented Gating Mechanism</strong>：</li>
<li><strong>Task Learning</strong>：</li>
</ul></li>
</ul>
<h1 id="attention-based-recurrent-neural-network-models-for-joint-intent-detection-and-slot-filling">Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling</h1>
<ul>
<li>使用 seq2seq + attention 技术</li>
<li>对于 ID 任务来说，提高了 0.56% 的性能，对于 SF 任务来说，提高了 0.23% 的性能。emmmm，attention 对序列标注可能没多大帮助，可能 seq2seq 模型都是多余的，但是语句分类来说可能有一点点帮助。</li>
</ul>
<h1 id="encoder-decoder-with-focus-mechanism-for-sequence-labelling-based-spoken-language-understanding">Encoder-decoder with focus-mechanism for sequence labelling based spoken language understanding</h1>
<ul>
<li><strong>此论文专注于 SLU 中的 <font color='red'>slot-filling 任务</font></strong>，并没有训练意图检测的模型</li>
<li>使用 encoder-decoder 结构，其中 encoder 是 Bi-LSTM，decoder 是 uni-LSTM
<ul>
<li>结合了 attention 机制，发现有局限性
<ul>
<li>序列标注任务中的输入和输出是对齐的，但是在执行 attention 时，却取了所有输入单词的加权和</li>
<li>单词的对齐（alignment）可由 attention 机制学习到，但是在序列标记任务中，很难拟合有限的标注数据（与此不同的是机器翻译更容易获得成对数据，如中英文翻译，而序列标注任务所需的数据非常稀少，且需要人工标注）。</li>
</ul></li>
<li>所以对 encoder-decoder 结构提出了一种新的 <strong>focus</strong> 机制</li>
</ul></li>
<li>首先使用 Bi-LSTM 编码，得到 <span class="math inline">\(h_i = [\overleftarrow{h_i}, \overrightarrow{h_i}], \, \overleftarrow{h_i} = f_l(\overleftarrow{h_{i+1}}, x_i), \, \overrightarrow{h_i} = f_r(\overrightarrow{h_{i-1}}, x_i)\)</span></li>
<li>然后使用 uni-LSTM 进行解码，初始状态 <span class="math inline">\(s_0 = \overleftarrow{h_1}\)</span>，每个时间步都由 uni-LSTM 训练并产生隐藏状态 <span class="math inline">\(s_i\)</span>，同时每个时间步除了输入值（输入值是 label 组成的，即 IOB），还需要输入 Bi-LSTM 对应时间步的隐藏状态 <span class="math inline">\(h_i\)</span>。
<ul>
<li><strong>focus mechanism 实际上就是把对应时间步的隐藏状态 <span class="math inline">\(h_i\)</span> 输入给 decoder</strong>。。。也就是说把 attention 机制稍微改装了一下，当前时间步的 score 是 1，其余时间步是 0。</li>
<li>decoder 的隐藏状态计算方法是 <span class="math inline">\(s_i = f_d(s_{t-1}, y_{t-1}, c_t)\)</span>，其中 <span class="math inline">\(s_{t-1}\)</span> 代表上一个时间步的隐藏状态，<span class="math inline">\(y_{t-1}\)</span> 代表输入值，<span class="math inline">\(c_t\)</span> 是上下文信息，其实就等于 <span class="math inline">\(h_i\)</span>。</li>
<li>f 函数均指 LSTM units function</li>
</ul></li>
</ul>
<h1 id="a-joint-model-of-intent-determination-and-slot-filling-for-spoken-language-understanding">A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding</h1>
<ol type="1">
<li><strong>Embeddings</strong>：<a href="http://www.iro.umontreal.ca/~lisa/pointeurs/taslp_RNNSLU_final_doubleColumn.pdf" target="_blank" rel="noopener" title="Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding">Mesnil et al., 2015</a> 发现使用一个 context word window 可以提高 RNN 在 SF 上的性能。于是 Zhang and Wang(2016) 利用此方法，对 ID 以及 SF 训练了一个联合模型。具体做法是：获得词向量 <span class="math inline">\(e(w_t)\)</span> 后，令 <span class="math inline">\(x^d_t = [e(w_{t-d}), \cdots, e(w_t), \cdots, e(w_{t+d})]\)</span> 重新表示词向量，其中 <span class="math inline">\(e(w_t)\)</span> 代表单词 <span class="math inline">\(w_t\)</span> 的词向量，d 代表窗口半径。为了使模型获得更好的性能，在 <span class="math inline">\(x^d_t\)</span> 中还拼接了单词所对应的命名体词向量，比如“New York”的命名体为“B-city I-City”，最终 <span class="math inline">\(x^d_t = [e(w_{t-d}), \cdots, e(w_t), \cdots, e(w_{t+d}), e\prime(n_{t-c}), \cdots, e\prime(n_t), \cdots, e\prime(n_{t+c})]\)</span>，其中 <span class="math inline">\(e\prime(n_t)\)</span> 代表命名体 <span class="math inline">\(n_t\)</span> 的词向量，c 代表窗口半径，矩阵被随机初始化。
<ul>
<li>小声逼逼，这不是 contextual word embedding 吗？这论文 2015 年的，比 BERT 之流早了不知道多少。</li>
<li><strong>博主注</strong>：单词的命名体在真实场景下似乎没那么容易获取。论文中，在结果对比表格中，W 代表词汇特征，N 代表命名体特征。最终发现 W+N 特征的性能更高，但是我还是选取 W 特征作为该论文的指标。同时在论文《<a href="https://arxiv.xilesou.top/pdf/1812.10235.pdf" target="_blank" rel="noopener">A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling</a>》中也是使用 W 特征作为指标。</li>
</ul></li>
<li>Recurrent Hidden Layers：使用 Bi-GRU 提取句子信息</li>
<li>Task Specific Layers：解码层（两个）
<ul>
<li>for SF</li>
<li>for ID</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>SLU</tag>
      </tags>
  </entry>
  <entry>
    <title>DST论文笔记（？-2019）</title>
    <url>/posts/89f2cf08.html</url>
    <content><![CDATA[<h1 id="trippy-a-triple-copy-strategy-for-value-independent-neural-dialog-state-tracking">TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking</h1>
<div class="note primary"><p>模型的计算方法与 DS-DST 几乎完全一致，只不过补充了几点 slot gate 的类型。</p>
<p>唯一不同的在特征提取这块。DS-DST 将 <code>CLS</code>，一个域槽对和对话上下文拼接起来。由于所有域槽对的词向量是不同的，则可以凭此遍历所有的域槽对，使得每次捕获到的特征都是根据域槽对的变化而变化。所以当使用 <code>CLS</code> 进行 slot gate 分类时，可以确定该 slot gate 是基于某一域槽对的，并且 <code>CLS</code> 表征总是不同的。<strong>但是这样的做法计算起来特别麻烦，因为如果想要向量化，必须复制 N 份上下文（N 为域槽对数量）</strong>。</p>
<p>TripPy 应该是略微地改进了它，它移除了输入中的域槽对，其他基本不变，顶多是改变了一下上下文的输入顺序，这并无大碍。然后，TripPy 为每一个域槽对都设计了一个线性层用于计算 slot gate。这也能使得 <code>CLS</code> 的表征总是不同，因为线性层中的权重矩阵是不同的。<strong>但是这样貌似更加无法向量化了？</strong>反而，弄巧成拙？</p>
<p>所以，我认为在 dst 模型上，还是 TRADE 模型设计的更合理，它是采用了 attention 的机制。<strong>相比于 DS-DST 和 TripPy，参数量大大地减少，并且可以向量化。</strong></p>
</div>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/TripPy.png" title="TripPy" alt="图 TripPy" /><figcaption>图 TripPy</figcaption>
</figure>
<p>本文提出三种复制机制：<strong>1）</strong>从用户语句中直接提取出槽值的跨度预测（span prediction）；<strong>2）</strong>从 system inform memory 中复制出槽值，其为系统回复操作的追踪；<strong>3）</strong>从对话状态历史中复制槽值。</p>
<p>令 <span class="math inline">\(X = \{(U_1, M_1), \cdots, (U_T, M_T)\}\)</span>，<span class="math inline">\(U_t\)</span> 是 <span class="math inline">\(t\)</span> 轮时的用户语句，<span class="math inline">\(M_t\)</span> 是 <span class="math inline">\(t\)</span> 轮时的回复语句。模型的任务是 <strong>1）</strong>决定每轮是否提到了 <span class="math inline">\(S = \{S_1, \cdots, S_N\}\)</span> 中的 <span class="math inline">\(N\)</span> 个域槽对；<strong>2）</strong>预测每个 <span class="math inline">\(S_n\)</span> 的槽值；<strong>3）</strong>追踪整场对话过程中的对话状态。</p>
<h2 id="context-encoder">Context Encoder</h2>
<p>使用 BERT 提取上下文特征，公式为：</p>
<p><span class="math inline">\(R_t = BERT([CLS] \oplus U_t \oplus [SEP] \oplus M_t \oplus [SEP] \oplus H_t \oplus [SEP])\)</span></p>
<p>其中 <span class="math inline">\(U_t\)</span> 是 t 轮的用户语句，<span class="math inline">\([CLS], [SEP]\)</span> 都是 BERT 需要的特殊符号，分别为分类特殊符和分隔符，<span class="math inline">\(H_t\)</span> 为对话历史。那么 <span class="math inline">\(R_t = [r^{CLS}_t, r^1_t, \cdots, r^{seq_{max}}_t]\)</span>。以上都是比较基础的公式，具体说明略。<strong>值得注意得是</strong>，TripPy 的输入是逆序的，先输入 t 轮的对话，再输入逆序的历史对话。</p>
<h2 id="slot-gates">Slot Gates</h2>
<p>Slot Gate 的思想应该取自 TRADE 模型，简单来说，就是设计一个多分类器，判断接下来的操作应该交给哪个组件执行，一般来说可以选择 <span class="math inline">\(\{None, dontcare, Ptr, \cdots\}\)</span>。</p>
<p><strong>TripPy 为每一个域槽对都配备了一个 slot gate。</strong>还是跟以往的做法差不多，将槽值的识别问题转换为一个分类问题。与 TRADE 模型不同的是，TripPy 的 slot gate 在每轮为槽位 <span class="math inline">\(S_n\)</span> 进行分类，类别包括 <span class="math inline">\(C = \{none, dontcare, span, inform, refer\}\)</span>，其中 inform 代表系统的通知，refer 代表历史对话状态中所提到的，其他都是类似的，就不提了。</p>
<p>由于在 <strong>Context Encoder</strong> 中已经提取到了上下文特征，而且这步也是 BERT 做的，所以 <strong>Slot Gate</strong> 实际上就是做几个线性分类而已。BERT 可以得到 <span class="math inline">\(r^{CLS}_t\)</span>，这代表 <span class="math inline">\(t\)</span> 轮 <span class="math inline">\([CLS]\)</span> 的表征，那么域槽对 <span class="math inline">\(S_n\)</span> 在类别 <span class="math inline">\(C\)</span> 上的概率分布为：</p>
<p><span class="math display">\[p^{gate}_{t,s}(r^{CLS}_t) = softmax(W^{gate}_s \cdot r^{CLS}_t + b^{gate}_s) \in \mathbb{R}^5
\]</span></p>
<p>需要注意的是，上述的分类器是对一个域槽对进行五元分类。但是<strong>在系统中我们拥有 <span class="math inline">\(N\)</span> 个域槽对，所以我们需要 <span class="math inline">\(N\)</span> 个上述的分类器</strong>，这就导致需要一定的参数量。</p>
<p>对于特殊的槽位 <strong>Boolean Slot</strong>，也使用了类似的方法，但是类别 <span class="math inline">\(C_{bool} = \{none, dontcare, true, false\}\)</span>。</p>
<h2 id="span-based-value-prediction">Span-based Value Prediction</h2>
<p>使用 Ptr 神经网络预测槽值在用户语句中的位置，包括 start 以及 end 位置。如果 end &gt; start，则简单地将跨度（span）置为空。</p>
<h2 id="system-inform-memory-for-value-prediction">System Inform Memory for Value Prediction</h2>
<p>系统通知记忆（System Inform Memory） <span class="math inline">\(I_t = \{I^1_t, \cdots, I^N_t\}\)</span> 追踪系统提到的所有槽值对。简单来说，这就是一个 python 中的 dict，记录每一个槽值对是否被系统提及到。简单来说，如果用户提到了某个系统所通知给用户的槽值，那么槽位应该直接填充这个“通知值”，而不是去使用 Ptr 预测跨度，然后从用户的语句中提取出来。</p>
<p>这听起来可能有点奇怪，因为如果用户提到了某个系统的“通知值”，那么理所当然地我们也可以使用 Ptr 从用于语句中提取出来，为什么要多此一举使用 System Inform Memory 呢？原因在于，用户所提到的“通知值”可能并不是其本身。思考下面的例句，“系统：‘xx酒店有你想要的食物类型。’；用户：‘好的，就是<strong>它</strong>了。’”。可见系统提到的“xx酒店”，用户并没有直接引用它，而是使用了一种<strong>共指</strong>的语法。</p>
<h2 id="ds-memory-for-coreference-resolution">DS Memory for Coreference Resolution</h2>
<p>更复杂的对话需要进行共指解析。简单来说，就是某一个槽位的槽值与另一个槽位的槽值相同，所以使用一个 N 元（槽位的数量）分类器，用于计算当前槽位的槽值是否指向另外一个槽位。<em>事实上，这与 System Inform Memory for Value Prediction 类似，都是解决共指解析</em>。</p>
<h2 id="auxiliary-features">Auxiliary Features</h2>
<p>辅助特征。个人认为这种特征没什么特别大的意义。</p>
<h2 id="dialog-state-update">Dialog State Update</h2>
<p>使用与 Chao and Lane (2019) 同样的规则更新机制。每轮，如果槽值不为 <em>none</em>，则更新槽值；否则不更新。</p>
<h2 id="总结">总结</h2>
<p>这模型与 TRADE 之类的 span-based 或者 open-vocabulary 模型有点不同。这个模型需要为每个域槽对都设计一个分类器，即有 <span class="math inline">\(N\)</span> 个权重矩阵，然后将 <span class="math inline">\([CLS]\)</span> 的特征输入<strong>每个分类器</strong>从而判断该域槽对是否被用户提取。而 TRADE 的做法是捕获域槽对的隐藏状态，然后将该隐藏状态 <span class="math inline">\(h^{dec}\)</span> 输入<strong>一个分类器</strong>从而判断该域槽对是否被用户提取。粗体就是区别，一个输入的是 <span class="math inline">\([CLS]\)</span> 特征，其是固定的，只能使用不同的权重矩阵来判断不同的域槽对，另一个输入的是域槽对的隐藏状态 <span class="math inline">\(h^{dec}\)</span>，由于域槽对是不同的，则 <span class="math inline">\(h^{dec}\)</span> 也是不同的，所只需要一个分类器即可。 <a id="more"></a></p>
<h1 id="multi-domain-dialogue-state-tracking-as-dynamic-knowledge-graph-enhanced-question-answering">Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering</h1>
<p>本文将多领域 DST 视为问答问题，被称为 <em>Dialogue State Tracking via Question Answering</em>（<strong>DSTQA</strong>）。在 DSTQA 之中，每一轮生成一个问题，询问域槽对的槽值，因此可以很自然地将其扩展到未知领域，槽位和槽值。此外，我们使用一个<strong>动态变化的知识图谱</strong>，以清楚地学习槽值对之间的关系。</p>
<ul>
<li>公式阐述：在多领域 DST 问题中，有 <span class="math inline">\(M\)</span> 个领域 <span class="math inline">\(D=\{d_1, d_2, \cdots, d_M\}\)</span>。每个领域 <span class="math inline">\(d \in D\)</span> 有 <span class="math inline">\(N^d\)</span> 个槽位 <span class="math inline">\(S^d=\{s^d_1, s^d_2, \cdots, s^d_{N^d}\}\)</span>。每个槽位 <span class="math inline">\(s \in S^d\)</span> 有 <span class="math inline">\(K^s\)</span> 个可能的值 <span class="math inline">\(V^s=\{v^s_1, v^s_2, \cdots, v^s_{K^s}\}\)</span>。对话 <span class="math inline">\(X\)</span> 定义为 <span class="math inline">\(X = \{U^a_1, U^u_1, U^a_2, U^u_2, \cdots, U^a_T, U^u_T\}\)</span>。</li>
</ul>
<h1 id="find-or-classify-dual-strategy-for-slot-value-predictions-on-multi-domain-dialog-state-tracking">Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking</h1>
<p><strong>作者：Zhang et al., 2019。</strong></p>
<p>现存的 DST 方法分为两种类型：picklist-based 和 span-based。<strong>picklist-based</strong> 方法在预定义本体的条件下，为每个槽位上潜在的槽值执行分类任务。但是它在工业环境下，是不切实际的，因为很难获得对本体的完全访问。<strong>span-based</strong> 方法在对话上下文中，通过寻找一个文本跨度（text spans），为每个槽位跟踪槽值。然而，由于槽值的多样性，很难在对话上下文中找到一个合适的字符串。为了解决这一问题，通过借鉴前两者方法的优点，本文提出 <strong>Dual Strategy for DST (DS-DST)</strong>。</p>
<p>本文的做法：将域槽对视为 picklist-based 槽位或者 span-based 槽位，决定域槽对类别归属的方法是凭借人类启发（human heuristics）。</p>
<p>例如在订酒店的场景下，请求一个停车位通常只有“yes”或者“no”的回复，所以将此类槽位视为 picklist-based 槽位。鉴于用户停留的天数是无限的，并且可以在上下文中找到，所以将其视为 span-based 槽位。</p>
<p><strong>DS-DST：</strong>令 <span class="math inline">\(X = \{(U^{sys}_1, U^{usr}_1), \cdots, (U^{sys}_T, U^{usr}_T)\}\)</span> 代表系统语句 <span class="math inline">\(U^{sys}_t\)</span> 和 用户语句 <span class="math inline">\(U^{usr}_t\)</span> 的集合（<span class="math inline">\(1 \le t \le T\)</span>），在给定 T 轮对话的情况下。令 N 个可能的域槽对表示为 <span class="math inline">\(S = \{S_1, \cdots, S_N\}\)</span>，其中，<strong>每个域槽对都有 n 个符号</strong>。</p>
<p>DST 是追踪整个对上的状态，因此每一轮，我们都需要在上下文 <span class="math inline">\(X_t = \{(U^{sys}_1, U^{usr}_1), \cdots, (U^{sys}_t, U^{usr}_t)\}\)</span> 中预测<strong>每个</strong>域槽对 S 的槽值，<strong>其中 <span class="math inline">\(X_t\)</span> 拥有 m 个符号</strong>。我们假定 span-based 槽位在 S 中有 M 个，picklist-based 槽位有 <code>N-M</code> 个。每个 picklist-based 槽位有 C 个可能的槽值，即 <span class="math inline">\(V_1, \cdots, V_C\)</span>，其中 C 是 picklist 的容量，<strong>每个槽值有 c 个符号</strong>。</p>
<p>我们首先使用 <strong>BERT</strong> 编码对话上下文 <span class="math inline">\(X_t\)</span> 的信息，编码时还考虑了 S 中每个域槽对，以此获取基于域槽对信息的上下文表征。然后使用 <strong>slot gate</strong> 处理特殊类型的槽值。对于 span-based 槽位，使用 <strong>two-way 线性映射</strong>以找到文本跨度。对于 picklist-based 槽位，我们基于上下文表征从 picklist 中选择可信的槽值。</p>
<h2 id="slot-context-encoder">Slot-Context Encoder</h2>
<div class="note danger"><p>请注意，DS-DST 的做法是将所有域槽对中的一个与上下文拼接起来，并使用 BERT 获取特征，然后将 <span class="math inline">\(r^{CLS}\)</span> 输入进一个线性层，以此计算该域槽对的 slot gate 是什么。最后，对于每一个域槽对都需要进行以上的操作。<strong>博主注：但是这样好像并行起来比较困难？</strong></p>
<p>而 TRADE 的做法是将域槽对单独拿出来，使用词向量表示，然后使用域槽对词向量与上下文执行 attention 机制，以此获得一个上下文向量。最后再使用该向量进行分类，从而得到 slot gate。</p>
<p>个人认为还是 TRADE 的方法更合理一点。</p>
</div>
<p>对于第 j 个域槽对以及 t 时的对话上下文，我们使用 BERT 进行编码，将二者拼接，然后获取表征： <span class="math display">\[R_{tj} = BERT([CLS] \oplus S_j \oplus [SEP] \oplus X_t) \tag{1}
\]</span></p>
<p>其中 <code>[CLS]</code> 是一个特殊符号，每个样本之前都应该有它，<code>[SEP]</code> 是一个特殊的分割符。公式 1 中的输出可拆解为 <span class="math inline">\(R_{tj} = [r^{CLS}_{tj}, r^1_{tj}, \cdots, r^k_{tj}]\)</span>，其中 <span class="math inline">\(r^{CLS}_{tj}\)</span> 代表 K 个输入的聚合表征（<strong>博主注</strong>：这个只是一个定义而已），<span class="math inline">\(r^k_{tj}\)</span> 就是普通的符号表征。</p>
<h2 id="slot-gate-classification">Slot-Gate Classification</h2>
<p>多领域对话中有非常多的域槽对，很不容易判断一个域槽对是否出现在每一轮的对话中。总的来说，在 t 轮，我们让分类器在 <code>{none, dontcare, prediction}</code> 中做出决策。<code>none</code> 代表没有提及，<code>dontcare</code> 代表对于某槽位用户可以接受任何槽值，<code>prediction</code> 代表应该由模型处理。我们在 slot-gate classification 中利用 <span class="math inline">\(r^{CLS}_{tj}\)</span>，t 轮中第 j 个域槽对的概率由如下公式计算： <span class="math display">\[P^{gate}_{tj} = softmax(W_{gate} \cdot (r^{CLS}_{tj})^T + b_{gate}) \tag{2}
\]</span></p>
<p>此分类器的 loss 函数为： <span class="math display">\[\mathcal{L}_{gate} = \sum^T_{t=1} \sum^N_{j=1} -log(P^{gate}_{tj} \cdot (y^{gate}_{tj})^T) \tag{3}
\]</span></p>
<p>其中 <span class="math inline">\(y^{gate}_{tj}\)</span> 是第 t 轮第 j 个域槽对的 one-hot 标签。</p>
<h2 id="span-based-slot-value-prediction">Span-Based Slot-Value Prediction</h2>
<p>计算 start 和 end 位置的向量： <span class="math display">\[[\alpha^{start}_{tj}, \alpha^{end}_{tj}] = W_{span} \cdot ([r^1_{tj}, \cdots, r^k_{tj}])^T +b_{span} \tag{4}
\]</span></p>
<p>那么，start 的概率可以使用公式：<span class="math inline">\(P^{start}_{tj} = \frac{e^{\alpha^{start}_{tj} \cdot r^i_{tj}}}{\sum_k \alpha^{start}_{tj} \cdot r^k_{tj}}\)</span> 得到（<strong>博主注</strong>：这应该是 softmax，所以他可能漏了个 e，正确公式我认为是这样的：<span class="math inline">\(P^{start}_{tj} = \frac{e^{\alpha^{start}_{tj} \cdot r^i_{tj}}}{\sum_k e^{\alpha^{start}_{tj} \cdot r^k_{tj}}}\)</span>），因此此模型的 loss 为（end 类似，不再赘述）： <span class="math display">\[\mathcal{L}_{start} = \sum^T_{t=1} \sum^M_{j=1} -log(P^{start}_{tj} \cdot (y^{start}_{tj})^T) \tag{5}
\]</span></p>
<h2 id="picklist-based-slot-value-prediction">Picklist-Based Slot-Value Prediction</h2>
<p>首先获得候选值的聚合表征 <span class="math display">\[Y_j = BERT([CLS] \oplus V_j \oplus [SEP]) \tag{6}
\]</span></p>
<p>（余下略，写起来太麻烦了）</p>
<h2 id="training-objective">Training Objective</h2>
<p><span class="math display">\[\mathcal{L}_{total} = \mathcal{L}_{sg} + \mathcal{L}_{span} + \mathcal{L}_{picklist} \tag{9}\]</span></p>
<h1 id="transferable-multi-domain-state-generator-for-task-oriented-dialogue-systems">Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</h1>
<blockquote class="blockquote-center">
<i class="fa fa-quote-left"></i>
<p><a href="https://yan624.github.io/posts/36b672d2.html">论文笔记</a>。<strong>作者：Wu, Chien-Sheng et al., 2019。</strong></p>

<i class="fa fa-quote-right"></i>
</blockquote>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/任务完成型对话系统论文笔记/TRADE.png" alt="图 TRADE" /><figcaption>图 TRADE</figcaption>
</figure>
<h1 id="global-locally-self-attentive-dialogue-state-tracker">Global-Locally Self-Attentive Dialogue State Tracker</h1>
<p><strong>作者：Zhong et al. 2018。</strong></p>
<h2 id="引言">引言</h2>
<ul>
<li>在 DST 中，state 通常由一系列的 <strong>requests</strong> 和 <strong>joint goals</strong> 组成。</li>
<li>DST 中的一个重要问题是，现存的方法没有解决<strong>对低频槽值的提取</strong>。这是因为任务导向的对话系统涵盖了巨大的状态空间，许多槽值对组成的状态在训练集中很少出现。尽管用户一轮对话指定一个低频槽值对的概率很小，但是他们在整个对话中指定一个的概率很大。</li>
<li>本文提出 <strong>G</strong>lobal-<strong>L</strong>ocally Self-<strong>A</strong>ttentive <strong>D</strong>ialogue State Tracker(GLAD) 。相比于先前的工作， GLAD 独立地估计每一个槽值，使用 global modules 在估计器之间为每一个槽位共享参数，使用 local modules 学习特定槽位的表征。</li>
</ul>
<h2 id="glad">GLAD</h2>
<p>GLAD 对每对槽值使用了一个估计器，将多元状态分类分解为一系列的二元分类问题，以此跟新状态。</p>
<ul>
<li><strong>Global-Locally Self-Attentive Encoder</strong>：每个状态都由一系列的槽值对组成，它们中有许多都是低频的，这会造成误差在多轮对话中累积。为了解决这一问题，使用 global module 对每个槽位进行参数共享，使用 local module 学习特定槽位的特征。使 n 代表序列长度， <span class="math inline">\(d_{emb}\)</span> 为词向量维度，<span class="math inline">\(X \in \mathbb{R}^{n \times d_{emb}}\)</span> 为序列中所有单词的词向量矩阵。我们使用 Bi-LSTM 产生 X <strong>全局编码</strong> <span class="math inline">\(H^g\)</span>，其中 <span class="math inline">\(d_{rnn}\)</span> 代表 LSTM 隐藏状态的维度。以同样的方法产生 X 的<strong>局部编码</strong> <span class="math inline">\(H^s\)</span>，这考虑的是槽位 s。然后二者通过一个混合函数产生一个 X 的 <strong>global-local 编码</strong> H，其中 <span class="math inline">\(\beta^s\)</span> 是一个特定于槽位 s 的 01 之间的可学习参数。公式如下所示： <span class="math display">\[
\begin{align}
  H^g &amp; = biLSTM^g(X) \in \mathbb{R}^{n \times d_{rnn}} \tag{1} \\
  H^s &amp; = biLSTM^s(X) \in \mathbb{R}^{n \times d_{rnn}} \tag{2} \\
  H &amp; = \beta^s H^s + (1 - \beta^s)H^g \in \mathbb{R}^{n \times d_{rnn}} \tag{3} \\
\end{align}
\]</span> 接下来计算 H 的 global-local self-attention context <span class="math inline">\(c\)</span>。self-attention（或称 intra-attention） 是一种计算变长序列长下文摘要的好方法。对于第 i 个元素 <span class="math inline">\(H_i\)</span>，我们计算全局自注意力分数标量 <span class="math inline">\(a^g_i\)</span>，之后通过 softmax 将所有元素归一化，global self-attention context（下称<strong>全局自注意力上下文</strong>）<span class="math inline">\(c^g\)</span> 就通过加权和计算出来了。 local self-attention context（下称<strong>局部自注意力上下文</strong>）<span class="math inline">\(c^s\)</span> 同理。而 global-local self-attention context <span class="math inline">\(c\)</span> 是它们的混合。计算公式如下所示： <span class="math display">\[
\begin{align}
  a^g_i &amp; = W^g H_i + b^g \in \mathbb{R} \tag{4} \\
  p^g &amp; = softmax(a^g) \in \mathbb{R}^n \tag{5} \\
  c^g &amp; = \sum_i p^g_i H_i \in \mathbb{R}^{d_{rnn}} \tag{6} \\
  a^s_i &amp; = W^s H_i + b^s \in \mathbb{R} \tag{7} \\
  p^s &amp; = softmax(a^s) \in \mathbb{R}^n \tag{8} \\
  c^s &amp; = \sum_i p^s_i H_i \in \mathbb{R}^{d_{rnn}} \tag{9} \\
  c &amp; = \beta^s c^s + (1 - \beta^s) c^g \in \mathbb{R}^{d_{rnn}} \tag{10}
\end{align}
\]</span> 为了便于说明，我们定义了函数 <code>encode(X)</code>，它将序列 X 映射为编码 H 和自注意力上下文 c： <span class="math display">\[encode: X \to H, c \tag{11}
\]</span></li>
<li><strong>Encoding module</strong>：定义好 global-locally self-attentive encoder 之后，我们可以构建用户语句、上一轮系统动作和槽值对的表征了。使 <span class="math inline">\(U\)</span> 代表用户语句的嵌入，<span class="math inline">\(A_j\)</span> 代表上一轮系统的第 j 个动作（例：request(price range)），<span class="math inline">\(V\)</span> 代表槽值对（例：food=french）。所以我们有公式： <span class="math display">\[
\begin{align}
  H^{utt}, c^{utt} &amp; = encode(U) \tag{12} \\
  H^{act}_j, C^{act}_j &amp; = encode(A_j) \tag{13} \\
  H^{val}, c^{val} &amp; = encode(V) \tag{14} \\
\end{align}
\]</span></li>
<li><strong>Scoring module</strong>：该组件，直观来说，我们可以通过检查两个输入，判断用户是否表达出了槽值对。第一个输入是用户语句，用户直接陈述<strong>目标与请求</strong>。做法是判断用户是否指定了某个槽值对。考虑用户语句 <span class="math inline">\(H^{utt}\)</span>，槽值对 <span class="math inline">\(c^{val}\)</span>，最后使用 resulting attention context <span class="math inline">\(q^{utt}\)</span> 计算槽值对的分数，其中 m 代表用户语句中单词数量，分数 <span class="math inline">\(y^{utt}\)</span> 代表用户表达槽值对的程度。公式如下所示： <span class="math display">\[
\begin{align}
  a^{utt}_i &amp; = (H^{utt}_i)^T c^{val} \in \mathbb{R} \tag{15} \\
  p^{utt} &amp; = softmax(a^{utt}) \in \mathbb{R}^m \tag{16} \\
  q^{utt} &amp; = \sum_i p^{utt}_i H^{utt}_i \in \mathbb{R}^{d_{rnn}} \tag{17} \\
  y^{utt} &amp; = W q^{utt} + b \in \mathbb{R} \tag{18} \\
\end{align}
\]</span> 第二个输入是前一轮系统动作。这在用户没有提供信息，但是提到先前系统动作时很有效。如：在系统询问“你喜欢在市中心的酒店吗”，用户回答“喜欢”。为了处理这种情况，考虑动作表征 <span class="math inline">\(C^{act} = [C^{act}_1, \cdots, C^{act}_l]\)</span> 以及用户语句上下文 <span class="math inline">\(c^{utt}\)</span>，<span class="math inline">\(l\)</span> 是动作数量，然后使用 <span class="math inline">\(q^{act}\)</span> 和 <span class="math inline">\(c^{val}\)</span> 之间的相似度来衡量槽值对： <span class="math display">\[
\begin{align}
  a^{act}_j &amp; = (C^{act}_j)^T c^{utt} \in \mathbb{R} \tag{19} \\
  p^{act} &amp; = softmax(a^{act}) \in \mathbb{R}^{l+1} \tag{20} \\
  q^{act} &amp; = \sum_i p^{act}_j C^{act}_j \in \mathbb{R}^{d_{rnn}} \tag{21} \\
  y^{act} &amp; = (q^{act})^T c^{val} \in \mathbb{R} \tag{22} \\
\end{align}
\]</span> 除了真实的动作，我们还引入了哨兵动作以忽略上一轮的系统动作。<span class="math inline">\(y^{act}\)</span> 代表上一轮动作表达了某个槽值的程度。最后的 y 使用二者的加权和，使用 sigmoid 函数归一化，w 是可学习参数。 <span class="math display">\[y = \sigma(y^{utt} + w y^{act}) \in \mathbb{R} \tag{23}
\]</span></li>
</ul>
<h2 id="总结-1">总结</h2>
<p><strong>虽然文中没有明确指出，但是 global Bi-LSTM 应该是所有的槽位共享一个模型，而 local Bi-LSTM 应该指的是对于每一个槽位都训练一个模型。最后从文中的实验结果发现，似乎 global 组件对于 request 的实验结果毫无影响？？？</strong></p>
<h1 id="scalable-multi-domain-dialogue-state-tracking">Scalable multi-domain dialogue state tracking</h1>
<p><strong>作者：Rastogi A et al., 2017。</strong></p>
<ul>
<li>引言
<ul>
<li><strong>相关工作</strong>：在有些方法中，本体为一个任务定义了一组槽位，这些槽位又关联了一组槽值。还有些方法使用本体中的条目去探测用户语句中潜在的槽值对（如 Henderson et al., 2014d）。</li>
<li><strong>缺陷与本文方法</strong>：<em>事实上，定义本体是困难且不切实际的，一个槽位所拥有的槽值是无穷无尽的，这使得灵活性成为了一个重大的问题。此外使用深度学习来表示槽位/槽值无法处理在训练期间从未见过的实体，使得很难与动态变化的数据库进行交互。</em>所以我们的论文提出：
<ol type="1">
<li>用一个巨大的或者无限的潜在值（possible values）集合表示槽位</li>
<li>为了给用户语句中的槽位打标签，我们使用了 <strong>multi-domain LU</strong> 模型</li>
<li>SLU 的输出被用于 delexicalize 用户语句，由 DST 处理并进行特征提取</li>
<li>然后通过集成一个独立的 candidate 生成步骤，使用 local conversation context 也有可能是外部的知识源（而不是本体）来估计一组<strong>候选槽值对</strong>（slot-value candidates）。DST 仅操作这些候选者，从而产生一种能够扩展到大且丰富的数据集的方法
<ul>
<li>此方法可以被扩展到其他大型数据集是因为：候选槽值对的产生依赖于上下文或者外部知识源，而不是预定义的本体。</li>
</ul></li>
<li>此外这个新颖的 DST 框架提取的一系列特征，其独立于槽值对集合
<ul>
<li>为了捕获语句中的长期依赖，使用 Bi-GRU 来表示输入语句，扩展了前人工作的 DNN，CNN</li>
</ul></li>
<li>共享一个领域但不同槽位之间的参数，并将参数迁移到从未见过的数据集或领域中。这样就不需要为每个领域中的每个 slot 类型训练模型，并有助于快速向领域中添加新 slot。</li>
</ol></li>
</ul></li>
<li>dialogue sate
<ul>
<li><strong>Candidate Set</strong>：令 <span class="math inline">\(C^t_s\)</span> 代表领域 D 中，第 t 轮对话，槽位 s 的候选集。对话初始，对于每个槽位，<span class="math inline">\(C^0_s\)</span> 都是空的。令 <span class="math inline">\(|C^t_s| \le K\)</span> 以限制候选集的上限（博主吐槽：这跟前人的工作有锤子区别，不还是假定槽值已知）。<span class="math inline">\(C^t_s\)</span> 由用户语句，前一轮的系统语句以及先前的候选集初始化，初始化的内容来自 LU 模块，一般 K 取 7。如果初始化完毕后，候选集溢出，则根据分数排序，并从后往前开始删除候选值；<br />
有两点需要说明：<strong>1）</strong>初始化步骤很容易拓展到诸如 ASR 或者来自后端（API）的响应；<strong>2）</strong>候选集的最大容量必须最够大以确保可能的值不会被冲洗掉。</li>
<li><strong>State Representation</strong>：在第 t 轮上使用 <span class="math inline">\({V&#39;}^t_s = C^t_s \cup \{\delta_s, \phi_s\}\)</span> 限制分布的大小，以此代替 <span class="math inline">\(V_s\)</span> 上的分布。<span class="math inline">\(V_s\)</span> 代表槽位 s 所有可能的值，<span class="math inline">\(C^t_s\)</span> 表示第 t 轮，槽位 s 生成的候选值，<span class="math inline">\(\delta_s, \phi_s\)</span> 分别表示 don't care（即对于槽位 s，用户不关心值是什么）和 null value（即用户所表达的语句中不包含任何槽位 s）。这样表示会更好，因为对话中未被提到的槽值，它们的概率只会接近 0。<br />
为了保持分布的大小，在 <span class="math inline">\({V&#39;}^t_s\)</span> 加入了 <span class="math inline">\(K - |C^t_s|\)</span> 个 <code>PAD</code> 符号，使其为一个定值 <code>K + 2</code>。此外，对于大多数槽位， <span class="math inline">\(|{V&#39;}_s| = K + 2 \ll |V_s|\)</span>。</li>
</ul></li>
<li>dialogue state tracking
<ul>
<li><strong>Model Description</strong>：是一个辨别式模型，用每个槽位的候选值集合作为输入，并更新候选值的分数。它也可识别 <span class="math inline">\(\delta_s\)</span> 或 <span class="math inline">\(\phi_s\)</span>。<br />
在用户轮数 t，DST 使用前一轮的候选集合 <span class="math inline">\(C^{t-1}_s\)</span> 及其分数，最近的用户/系统语句和它们的对话状态，去提取语句相关（<span class="math inline">\(r^t_{utt}\)</span>），槽相关（<span class="math inline">\(r^t_{slot}(s)\)</span>），候选值相关（<span class="math inline">\(r^t_{cand}(c^t_{s,i})\)</span>）的特征。候选集 <span class="math inline">\(\alpha \in {V&#39;}^t_s = C^t_s \cap \{\delta_s, \phi_s\}\)</span> 的分数 <span class="math inline">\(p^t_{\alpha}\)</span> <strong>更新公式</strong>如下所示，其中 <span class="math inline">\(\oplus\)</span> 代表向量拼接，图 2 描述了模型的架构： <span class="math display">\[
  \begin{align}
  g^t_s &amp; = r^t_{utt} \oplus r^t_{slot}(s) \\
  f^t_{c_{s,i}} &amp; = g^t_s \oplus r^t_{cand}(c^t_{s,i}) \\
  l^t_{\phi_s} &amp; = l_{\phi_s} \\
  l^t_{c_{s,i}} &amp; = W^s_2 \cdot \sigma(W^s_1 \cdot f^t_{c_{s,i}} + b^s_1) + b^s_2 \tag{1} \\
  l^t_{\delta_s} &amp; = W^s_4 \cdot \sigma(W^s_3 \cdot g^t_s + b^s_3) + b^s_4 \tag{2} \\
  p^t_{\alpha} &amp; = \frac{\exp(l^t_{\alpha})}{\exp(l^t_{\phi_s}) + \exp(l^t_{\delta_s}) + \Sigma_i \exp(l^t_{c_{s,i}})} \tag{3} \\
  \end{align}
  \]</span> 其中 <span class="math inline">\(l_{\phi_s}, W^s_k, b^s_k\)</span> 都是可训练的模型参数，接下来描述特征 <span class="math inline">\(r^t_{utt}, r^t_{slot}(s), r^t_{cand}(c^t_{s,i})\)</span> 是如何背计算出来的。</li>
<li><strong>Feature Extraction</strong>：使用一个特殊的符号替换所有的槽值，这些槽值由 SLU 模块识别出来，<strong>所以并不需要知道槽位关联的所有槽值或是人工构建的词表</strong>。需要注意的是只替换槽值，并不替换槽位。最后使用一个两层 Bi-GRU 处理被 delexicalisation 的语句。<br />
除了为槽位的所有槽值打上标签之外，SLU 还预测用户语句对应的动作，如 <code>affirm, negate(time)</code> 等。<br />
此外对于系统的语句也是类似操作。
<ul>
<li>语句特征：<span class="math inline">\(r^t_{utt} = c^t \oplus a^t_u \oplus {c&#39;}^t \oplus {a&#39;}^t_u\)</span>，其中 <span class="math inline">\(c^t\)</span> 代表语句的表征，来自 Bi-GRU 的隐藏状态；<span class="math inline">\(a^t_u\)</span> 代表动作表征，由 SLU 模块产生；<span class="math inline">\({c&#39;}^t\)</span> 和 <span class="math inline">\({a&#39;}^t_u\)</span> 表示用户语句之前的系统语句所对应的特征。</li>
<li>槽特征：<span class="math inline">\(r^t_{slot}(s) = a^t_u(s) \oplus {a&#39;}^t_s(s) \oplus p^{t-1}_{\delta_s} \oplus p^{t-1}_{\phi_s}\)</span>，其中 <span class="math inline">\(p^{t-1}_{\delta_s}\)</span> 和 <span class="math inline">\(p^{t-1}_{\phi_s}\)</span> 代表特殊值 <code>dontcare</code> 和 <code>null</code> 在前一轮 DST 输出中的分数；<span class="math inline">\(a^t_s(s)\)</span> 是带参对话动作的二维向量，如 <code>request(s), deny(s)</code>；<span class="math inline">\({a&#39;}^t_s\)</span> 是系统动作对应的二维向量。</li>
<li>候选值特征：</li>
</ul></li>
</ul></li>
<li>参数共享以及迁移学习：上式中，候选值评分函数的参数 <span class="math inline">\(l_{\phi_s}, W^t_k, W^s_k, 1 \le k \le 4\)</span>，每个槽位都会定义一组，但是 GUR 的参数是为一个领域定义的。这些参数的维度不依赖槽位和领域，这得以参数共享或者在跨领域迁移。</li>
</ul>
<h1 id="neural-belief-tracker-data-driven-dialogue-state-tracking">Neural Belief Tracker: Data-Driven Dialogue State Tracking</h1>
<blockquote class="blockquote-center">
<i class="fa fa-quote-left"></i>
<p><a href="https://yan624.github.io/posts/f102a8ae.html">论文笔记</a>。<strong>作者：Mrkšić N et al., 2016。</strong></p>

<i class="fa fa-quote-right"></i>
</blockquote>
<h1 id="incremental-lstm-based-dialog-state-tracker">Incremental LSTM-based dialog state tracker</h1>
<p><strong>作者：Zilka and Jurcicek, 2015。</strong></p>
<p>此论文是作者同年发表的论文的扩展，他们将论文中的状态跟踪器称为 LecTrack。<strong>它能一个接一个地处理单词，这其实是 RNN 的特性，也是论文名中“Incremental”的起因。</strong> 本文定义：在第 t 轮，对话状态 <span class="math inline">\(s_t \in C_1 \times \cdots \times C_k\)</span> 为一个向量，包含 k 个元素，有时候在文献中它们被称为槽位（slot）。每个 <span class="math inline">\(c_i \in C_i = \{v_1, \cdots, v_{n_i}\}\)</span> 包含 <span class="math inline">\(n_i\)</span> 个槽值，并且我们假设各成分（slot）之间是独立的，则： <span class="math display">\[P(s_t | w_1, \cdots, w_t) = \prod_i p(c_i | w_1, \cdots, w_t; \theta)
\]</span></p>
<p><strong>LSTM dialogue state tracker</strong>：</p>
<ul>
<li><strong>model</strong>：使用 LSTM 提取语句信息，但是做了小小的改动，将输入门的 sigmoid 函数换做了 tanh。公式如下所示： <span class="math display">\[
\begin{align}
  u &amp; = NN(a, r) \\
  q_t &amp; = Enc(u, q_{t-1}) \\
  p_t &amp; = C(h_t) \\
\end{align}
\]</span> 其中单词 a 与其 ASR 置信度分数 r 的联合表征为 u，LSTM decoder 使用 u 以及前一时间步的隐藏状态 <span class="math inline">\(q_{t-1} = (c_{t-1}, h_{t-1})\)</span> 计算出当前隐藏状态 <span class="math inline">\(q_t\)</span>，C 代表 softmax 层，将隐藏状态映射为各个可能值的分布。<br />
注意，虽然论文中没有明确写出，但是对于最后一个公式 <span class="math inline">\(p_t = C(h_t)\)</span>，它可能需要<strong>为每一个槽位都设计一个函数</strong>。这个公式应该是这样的：<span class="math inline">\(p^j_t = C(h_t), \forall j \in 1, \cdots, k\)</span>，j 代表槽位索引，t 代表单词在句子中的索引。<br />
</li>
<li><strong>Improvements</strong>：1）包括了 ASR 置信度分数；2）将训练集中的 Transcriptions 加入训练；3）多个模型取均值；4）低频词抽象化</li>
</ul>
<p>模型流程（个人向）：输入每个单词，输出对应的隐藏状态。隐藏状态经过一个函数输出槽值的分布，这个函数是特定于槽位的。也就是说每个槽位都有一个独一无二的函数，在生成槽值时，只需要遍历所有槽位的函数，然后将隐藏状态传入每一个函数，就可以得到每个槽位对应的槽值分布。</p>
<h1 id="word-based-dialog-state-tracking-with-recurrent-neural-networks">Word-Based Dialog State Tracking with Recurrent Neural Networks</h1>
<div class="note warning"><p>之前的论文大都是使用 SLU 的结果作为输入，这篇论文则直接使用 ASR 的结果作为输入。由于我看的论文不是很多，对于这篇论文，我不敢说它是首创，但是应该有渐隐之色。这种做法的好处是，消除了 ASR 到 SLU 的误差 [<a href="https://www.cnblogs.com/jiangxinyang/p/10794364.html" target="_blank" rel="noopener">4</a>]。<strong>作者：Henderson et al., 2014d</strong>。</p>
</div>
<p>近来 DST 领域的辨别式方法已经展示出了超于传统的生成式方法的性能。本文提出 word-based DST，直接从 ASR 结果映射到对话状态。使用 RNN 结构，有能力泛化到未见的对话状态假设，只需要一点特征工程。</p>
<p>通常，DST 假定 SLU 将 ASR 的假设映射为一系列的语义假设，本论文直接将 ASR 的假设映射为对话中某轮的对话状态，省略了中间 SLU 的处理步骤。这避免了显式语义表征的需要以及在 SLU 阶段可能的信息误差。</p>
<p>与用户交流时，统计对话系统必须维护一个潜在的对话状态的分布，这个步骤被称为 DST。这个分布有时候也被称作 belief state （<strong>划重点要考</strong>），直接决定了系统的决策。</p>
<p><em>介绍了一堆 14 年前的做法以及区别。</em></p>
<p><strong>Feature Representation</strong>(1-2)/<strong>Generalisation to Unseen States</strong>(3)：</p>
<ol type="1">
<li>如图 1 所示，从 ASR 的 N-best 列表中提取出 n-gram 特征，即为每个假设计算 uni-/bi-/tri-gram。然后用 N-best 列表的概率计算加权和求得到单个向量。如果出现了相同的项，把对应的概率相加即可。</li>
<li><strong>此领域的 dialogue acts 由形如 acttype(slot=value) 的一系列 act 成分组成，其中 slot=value 是可选的</strong>。n-gram 正是提取自这些成分，如：<code>'acttype', 'slot', 'value', 'acttype slot', 'slot value'</code> 和 <code>'acttype slot value'</code> 或者对于 <code>acttype()</code> 只有 <code>'acttype'</code>。处理方法与 1 类似，只是它们的权重都置为 1</li>
<li>处理未在训练集出现的状态（如一种食物类型）的方法是：使用 'tagged' 方法，即忽略特定的槽值，将其替换为类似 <code>&lt;value&gt;</code> 的标签。如图 1 所示，<span class="math inline">\(f_s, f_v\)</span> 来自未标过的 <span class="math inline">\(f\)</span>。</li>
</ol>
<p><strong>Model Definition</strong>：</p>
<ol type="1">
<li>RNN 拥有一个内部的记忆 <span class="math inline">\(m \in \mathbb{R}^{N_{mem}}\)</span>。如果对于槽位 s 有 N 个槽值，那么概率分布输出 <span class="math inline">\(p \in \mathbb{R}^{N+1}\)</span>，其中最后一个成分 <span class="math inline">\(P|_N\)</span> 代表 None。图 2 解释了 p 和 m 在某一轮中是如何被更新为 p' 和 m' 的。</li>
<li>神经网络的一部分结构用于学习将 untagged input, memory, previous state 映射为向量 <span class="math inline">\(h \in \mathbb{R}^N\)</span>，它将直接参与 <span class="math inline">\(p&#39;\)</span> 的计算。公式为：<span class="math inline">\(h=NNet(f \oplus p \oplus m) \in \mathbb{R}^N\)</span>。（<strong>博主注</strong>：h 学习将 lexical n-grams 映射为特定的槽值对，<strong>此步可能对 domain-independent 具有一定的影响</strong>，故<a href="https://arxiv.org/pdf/1506.07190.pdf" target="_blank" rel="noopener">这篇论文</a>移除了这部分的网络）</li>
<li>本文 <span class="math inline">\(NNet(\cdot)\)</span> 均代表激活函数为 sigmoid 的隐藏层</li>
<li>其次，由于 h 的计算需要使用训练集中每一个槽值的样本，所以泛化性并不好。<strong>通过 g</strong>，采用 tagged feature 作为输入，<strong>可能可以提高泛化性</strong>。对于一个槽位的槽值 v，计算公式为：<span class="math inline">\(g|_v = NNet(f \oplus f_s \oplus f_v \oplus \{p|_v, P|_N\} \oplus m) \in \mathbb{R}\)</span>。此结构的网络能够处理未见或者不频繁的 dailogue state</li>
<li><strong>博主注</strong>：不同的槽位拥有不同模型，即其中的每个 p 都不同</li>
<li>new belief <span class="math inline">\(p&#39;\)</span> 的更新公式为：<span class="math inline">\(p&#39; = softmax([h+g] \oplus \{B\}) \in \mathbb{R}^{N+1}\)</span>，其中 B 是 RNN 的一个参数，有助于 None 的假设的估计</li>
<li>最后 memory 的更新公式为：<span class="math inline">\(m&#39; = \sigma(W_{m0}f + W_{m1}m) \in \mathbb{R}^{N_{mem}}\)</span>，其中 <span class="math inline">\(W_{mi}\)</span> 是 RNN 的参数</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>DST</tag>
      </tags>
  </entry>
  <entry>
    <title>win10下安装NVIDIA CUDA</title>
    <url>/posts/49e8bc0c.html</url>
    <content><![CDATA[<p>我按照文章《<a href="https://blog.csdn.net/qq_36026791/article/details/88793488" target="_blank" rel="noopener">基于NVIDIA GeForce MX150 的Windows10安装TensorFlow-GPU详解</a>》中的内容进行安装，但是碰到了一些问题。 1. 首先是安装的选择问题，文中选择的是自定义安装，但是取消了 NVIDIA GeForce Experience... 的安装。但是我也不知道这个组件是干嘛用的，所以我没取消它，但是我取消了 CUDA 下的 Visual Studio Integration，因为我不使用 VS； 2. 按照以上操作，我安装失败了。我上网搜了一下，我发现可能是我 NVIDIA 版本的问题，所以建议下载驱动精灵，它会自动升级你的版本，我从 9.1 升级到了 10.0； 3. 再去 <a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">CUDA 官网</a>下载新版本的 NVIDIA 安装； 4. 但是更新完毕之后，NVIDIA 控制面板不见了！参考<a href="https://jingyan.baidu.com/article/eb9f7b6d30057f869364e823.html" target="_blank" rel="noopener">这篇文章</a>将服务开启就可以了； 5. 这次再根据以上的步骤安装，安装成功了。 <a id="more"></a> 安装完 CUDA 后，根据文章中的说法，cuDNN 可以在 GPU 的基础上再次提速 1.5 倍速。 但是安装 cuDNN 需要在 NVIDIA 注册账户才行，这里有个坑需要注意。在注册时，有一个选项是“请向我发送 NVIDIA 的开发人员最新动态、公告及更多内容。我可以随时取消订阅。”。这个选项不能勾选，否则无法注册。 总之，这个注册挺麻烦的。 还有一点，上面的文章对于安装 cuDNN 写得不太好，可以参考<a href="https://blog.csdn.net/qilixuening/article/details/77503631" target="_blank" rel="noopener">这篇</a>。 <div class="note danger"><p>安装完上面的软件之后，发现还是不能使用 gpu 版的 pytorch，可能是因为电脑上的 pytorch 是 cput 版的。所以将原先的 pytoch 删除，重新下载一个。 访问 pytorch <a href="https://pytorch.org/get-started/locally/#windows-prerequisites" target="_blank" rel="noopener">官网</a>，按照你想要的配置获取下载链接。有一点需要注意，你获取到的链接末尾有代码 <code>-c pytorch</code>，这意味着你不会从你设置的镜像中获取下载链接，导致下载极卡，所以只需要去掉这段代码即可。 其次，即使去掉这段代码，也仅仅是让 pytorch 的下载速度变快。gpu 版本的 pytorch 还需要 cudatoolkit，它在各大镜像源中都没有，所以下载速度特别慢（如果电脑会开 VPN，应该可以直接下载，下面的步骤可以不看）。 接下来介绍如何下载它： 1. 安装 cudatoolkit 1. 如果你使用原来的命令去下载，你会下载失败，报出连接超时之类的错误。此时，anaconda 会告诉你哪个模块下载有问题，<strong>并且它会告诉你这个模块的下载链接</strong>。如果你没有这个提示，可以进入<a href="https://repo.anaconda.com/pkgs/main/win-64/cudatoolkit-10.0.130-0.conda" target="_blank" rel="noopener">这个网站</a>，这是 cudatoolkit10.0 的下载链接； 2. 当然你用电脑下依旧很慢，将这个链接发到手机上，在手机上开 VPN。这样你就会下载得到压缩包 <code>cudatoolkit-10.0.130-0.conda</code>，请注意，这个压缩包很奇怪，在 anaconda 中，你的虚拟环境目录下的 <code>pkgs</code> 文件夹中，所有的压缩包都是 <code>.tar.bz2</code> 结尾，不知道为什么它以 <code>.conda</code> 结尾； 3. 不过没关系，它依旧是压缩包，你只需要运行命令 <code>conda install --use-local D:\anaconda\pkgs\cudatoolkit-10.0.130-0.conda</code>，后面的路径，你需要自己设置； 4. 等几秒钟 cudatoolkit 就安装好了； 5. 还有一点，我不知道这个操作有没有用，但是还是加上来了。在 <code>anaconda/env/虚拟环境名/pkgs</code> 文件夹中有一份 <code>urls.txt</code> 文件，你需要把 cudatoolkit 的安装链接（安装链接上面已经给出，或者你可以自己获取）加在末尾； 6. 最后，你再运行 pytorch 提供的命令，它就会跳过安装 cudatoolkit 了； 2. 安装 pytorch 和 torchvision 1. 强烈建议对于下载 pytorch，不要使用 anaconda！而是使用 pip！ 2. 强烈建议不要使用 pytorch 官网提供的命令行去下载！因为它提供的命令行下载得到的 pytorch 和 torchvision 是 cpu 版本的！ 3. 找到 pytorch 和 torchvision 的 whl 文件（注意一定要是 gpu 版），如果找不到，可以访问 <a href="https://download.pytorch.org/whl/cu101/torch-1.4.0-cp36-cp36m-win_amd64.whl" target="_blank" rel="noopener">pytorch whl 文件</a> 和 <a href="https://download.pytorch.org/whl/cu101/torchvision-0.5.0-cp36-cp36m-win_amd64.whl" target="_blank" rel="noopener">torchvision whl 文件</a>； 4. 下载下来后，使用 <code>pip install whl文件名</code> 安装； 5. 安装成功后，就可以使用了； 3. 对于 cudatoolkit，我使用 1 中的命令安装之后，在 site-packages 文件夹中并没有发现它，我不知道这步是不是必需的，还是加上吧。</p>
</div></p>
<p><a href="https://download.pytorch.org/whl/cu101/torch-1.4.0-cp36-cp36m-win_amd64.whl" target="_blank" rel="noopener"></a></p>
]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>NVIDIA</tag>
      </tags>
  </entry>
  <entry>
    <title>【算法设计题目】动态规划</title>
    <url>/posts/f592f293.html</url>
    <content><![CDATA[<h1 id="爬楼梯">70. 爬楼梯</h1>
<p>这是道简单题，思想是找到递推式。<mark class="label success">简单</mark> 题设你正在爬楼梯，需要 n 阶你才能到楼顶，那么我们反着思考，在此之前我们设 <code>OPT(i)</code> 代表 i 阶楼梯共有几种走法。现在假设现在只需要一步就可以到楼顶，我们只有两种选择：1）一步跨一阶；2）一步跨两阶。它们分别对应于 <code>OPT(i - 1)</code> 和 <code>OPT(i - 2)</code>，显然这两种走法是不同的！所以我们实际上 <code>OPT(i) = OPT(i - 1) + OPT(i - 2)</code>。这是其实已经可以用数组解决了，已知一阶楼梯只有一种走法，二阶楼梯有两种走法，则已知数组 <code>[1, 2]</code>，然后第三项只是前两项的和得到 <code>[1, 2, 3]</code>，以此类推得到 <code>[1, 2, 3, 5]</code>。 然而这需要额外的数组，实际上这个公式就是菲波那切数列，所以在写代码时，没必要用数组存储全部的变量。最后给出递推式的完整版： <span class="math display">\[
OPT(i) = 
\begin{cases}
    OPT(i - 1) , &amp; \text{一步一阶} \\
    OPT(i - 2) , &amp; \text{一步两阶} \\
\end{cases}
\]</span> <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def climbStairs(self, n: <span class="keyword">int</span>) -&gt; in<span class="variable">t:</span></span><br><span class="line">        <span class="keyword">if</span> n == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">res</span> = [<span class="number">0</span> <span class="keyword">for</span> _ in <span class="built_in">range</span>(n)]</span><br><span class="line">        <span class="keyword">res</span>[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">res</span>[<span class="number">1</span>] = <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="number">2</span>, n):</span><br><span class="line">            <span class="keyword">res</span>[i] = <span class="keyword">res</span>[i - <span class="number">1</span>] + <span class="keyword">res</span>[i - <span class="number">2</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">res</span>[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure> <a id="more"></a></p>
<h1 id="买卖股票的最佳时机">121. 买卖股票的最佳时机</h1>
<p>这是道简单题，但是是我碰到的一种新的类型的题目，所以想了一会没想出来，看了一眼评论才有思路。<mark class="label success">简单</mark> 思路与简单的动态规划类似。 1. 首先从第 <code>i</code> 个价格出发，前 <code>i-1</code> 个价格中必然有一个最小值，我们买股票肯定是希望从从小的价钱买进，从最大的价钱卖出，从而赚取差价。所以只需要用当前值减去前 <code>i-1</code> 个价格中的最小值，即可求得 <code>i</code> 个价格的最大利润，即 <code>prices[i] - min(prices[: i-1])</code>。 2. 其次，如果我们从第 <code>i-1</code> 个价格出发呢？同理，我们可以得到公式 <code>prices[i-1] - min(prices[: i-2])</code>。 3. 所以我们就得到了状态转移公式： <span class="math display">\[
opt(i) =
\begin{cases}
    max{opt(i - 1), prices[i] - min(prices[: i-1])}
\end{cases}
\]</span> 4. 还有一点，我们虽然状态转移公式是从后往前递推的，但是代码是从前往后遍历的，所以实际上 <code>min()</code> 这个函数并不需要。如下代码所示，只需要一边遍历，一边记录最小的价格即可。 <figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxProfit</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">prices:</span> List[int])</span></span> -&gt; <span class="symbol">int:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="symbol">prices:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        min_price = prices[<span class="number">0</span>]</span><br><span class="line">        a = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(prices))<span class="symbol">:</span></span><br><span class="line">            min_price = prices[i] <span class="keyword">if</span> min_price &gt; prices[i] <span class="keyword">else</span> min_price</span><br><span class="line">            a = max(a, prices[i] - min_price)</span><br><span class="line">        <span class="keyword">return</span> a</span><br></pre></td></tr></table></figure></p>
<h1 id="打家劫舍">198. 打家劫舍</h1>
<p>这是道简单题，思想是找到递推式（2020.3.26：今天学到了，原来这公式叫状态转移公式）。<mark class="label success">简单</mark> 首先要理解一点，这里的相邻房屋指的是字面意思，虽然这样理解在理论上有点说不通。比如说现在有 A，B，C 三幢房子，偷 AB 房子会触发警报，BC也会触发，但是 AC 不会。 理解了相邻房子的概念之后，就可以做题了。显然这题是“偷与不偷”的想法，我们将所有房子用一个数列表示。设有 n 间房，则对于第 <code>n</code> 间房，我们可以选择“偷”和“不偷”。如果“偷”，则第 <code>n-1</code> 间房不能偷，下间可“偷”的房是第 <code>n-2</code> 间；如果“不偷”，则第 <code>n-1</code> 间房可以偷，下间可“偷”的房是第 <code>n-3</code> 间。我们假定 <code>OPT(i)</code> 表示可以偷到钱财的最大值，<code>nums</code> 表示各间房屋中所拥有的钱财。则“偷”可表示为 <code>OPT(n) = OPT(n-2) + nums[n]</code>，“不偷”可表示为 <code>OPT(n) = OPT(n-3) + nums[n-1]</code>。将表达式形式化为： <span class="math display">\[
OPT(i) = 
\begin{cases}
    OPT(i - 2) + nums[i] &amp; \text{偷第i间} \\
    OPT(i - 3) + nums[i-1] &amp; \text{不偷第i间} \\
\end{cases}
\]</span> 有一点需要注意，在编程上需要对以上公式做一个细小的改动。因为 <code>OPT(0) = 0</code>，但是实际上不存在第 0 间房，我们都是从 1 开始数的。所以解向量 opt 包含 n+1 个元素，而房子只有 n 间，这会导致程序的索引出错。由于我们遍历的是 opt 的长度，所以我们只需要在编程时对索引减 1 就行了。 最后，下面的算法还可以略微改进，由于我们只需要使用索引为 i, i-1, i-2, i-3 的值，所以我们并不需要一个长度为 n +1 的向量。 <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def rob(self, num<span class="variable">s:</span> List[<span class="keyword">int</span>]) -&gt; in<span class="variable">t:</span></span><br><span class="line">        <span class="keyword">if</span> not num<span class="variable">s:</span></span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        elif <span class="built_in">len</span>(nums) == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>]</span><br><span class="line">        elif <span class="built_in">len</span>(nums) == <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">max</span>(nums[<span class="number">0</span>], nums[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">opt</span> = [<span class="number">0</span> <span class="keyword">for</span> _ in <span class="built_in">range</span>(<span class="built_in">len</span>(nums) + <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">opt</span>[<span class="number">1</span>] = nums[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">opt</span>[<span class="number">2</span>] = <span class="built_in">max</span>(nums[<span class="number">0</span>], nums[<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">for</span> i in <span class="built_in">range</span>(<span class="number">3</span>, <span class="built_in">len</span>(nums) + <span class="number">1</span>):</span><br><span class="line">            rob = <span class="keyword">opt</span>[i - <span class="number">2</span>] + nums[i - <span class="number">1</span>]</span><br><span class="line">            not_rob = <span class="keyword">opt</span>[i - <span class="number">3</span>] + nums[i - <span class="number">1</span> - <span class="number">1</span>]</span><br><span class="line">            <span class="keyword">opt</span>[i] = <span class="built_in">max</span>(rob, not_rob)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">opt</span>[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure></p>
<h1 id="面试题-17.16.-按摩师">面试题 17.16. 按摩师</h1>
<p>此题与 <code>198. 打家劫舍</code> 类似，不再进行分析，下面对公式稍作更改： <span class="math display">\[
OPT(i) = 
\begin{cases}
    OPT(i - 2) + nums[i] &amp; \text{偷第i间} \\
    OPT(i - 1) &amp; \text{不偷第i间} \\
\end{cases}
\]</span></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>【算法设计题目】分治法</title>
    <url>/posts/3624b325.html</url>
    <content><![CDATA[<h1 id="算法思想">算法思想</h1>
<a id="more"></a>
<h1 id="最大子序和面试题16.17.连续数列面试题42.连续子数组的最大和">53. 最大子序和/面试题16.17.连续数列/面试题42.连续子数组的最大和</h1>
<p>这题想了很久没想出怎么做，最后是看了评论才想出来的。<mark class="label success">简单</mark></p>
<p>主要是我都没做过分治法的题，由于思维定势，我一直在想“怎么才能将一个序列划分出各种可能的子序列”，然后我又觉得这根本不可能划分出来。</p>
<p>书上看的例子都是二分搜索、合并排序、快速排序等，所以我就觉得可以分割成一块一块最小的序列，然后比较每块的大小就可以解决了。但是比较左右两块的最大值无法得到最终解，因为一个子序列可能会横跨左右两个块，所以按照这个逻辑必须枚举所有的组合。</p>
<p>其实上述的思想已经对了一半了，主要是没经验。按照上述的思想继续往下，由于左右两部分的最大值是最容易求的，我们默认已经求得 max1，max2，那么我们只需要解决“子序列横跨左右两部分”的情况。</p>
<p>其实解决办法就是，逆序遍历左部，通过累加判断左部的最大值。正序遍历右部，通过累加判断右部的最大值。然后将二者相加就是“子序列横跨左右两部分”的最大值 max3。最后取 max1，max2，max3 的最大值即可。 <figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">import math</span><br><span class="line">class Solution:</span><br><span class="line">    def maxSubArray(self, nums: List[int]) -&gt; int:</span><br><span class="line">        def rec(low, high):</span><br><span class="line">            <span class="comment"># 划分到最简便时，返回当前值</span></span><br><span class="line">            <span class="keyword">if</span> high == low:</span><br><span class="line">                <span class="literal">return</span> nums[low]</span><br><span class="line">            <span class="comment"># 计算中间索引</span></span><br><span class="line">            <span class="keyword">mid</span> = math.floor((high - low) / <span class="number">2</span>) + low</span><br><span class="line">            <span class="comment"># 计算 mid 以左的最大值</span></span><br><span class="line">            max_left = rec(low, <span class="keyword">mid</span>)</span><br><span class="line">            <span class="comment"># 计算 mid 以右的最大值</span></span><br><span class="line">            max_right = rec(<span class="keyword">mid</span> + <span class="number">1</span>, high)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 以下均为计算横跨 mid 的序列的最大值</span></span><br><span class="line">            left_max = nums[<span class="keyword">mid</span>]</span><br><span class="line">            accumulation = left_max</span><br><span class="line">            <span class="keyword">for</span> <span class="keyword">item</span> <span class="keyword">in</span> reversed(nums[low: <span class="keyword">mid</span>]):</span><br><span class="line">                accumulation += <span class="keyword">item</span></span><br><span class="line">                left_max = accumulation <span class="keyword">if</span> accumulation &gt; left_max <span class="keyword">else</span> left_max</span><br><span class="line">            </span><br><span class="line">            right_max = nums[<span class="keyword">mid</span> + <span class="number">1</span>]</span><br><span class="line">            accumulation = right_max</span><br><span class="line">            <span class="keyword">for</span> <span class="keyword">item</span> <span class="keyword">in</span> nums[<span class="keyword">mid</span> + <span class="number">2</span>: high + <span class="number">1</span>]:</span><br><span class="line">                accumulation += <span class="keyword">item</span></span><br><span class="line">                right_max = accumulation <span class="keyword">if</span> accumulation &gt; right_max <span class="keyword">else</span> right_max</span><br><span class="line">            <span class="comment"># 返回三者的最大值</span></span><br><span class="line">            <span class="literal">return</span> <span class="built_in">max</span>(max_left, max_right, left_max + right_max)</span><br><span class="line">        <span class="literal">return</span> rec(<span class="number">0</span>, <span class="built_in">len</span>(nums) - <span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="多数元素面试题39.-数组中出现次数超过一半的数字面试题17.10.主要元素">169. 多数元素/面试题39. 数组中出现次数超过一半的数字/面试题17.10.主要元素</h1>
<p>此题的关键是题目允许你<em>可以假设数组是非空的，并且给定的数组总是存在多数元素</em>。<mark class="label success">简单</mark></p>
<ol type="1">
<li>首先判断左部出现最多的数 <code>left</code></li>
<li>其次判断右部出现最多的数 <code>right</code></li>
<li>如果 <code>left</code> 与 <code>right</code> 相等，则任意返回一个数</li>
<li>否则遍历两部分，判断 <code>left</code> 与 <code>right</code> 两个值，到底哪个出现最多次。
<ol type="1">
<li>例如 <code>5 5 6 6 | 6 6 6 6</code>。对于左侧的 <code>55|66</code>，我们再次划分出左右两部分，我们首先得出 <code>5</code> 与 <code>6</code> 分别是最常出现的数</li>
<li>于是遍历 <code>5566</code>，以此判断 <code>5</code> 与 <code>6</code> 哪个出现最多次，返回出现最多次的那一个</li>
<li>但是题目中是相等的，直觉来讲，我们无法判断出应该返回哪个，因为我们还没考虑右半部分，比如 <code>5566|6689</code>，如果返回 <code>5</code>，那么是不妥的，因为明明 <code>6</code> 才是出现最多次的。返回 <code>6</code>，对于 <code>5566|5589</code>，则是不妥的。</li>
<li>但是实际上可以任意返回一个值，因为我们已经假定了<strong>数组总是存在多数元素</strong>，这就意味着这个“多数”必定存在于左右其中一部分。所以我们总能找到这个数。</li>
<li>但是假设数组中并不是总是存在“多数”，则该算法实际上是错误的。 <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def majorityElement(self, num<span class="variable">s:</span> List[<span class="keyword">int</span>]) -&gt; in<span class="variable">t:</span></span><br><span class="line">        def <span class="keyword">rec</span>(low, high):</span><br><span class="line">            <span class="keyword">if</span> high - low &lt;= <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">return</span> nums[low]</span><br><span class="line">            </span><br><span class="line">            mid = (high + low) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">left</span> = <span class="keyword">rec</span>(low, mid)</span><br><span class="line">            <span class="keyword">right</span> = <span class="keyword">rec</span>(mid, high)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">left</span> == righ<span class="variable">t:</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">left</span></span><br><span class="line">            <span class="keyword">a</span> = sum(<span class="number">1</span> <span class="keyword">for</span> item in nums[<span class="keyword">lo</span><span class="variable">w:</span> high] <span class="keyword">if</span> item == <span class="keyword">left</span>)</span><br><span class="line">            <span class="keyword">b</span> = sum(<span class="number">1</span> <span class="keyword">for</span> item in nums[<span class="keyword">lo</span><span class="variable">w:</span> high] <span class="keyword">if</span> item == <span class="keyword">right</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">left</span> <span class="keyword">if</span> <span class="keyword">a</span> &gt;= <span class="keyword">b</span> <span class="keyword">else</span> <span class="keyword">right</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">rec</span>(<span class="number">0</span>, <span class="built_in">len</span>(nums))</span><br></pre></td></tr></table></figure></li>
</ol></li>
</ol>
<h1 id="剑指offer-40.-最小的k个数面试题-17.14.-最小-k-个数">剑指offer 40. 最小的k个数/面试题 17.14. 最小 K 个数</h1>
<p>思想：取出左边的 k 个最小值，再取出右边的 k 个最小值。最后合并取 k 个最小值。<mark class="label success">简单</mark> <mark class="label warning">中等</mark></p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def getLeastNumbers(self, arr: List[<span class="keyword">int</span>], <span class="keyword">k</span>: <span class="keyword">int</span>) -&gt; List[<span class="keyword">int</span>]:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">k</span> == <span class="number">0</span>: <span class="keyword">return</span> []</span><br><span class="line">        def <span class="keyword">rec</span>(start, end):</span><br><span class="line">            <span class="keyword">if</span> end - start &lt;= <span class="keyword">k</span>:</span><br><span class="line">                <span class="keyword">return</span> arr[<span class="keyword">star</span><span class="variable">t:</span> end]</span><br><span class="line">            </span><br><span class="line">            mid = (start + end) // <span class="number">2</span></span><br><span class="line">            <span class="keyword">left</span> = <span class="keyword">rec</span>(start, mid)</span><br><span class="line">            <span class="keyword">right</span> = <span class="keyword">rec</span>(mid, end)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">left</span>.<span class="built_in">extend</span>(<span class="keyword">right</span>)</span><br><span class="line">            <span class="keyword">left</span>.<span class="keyword">sort</span>()</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">left</span>[: <span class="keyword">k</span>]</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">rec</span>(<span class="number">0</span>, <span class="built_in">len</span>(arr))</span><br></pre></td></tr></table></figure>
<h1 id="漂亮数组">932. 漂亮数组</h1>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>分治法</tag>
      </tags>
  </entry>
  <entry>
    <title>Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</title>
    <url>/posts/36b672d2.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/1905.08743.pdf" target="_blank" rel="noopener">论文地址</a>，作者为 Wu, Chien-Sheng et al.，发表于 2019 年。</p>
</div>
<h1 id="引言">引言</h1>
<p>传统的状态跟踪假设本体已经定义好，所有的 slot-value 均已知，这可以将 DST 简化为分类任务。<strong>但是这种方法有两种缺陷：1）</strong>完整的本体很难提前获得。工业界，数据库通常由 API 支撑，由他人维护，很难枚举所有 slot-value；<strong>2）</strong>即使完整的本体存在，slot-value 的数量也会极其庞大。例如酒店名称和列车出发时间包含大量可能的值。因此许多先前的工作都基于神经分类模型，其在现实场景下并不适用。</p>
<p>最近 <a href="https://arxiv.xilesou.top/pdf/1810.00278.pdf" target="_blank" rel="noopener">Budzianowski et al. (2018)</a> 介绍了多领域对话数据集 MultiWOZ，由于它的混合领域对话，<strong>其在 DST 中引入了新的挑战</strong>。<strong>1）</strong>如图一所示，用户先订了酒店，再询问了风景名胜，最后订了一辆出租车。此例中，DST 模型需要探测 (domain, slot, value) 三元组，这在本体中包含了大量的组合，即 30 对 (domian, slot) 以及总计 4500 个可能的值。<strong>2）</strong>另一挑战是，需要进行多轮映射。<strong>单轮映射指的是从单轮对话中推断出 (domain, slot, value) 的场景，但是多轮映射指的是从多轮对话中推断，这些对话发生在多个领域。</strong>例如图 1 中，atrraction 领域的 (area, centre) pair 中的 area 信息是在 restaurant 领域中被预测出的，且这是在前几轮被提到的内容。</p>
<p>为了解决这些问题，我们强调 DST 模型应该跨领域共享跟踪知识。不同领域中有许多 slot 可以共享它们的值。例如，area slot 可以存在于 restaurant, attraction, and taxi 中。此外 restaurant 领域的 name slot 可以与 taxi 领域的 departure slot 共享槽值。另外，<strong>为了使 DST 在未知领域跟踪 slot</strong>，跨领域转移知识势在必行。<strong>我们期望 DST 模型可以通过学习跟踪其他领域中的 slot 来学习跟踪 zero-shot 领域中某些相同的 slot。</strong> <a id="more"></a></p>
<h1 id="trade-model">TRADE Model</h1>
<p>与预测预定义本体项的概率不同，我们的模型直接生成 slot-values。类似于 <a href="https://www.aclweb.org/anthology/Q17-1024/" target="_blank" rel="noopener">Johnson et al. (2017)</a> 的多领域机器翻译，我们共享所有的模型参数，<strong>state generator</strong> 以一个句首符号开始生成。</p>
<p><strong>utterance encoder</strong> 将语句编码为固定的向量。为了探测任意一个 (domain, slot) 是否被提到的问题，context-enhanced <strong>slot gate</strong> 与 state generator 一起使用。</p>
<ol type="1">
<li>state generator 为所有 (domain, slot) 解码，以预测对应值。</li>
<li>context-enhanced slot gate 通过一个三元分类器预测对话是否真的触发了每一对。（<strong>博主注</strong>：假设模型认为语句中没有提到 slot，就不执行 state generator）</li>
</ol>
<h2 id="utterance-encoder">Utterance Encoder</h2>
<p>注意 utterance encoder 可以是任何现存的编码模型，我们用 Bi-GRU(<a href="https://arxiv.org/pdf/1412.3555.pdf" target="_blank" rel="noopener">Chung et al., 2014</a>) 去编码历史对话。<strong>输入记为 history <span class="math inline">\(X_t = [U_{t-l}, R_{t-l}, \cdots, U_t, R_t] \in \mathbb{R}^{|X_t| \times d_{emb}}\)</span>，就是说拼接了所有历史对话</strong>。<strong><span class="math inline">\(l\)</span> 是所选对话轮数</strong>，<strong><span class="math inline">\(d_{emb}\)</span> 是 embedding size</strong>。<strong>编码后的对话历史表示为</strong> <span class="math inline">\(H_t = [h^{enc}_1, \cdots, h^{enc}_{|X|_t}] \in \mathbb{R}^{|X_t| \times d_{hdd}}\)</span>，<strong>其中 <span class="math inline">\(d_{hdd}\)</span> 是 hidden size</strong>。由于之前提到的多轮映射问题，模型应该推断出一段轮数内的状态。因此我们使用长度为 <span class="math inline">\(l\)</span> 的最近的对话历史，而不仅仅是当前对话。</p>
<h2 id="state-generator">State Generator</h2>
<p>为了从语句中提取 slot，需要使用 copy mechanism，其有以下几种类型，我们选择 soft-gated copy 机制。</p>
<ul>
<li>index-based copy：这不适合 DST，因为在语句中并不总能找到 slot value 的确切单词。</li>
<li>hard-gated copy：这通常需要对门函数进行额外的监督</li>
<li>soft-gated copy：将词汇表上的分布和对话历史上的分布合并为一个输出分布。</li>
</ul>
<p>使用 GRU 作为 decoder ，并独立预测 <span class="math inline">\(J\)</span> 个 (domain, slot) 的 value。我们仅简单地使用域槽对的 embedding 之和作为输入。</p>
<ol type="1">
<li>对于第 <span class="math inline">\(j\)</span> 个 (domain, slot) 的第 <span class="math inline">\(k\)</span> 个解码步（<strong>博主注</strong>：一个值可能包含多个单词，所以需要多步解码，参考了<a href="https://www.jianshu.com/p/fcaf02fc025d" target="_blank" rel="noopener">文章</a>），decoder 将词向量 <span class="math inline">\(w_{jk}\)</span> 作为输入并返回隐藏状态 <span class="math inline">\(h^{dec}_{jk}\)</span>。</li>
<li>state generator 首先使用可训练的权重向量（<strong>博主注</strong>：这个 <span class="math inline">\(E\)</span> 应该就是权重，随机初始化即可。不要被 <span class="math inline">\(E\)</span> 这个表示所欺骗，以为它是词嵌入） <span class="math inline">\(E \in \mathbb{R}^{|V| \times d_{hdd}}\)</span> 将 <span class="math inline">\(h^{dec}_{jk}\)</span> 映射为词表空间的概率 <span class="math inline">\(P^{vocab}_{jk}\)</span>，|V| 代表词表大小。同时，<span class="math inline">\(h^{dec}_{jk}\)</span> 还被用于计算 <span class="math inline">\(H_t\)</span> 的历史 attention <span class="math inline">\(P^{history}_{jk}\)</span>。
<ul>
<li><span class="math inline">\(P^{vocab}_{jk} = Softmax(E \cdot (h^{dec}_{jk})^T) \in \mathbb{R}^{|V|} \tag{1}\)</span></li>
<li><span class="math inline">\(P^{history}_{jk} = Softmax(H_t \cdot (h^{dec}_{jk})^T) \in \mathbb{R}^{|X_t|} \tag{1}\)</span></li>
</ul></li>
<li>最后的输出分布 <span class="math inline">\(P^{final}_{jk}\)</span> 是两个分布加权和：
<ul>
<li><span class="math inline">\(P^{final}_{jk} = p^{gen}_{jk} \times P^{vocab}_{jk} + (1 - p^{gen}_{jk}) \times P^{history}_{jk} \in \mathbb{R}^{|V|} \tag{2}\)</span></li>
<li>标量 <span class="math inline">\(p^{gen}_{jk}\)</span> 是可训练的，以融合两个分布：
<ul>
<li><span class="math inline">\(p^{gen}_{jk} = Sigmoid(W_1 \cdot [h^{dec}_{jk}; w_{jk}; c_{jk}]) \in \mathbb{R}^1 \quad c_{jk} = P^{history}_{jk} \cdot H_t \in \mathbb{R}^{d_{hdd}} \tag{3}\)</span></li>
</ul></li>
<li>其中 <span class="math inline">\(W_1\)</span> 是可训练的矩阵，<span class="math inline">\(c_{jk}\)</span> 是上下文向量。注意由于<strong>公式 2</strong>，我们的模型能够生成单词，即使其没有定义在词表中。</li>
</ul></li>
</ol>
<h2 id="slot-gate">Slot Gate</h2>
<p>与单领域的 DST 不同（WOZ 有 4 个 slot，<a href="https://www.aclweb.org/anthology/W14-4337.pdf" target="_blank" rel="noopener">DSTC2</a> 8 个），多领域 DST 问题有大量的 (domain, slot)，因此在 t 轮时预测 domin 和 slot 的能力变得更具有挑战性。</p>
<p>context-enhanced slot gate G 是一个简单的三元分类器，将从 encoder 隐藏状态 <span class="math inline">\(H_t\)</span> 中获取的上下文向量用映射为概率分布 <span class="math inline">\(\{ptr, none, dontcare\}\)</span> 类别。对于每一个 (domain ,slot)，如果预测的结果是 none 或者 dontcare，就无视它们，并将 slot 填充值“not-mentioned”或者“does not care”。否则就采取 state generator 的输出作为其值。</p>
<p>给出线性层的参数 <span class="math inline">\(W_g \in \mathbb{R}^{3 \times d_{hdd}}\)</span>，第 <span class="math inline">\(j\)</span> 个 (domain, slot) 的 slot gate 公式被定义为：</p>
<p><span class="math display">\[G_j = Softmax(W_g \cdot (c_{j0})^T) \in \mathbb{R}^3 \tag{4}
\]</span></p>
<p><span class="math inline">\(c_{jo}\)</span> 是上下文向量，由公式 3 使用 decoder 的第一个隐藏状态计算出。</p>
<h2 id="optimization">Optimization</h2>
<p>交叉熵，略。</p>
<h1 id="unseen-domain-dst">Unseen Domain DST</h1>
<h1 id="experiments">Experiments</h1>
<h2 id="results">Results</h2>
<p>数据集一共有两个评分标准：</p>
<ol type="1">
<li>joint goal accuracy：将预测出的对话状态和每轮对话 t 的真实值 <span class="math inline">\(B_t\)</span> 进行比较，当且仅当所有预测出的 value 与真实值 <span class="math inline">\(B_t\)</span>中的 value 完全匹配时才认为正确</li>
<li>slot accuracy：将每一个 (domain, slot, value) 三元组分别与其对应真实值的标签进行比较</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Collaborative Multi-Agent Dialogue Model Training Via Reinforcement</title>
    <url>/posts/b9655d18.html</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>机器学习在对话式代理（conversational agent）上已经取得了巨大的进展，尤其是采用了深度学习之后。然而大多数工作都遭受着缺乏数据的困境，因为为代理（复杂到能够完成有意义对话的代理）设计一个样本有效的学习算法是非常有挑战的。在其他的简化版本之中，<strong>这一挑战导致了只能将代理之间的交互视为单个（多个代理交互更难）代理的学习问题</strong>。 本项工作中，我们将对话交互建模为随机博弈的形式，并训练两个交互式代理，每一个代理都拥有不同的角色，它们能够通过自然语言与对方交互。我们首先对每个代理训练了 NLU 和 NLG 神经网络，然后使用 multi-agent 强化学习技术，即 <a href="https://www.cs.cmu.edu/~mmv/papers/01ijcai-mike.pdf" target="_blank" rel="noopener">Win or Lose Fast Policy Hill Climbing (WoLF-PHC)</a> 算法。以在高度的不确定（源于每个代理的统计 NLU 和 NLG）以及另一个代理的不稳定行为（因为另一个代理同时在学习）面前学习到最优对话策略。<strong>虽然不能完全减少训练 NLU 和 NLG 组件所需的种子数据，但 multi-agent 的设置具有增强它们的效果，允许我们生成原始数据中不存在的对话和行为。</strong> <a id="more"></a></p>
<h1 id="系统概述">系统概述</h1>
<p>图一显示我们系统的架构以及信息流，虽然我们的系统操作众所周知的 DSTC-2 数据，它关注的是剑桥餐厅的信息，但是我们的 multi-agent 系统支持任何 slot-filling/information-seeking 的领域。NLU 和 NLG 组件可以线下训练，将在以下章节描述，不过 dialogu policy 可以在代理交互时进行线上训练。鉴于我们的 NLU 是基于模型的，而不是基于检索或者模版，所以对话的质量令人兴奋。</p>
<h2 id="language-understanding">Language Understanding</h2>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>multi-agent</tag>
      </tags>
  </entry>
  <entry>
    <title>任务完成型对话系统论文调研（一）</title>
    <url>/posts/e0902c9c.html</url>
    <content><![CDATA[<div class="note info"><p>由于该领域涉及太多知识点，本文只涉及 task-oriented dialog system 四大组件之二：SLU 和 DST。其余两项组件 DPL 以及 NLG 将在 <a href="#">xxxx</a> 中给出。</p>
<p>本文是系列文章的第一篇，一开始架构文章的时候没有考虑太多，所以到目前为止只是写了一些基础的内容，并且逻辑有点乱。更多的内容可以移驾<strong><a href="https://yan624.github.io/posts/4ec51203.html">任务完成型对话系统论文调研（二）</a></strong>。</p>
</div>
<h1 id="任务完成型对话系统">任务完成型对话系统</h1>
<div class="note info"><p>可以点击后面对应的按钮，找到各领域论文的详细对比。<a class="btn" href="#slu论文对比"><i class="fa fa-"></i>SLU 论文对比</a><a class="btn" href="#dst论文对比"><i class="fa fa-"></i>DST 论文对比</a></p>
</div>
<p>任务完成型对话系统（Task-oriented Dialog System，<strong>TODS</strong>），也被称为口语对话系统（Spoken Dialogue System，<strong>SDS</strong>），下统称为 TODS。</p>
<h2 id="对话状态与对话动作">对话状态与对话动作</h2>
<p>对话状态（Dialog State，DS）是 TODS 中的一个重要概念，它贯穿了整个系统的运行过程。要理解 TODS，首先需要从对话状态入手。</p>
<p>对话状态也被称为信念状态（Belief State），或者对话信念状态（Dialog Belief State）。这是历史问题，一般在以前的模型中称之为对话状态，现在使用深度学习技术的对话系统称之为信念状态<span class="citation" data-cites="zhang2020recent">(Zhang et al. 2020)</span>，不过如今二者混用，下称之为对话状态。<span class="citation" data-cites="zhang2020recent">(Zhang et al. 2020)</span>认为<strong>对话状态由槽值对组成</strong>，以此呈现用户的目的。</p>
<div class="note danger"><p>需要在此说明很重要的一点。狭义来讲，对话状态指的是槽值对。但是广义来讲，对话状态可以保存任意的对象，因为对话状态的本意是对话的<strong>状态</strong>。例如还可以保存当前对话的轮数、历史的对话动作、是否已经完成用户的任务、是否超时、根据当前轮所拥有的信息从数据库中查到的一系列数据项等。</p>
</div>
<p>对话动作（Dialog Action）由用户意图（Intention）和<strong>若干槽值对</strong>（通常只有 1 对）组成。一般来说，槽值对的表示方式为 <code>slot=value</code>。但是实际上还有多种不同的表示方式，例如 <code>slot&gt;value</code>，<code>slot in value</code> 等（<strong>参考 Plato 框架</strong>）。下面如果不做说明，我们还是默认使用 <code>slot=value</code> 的方式。</p>
<p><strong>值得注意的是，对话状态由槽值对组成，对话动作也由槽值对组成。但是对话状态保存的是对话历史中提到的所有槽值对，而对话动作只保存当前轮提到的若干槽值对。</strong></p>
<a id="more"></a>
<p>举个例子，用户：“请帮我预定一个在市中心的餐厅，四人桌，大概晚上 6:30 到。”则对话动作为：</p>
<figure class="highlight less"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attribute">intention</span>: <span class="string">'inform'</span>,</span><br><span class="line">  <span class="attribute">sv</span>: &#123;</span><br><span class="line">    <span class="attribute">location</span>: <span class="string">'市中心'</span>,</span><br><span class="line">    <span class="attribute">time</span>: <span class="string">'晚上 6:30'</span>,</span><br><span class="line">    <span class="attribute">num_people</span>: <span class="number">4</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果系统回复：“那么，您需要什么口味呢？”此时系统也拥有对话状态和对话动作，但是暂且不做解释，目前只讲解<strong>用户相关</strong>的对话状态和对话动作。用户回复：“我们吃浙菜。”则此时的对话动作为：</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attribute">intention</span>: <span class="string">'inform'</span>,</span><br><span class="line">  sv: &#123;</span><br><span class="line">    food_type: <span class="string">'浙菜'</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时，系统可能就可以根据以上的条件，到数据库中检索出一个合适的餐厅返回给用户。通过上述的例子可以观察到，我们追踪到的只是用户的动作。然而，其实可以很容易地取出槽值对，从而形成对话状态。那么为什么要多次一举呢？有了对话动作，还要有对话状态。首先，这还是历史遗留问题。一般而言，以前，对话动作都从 SLU 模块获取，然后将其输入进 DST。但是近几年，许多模型都将该模块并入 DST 模块，导致对话动作没什么发挥的空间。其次，在对话状态中可以保存当前轮的对话动作，乍一听这没什么用！但是遇到需要更新槽值的情况时，就有用了。</p>
<p>例如，当前的对话动作是 <code>inform(food_type='浙菜')</code>，那么我们可以得到对话状态 <code>food_type='浙菜'</code>。但是，如果在后面几轮中，用户突然改变了用餐的类型呢？那么我们的对话状态就是 <code>food_type='*'</code>，而之前的对话动作还是成立的，只不过是用户改了想法而已。如果以后还需要使用到很久以前用户做出的决策，那么就可以用到之前所保存的动作了。<strong>所以这也是对话动作和对话状态之间的一个区别。</strong></p>
<p>最后需要说明的是，以上提到的名词在不同的框架或者论文中还有不同的叫法。例如，intention 被称为动作；对话动作被称为语义框架（Semantic Frame）等。</p>
<h2 id="系统动作">系统动作</h2>
<p>系统动作与用户动作（即上节的状态动作）类似，有区别的是，系统动作包含一些用户所不具有的动作。</p>
<h1 id="slu">SLU</h1>
<div class="note warning"><p>注意，由于 2019 年之后大部分论文都默认将 SLU 并入 DST 中，故本节以后将不再更新。</p>
</div>
<p><strong>口语理解</strong>（Spoken language Understanding，<strong>SLU</strong>）是 TODS 的重要组成部分。其共由两项任务组成，分别是<strong>意图检测</strong>（Intent detection，<strong>ID</strong>）与<strong>槽填充</strong>（slot-filling，<strong>SF</strong>）。在实际操作中，ID 可以被视为句子分类任务，SF 可以被视为序列标注任务。需要注意的是，有些作者也将 SLU 称为自然语言理解（Natural Language Understanding，NLU），但是由于 NLU 本身在自然语言处理中就是一项比较重要的任务，难免会产生歧义，所以下文统称为 SLU。另外，有时意图检测也被称为<strong>意图识别</strong>（Intent Determination，<strong>ID</strong>）。</p>
<p>SLU 的实现大致分为两种：1）独立模型（separate models）：训练两个独立的神经网络，一个用于 ID 任务，另一个用于 SF 任务；2）联合模型（joint model）：使用一个神经网络对两个任务进行联合训练，它旨在共享两个任务所捕获的信息。</p>
<p><em>突然发现已经有人对比过很多论文，详见<a href="https://blog.csdn.net/black_soil/article/details/90405098" target="_blank" rel="noopener">【综述】对话系统中的口语理解技术</a>，就不重复造轮子了。以下大部分都是该文未统计的论文，一般是 2018 年以后的论文。</em></p>
<p>以下论文按发表时间（或提交到 arxiv 的时间）排序： <div class="tabs" id="slu论文对比"><ul class="nav-tabs"><li class="tab"><a href="#slu论文对比-1">论文介绍</a></li><li class="tab"><a href="#slu论文对比-2">论文瑕瑜</a></li><li class="tab"><a href="#slu论文对比-3">数据集评估对比</a></li></ul><div class="tab-content"><div class="tab-pane" id="slu论文对比-1"><table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>论文</th>
<th style="text-align: center;">类别</th>
<th>标签</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#btn" title="A Joint Learning Framework With BERT for Spoken Language Understanding"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907842" target="_blank" rel="noopener" title="19.11"><i class="fa fa-"></i>论文</a> Zhang et al. 2019</td>
<td style="text-align: center;"></td>
<td><mark class="label primary">BERT</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#btn" title="BERT for Joint Intent Classification and Slot Filling"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1902.10909.pdf" target="_blank" rel="noopener" title="19.02"><i class="fa fa-"></i>论文</a> Chen et al. 2019</td>
<td style="text-align: center;"></td>
<td><mark class="label primary">BERT</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#A-Bi-model-based-RNN-Semantic-Frame-Parsing-Model-for-Intent-Detection-and-Slot-Filling" title="A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1812.10235.pdf" target="_blank" rel="noopener" title="18.12"><i class="fa fa-"></i>论文</a> <strong><font color='blue'>Wang et al., 2018</font></strong></td>
<td style="text-align: center;">separate</td>
<td><mark class="label primary">BiLSTM</mark><br />
<mark class="label primary">encoder-decoder</mark> <mark class="label info">cross-impact</mark> <mark class="label danger"><strong>hidden state sharing</strong></mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#A-Self-Attentive-Model-with-Gate-Mechanism-for-Spoken-Language-Understanding" title="A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://www.aclweb.org/anthology/D18-1417.pdf" target="_blank" rel="noopener" title="18.11"><i class="fa fa-"></i>论文</a> <strong>Li et al., 2018</strong></td>
<td style="text-align: center;">joint</td>
<td><mark class="label primary">BiLSTM</mark><br />
<mark class="label info">self-attention</mark> <mark class="label success">Intent-Augmented Gating Mechanism</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#Attention-Based-Recurrent-Neural-Network-Models-for-Joint-Intent-Detection-and-Slot-Filling" title="Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1609.01454.pdf" target="_blank" rel="noopener" title="16.09"><i class="fa fa-"></i>论文</a> Liu and Lane, 2016a</td>
<td style="text-align: center;">joint</td>
<td><mark class="label primary">BiLSTM</mark><br />
<mark class="label primary">encoder-decoder</mark> <mark class="label info">attention</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#Encoder-decoder-with-focus-mechanism-for-sequence-labelling-based-spoken-language-understanding" title="Encoder-decoder with focus-mechanism for sequence labelling based spoken language understanding"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1608.02097.pdf" target="_blank" rel="noopener" title="16.08"><i class="fa fa-"></i>论文</a> Zhu and Yu, 2017</td>
<td style="text-align: center;">separate</td>
<td><mark class="label primary">BiLSTM</mark><br />
<mark class="label primary">encoder-decoder</mark> <mark class="label info">focus mechanism</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#A-Joint-Model-of-Intent-Determination-and-Slot-Filling-for-Spoken-Language-Understanding" title="A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://pdfs.semanticscholar.org/1f9e/2d6df1eaaf04aebf428d9fa9a9ffc89e373c.pdf" target="_blank" rel="noopener" title="16"><i class="fa fa-"></i>论文</a> <strong>Zhang and Wang, 2016</strong></td>
<td style="text-align: center;">joint</td>
<td><mark class="label primary">Bi-GRU</mark><br />
<mark class="label primary">contextual word embedding</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/81299a9a.html#btn"><i class="fa fa-"></i>笔记</a><a class="btn" href="#url"><i class="fa fa-"></i>论文</a> 粗体代表有启发的论文</td>
<td style="text-align: center;"></td>
<td><mark class="label primary">BERT</mark>\</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="slu论文对比-2"><table>
<thead>
<tr class="header">
<th>论文</th>
<th>解决的问题</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Wang et al., 2018</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Li et al., 2018</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Liu and Lane, 2016a</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Zhu and Yu, 2017</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Zhang and Wang, 2016</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>----------------</td>
<td>粗体代表不错的想法</td>
<td>斜体代表在以后的论文中此缺点大致已被解决</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="slu论文对比-3"><p><a class="btn" href="#slu-atis"><i class="fa fa-"></i>ATIS</a></p></div></div></div></p>
<h2 id="难点未来的工作">难点/未来的工作</h2>
<p>大多数模型都假定用户的语句只有一个意图分类，但是现实并不是如此。而且在系统覆盖多个领域时，ID 模型的决策空间变得过大。如果以后要新增一个意图，必须重新训练整个模型。</p>
<p>此外任务完成型对话系统很难找到现成的数据，因为完成任务的系统动作有时可能并不是语言，而是数据库查询语句或是其他动作，这就使得难以界定任务是否完成，导致数据难以爬取。综上所述，SLU 的难点大致如下所示：</p>
<ul>
<li>如何解决多意图分类？</li>
<li>如何解决未知的意图和槽值对？</li>
<li>如何解决数据稀缺问题？</li>
</ul>
<h2 id="相关工作">相关工作</h2>
<p>传统模型将 SF 和 ID 视为两个独立的任务，许多工作为它们单独一个训练神经网络，并执行预测。这忽略了二者之间的联系。近年来，一些工作开始将二者进行联合训练，共享它们的信息。</p>
<p>以下将分别介绍独立模型和联合模型的几项工作。</p>
<h3 id="独立模型">独立模型</h3>
<ol type="1">
<li><span class="citation" data-cites="zhu2017encoder">(Zhu and Yu 2017)</span> 对 SF 任务提出了一个模型，使用 encoder-decoder 架构，encoder 部分应用 BiLSTM，deocder 部分应用 uniLSTM，同时结合 attention 机制。但是他们发现 attention 机制对于 SF 任务确实有一定局限性：1）序列标注任务中的输入和输出是对齐（alignment）的，一个单词对应着一个标注，但是 attention 机制的思想却是取所有输入单词的加权和；2）单词的对齐可由 attention 机制学习到，但是在序列标记任务中，很难拟合有限的标注数据（与此不同的是机器翻译更容易获得成对数据，如中英文翻译，而序列标注任务的数据非常稀少，且需要人工标注）。所以他们提出了一种新的 focus 机制。原理是在执行 attention 机制时，放弃其他上下文单词，只关注当前单词。</li>
<li><strong><span class="citation" data-cites="wang2018bi">(Wang, Shen, and Jin 2018)</span></strong> 认为先前的工作经常将 ID 和 SF 当做两个平行的任务看待，一般使用一个联合模型建模两个认为，他们认为这样无法完全利用二者之间的交叉影响。所以为了考虑二者的交叉影响，虽然他们使用的是独立模型架构，分别为 ID 以及 SF 任务训练一个 LSTM 模型，但是在训练时，<strong>共享了两个模型的隐藏状态</strong>。</li>
</ol>
<h3 id="联合模型">联合模型</h3>
<ol type="1">
<li><span class="citation" data-cites="mesnil2014using">(Mesnil et al. 2014)</span> 发现使用一个 context word window 可以提高 RNN 在 SF 上的性能。<strong><span class="citation" data-cites="zhang2016joint">(Zhang and Wang 2016)</span></strong> 利用此方法，对 ID 以及 SF 训练了一个联合模型。具体做法是：获得词向量 <span class="math inline">\(e(w_t)\)</span> 后，令 <span class="math inline">\(x^d_t = [e(w_{t-d}), \cdots, e(w_t), \cdots, e(w_{t+d})]\)</span> 重新表示词向量，其中 <span class="math inline">\(e(w_t)\)</span> 代表单词 <span class="math inline">\(w_t\)</span> 的词向量，d 代表窗口半径。此外为了使模型获得更好的性能，在 <span class="math inline">\(x^d_t\)</span> 中还拼接了单词所对应的命名体词向量，比如“New York”的命名体为“B-city I-City”，最终 <span class="math inline">\(x^d_t = [e(w_{t-d}), \cdots, e(w_t), \cdots, e(w_{t+d}), e\prime(n_{t-c}), \cdots, e\prime(n_t), \cdots, e\prime(n_{t+c})]\)</span>，其中 <span class="math inline">\(e\prime(n_t)\)</span> 代表命名体 <span class="math inline">\(n_t\)</span> 的词向量，c 代表窗口半径。在编码部分，句子的信息由 Bidirectional GRU（Bi-GRU）进行提取。在解码部分，一个 decoder 用于输出意图，另一个 decoder 用于输出句子中每个单词的命名体。<strong><em>不过在真实的场景下可能无法获取单词的命名体信息</em></strong>（<em>所以本文不采用 W+N 的特征，而是选用 W 的特征与其他论文作对比</em>）。</li>
<li><span class="citation" data-cites="liu2016attention">(Liu and Lane 2016)</span> 采用 sequence-to-sequence 模型以及 attention 机制，对于 ID 任务来说，提高了 0.56% 的性能，对于 SF 任务来说，提高了 0.23% 的性能。就实验的结果来看，attention 机制对于序列标注任务来说提升不明显，对于意图分类任务有些许提升。</li>
<li><strong><span class="citation" data-cites="li2018self">(Li, Li, and Qi 2018)</span></strong> 使用词级别的嵌入和字母级别的嵌入组合而成的词向量进行模型训练。<strong>使用 self-attention 机制获取上下文信息</strong>，然后使用 BiLSTM 产生隐藏状态，此时利用隐藏状态生成意图分类，最后加上<strong>意图增强门控机制</strong>产生槽位标签。</li>
</ol>
<h2 id="论文笔记">论文笔记</h2>
<p>详见 <a href="https://yan624.github.io/posts/81299a9a.html">SLU论文笔记（？-2020）</a>。</p>
<h2 id="引用">引用</h2>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/83825070" target="_blank" rel="noopener">认真的聊一聊对话系统（任务型、检索式、生成式对话论文与工具串讲）</a></li>
<li><a href="https://mp.weixin.qq.com/s/DTcwvTx-JDZJqqOI_FRiIQ" target="_blank" rel="noopener">Awesome Paper List of Dialogue Systems</a></li>
<li><a href="https://www.cnblogs.com/jiangxinyang/p/10789512.html" target="_blank" rel="noopener">任务型对话（一）—— NLU/SLU（意图识别和槽值填充）</a></li>
<li><a href="https://github.com/sz128/Natural-language-understanding-papers" target="_blank" rel="noopener">Natural-language-understanding-papers</a></li>
</ol>
<h1 id="dst">DST</h1>
<div class="note primary"><p>由于最初并没有打算写那么多内容，导致以下内容的逻辑很乱。故已将其整理至<a href="https://yan624.github.io/posts/4ec51203.html#前情提要">任务完成型对话系统论文调研（二）</a>。</p>
</div>
<div class="note info"><p>目前 DST 的做法多种多样，(Zhang et al. 2019)<!-- @zhang2019find --> 认为主要可以分为：1）picklist-based；2）span-based。但是也有其他论文(Eric et al. 2019)将其分为：1）fixed-vocabulary；2）open-vocabulary。 <!-- @eric2019multiwoz --> 实际上上述两种分类方法是一一对应的。以下将 picklist-based 称为 <code>classify</code>，将 span-based 称为 <code>span</code>。</p>
</div>
<table>
<thead>
<tr class="header">
<th>模型</th>
<th>槽值生成方法</th>
<th>槽位门控</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>TripPy<span class="citation" data-cites="heck2020trippy">(Heck et al. 2020)</span></td>
<td><mark class="label success">discriminative</mark></td>
<td><mark class="label info">bool</mark> <mark class="label info">span</mark> <mark class="label info">refer</mark> <mark class="label info">inform</mark></td>
</tr>
<tr class="even">
<td>DS-DST<span class="citation" data-cites="zhang2019find">(Zhang et al. 2019)</span></td>
<td><mark class="label success">discriminative</mark></td>
<td><mark class="label info">classify</mark> <mark class="label info">span</mark></td>
</tr>
<tr class="odd">
<td>BERT-DST</td>
<td><mark class="label success">discriminative</mark></td>
<td><mark class="label info">span</mark></td>
</tr>
<tr class="even">
<td>TRADE<span class="citation" data-cites="wu2019transferable">(Wu et al. 2019)</span></td>
<td><mark class="label success">generatvie</mark></td>
<td><mark class="label info">soft-gated copy</mark></td>
</tr>
<tr class="odd">
<td>GLAD<span class="citation" data-cites="zhong2018global">(Zhong, Xiong, and Socher 2018)</span></td>
<td><mark class="label success">discriminative</mark></td>
<td><mark class="label info">classify</mark></td>
</tr>
<tr class="even">
<td>NBT<span class="citation" data-cites="mrkvsic2016neural">(Mrkšić et al. 2016)</span></td>
<td><mark class="label success">discriminative</mark></td>
<td><mark class="label info">classify</mark></td>
</tr>
</tbody>
</table>
<div class="tabs" id="dst论文对比"><ul class="nav-tabs"><li class="tab active"><a href="#dst论文对比-1">论文介绍</a></li><li class="tab"><a href="#dst论文对比-2">论文瑕瑜</a></li><li class="tab"><a href="#dst论文对比-3">重要思想</a></li><li class="tab"><a href="#dst论文对比-4">数据集评估对比</a></li></ul><div class="tab-content"><div class="tab-pane active" id="dst论文对比-1"><table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>论文</th>
<th>标签</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#trippy-a-triple-copy-strategy-for-value-independent-neural-dialog-state-tracking" title="TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/2005.02877.pdf" target="_blank" rel="noopener" title="20.05"><i class="fa fa-"></i>论文</a> <br /> Heck et al., 2020</td>
<td><mark class="label primary"><strong>BERT</strong></mark> <mark class="label warning"><strong>处理变化的槽值</strong></mark><br />
<mark class="label success"><strong>TripPy</strong></mark> <mark class="label warning">Context Encoder</mark> <mark class="label primary">Slot Gate</mark> <mark class="label primary">Boolean slot</mark> <mark class="label success">System Inform Memory</mark> <mark class="label info">DS Memory</mark> <mark class="label danger">Auxiliary Features</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Find-or-Classify-Dual-Strategy-for-Slot-Value-Predictions-on-Multi-Domain-Dialog-State-Tracking" title="Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1910.03544.pdf" target="_blank" rel="noopener" title="19.10"><i class="fa fa-"></i>论文</a> <br /> Zhang et al., 2019</td>
<td><mark class="label primary"><strong>BERT</strong></mark> <mark class="label warning"><strong>处理变化的槽值</strong></mark><br />
<mark class="label success"><strong><a href="https://github.com/gusalsdmlwlq/DS-DST" target="_blank" rel="noopener">DS-DST</a></strong></mark> <mark class="label success"><strong>DST-Picklist</strong></mark> <mark class="label info">Slot-Context Encoder</mark> <mark class="label danger">Slot-Gate</mark> <mark class="label default">拼接词向量</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#btn"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1907.03040.pdf" target="_blank" rel="noopener" title="19.07"><i class="fa fa-"></i>论文</a> <br /> Chao et al., 2019</td>
<td><mark class="label primary"><strong>BERT</strong></mark><br />
<mark class="label success"><strong><a href="https://github.com/guanlinchao/bert-dst" target="_blank" rel="noopener">BERT-DST</a></strong></mark> <mark class="label info">turn level ds</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Transferable-Multi-Domain-State-Generator-for-Task-Oriented-Dialogue-Systems" title="Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1905.08743.pdf" target="_blank" rel="noopener" title="19.05"><i class="fa fa-"></i>论文</a> <br /> Wu, Chien-Sheng et al., 2019</td>
<td><mark class="label primary"><strong>BiGRU</strong></mark> <mark class="label warning"><strong>处理变化的槽值</strong></mark><br />
<mark class="label success"><strong><a href="https://github.com/jasonwu0731/trade-dst" target="_blank" rel="noopener">TRADE</a></strong></mark> <mark class="label info">Utterance Encoder</mark> <mark class="label primary">State Generator</mark> <mark class="label danger">Slot Gate</mark> <mark class="label warning">soft-gated copy</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Global-Locally-Self-Attentive-Dialogue-State-Tracker" title="Global-Locally Self-Attentive Dialogue State Tracker"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1805.09655.pdf" target="_blank" rel="noopener" title="18.05"><i class="fa fa-"></i>论文</a> <br /> Zhong et al. 2018</td>
<td><mark class="label primary"><strong>BiLSTM</strong></mark> <mark class="label warning"><strong>处理变化的槽值</strong></mark> <mark class="label warning"><strong>处理低频槽值</strong></mark><br />
<mark class="label success"><strong><a href="https://github.com/salesforce/glad" target="_blank" rel="noopener">GLAD</a></strong></mark> <mark class="label primary">global-locally</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Scalable-multi-domain-dialogue-state-tracking" title="Scalable multi-domain dialogue state tracking"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1712.10224.pdf" target="_blank" rel="noopener" title="17.12"><i class="fa fa-"></i>论文</a> <br /> Rastogi A et al., 2017</td>
<td><mark class="label primary"><strong>2 layer BiGRU</strong></mark> <mark class="label warning"><strong>处理变化的槽值</strong></mark> <mark class="label info"><strong>classify</strong></mark><br />
<mark class="label primary">使用有限候选集</mark> <mark class="label warning">delexicalisation</mark> <mark class="label danger">迁移到其他领域</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Neural-Belief-Tracker-Data-Driven-Dialogue-State-Tracking" title="Neural Belief Tracker: Data-Driven Dialogue State Tracking"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener" title="16.06"><i class="fa fa-"></i>论文</a> <br /> <font color='blue'>Mrkšić N et al., 2016</font></td>
<td><mark class="label primary"><strong>simpleNN</strong></mark> <mark class="label default"><strong>摆脱人工构建的词表</strong></mark><br />
<mark class="label success"><strong>NBT-DNN</strong></mark> <mark class="label success"><strong>NBT-CNN</strong></mark> <mark class="label warning">Semantic Decoding</mark> <mark class="label primary">Context Modelling</mark> <mark class="label default">二元决策</mark> <mark class="label danger">Belief State Update Mechanism</mark></td>
</tr>
<tr class="even">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Incremental-LSTM-based-dialog-state-tracker" title="Incremental LSTM-based dialog state tracker"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://arxiv.org/pdf/1507.03471.pdf" target="_blank" rel="noopener" title="15.07"><i class="fa fa-"></i>论文</a> <br /> Zilka and Jurcicek, 2015</td>
<td><mark class="label primary"><strong>LSTM</strong></mark> <mark class="label default"><strong>摆脱人工构建的词表</strong></mark> <mark class="label info"><strong>classify</strong></mark><br />
<mark class="label success"><strong>LecTrack</strong></mark> <mark class="label danger">结合置信度分数</mark> <mark class="label success">无需遍历槽值</mark> <mark class="label primary">低频词抽象化</mark> <mark class="label info">Model Averaging</mark></td>
</tr>
<tr class="odd">
<td><a class="btn" href="https://yan624.github.io/posts/89f2cf08.html#Word-Based-Dialog-State-Tracking-with-Recurrent-Neural-Networks" title="Word-Based Dialog State Tracking with Recurrent Neural Networks"><i class="fa fa-"></i>笔记</a><a class="btn" href="https://www.aclweb.org/anthology/W14-4340.pdf" target="_blank" rel="noopener" title="14.06"><i class="fa fa-"></i>论文</a> <br /> Henderson et al., 2014d</td>
<td><mark class="label primary"><strong>RNN</strong></mark> <mark class="label default"><strong>省略SLU，但需要词汇表</strong></mark> <mark class="label info"><strong>classify</strong></mark><br />
<mark class="label info">delexicalisation</mark> <mark class="label primary">n-gram</mark></td>
</tr>
<tr class="even">
<td>--</td>
<td>目前以上除 Rastogi A et al., 2017 之外全是<mark class="label warning">联合模型</mark></td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="dst论文对比-2"><table>
<colgroup>
<col style="width: 23%" />
<col style="width: 52%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">论文</th>
<th>解决的问题</th>
<th>局限性</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Heck et al., 2020</td>
<td><strong>1）</strong>使用 span-based 方法同时处理了 span-based slot 和 boolean slot；<strong>2）初步处理了共指解析问题</strong>；</td>
<td><strong>1）</strong>需要枚举 (domian, slot)，并且相比于 TRADE/DS-DST，参数量更大；<strong>2）</strong>使用了两种内存记忆实现共指解析，但是感觉只使用一种也可以做到；<strong>3）</strong>并没有处理 pick-list slot；</td>
</tr>
<tr class="even">
<td style="text-align: center;">Zhang et al., 2019</td>
<td><strong>1）</strong>使用 (domian, slot, value) 三元组；<strong>2）</strong>使用 Ptr，槽值不再预定义与本体中；<strong>3）结合 picklist-based 和 span-based 方法</strong>；</td>
<td><strong>1）</strong>需要枚举 (domian, slot)；<strong>2）</strong>需要人工定义哪个槽位是 picklist-based，哪个是 span-based。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Wu, Chien-Sheng et al., 2019</td>
<td><strong>1）使用 (domian, slot, value) 的三元组形式，只需要枚举 (domain, slot) 即可</strong>；<strong>2）</strong>三元组中的槽值不再预定义在本体之中，而是使用 Ptr 直接在用户的语句中抽取出来；<strong>3）能够处理未见或低频的槽位（zero-shot）。</strong></td>
<td><strong>1）</strong>每一轮都需要枚举 (domian, slot)；<strong>2）</strong>可能会生成错误格式的字符串；<strong>3）</strong>有些槽位并不需要直接生成，直接选取槽值即可（例如“是否”问题）；<strong>4）</strong>没有利用领域和槽位之间的联系。</td>
</tr>
<tr class="even">
<td style="text-align: center;">Zhong et al. 2018</td>
<td><strong>1）使用 global-locally self-attn 机制处理低频槽值对不好追踪的问题</strong>。</td>
<td><strong>1）</strong>对于局部编码器来说，每一个槽位都需要一个模型，这很麻烦；<em>2）要遍历所有的槽值对</em>。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Rastogi A et al., 2017.12</td>
<td><strong>1）</strong>不再需要枚举槽值对，转而使用一个有限的候选集（一般只有 7 个）；<strong>2）</strong>不再需要人工构建的词表，但需要 SLU 模块；<strong>3）提取特征的 GRU 实现领域内参数共享，所以可以进行迁移学习，能够迁移到新领域之中（这里应该知识简单的贡献 GRU 的隐藏状态而已）</strong>。</td>
<td><em>1）还是需要遍历有限的槽值对</em>；<strong>2）</strong>需要使用 SLU 模块进行 delexicalisation，所以实际上它是使用两个独立模型进行训练的；<em>3）不同的槽位需要不同的参数，没有做到槽位之间也贡献参数</em>。</td>
</tr>
<tr class="even">
<td style="text-align: center;">Mrkšić N et al., 2016</td>
<td><strong>1）</strong>利用词向量来进行语义匹配，省去了人工构建的词汇表；<strong>2）</strong>只需要训练一个模型就可以完成 DST 过程。</td>
<td><em>1）DST 模型需要遍历所有槽值对组合，但是有时候用户的语句所对应的槽值对可能并没有出现在训练集中</em>；<em>2）槽值对可能有时无法枚举</em>；<em>3）很难迁移到一个新的领域</em>。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Zilka and Jurcicek, 2015</td>
<td><strong>1）</strong>结合了 ASR 的置信度分数；<strong>2）将槽值的生成转为多分类问题（其中每个槽位都有一个独立的函数去生成槽值的分布）</strong>；<strong>3）</strong>使用特殊处理，缓解低频词的问题，这使得无需使用人工构建的词表（抽象化）。</td>
<td><em>1）还是需要遍历槽位，并为每一个都设计一个分类函数</em>；<strong>2）</strong>太过于简化模型，在现实中应该无法适用。</td>
</tr>
<tr class="even">
<td style="text-align: center;">Henderson et al., 2014d</td>
<td><strong>1）</strong>使用 ASR 的结果作为 DST 的输入，而不是使用 SLU 的结果，减去了来自 SLU 潜在的信息误差；<strong>2）</strong>使用 delexicalisation 特征工程（这步还是需要一个词汇表来做替换），提高模型的泛化性，有助于模型能够处理未见或低频的对话状态；<strong>3）使用 n-grams 特征，而不是 ASR 直接的输出（此效果暂不明）</strong>。</td>
<td><strong>1）</strong>需要为每个槽位都训练一个模型，在确定<strong>槽值</strong>是否出现在语句中时，需要遍历所有<strong>槽位</strong>的模型；<em>2）还是需要人工构建的词汇表</em>。</td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span style="display:block; width:9em"></td>
<td>粗体代表不错的想法</td>
<td>斜体代表在以后的论文中此缺点大致已被解决</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="dst论文对比-3"><table>
<colgroup>
<col style="width: 42%" />
<col style="width: 31%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="header">
<th>更新时间</th>
<th>介绍</th>
<th>难点</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2020.3.29</td>
<td>对当下难点的尝试</td>
<td><strong>槽值</strong>：<strong>1）</strong>使用 Ptr 直接生成槽值</td>
</tr>
<tr class="even">
<td>2020.3.29</td>
<td>过渡的技术</td>
<td>摒弃人工构建的词表：<strong>1）</strong>Zilka and Jurcicek (2015) 对低频槽值抽象化（比如对于低频槽值“jamaican”，可以将其替换为“#food1”），使得可以脱离词表；<strong>2）</strong>此后的技术大都使用<strong>词向量的技术</strong>脱离词表的束缚。</td>
</tr>
<tr class="odd">
<td>2020.3.28</td>
<td>传统难题的解决</td>
<td><strong>1）</strong>Henderson et al., 2014d 使用 ASR 的结果作为 DST 的输入，而不是使用 SLU；<strong>2）</strong>Zilka and Jurcicek (2015) 结合了 ASR 的置信度分数；<strong>3）</strong>Henderson et al., 2014d 提出 delexicalisation 技术（这需要词表）。</td>
</tr>
<tr class="even">
<td>--</td>
<td><span style="display:block; width:5em"></td>
<td>此处只记录突破性的思想</td>
</tr>
</tbody>
</table></div><div class="tab-pane" id="dst论文对比-4"><p><a class="btn" href="#dst-dstc2"><i class="fa fa-"></i>DSTC2</a> <a class="btn" href="#dst-woz2.0"><i class="fa fa-"></i>WOZ 2.0</a> <a class="btn" href="#dst-multiwoz2.1"><i class="fa fa-"></i>MultiWOZ 2.1</a></p></div></div></div>
<p>对话状态追踪（Dialogue State Tracking，DST）是 TODS 中一个重要的模块，同时它也是对话管理（Dialog Manager，DM）模块中的一部分，另一部分为对话策略学习（Dialog Policy Learning，DPL）。下面将简单地介绍 DST 的两种实现方式，具体的论文可参考上方提供的各个 Tab，或者参考其他的 task-oriented dialog system 综述。然后对 DST 任务中目前具有的各项挑战做一个总结。最后给出近年（到 2019 年为止）的相关工作。</p>
<h2 id="独立模型与联合模型">独立模型与联合模型</h2>
<p>DST 的工作是处理人机对话过程中的各种信息，并将其记录下来，简单来说也是一个 CRUD（增删改查） 的活。</p>
<p>传统的做法是：接收 SLU 模块的输出，从而生成当前的对话状态。这类模型被称为<strong>独立模型</strong>。但是这种做法会导致信息误差的层级传播，这是因为 ASR 以及 SLU 模块都可能会存在信息误差。这些误差会被携带进 DST 模块，最后再一次地被 DST 扩大。</p>
<p>2014 年左右开始，有研究工作开始采用<strong>联合模型</strong>，直接将 ASR 识别出的用户语句作为 DST 的输入，不再是 SLU 模块输出的语义表征。该模型同时执行了语音理解以及对话状态跟踪的功能，对于此方法而言，SLU 模块在名义上已经不再存在。</p>
<div class="tabs" id="两种dst模型对比"><ul class="nav-tabs"><li class="tab"><a href="#两种dst模型对比-1">独立模型</a></li><li class="tab"><a href="#两种dst模型对比-2">联合模型</a></li></ul><div class="tab-content"><div class="tab-pane" id="两种dst模型对比-1"><ol type="1">
<li>结合<em>从 SLU 模块提取出的语义</em>去估计当前的对话状态。（论文 07-14）[<a href="https://arxiv.org/pdf/1905.08743.pdf" target="_blank" rel="noopener">3</a>]</li>
</ol>
<blockquote>
<p>传统的 TODS pipeline 使用 SLU decoder 来检测在 ASR 输出中所表达的槽值对。然后下游 DST 模型将这些信息与过去的对话上下文结合起来更新 belief state。</p>
<p>在 DSTC 挑战中，一些系统使用<strong>基于模板</strong>的匹配系统（如 <a href="https://www.isca-speech.org/archive/archive_papers/icslp_1994/i94_0083.pdf" target="_blank" rel="noopener" title="Extracting Information in Spontaneous Speech">Phoenix</a>）的输出。然而还有许多更精确的<strong>统计 SLU 系统</strong>可用。</p>
<ol type="1">
<li>许多辨别式 SLU 训练独立的<strong>二元模型</strong>，以此决定每个槽值对是否出现在用户话语中（<a href="https://www.researchgate.net/publication/220735369_Spoken_language_understanding_from_unaligned_data_using_discriminative_classification_models" target="_blank" rel="noopener">Mairesse et al., 2009</a>）。这项工作后来将重点转移到对 ASR 输出的处理上（<a href="http://svr-ftp.eng.cam.ac.uk/~sjy/papers/hgtt12.pdf" target="_blank" rel="noopener">Henderson et al., 2012</a>;<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.702.3627&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Tur et al., 2013</a>）。</li>
<li>SLU 也被视为<strong>序列标注</strong>的问题，句中的每个字都根据用户的意图贴上标签，可以使用标准的标记模型，如 CRFs 或 RNN（07-16 论文）。</li>
<li>另外的方法受语义解析的启发，采用更复杂的建模结构（14 论文）。</li>
</ol>
<p>这些方法有一个<strong>共同的缺点</strong>：资源需求。要么是因为它们需要为每个槽值对学习独立的参数，要么是因为它们需要在单词级别上进行精细的人工标注。这阻碍了其扩展到更大、更现实的应用程序上 [<a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener" title="Neural Belief Tracker: Data-Driven Dialogue State Tracking">2</a>]。</p>
</blockquote></div><div class="tab-pane" id="两种dst模型对比-2"><ol start="2" type="1">
<li>或者与 SLU 模块联合学习（论文 14-17）[<a href="https://arxiv.xilesou.top/pdf/1905.08743.pdf" target="_blank" rel="noopener">3</a>]</li>
</ol>
<blockquote>
<p>研究发现，以 ASR 预测为输入，以信念状态的产生为输出。联合 SLU 和 DST，有利于两个模型的推理。</p>
<p>联合模型通常依赖一种 delexicalisation 策略，即将句子中出现的槽位/槽值替换为通用的标签。替换完毕之后可以使用 n-gram 提取特征，比如 <code>[want &lt;value&gt; food]</code>，<code>[want Chinese &lt;slot&gt;]</code> 等。为了执行 DST，这个模型需要遍历所有的槽值对，提取特征，并进行二元决策。</p>
<p><strong>Delexicalisation 引入了一个很少被讨论的隐藏依赖关系：我们如何识别文本中提到的槽位/槽值？</strong>对于不是很正式的领域，可以手动构建词表，枚举所有可能的表达。如 <a href="https://arxiv.xilesou.top/pdf/1603.00892.pdf" target="_blank" rel="noopener" title="Counter-fitting Word Vectors to Linguistic Constraints">Mrkšić N et al., 2016</a> 所示，使用此类词典对于当前基于 delexicalisation 的模型的性能至关重要。<strong>不过，这也不能扩展到丰富多样的用户语言或者通用领域</strong> [<a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener" title="Neural Belief Tracker: Data-Driven Dialogue State Tracking">2</a>]。</p>
</blockquote></div></div></div>
<h2 id="难点未来的工作-1">难点/未来的工作</h2>
<p>当前 DST 模型还有许多问题亟待解决，在《相关工作》一节中罗列了数篇论文。遗憾的是，它们大都是在解决“可扩展性”中“变化的槽值”这一难题。下面将列出目前已知的几类难点：</p>
<ul>
<li>可扩展性 [<a href="https://zhuanlan.zhihu.com/p/100843827" target="_blank" rel="noopener" title="任务导向型对话系统——对话管理模型研究最新进展">1</a>]
<ul>
<li>变化的槽位：槽值对的表征不够灵活，目前的做法是将槽位预定义在本体之中，其拥有对应的槽值。但是如果有些槽位是未见过的或者低频的，那么系统将无法处理。<em>注：大约在 2019 年开始已经有工作（TRADE）开始在处理这一问题，但是本文暂且不涉及此类问题。</em></li>
<li>变化的槽值：无法表示无限的或者动态的值，即有些槽值不可枚举，例如日期、地点。</li>
<li>新增的意图：随着系统的更新迭代，有可能会新增意图，这样就必须重新训练模型。</li>
<li>变化的<strong>系统</strong>动作（action）：注意，用户的意图+槽值对也是 action，即 user act，而这里所阐述的是 system act。例如在手机销售的场景下，系统原本只有提供产品信息的动作。但是假设一个用户询问“如何升级手机系统？”[<a href="https://zhuanlan.zhihu.com/p/100843827" target="_blank" rel="noopener" title="任务导向型对话系统——对话管理模型研究最新进展">1</a>]，系统必定无法告知用户操作方法，因为系统不具有提供手机系统升级步骤的动作。</li>
<li>多领域 DST：略</li>
</ul></li>
<li>数据稀缺：DST 模型需要标签数据。数据的稀缺对于创建一个新领域的模型有着巨大的挑战。</li>
<li>计算复杂度高</li>
</ul>
<h2 id="相关工作-1">相关工作</h2>
<p>早年（最初-2014 年左右），由于深度学习以及基于深度学习的自然语言处理技术才刚开始起步，并没有词向量作为支撑，大多数模型都需要采用一个<strong>人工构建的词汇表</strong>，这是一个相当费时费力的工作。由于近几年的工作已经抛弃这一做法，所以可能有部分人都无法理解这个词汇表到底代表什么意思。接下来本文将举例介绍一下它。简单来说，它其实就是一个同义词表。</p>
<p>例如某人告知系统，心仪的餐厅位置是“the center of town”，直观来说模型可以提取出槽值对“area=center”，但是对于值“center”，它还有其他的变体词汇，如 [center, downtown, central, city centre, midtown, town centre...] [<a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener" title="Neural Belief Tracker: Data-Driven Dialogue State Tracking">2</a>]。这就使得模型很难提取出确切的词汇，因此如上所述，系统需要维护一个人工构建的词汇表，将所有的同义词都替换为同一个单词。</p>
<h3 id="传统模型">传统模型</h3>
<p>传统 DST 模型的做法大都结合 SLU 模块。一般的做法是：使用从 SLU 模块提取出的语义信息，例如意图以及槽值对，去估计当前的对话状态。 <blockquote class="blockquote-center">
<i class="fa fa-quote-left"></i>
<p>传统 DST 模型具有如下几项缺点：<strong>1）</strong>依赖人工制作的特征；<strong>2）</strong>需要复杂的特定于领域的词汇表（本体除外）；<strong>3）</strong>很难扩展以及灵活调整到新的领域 [<a href="https://arxiv.xilesou.top/pdf/1905.08743.pdf" target="_blank" rel="noopener" title="Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems">3</a>]；<strong>4）</strong>需要显式语义表征以及在 SLU 阶段可能存在信息误差 [<a href="https://www.aclweb.org/anthology/W14-4340.pdf" target="_blank" rel="noopener" title="Word-Based Dialog State Tracking with Recurrent Neural Networks">5</a>]，这些误差将传播到 DST 模型上，使得误差累积；<strong>5）</strong>并未解决上述 DST 模型所拥有的难点。</p>

<i class="fa fa-quote-right"></i>
</blockquote></p>
<p>由于时代过于久远，本节不做深度展开。</p>
<h3 id="可扩展性">可扩展性</h3>
<p>近年（<strong>2014 年左右</strong>起）的工作试图<strong>1）</strong>摒弃复杂、高人力成本且难以维护的词汇表；<strong>2）</strong>直接从用户的语句中提取对话状态而不是从 SLU 的输出中。具体做法是使用词向量去匹配用户语句与槽值对之间的关系，例如对于单词“centre”和“center”都是“中心”的意思，虽然它们在单词的形态上不同，但是在词向量空间中的距离却很接近。这避免了显式语义表征的需要以及在 SLU 阶段可能的信息误差 [<a href="https://www.aclweb.org/anthology/W14-4340.pdf" target="_blank" rel="noopener">5</a>]。不过这些工作大都是在单领域之中。<strong>2018 年开始，渐渐地有人开始考虑多领域 DST 的问题。</strong></p>
<p>根据《<a href="#难点未来的工作-1">难点/未来的工作</a>》章节提出的几条难点，以下，我们将分析几篇试图解决对应难点的论文。此外，由于槽值受到大家的广泛关注，我们将其分为单领域 DST 以及多领域 DST。由于其余的难题并未受到过多的关注，本文暂不对其进行总结。</p>
<p><em>文章写毕之后更新（2020.10.05）：以下的绝大多数论文都只在解决“变化的槽值”问题。</em></p>
<h4 id="单领域dst">单领域DST</h4>
<ol type="1">
<li><a href="https://www.aclweb.org/anthology/W14-4340.pdf" target="_blank" rel="noopener"><span class="citation" data-cites="henderson2014word">(Henderson, Thomson, and Young 2014)</span></a> 使用 RNN 试图直接使用 ASR 的结果作为 DST 输入，这避免了<strong>显式语义表征的需要</strong>以及在 SLU 阶段<strong>潜在的信息误差</strong>。并且继续沿用作者同年发表的论文中的方法——使用 <strong>delexicalised features</strong>，但是该方法有一个弊端，需要使用一个人工构建的词汇表。比如说对于“i want chinese food”可以被替换为“<code>i want &lt;value&gt; &lt;slot&gt;</code>”，这样可以提升模型的泛化性，使得模型能够<strong>处理未见或低频的对话状态</strong>。但是该模型的<strong>缺点</strong>是需要为每一个槽位都训练一个模型，而后遍历所有槽位的模型，以此确定某槽值是否与用户的语句有关联。此外该论文还从用户语句和对话状态中提取出了 n-grams 特征。<strong>最后由于此论文发表的时间尚早，人工构建词汇表的问题并没有得到解决。</strong></li>
<li><a href="https://arxiv.org/pdf/1507.03471.pdf" target="_blank" rel="noopener"><span class="citation" data-cites="zilka2015incremental">(Zilka and Jurcicek 2015)</span></a> 在输入用户语句时还结合了 ASR 的置信度分数，并且将生成对话状态中的槽值转为了多分类问题，<strong>不再需要人工构建的词表。</strong></li>
<li><a href="https://www.aclweb.org/anthology/P17-1163/" target="_blank" rel="noopener"><span class="citation" data-cites="mrkvsic2016neural">(Mrkšić et al. 2016)</span></a> 提出了 Neural Belief Tracker（<strong>NBT</strong>），使用分布式表征表达的语义信息解决<strong>一义多词</strong>的问题。借助词向量的优势，可以使得回答“center”的语句也能匹配槽值对 (area=central)，这得以<strong>摆脱人工构建词表的束缚</strong>。由于该论文的做法是迭代所有预定义好的槽值对去和历史对话做匹配，故有一定缺陷。因为槽值对的组合无穷无尽，即使有穷，也会拥有大量的组合（这也导致<strong>参数在槽位之间无法共享</strong> [<a href="https://arxiv.org/pdf/1905.08743.pdf" target="_blank" rel="noopener" title="Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems">3</a>]），并且这种枚举的做法也无法处理从未见过的槽值。此外它<strong>还缺少一些扩展性</strong>，它的信念状态（belief state）更新机制在其他领域需要进行大量修改，所以无法跨领域<em>（这已经有人在解决了，详见论文 <a href="https://arxiv.xilesou.top/pdf/1805.11350.pdf" target="_blank" rel="noopener">Fully Statistical Neural Belief Tracking</a>）</em>。</li>
<li><a href="http://aclweb.org/anthology/P18-1135" target="_blank" rel="noopener"><span class="citation" data-cites="zhong2018global">(Zhong, Xiong, and Socher 2018)</span></a> 使用 global-locally 自注意力机制改进了<strong>对低频槽值对的追踪</strong>。具体做法是，每一个槽位拥有一个局部编码器，编码用户的输入。除此之外，所有的槽位还共享同一个全局编码器，这意味着该编码器的参数被所有槽位共享。状态追踪的思想还是与 NBT 类似，将其分解为一个个的二元分类问题，即遍历所有槽值对组合，判断此槽值对是否在用户语句中被提及。它的缺点也与 NBT 类似，需要遍历所有的槽值对。此外它的另一个缺陷是需要每个槽位创建一个局部编码器，这很麻烦。</li>
<li><em>另一方面，<a href="https://arxiv.org/pdf/1810.09587.pdf" target="_blank" rel="noopener">Ren et al. (2018)</a> 提出了 StateNet，它可以<strong>生成对话历史的表征</strong>并且作者<strong>与候选集中的槽值向量比对了距离</strong>。</em></li>
<li><a href="https://www.aclweb.org/anthology/P18-1134/" target="_blank" rel="noopener"><span class="citation" data-cites="xu-hu-2018-end">(Xu and Hu 2018)</span></a> 将 <strong>index-based Pointer Network</strong> 用于不同的槽位，展示了<strong>指向未知槽值的能力</strong>。然而，许多模型都需要一个预定义的领域本体，并且模型<strong>只在单领域的设置（DSTC2）上进行评估</strong>。</li>
<li><em><a href="https://arxiv.org/abs/1812.00899" target="_blank" rel="noopener">Nouri and Hosseini-Asl (2018)</a> 对 GLAD 改进，去除了局部编码器及其 self-attention 机制。</em></li>
</ol>
<h4 id="多领域dst">多领域DST</h4>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1712.10224.pdf" target="_blank" rel="noopener"><span class="citation" data-cites="rastogi2017scalable">(Rastogi, Hakkani-Tür, and Heck 2017)</span></a> <strong>1）</strong>提出一个多领域模型，它使用两层的 Bi-GRU。虽然该方法不再需要枚举所有的槽值对组合，而是转用一个候选集（因为某些槽位不可能出现在用户语句中，在预测时并不需要它），但它需要依赖 delexicalisation 来提取特征；<strong>2）</strong>由于该方法利用 SLU 模块提取槽值，进而将此槽值替换成一个特殊的符号，因此<strong>它不算是一个联合模型</strong>；<strong>3）</strong>另外它还是不可避免地需要遍历所有的槽位。对于槽值，由于有候选集，所以只需要枚举槽值即可；<strong>4）</strong>最后评分函数中的参数，每个槽位都有特定的一组，但是 GRU 中的参数都是为一整个领域定义的，因此它可以轻松地被迁移到新的领域之中。</li>
<li>无论是传统模型，还是近年使用的深度学习模型，都不可避免地需要使用本体，其定义了槽值对。<a href="https://arxiv.org/pdf/1905.08743.pdf" target="_blank" rel="noopener" title="Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems"><span class="citation" data-cites="wu2019transferable">(Wu et al. 2019)</span></a> 认为一个完整的本体很难获取，即使存在这么一个本体，槽值对的数量也会极其的庞大。此外，由于 <span class="citation" data-cites="budzianowski2018multiwoz">(Budzianowski et al. 2018)</span> 提出了多领域对话数据集 MultiWOZ，将 DST 迁移到多领域内势在必行。<span class="citation" data-cites="wu2019transferable">(Wu et al. 2019)</span><strong>1）</strong>提出将原先的 (slot, value) 二元组修改为 (domain, slot, value) 的三元组形式，并且槽值不再预定义于本体之中，而是使用 Pointer Network 直接从用户的语句中提取而出；<strong>2）</strong>另外他们强调要共享知识，因为一个槽位可能会出现在多个领域之内；<strong>3）</strong>zero-shot。</li>
<li><a href="https://arxiv.org/pdf/1910.03544.pdf" target="_blank" rel="noopener"><span class="citation" data-cites="zhang2019find">(Zhang et al. 2019)</span></a> 认为当前基于神经网络的对话系统大致可以分为两类：<strong>1）</strong>picklist-based；<strong>2）</strong>span-based。picklist-based 讲究从预定义的槽值中选取最可能的值，span-based 讲究使用 Ptr 直接从用户语句中生成槽值，它由 <a href="https://www.aclweb.org/anthology/P18-1134/" target="_blank" rel="noopener"><span class="citation" data-cites="xu-hu-2018-end">(Xu and Hu 2018)</span></a> 首次提出。作者认为二者各有优缺点，picklist-based 方法太麻烦，而 span-based 方法中，由于用户语言的多样性，有些槽值并不会出现在上下文中（如，回答有关“是否”的问题，它拥有一个包含两个元素的 picklist 就可以解决，不需要 Ptr 生成）。所以作者将二者结合起来，提出了 DS-DST。<br />
由于模型中会出现多个句子或者符号，比如说对于 picklist-based 方法，一个 picklist 中有多个槽值，那么该怎么处理它们？作者直接用了<strong>拼接</strong>的方式。用户的多轮对话语句，域槽对都是使用此方法。</li>
<li><span class="citation" data-cites="heck2020trippy">(Heck et al. 2020)</span> 提出 TripPy，其包含三种拷贝机制，即<strong>1）</strong>Ptr；<strong>2）</strong>from System Inform Memory（SIM）；<strong>3）</strong>from Dialog State Memory（DSM）。TripPy 主要通过一个 Slot Gate 判断使用哪种拷贝机制，与 TRADE 等模型类似。具体来讲，模型的运行流程为：使用 BERT 对上下文建模，然后将 BERT 的特殊符号 <span class="math inline">\([CLS]\)</span> 输入 Slot Gate 进行五元分类，即 <span class="math inline">\(\{none, dontcare, span, inform, refer\}\)</span>，然后执行对应的拷贝机制。以下将介绍三种机制的具体实现。 <mark class="label danger">但是没说怎么追踪 system inform，猜测是生成自 DPL。</mark><br />
<strong>1）</strong>Ptr 为 span-based 方法，即从用户的语句中直接提取槽值，具体公式略，可参考原文。此外，对于特殊的 Boolean Slot，他们的做法与 DS-DST 类似，DS-DST 采用 picklist-based 方法，而 TripPy 将 Slot Gate 改为四元分类，即 <span class="math inline">\(\{none, dontcare, true, false\}\)</span>。<strong>2）</strong>SIM 记录被系统提及到的槽值，如果用户引用了它，则直接从 SIM 中拷贝，而不使用 Ptr（例，“<font color='red'>xx酒店</font>不错”；“那就<font color='red'>它</font>了”）。<strong>3）</strong>DSM 用于共指解析（个人认为，SIM 也算共指解析）。假设槽位 A 的槽值已在上文中被提及，如果槽位 B 在当前轮被触发，且槽值与槽位 A 相同，那么直接引用槽位 A 的槽值，而不使用 Ptr（例，订餐的酒店地址和用餐后打的的乘车地址）。</li>
</ol>
<h3 id="计算复杂度高">计算复杂度高</h3>
<p><span class="citation" data-cites="Ren_2019">(Ren, Ni, and McAuley 2019)</span> 认为以往的 DST 模型依赖一个预定义的本体，其包含一系列的潜在的槽值对。这些模型在单领域上已经取得了不错的性能，但是它们都一直遭受着计算复杂度的问题。这个问题在多领域中将更为严重，因为多领域中的槽值对是单领域的数倍之多。<span class="citation" data-cites="Ren_2019">(Ren, Ni, and McAuley 2019)</span>提出以往算法的推理时间复杂度（Inference Time Complexity，<strong>ITC</strong>）为 <span class="math inline">\(O(mn)\)</span> 或 <span class="math inline">\(O(n)\)</span>，他们提出的模型则是 <span class="math inline">\(O(1)\)</span>。<strong>为了解决以上的问题</strong>，他们提出了 <strong>COMER</strong> 模型，抛弃了传统的模型架构，即将槽值的识别或者生成视为一个二元分类问题，而是转用了 seqseq 模型。</p>
<h2 id="论文笔记-1">论文笔记</h2>
<p>详见 <a href="https://yan624.github.io/posts/89f2cf08.html">DST论文笔记（？-2019）</a>。</p>
<h2 id="引用-1">引用</h2>
<ol type="1">
<li><a href="https://zhuanlan.zhihu.com/p/100843827" target="_blank" rel="noopener">任务导向型对话系统——对话管理模型研究最新进展</a></li>
<li><a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a></li>
<li><a href="https://arxiv.xilesou.top/pdf/1905.08743.pdf" target="_blank" rel="noopener">Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</a></li>
<li><a href="https://www.cnblogs.com/jiangxinyang/p/10794364.html" target="_blank" rel="noopener">任务型对话（二）—— DST（对话状态追踪）</a></li>
<li><a href="https://www.aclweb.org/anthology/W14-4340.pdf" target="_blank" rel="noopener">Word-Based Dialog State Tracking with Recurrent Neural Networks</a></li>
<li><a href="https://blog.csdn.net/weixin_44385551/article/details/103180371" target="_blank" rel="noopener">多领域多轮问答调研报告 3</a>：也是一个综述文章。</li>
<li>文中已给出的论文链接</li>
</ol>
<h1 id="结果对比">结果对比</h1>
<h2 id="slu模块结果对比">SLU模块结果对比</h2>
<div id="slu-atis" style="width: 100%;height: 350px;margin: 0 auto"></div>
<script src="https://cdn.bootcdn.net/ajax/libs/echarts/5.0.0-alpha.2/echarts.common.min.js"></script>
<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('slu-atis'));
        // 指定图表的配置项和数据
        var option = {
	title: {text: 'ATIS 结果对比'},
	tooltip: {trigger: 'axis', axisPointer: {type: 'shadow'}},
	legend: {
		type: 'scroll',
		data: ['Zhang et al.', 'Chen et al.', 'Wang et al.', 'Li et al.', 'Liu and Lane, 2016a', 'Zhu and Yu', 'Zhang and Wang'],
		top: 25,
	},
	toolbox: {
		orient: 'vertical',
		left: 'right',
		top: 'center',
		feature: {
			dataView: {show: true},
			magicType: {show: true, type: ['bar', 'tiled']},
			restore: {show: true},
			saveAsImage: {show: true, pixelRatio: 2}
		}
	},
	xAxis: {type: 'category', name: '<--年份--', nameLocation: 'middle', data: ['Slot(F1)', 'Intent(Acc)']},
	yAxis: {
		type: 'value',
		min: function (value) {
			_min = value.min - 20;
			if(_min < 0) return 0;
			else return Math.floor(_min);
		},
		max: 100
	},
	series: [{
			name: 'Zhang et al.',
			type: 'bar',
			data: [98.75, 99.76],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'BERT-SLU',}
			},
		},{
			name: 'Chen et al.',
			type: 'bar',
			data: [96, 97.9],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'BERT + CRF', offset: [0, 20]}
			},
		},{
			name: 'Wang et al.',
			type: 'bar',
			data: [96.89, 98.99],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'with dec', }
			},
		},{
			name: 'Li et al.',
			type: 'bar',
			data: [96.52, 98.77],
		},{
			name: 'Liu and Lane, 2016a',
			type: 'bar',
			data: [95.98, 98.21],
		},{
			name: 'Zhu and Yu',
			type: 'bar',
			data: [95.79],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'focus', }
			},
		},{
			name: 'Zhang and Wang',
			type: 'bar',
			data: [95.49, 98.1],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'W', }
			},
		},]
};
        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>
<h2 id="dst模块结果对比">DST模块结果对比</h2>
<div id="dst-dstc2" style="width: 100%;height: 350px;margin: 0 auto"></div>
<script src="https://cdn.bootcdn.net/ajax/libs/echarts/5.0.0-alpha.2/echarts.common.min.js"></script>
<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('dst-dstc2'));
        // 指定图表的配置项和数据
        var option = {
	title: {text: 'DSTC2 结果对比'},
	tooltip: {trigger: 'axis', axisPointer: {type: 'shadow'}},
	legend: {
		type: 'scroll',
		data: ['GLAD', 'Rastogi A et al.', 'Mrkšić N et al.', 'LecTrack', 'Henderson et al., 2014d'],
		top: 25,
	},
	toolbox: {
		orient: 'vertical',
		left: 'right',
		top: 'center',
		feature: {
			dataView: {show: true},
			magicType: {show: true, type: ['bar', 'tiled']},
			restore: {show: true},
			saveAsImage: {show: true, pixelRatio: 2}
		}
	},
    xAxis: {type: 'category', name: '<--年份--', nameLocation: 'middle', data: ['Goals', 'Requests']},
    yAxis: {
    	type: 'value',
		min: function (value) {
			_min = value.min - 20;
			if(_min < 0) return 0;
			else return Math.floor(_min);
		},
    	max: 100
    },
    series: [
		{name: 'GLAD', type: 'bar', data: [74.5, 97.5],},
		{
            name: 'Rastogi A et al.',
            type: 'bar',
            data: [70.3],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'shared', }
			},
        },{ 
            name: 'Mrkšić N et al.',
            type: 'bar',
            data: [72.6, 96.4],
			label: {
				normal: { show: true, textBorderColor: 'black', formatter:'NBT-DNN', offset: [0, 30]
				}
			},
        },{
            name: 'Mrkšić N et al.',
            type: 'bar',
            data: [73.4, 96.5],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'NBT-CNN'}
			},
        },{
            name: 'LecTrack',
            type: 'bar',
            data: [72, 97],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'model avg', offset: [0, 15]}
			},
        },{
            name: 'Henderson et al., 2014d',
            type: 'bar',
            data: [76.8, 97.8],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'include h',}
			},
        }]
};
        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>
<div id="dst-woz2.0" style="width: 100%;height: 350px;margin: 0 auto"></div>
<script src="https://cdn.bootcdn.net/ajax/libs/echarts/5.0.0-alpha.2/echarts.common.min.js"></script>
<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('dst-woz2.0'));
        // 指定图表的配置项和数据
        var option = {
	title: {text: 'WOZ 2.0 结果对比'},
	tooltip: {trigger: 'axis', axisPointer: {type: 'shadow'}},
	legend: {
		type: 'scroll',
		data: ['TripPy', 'GLAD', 'Rastogi A et al.', 'Mrkšić N et al.'],
		top: 25,
	},
	toolbox: {
		orient: 'vertical',
		left: 'right',
		top: 'center',
		feature: {
			dataView: {show: true},
			magicType: {show: true, type: ['bar', 'tiled']},
			restore: {show: true},
			saveAsImage: {show: true, pixelRatio: 2}
		}
	},
    xAxis: {type: 'category', name: '<--年份--', nameLocation: 'middle', data: ['Goals/Joint Accuracy', 'Requests']},
    yAxis: {
		type: 'value',
		min: function (value) {
			_min = value.min - 20;
			if(_min < 0) return 0;
			else return Math.floor(_min);
		},
		max: 100
	},
    series: [
		{name: 'TripPy', type: 'bar', data: [92.7],},
		{name: 'GLAD', type: 'bar', data: [88.1, 97.1],},
		{ 
            name: 'Mrkšić N et al.',
            type: 'bar',
            data: [84.4, 91.2],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'NBT-DNN', offset: [0, 30]}
			},
        },{
            name: 'Mrkšić N et al.',
            type: 'bar',
            data: [84.2, 91.6],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'NBT-CNN'}
			},
        }]
};
        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>
<div id="dst-multiwoz2.1" style="width: 100%;height: 350px;margin: 0 auto"></div>
<script src="https://cdn.bootcdn.net/ajax/libs/echarts/5.0.0-alpha.2/echarts.common.min.js"></script>
<script type="text/javascript">
        // 基于准备好的dom，初始化echarts实例
        var myChart = echarts.init(document.getElementById('dst-multiwoz2.1'));
        // 指定图表的配置项和数据
        var option = {
	title: {text: 'MultiWOZ 2.1 结果对比'},
	tooltip: {trigger: 'axis', axisPointer: {type: 'shadow'}},
	legend: {
		type: 'scroll',
		data: ['TripPy', 'Zhang et al.', 'TRADE',],
		top: 25,
	},
	toolbox: {
		orient: 'vertical',
		left: 'right',
		top: 'center',
		feature: {
			dataView: {show: true},
			magicType: {show: true, type: ['bar', 'tiled']},
			restore: {show: true},
			saveAsImage: {show: true, pixelRatio: 2}
		}
	},
    xAxis: {type: 'category', name: '<--年份--', data: ['Goals/Joint Accuracy']},
    yAxis: {
		type: 'value',
		min: function (value) {
			_min = value.min - 20;
			if(_min < 0) return 0;
			else return Math.floor(_min);
		},
		max: 100
	},
    series: [
		{name: 'TripPy', type: 'bar', data: [55.29],},
		{ 
            name: 'Zhang et al.',
            type: 'bar',
            data: [53.3],
			label: {
				normal: {show: true, textBorderColor: 'black', formatter:'DST-Picklist', offset: [0, 10]}
			}
		},
		{name: 'TRADE', type: 'bar', data: [45.6],}
	]
};
        // 使用刚指定的配置项和数据显示图表。
        myChart.setOption(option);
</script>
<h1 id="名词">名词</h1>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 66%" />
</colgroup>
<thead>
<tr class="header">
<th>中文</th>
<th>对应的英文</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>槽位</td>
<td>slot</td>
</tr>
<tr class="even">
<td>槽值</td>
<td>value</td>
</tr>
<tr class="odd">
<td>槽值对</td>
<td>slot-value / slot value / slot value pair<br />
（有时为了简便，可能会直接称之为“槽值”，但是本文中如此称呼有歧义，所以几乎不会出现这种情况）</td>
</tr>
<tr class="even">
<td>意图</td>
<td>intent</td>
</tr>
<tr class="odd">
<td>域槽对</td>
<td>domain-slot pair</td>
</tr>
</tbody>
</table>
<script>
window.onload = function () {
    $('colgroup').remove()
    }
</script>
<h1 id="bibliography" class="unnumbered">参考文献</h1>
<div id="refs" class="references">
<div id="ref-budzianowski2018multiwoz">
<p>Budzianowski, Pawel, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić. 2018. “Multiwoz-a Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling.” <em>arXiv Preprint arXiv:1810.00278</em>.</p>
</div>
<div id="ref-heck2020trippy">
<p>Heck, Michael, Carel van Niekerk, Nurul Lubis, Christian Geishauser, Hsien-Chin Lin, Marco Moresi, and Milica Gašić. 2020. “TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking.”</p>
</div>
<div id="ref-henderson2014word">
<p>Henderson, Matthew, Blaise Thomson, and Steve Young. 2014. “Word-Based Dialog State Tracking with Recurrent Neural Networks.” In <em>Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (Sigdial)</em>, 292–99.</p>
</div>
<div id="ref-li2018self">
<p>Li, Changliang, Liang Li, and Ji Qi. 2018. “A Self-Attentive Model with Gate Mechanism for Spoken Language Understanding.” In <em>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, 3824–33.</p>
</div>
<div id="ref-liu2016attention">
<p>Liu, Bing, and Ian Lane. 2016. “Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling.” <em>arXiv Preprint arXiv:1609.01454</em>.</p>
</div>
<div id="ref-mesnil2014using">
<p>Mesnil, Grégoire, Yann Dauphin, Kaisheng Yao, Yoshua Bengio, Li Deng, Dilek Hakkani-Tur, Xiaodong He, et al. 2014. “Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding.” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 23 (3). IEEE: 530–39.</p>
</div>
<div id="ref-mrkvsic2016neural">
<p>Mrkšić, Nikola, Diarmuid O Séaghdha, Tsung-Hsien Wen, Blaise Thomson, and Steve Young. 2016. “Neural Belief Tracker: Data-Driven Dialogue State Tracking.” <em>arXiv Preprint arXiv:1606.03777</em>.</p>
</div>
<div id="ref-rastogi2017scalable">
<p>Rastogi, Abhinav, Dilek Hakkani-Tür, and Larry Heck. 2017. “Scalable Multi-Domain Dialogue State Tracking.” In <em>2017 Ieee Automatic Speech Recognition and Understanding Workshop (Asru)</em>, 561–68. IEEE.</p>
</div>
<div id="ref-Ren_2019">
<p>Ren, Liliang, Jianmo Ni, and Julian McAuley. 2019. “Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation.” <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>. Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/d19-1196" target="_blank" rel="noopener" class="uri">https://doi.org/10.18653/v1/d19-1196</a>.</p>
</div>
<div id="ref-wang2018bi">
<p>Wang, Yu, Yilin Shen, and Hongxia Jin. 2018. “A Bi-Model Based Rnn Semantic Frame Parsing Model for Intent Detection and Slot Filling.” <em>arXiv Preprint arXiv:1812.10235</em>.</p>
</div>
<div id="ref-wu2019transferable">
<p>Wu, Chien-Sheng, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, and Pascale Fung. 2019. “Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems.” <em>arXiv Preprint arXiv:1905.08743</em>.</p>
</div>
<div id="ref-xu-hu-2018-end">
<p>Xu, Puyang, and Qi Hu. 2018. “An End-to-End Approach for Handling Unknown Slot Values in Dialogue State Tracking.” In <em>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, 1448–57. Melbourne, Australia: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/P18-1134" target="_blank" rel="noopener" class="uri">https://doi.org/10.18653/v1/P18-1134</a>.</p>
</div>
<div id="ref-zhang2019find">
<p>Zhang, Jian-Guo, Kazuma Hashimoto, Chien-Sheng Wu, Yao Wan, Philip S Yu, Richard Socher, and Caiming Xiong. 2019. “Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking.” <em>arXiv Preprint arXiv:1910.03544</em>.</p>
</div>
<div id="ref-zhang2016joint">
<p>Zhang, Xiaodong, and Houfeng Wang. 2016. “A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding.” In <em>IJCAI</em>, 16:2993–9.</p>
</div>
<div id="ref-zhang2020recent">
<p>Zhang, Zheng, Ryuichi Takanobu, Qi Zhu, Minlie Huang, and Xiaoyan Zhu. 2020. “Recent Advances and Challenges in Task-Oriented Dialog Systems.” <em>Science China Technological Sciences</em>. Springer, 1–17.</p>
</div>
<div id="ref-zhong2018global">
<p>Zhong, Victor, Caiming Xiong, and Richard Socher. 2018. “Global-Locally Self-Attentive Dialogue State Tracker.” <em>arXiv Preprint arXiv:1805.09655</em>.</p>
</div>
<div id="ref-zhu2017encoder">
<p>Zhu, Su, and Kai Yu. 2017. “Encoder-Decoder with Focus-Mechanism for Sequence Labelling Based Spoken Language Understanding.” In <em>2017 Ieee International Conference on Acoustics, Speech and Signal Processing (Icassp)</em>, 5675–9. IEEE.</p>
</div>
<div id="ref-zilka2015incremental">
<p>Zilka, Lukas, and Filip Jurcicek. 2015. “Incremental Lstm-Based Dialog State Tracker.” In <em>2015 Ieee Workshop on Automatic Speech Recognition and Understanding (Asru)</em>, 757–62. IEEE.</p>
</div>
</div>
]]></content>
      <categories>
        <category>AI</category>
        <category>nlp</category>
      </categories>
      <tags>
        <tag>dialogue system</tag>
      </tags>
  </entry>
  <entry>
    <title>【算法设计题目】回溯法</title>
    <url>/posts/7f2adc4d.html</url>
    <content><![CDATA[<h1 id="总结">总结</h1>
<ol type="1">
<li>二维搜索
<ul>
<li>题 79 和 1219 是在二维上的回溯法，但是做法与普通的回溯法是一样的，只不过搜索路径变成了“上下左右”。</li>
<li>题 79 和 1219 相对来说比较简单，返回的分别是“是否合法”和“黄金的总量”，二者都不需要做额外的处理。对于后者来说也只需要在递归的同时进行累加即可。</li>
</ul></li>
<li>返回所有可能解：递归时返回部分解或者初始化一个全局列表保存所有可能解
<ul>
<li>题 131 要求返回“解的所有可能”，那么在递归的时候势必需要返回部分解，最后拼装成全部解。<strong>或者可以初始化一个全局的列表用于保存解，但是我没这么做过。</strong></li>
</ul></li>
<li>返回所有可能解中的<strong>最优解</strong>：初始化一个全局列表保存所有可能解
<ul>
<li>题 1593 符合。但是并不需要真的保存所有解，尝试完一种情况后，删除即可。这样可以节省空间。</li>
</ul></li>
<li>返回所有可能解中的<strong>任意解</strong>：初始化一个<code>exit</code>变量，当找到一个解时立即设置为<code>True</code>，并在其他的代码中加入判断，当且仅当<code>exit==False</code>时，程序才继续进行</li>
</ol>
<h1 id="算法思想">算法思想</h1>
<p>比较全的概念：<a href="https://leetcode-cn.com/tag/backtracking/" target="_blank" rel="noopener">leetcode 回溯法概念</a>。</p>
<p>大白话：世界上有许多只能执行穷举法的问题，并且事实上，这些问题解决办法中<strong>不存在除穷尽搜索之外的方法</strong>。如果问题满足以下的描述就可以使用回溯法：算法从根节点开始枚举所有的解，深度优先。如果当前节点（可以是叶节点，也可以是非叶节点）的解不满足条件，则“回溯”返回，尝试上一个节点的其他子节点，即其他的可能解。直到找到一个可行解，或者找到所有可行解。可以将回溯法的搜索空间想象成一棵 n 叉树。</p>
<p><strong>回溯法基本特征</strong>：</p>
<ol type="1">
<li>节点是用<strong>深度优先搜索</strong>的方法生成的；</li>
<li>不需要存储整棵搜索树（事实上，连树都没必要存储，只需要记录路径即可） <a id="more"></a></li>
</ol>
<h2 id="例子三着色问题">例子：三着色问题</h2>
<p>给定一个无向图 G=(V, E)，需要使用三种颜色之一为 G 的顶点着色，使得没有两个相邻顶点的颜色相同。</p>
<ol type="1">
<li>合法：没有两个相邻顶点的颜色相同；</li>
<li>非法：相邻顶点的颜色相同；</li>
<li>搜索树：一个 n 个顶点的无向图共有 <code>3^n</code> 种可能的着色，所有可能的着色集合可以用一棵完全三叉树表示，即搜索树；</li>
<li>部分：如果某时没有两个相邻顶点的颜色相同，但图的着色还未完成，称此时的解为部分解；</li>
<li>现节点：当前待判断该着色是否合法的节点；</li>
<li>死节点：当前节点的着色已经是非法的，则称此节点为死节点。</li>
</ol>
<h1 id="面试题08.09.-括号22.-括号生成">面试题08.09. 括号/22. 括号生成</h1>
<mark class="label warning">中等</mark>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">generateParenthesis</span><span class="params">(self, n: int)</span> -&gt; List[str]:</span></span><br><span class="line">        x = [<span class="number">-1</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(n * <span class="number">2</span>)]</span><br><span class="line">        x[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        result = []</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> x[i] &lt; <span class="number">1</span>:</span><br><span class="line">                x[i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> self.is_legal(x):</span><br><span class="line">                    result.append(self.transform(x))</span><br><span class="line">                <span class="keyword">elif</span> self.is_partial(x, n):</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            x[i] = <span class="number">-1</span></span><br><span class="line">            i -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_legal</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        1）x 中最后一位不是 -1 才代表此种组合可能合法；</span></span><br><span class="line"><span class="string">        2）约束函数的结果必须等于 0。（此方法无法保证括号是合法的，有部分组合可以使结果等于 0 也不合法，如“"()))(("”。</span></span><br><span class="line"><span class="string">        这些组合出现的前提条件是使 is_partial() 为 True，当然，它们组合根本无法通过该方法，所以我们把合法判定的范围缩减了。）</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> x[<span class="number">-1</span>] != <span class="number">-1</span> <span class="keyword">and</span> self.constraint(x) == <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_partial</span><span class="params">(self, x, n)</span>:</span> </span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        1）x 中最后一位是 -1 才代表此种组合可能为部分；</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">return</span> x[<span class="number">-1</span>] == <span class="number">-1</span> <span class="keyword">and</span> <span class="keyword">True</span> <span class="keyword">if</span> -n &lt;= self.constraint(x) &lt;= <span class="number">0</span> <span class="keyword">else</span> <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">constraint</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> x[::<span class="number">-1</span>]:</span><br><span class="line">            <span class="keyword">if</span> item == <span class="number">1</span>:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> item == <span class="number">0</span>:</span><br><span class="line">                count -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">pass</span> </span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        pattern = []</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> x:</span><br><span class="line">            <span class="keyword">if</span> item == <span class="number">0</span>:</span><br><span class="line">                pattern.append(<span class="string">'('</span>)</span><br><span class="line">            <span class="keyword">elif</span> item == <span class="number">1</span>:</span><br><span class="line">                pattern.append(<span class="string">')'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                pattern.append(<span class="string">'.'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(pattern)</span><br></pre></td></tr></table></figure>
<h1 id="电话号码的字母组合">17. 电话号码的字母组合</h1>
<p>分析：回溯法模版套进去就行了。<mark class="label warning">中等</mark> <figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCombinations</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">digits:</span> str)</span></span> -&gt; List[str]<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> len(digits) == <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        alpha_num_list = [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">        x = [-<span class="number">1</span> <span class="keyword">for</span> <span class="number">_</span> <span class="keyword">in</span> range(len(digits))]</span><br><span class="line">        res = []</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">while</span> x[i] &lt; alpha_num_list[int(digits[i]) - <span class="number">2</span>] - <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">                x[i] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">self</span>.is_legal(x)<span class="symbol">:</span></span><br><span class="line">                    res.append(<span class="keyword">self</span>.transform(x, alpha_num_list, digits))</span><br><span class="line">                elif <span class="keyword">self</span>.is_partial(x)<span class="symbol">:</span></span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            x[i] = -<span class="number">1</span></span><br><span class="line">            i -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">                </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_legal</span><span class="params">(<span class="keyword">self</span>, x)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> x[-<span class="number">1</span>] != -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_partial</span><span class="params">(<span class="keyword">self</span>, x)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> x[-<span class="number">1</span>] == -<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(<span class="keyword">self</span>, x, alpha_num_list, digits)</span></span><span class="symbol">:</span></span><br><span class="line">        res = []</span><br><span class="line">        a = <span class="number">97</span></span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> enumerate(x)<span class="symbol">:</span></span><br><span class="line">            a += sum(alpha_num_list[: int(digits[i]) - <span class="number">2</span>])</span><br><span class="line">            res.append(chr(a + item))</span><br><span class="line">            a = <span class="number">97</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(res)</span><br></pre></td></tr></table></figure></p>
<h1 id="单词搜索">79. 单词搜索</h1>
<p>这道题跟普通的回溯法不大一样，普通的回溯法套模板就有解了。但是对于这道，首先我想了一下，迭代回溯法比较难实现，所以选择了递归回溯法。<mark class="label warning">中等</mark></p>
<ol type="1">
<li>需要思考的是如何控制单词的移动？显然由于题设，单词只能与相邻的单词两两组合，所以有四个方向，即上下左右。</li>
<li>“合法”条件比较好判断，就是从矩阵中找到的单词与给定的单词 <code>word</code> 相等就算合法了。</li>
<li>“部分”条件也是类似的，只需要使得与给定单词 <code>word</code> 的前部匹配即可。</li>
<li>另外此题还有一个隐含的约束，就是矩阵中的单词只能被用一次，所以还需要一个记录单词是否被使用的矩阵。</li>
</ol>
<p>上述理清之后，就差不多有解了。 <figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment"># 上下左右</span></span><br><span class="line">        <span class="keyword">self</span>.directions = [(-<span class="number">1</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">self</span>.<span class="symbol">board:</span> list = None</span><br><span class="line">        <span class="keyword">self</span>.word = None</span><br><span class="line">        <span class="keyword">self</span>.rows = <span class="number">0</span></span><br><span class="line">        <span class="keyword">self</span>.columns = <span class="number">0</span></span><br><span class="line">        <span class="keyword">self</span>.<span class="symbol">board_tag:</span> list = None</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">exist</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">board:</span> List[List[str]], <span class="symbol">word:</span> str)</span></span> -&gt; <span class="symbol">bool:</span></span><br><span class="line">        <span class="keyword">self</span>.board = board</span><br><span class="line">        <span class="keyword">self</span>.word = word</span><br><span class="line">        <span class="keyword">self</span>.rows = len(board)</span><br><span class="line">        <span class="keyword">self</span>.columns = len(board[<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># 一个单词是否被使用过的标志</span></span><br><span class="line">        <span class="keyword">self</span>.board_tag = [[<span class="number">0</span> <span class="keyword">for</span> <span class="number">_</span> <span class="keyword">in</span> board[<span class="number">0</span>]] <span class="keyword">for</span> <span class="number">_</span> <span class="keyword">in</span> board]</span><br><span class="line">        <span class="comment"># 遍历所有可能的首字母</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="keyword">self</span>.rows)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="keyword">self</span>.columns)<span class="symbol">:</span></span><br><span class="line">                w = board[i][j]</span><br><span class="line">                <span class="comment"># 如果第一个单词不相等，就直接跳过这种可能</span></span><br><span class="line">                <span class="keyword">if</span> w != word[<span class="number">0</span>]<span class="symbol">:</span></span><br><span class="line">                    continue</span><br><span class="line">                <span class="comment"># 1）word 只有一个单词；2）递归求得正确解</span></span><br><span class="line">                <span class="keyword">if</span> w == word <span class="keyword">or</span> <span class="keyword">self</span>.rec(i, j, w)<span class="symbol">:</span></span><br><span class="line">                    <span class="keyword">return</span> True</span><br><span class="line">        <span class="keyword">return</span> False</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">rec</span><span class="params">(<span class="keyword">self</span>, i, j, w)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="comment"># 1 代表这个单词被用过了</span></span><br><span class="line">        <span class="keyword">self</span>.board_tag[i][j] = <span class="number">1</span></span><br><span class="line">        <span class="comment"># 遍历“上下左右”四个方位</span></span><br><span class="line">        <span class="keyword">for</span> vec, hor <span class="keyword">in</span> <span class="keyword">self</span>.<span class="symbol">directions:</span></span><br><span class="line">            new_i = i + vec</span><br><span class="line">            new_j = j + hor</span><br><span class="line">            <span class="comment"># 1）坐标必须满足一定条件，它不能小于 0，也不能越界；2）坐标所在位置的单词必须没有被使用过</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> (<span class="number">0</span> &lt;= new_i &lt; <span class="keyword">self</span>.rows <span class="keyword">and</span> <span class="number">0</span> &lt;= new_j &lt; <span class="keyword">self</span>.columns) <span class="keyword">or</span> <span class="keyword">self</span>.board_tag[new_i][new_j] == <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">                continue</span><br><span class="line">            new_w = w + <span class="keyword">self</span>.board[new_i][new_j]</span><br><span class="line">            <span class="comment"># 这一步合并了“合法”判断以及“部分”判断，拆开来写也可以，但是代码太长了</span></span><br><span class="line">            <span class="keyword">if</span> new_w == <span class="keyword">self</span>.word <span class="keyword">or</span> (new_w == <span class="keyword">self</span>.word[: len(new_w)] <span class="keyword">and</span> <span class="keyword">self</span>.rec(new_i, new_j, new_w))<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">return</span> True</span><br><span class="line">        <span class="comment"># 递归结束前要把用过的标记清除掉，因为退出递归后，该单词又是出于可用状态</span></span><br><span class="line">        <span class="keyword">self</span>.board_tag[i][j] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> False</span><br></pre></td></tr></table></figure></p>
<h1 id="分割回文串">131. 分割回文串</h1>
<mark class="label warning">中等</mark>
<h2 id="解题思路">解题思路</h2>
<p><strong>画图</strong>。从字符串的第一个字符开始，将每种情况画出来，然后</p>
<ol type="1">
<li>假设<strong>字符串</strong>的长度为 1，则直接返回；</li>
<li>假设<strong>字符串</strong>的长度不为 1，但是其本身是回文，则加入部分解中；</li>
<li>否则进入循环，遍历所有的情况，每一种情况都要再进行递归；
<ol type="1">
<li>如果是<strong>字符串</strong>切割出的<strong>子字符串</strong>是回文，那么进行递归判断除<strong>子字符串</strong>之外的其他部分；
<ol type="1">
<li>递归会产生一个部分解，将当前的回文<strong>子字符串</strong>加入每种部分解的开头。</li>
</ol></li>
<li>如果不是，那么不作任何处理；</li>
</ol></li>
<li>返回部分解</li>
</ol>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">s:</span> str)</span></span> -&gt; List[List[str]]<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> len(s) == <span class="number">1</span>: <span class="keyword">return</span> [[s]]</span><br><span class="line"></span><br><span class="line">        solutions = []</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.is_huiwen(s): solutions.append([s])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> pointer <span class="keyword">in</span> range(<span class="number">1</span>, len(s))<span class="symbol">:</span></span><br><span class="line">            piece = s[: pointer]</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">self</span>.is_huiwen(piece)<span class="symbol">:</span></span><br><span class="line">                partial_solutions = <span class="keyword">self</span>.partition(s[<span class="symbol">pointer:</span>])</span><br><span class="line">                <span class="keyword">for</span> partial_solution <span class="keyword">in</span> <span class="symbol">partial_solutions:</span></span><br><span class="line">                    partial_solution.insert(<span class="number">0</span>, piece)</span><br><span class="line">                solutions.extend(partial_solutions)</span><br><span class="line">        <span class="keyword">return</span> solutions</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_huiwen</span><span class="params">(<span class="keyword">self</span>, s)</span></span>: <span class="keyword">return</span> s == s[<span class="symbol">:</span><span class="symbol">:-</span><span class="number">1</span>]</span><br></pre></td></tr></table></figure>
<h1 id="累加数">306. 累加数</h1>
<mark class="label warning">中等</mark>
<h2 id="解题思路-1">解题思路</h2>
<ol type="1">
<li>首先根据题目在脑子里思考搜索树应该是怎么样的，我的如下图所示（当然图中的例子，使用深度优先遍历就已经得到解了，其他的几个节点只是举个例子）： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/【算法设计题目】回溯法/累加数字搜索树示例.png" alt="累加数字搜索树示例" /></li>
<li>判断合法条件（合法即找到解）：
<ol type="1">
<li>字符串中的数字均考虑过，即已走到搜索树的叶结点</li>
<li>符合约束函数：数字不得以“0”开头，“0”本身除外</li>
<li>是否为累加的：前两个数字相加等于当前的数字</li>
</ol></li>
<li>判断是部分解的条件（如果是部分解就进入下一层）：
<ol type="1">
<li>字符串中的数字未全考虑过，即未走到搜索树的叶结点</li>
<li>同 2.2</li>
<li>同 2.3</li>
</ol></li>
</ol>
<h2 id="算法执行">算法执行</h2>
<ol type="1">
<li>字符串长度小于 3 直接返回 False</li>
<li>初始化前两个数字为 a, b = ''</li>
<li>开始递归，除了必需的变量，还需要一个字符串剩余长度（rest_len），方便在剩余的字符串中计算当前的数字
<ul>
<li>比如在上图中，当前所在层数为 3（即第四层），我们需要计算当前节点的数字。已知 rest_len = 3，str_len = 6，则取出当前节点的数字为 num[6 - 3: 6 - 3 + span]，span 为取数字的跨度，从 1 开始，所以就取到了数字“3”。在图中可以看到此层还有一个节点“35”，如果 span = 2，我们就取得了 num[6 - 3: 6 - 3 + 2]
<ul>
<li>array[i: j] 在 python 中意为<strong>取出在 array 中从 i 到 j 的元素</strong>（遵从包头不包尾原则）</li>
</ul></li>
<li>rest_len 另一个用途是计算 span，比如“112358”，rest_len = 3，那么我们只能选择取[3, 35 ,358]。我们从 1 遍历到 rest_len + 1，刚好可以得到可取的 span = [1, 2 ,3]</li>
</ul></li>
<li>使用 rest_len 计算当前数字 c</li>
<li>合法则返回 True</li>
<li>部分则进入下一层
<ul>
<li>由于第 0 层和 第 1 层无法进行比对，所以碰到此两层也可进入下一层</li>
</ul></li>
</ol>
<h2 id="回溯法">回溯法</h2>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> Solution:</span><br><span class="line">    def <span class="constructor">__init__(<span class="params">self</span>)</span>:</span><br><span class="line">        self.success = False</span><br><span class="line">        self.str_len = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    def is<span class="constructor">AdditiveNumber(<span class="params">self</span>, <span class="params">num</span>: <span class="params">str</span>)</span> -&gt; <span class="built_in">bool</span>:</span><br><span class="line">        self.str_len = len(num)</span><br><span class="line">        <span class="keyword">if</span> self.str_len &lt; <span class="number">3</span>:</span><br><span class="line">            return False</span><br><span class="line">        # 开始递归</span><br><span class="line">        self.<span class="keyword">rec</span>(num, self.str_len, <span class="number">0</span>, '', '')</span><br><span class="line">        return self.success</span><br><span class="line"></span><br><span class="line">    def <span class="keyword">rec</span>(self, num_str, rest_len, current_layer, a, b):</span><br><span class="line">        # 遍历所有可能的跨度</span><br><span class="line">        for span <span class="keyword">in</span> range(<span class="number">1</span>, rest_len + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> not self.success:</span><br><span class="line">                # 获取当前的数字</span><br><span class="line">                start = self.str_len - rest_len</span><br><span class="line">                c = num_str<span class="literal">[<span class="identifier">start</span>: <span class="identifier">start</span> + <span class="identifier">span</span>]</span></span><br><span class="line">                # 是否合法，合法则找到解，直接退出程序</span><br><span class="line">                <span class="keyword">if</span> current_layer &gt; <span class="number">1</span> <span class="keyword">and</span> self.is<span class="constructor">_legal(<span class="params">rest_len</span>, <span class="params">span</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">                    self.success = True</span><br><span class="line">                    return</span><br><span class="line">                # 是否为部分解，是则进入下一层</span><br><span class="line">                elif current_layer &lt;= <span class="number">1</span> <span class="keyword">or</span> self.is<span class="constructor">_partial(<span class="params">rest_len</span>, <span class="params">span</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">                    self.<span class="keyword">rec</span>(num_str, rest_len - span, current_layer + <span class="number">1</span>, b, c)</span><br><span class="line"></span><br><span class="line">    def is<span class="constructor">_legal(<span class="params">self</span>, <span class="params">rest_len</span>, <span class="params">span</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">        return rest_len - span<span class="operator"> == </span><span class="number">0</span> <span class="keyword">and</span> self.<span class="keyword">constraint</span><span class="constructor">_func(<span class="params">a</span> , <span class="params">b</span>, <span class="params">c</span>)</span> <span class="keyword">and</span> self.is<span class="constructor">_additive(<span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span></span><br><span class="line"></span><br><span class="line">    def is<span class="constructor">_partial(<span class="params">self</span>, <span class="params">rest_len</span>, <span class="params">span</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">        return rest_len - span != <span class="number">0</span> <span class="keyword">and</span> self.<span class="keyword">constraint</span><span class="constructor">_func(<span class="params">a</span> , <span class="params">b</span>, <span class="params">c</span>)</span> <span class="keyword">and</span> self.is<span class="constructor">_additive(<span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span></span><br><span class="line"></span><br><span class="line">    def <span class="keyword">constraint</span><span class="constructor">_func(<span class="params">self</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">        return not (len(a) &gt; <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">int</span>(a<span class="literal">[<span class="number">0</span>]</span>)<span class="operator"> == </span><span class="number">0</span> <span class="keyword">or</span> len(b) &gt; <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">int</span>(b<span class="literal">[<span class="number">0</span>]</span>)<span class="operator"> == </span><span class="number">0</span> <span class="keyword">or</span> len(c) &gt; <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">int</span>(c<span class="literal">[<span class="number">0</span>]</span>)<span class="operator"> == </span><span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    def is<span class="constructor">_additive(<span class="params">self</span>, <span class="params">a</span>, <span class="params">b</span>, <span class="params">c</span>)</span>:</span><br><span class="line">        return <span class="built_in">int</span>(a) + <span class="built_in">int</span>(b)<span class="operator"> == </span><span class="built_in">int</span>(c)</span><br></pre></td></tr></table></figure>
<h1 id="二进制手表">401. 二进制手表</h1>
<p>分析：<mark class="label success">简单</mark> 1. 问题可转化为： 10（4+6） 个电子灯一次实验取出 n 个，取完之后放回，问共有多少种取法？ 2. 显然一次实验中只能取一个电子灯，所以电子灯是不可重复选取的，但是顺序却有关系，这是由于前 4 个电子灯代表小时，后 6 个电子灯代表分钟。所以这是一个排列的问题，共有 <span class="math inline">\(\frac{10!}{(10 - k)!}\)</span> 种。 3. 此问题的<strong>约束函数</strong>是前 4 个电子灯的二进制表示只能在 0~11 之间，后 6 个电子灯的二进制表示只能在 0~59 之间。 - 并且电子灯亮着的个数要为 n。</p>
<h2 id="回溯法-1">回溯法</h2>
<p>解决办法为： <figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.led_num = <span class="number">10</span></span><br><span class="line">        <span class="comment"># 前四个灯代表时，后六个灯代表分</span></span><br><span class="line">        <span class="keyword">self</span>.leds = [-<span class="number">1</span> <span class="keyword">for</span> <span class="number">_</span> <span class="keyword">in</span> range(<span class="keyword">self</span>.led_num)]</span><br><span class="line">        <span class="comment"># “排列”答案</span></span><br><span class="line">        <span class="keyword">self</span>.permutation = []</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">readBinaryWatch</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">num:</span> int)</span></span> -&gt; List[str]<span class="symbol">:</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 算法实现</span></span><br><span class="line">        <span class="keyword">while</span> index &gt;= <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">self</span>.leds[index] &lt; <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.leds[index] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">self</span>.is_legal(num)<span class="symbol">:</span></span><br><span class="line">                    h, m = <span class="keyword">self</span>.gethm()</span><br><span class="line">                    <span class="keyword">self</span>.permutation.append(<span class="string">'%i:%s'</span> % (h, <span class="string">'0%i'</span> % m <span class="keyword">if</span> m &lt; <span class="number">10</span> <span class="keyword">else</span> str(m)))</span><br><span class="line">                elif <span class="keyword">self</span>.is_partial(num) <span class="keyword">and</span> index &lt; <span class="keyword">self</span>.led_num - <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">                    index += <span class="number">1</span></span><br><span class="line">            <span class="keyword">self</span>.leds[index] = -<span class="number">1</span></span><br><span class="line">            index -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.permutation</span><br><span class="line">                </span><br><span class="line">    <span class="comment"># 合法条件：亮灯必须等于 num，并且满足约束函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_legal</span><span class="params">(<span class="keyword">self</span>, num)</span></span>: <span class="keyword">return</span> sum([<span class="number">1</span> <span class="keyword">for</span> _b <span class="keyword">in</span> <span class="keyword">self</span>.leds <span class="keyword">if</span> _b == <span class="number">1</span>]) == num <span class="keyword">and</span> <span class="keyword">self</span>.constraint_function()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 部分条件：亮灯必须小于等于 num，并且满足约束函数</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_partial</span><span class="params">(<span class="keyword">self</span>, num)</span></span>: <span class="keyword">return</span> sum([<span class="number">1</span> <span class="keyword">for</span> _b <span class="keyword">in</span> <span class="keyword">self</span>.leds <span class="keyword">if</span> _b == <span class="number">1</span>]) &lt;= num <span class="keyword">and</span> <span class="keyword">self</span>.constraint_function()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 约束函数为小时的范围为 0~11，分钟的范围为 0~59</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">constraint_function</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        h, m = <span class="keyword">self</span>.gethm()</span><br><span class="line">        <span class="keyword">return</span> h &lt;= <span class="number">11</span> <span class="keyword">and</span> m &lt;= <span class="number">59</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">gethm</span><span class="params">(<span class="keyword">self</span>)</span></span><span class="symbol">:</span></span><br><span class="line">        h = <span class="number">0</span></span><br><span class="line">        m = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> index, _b <span class="keyword">in</span> enumerate(<span class="keyword">self</span>.leds)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">if</span> _b &gt;= <span class="number">0</span><span class="symbol">:</span></span><br><span class="line">                <span class="keyword">if</span> index &lt;= <span class="number">3</span><span class="symbol">:</span></span><br><span class="line">                    h += (<span class="number">2</span> ** index) * _b</span><br><span class="line">                <span class="symbol">else:</span></span><br><span class="line">                    m += (<span class="number">2</span> ** (index - <span class="number">4</span>)) * _b</span><br><span class="line">        <span class="keyword">return</span> h, m</span><br></pre></td></tr></table></figure></p>
<h2 id="其他办法">其他办法</h2>
<p>leetcode 上有非回溯法的做法。</p>
<h1 id="字母大小写全排列">784. 字母大小写全排列</h1>
<p>一开始是按照回溯法的思想去思考的，但是后来我反应过来了。这题不就是穷举法吗？只不过排除了相同的组合。完全可以使用穷举做出来，只需要用集合的概念将重复的元素剔除即可。<mark class="label success">简单</mark></p>
<h2 id="暴力穷举法">暴力穷举法</h2>
<p>经过十来分钟的研究，发现穷举法不可行，必须要用递归考虑进每种情况。之前想太简单了，还是用回溯法吧。</p>
<h2 id="回溯法-2">回溯法</h2>
<p>就是普通的回溯，需要注意回溯的时候不再是索引减一，而是回到当前索引位置的字符不为数字为止。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCasePermutation</span><span class="params">(self, S: str)</span>:</span></span><br><span class="line">        str_len = len(S)</span><br><span class="line">        x = [<span class="number">-1</span> <span class="keyword">for</span> _ <span class="keyword">in</span> range(str_len)]</span><br><span class="line">        res = []</span><br><span class="line">        tail_index = len(re.search(<span class="string">r'^.*?(\d*)$'</span>, S).group(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 数字直接返回</span></span><br><span class="line">        <span class="keyword">if</span> tail_index == str_len:</span><br><span class="line">            <span class="keyword">return</span> [S]</span><br><span class="line"></span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">while</span> x[i] &lt; <span class="number">1</span>:</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> S[i].isdigit():</span><br><span class="line">                    x[i] += <span class="number">1</span></span><br><span class="line">                    <span class="keyword">if</span> self.is_legal(x, tail_index):</span><br><span class="line">                        res.append(self.transform(x, S))</span><br><span class="line">                <span class="keyword">if</span> (x[-(tail_index + <span class="number">1</span>)] &lt; <span class="number">1</span> <span class="keyword">or</span> S[i].isdigit()) <span class="keyword">and</span> i &lt; str_len - tail_index - <span class="number">1</span>:</span><br><span class="line">                    i += <span class="number">1</span></span><br><span class="line">            <span class="comment"># 回溯，回到当前索引位置的字符不为数字为止</span></span><br><span class="line">            <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">                x[i] = <span class="number">-1</span></span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> S[i].isdigit():</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_legal</span><span class="params">(self, x, tail_index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> x[-(tail_index + <span class="number">1</span>)] != <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span><span class="params">(self, x, s)</span>:</span></span><br><span class="line">        final_s = []</span><br><span class="line">        <span class="keyword">for</span> i, item <span class="keyword">in</span> enumerate(x):</span><br><span class="line">            <span class="keyword">if</span> item == <span class="number">-1</span>:</span><br><span class="line">                final_s.append(s[i])</span><br><span class="line">            <span class="keyword">elif</span> item == <span class="number">0</span>:</span><br><span class="line">                final_s.append(s[i].lower())</span><br><span class="line">            <span class="keyword">elif</span> item == <span class="number">1</span>:</span><br><span class="line">                final_s.append(s[i].upper())</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">'未知错误'</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span>.join(final_s)</span><br></pre></td></tr></table></figure></p>
<h1 id="将数组拆分为斐波那契序列">842. 将数组拆分为斐波那契序列</h1>
<mark class="label warning">中等</mark>
<h2 id="解题思路-2">解题思路</h2>
<p>本代码最后没有通过测试，但是我验算了最后打印出来的错误提示，发现并没有错。后来发现其他人也有遇到这问题，所以暂时不做这题了。</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">import copy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, )</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.exit = False</span><br><span class="line">        <span class="keyword">self</span>.solution = None</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">splitIntoFibonacci</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">S:</span> str)</span></span> -&gt; List[int]<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> len(S) &lt; <span class="number">3</span><span class="symbol">:</span></span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        </span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(start)</span></span>: </span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">self</span>.done(solution, S, start)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">self</span>.exit = True</span><br><span class="line">                <span class="keyword">self</span>.solution = copy.copy(solution)</span><br><span class="line">            elif <span class="keyword">self</span>.partial(solution, S, start)<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">for</span> <span class="keyword">end</span> <span class="keyword">in</span> range(start + <span class="number">1</span>, len(S) + <span class="number">1</span>)<span class="symbol">:</span></span><br><span class="line">                    piece = S[<span class="symbol">start:</span> <span class="keyword">end</span>]</span><br><span class="line">                    <span class="keyword">if</span> int(piece[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">and</span> len(piece) &gt; <span class="number">1</span><span class="symbol">:</span></span><br><span class="line">                        <span class="keyword">break</span> </span><br><span class="line">                    solution.append(int(piece))</span><br><span class="line">                    f(<span class="keyword">end</span>)</span><br><span class="line">                    solution.pop()</span><br><span class="line">            </span><br><span class="line">        solution = []</span><br><span class="line">        f(<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.solution</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">is_fibonacci</span><span class="params">(<span class="keyword">self</span>, solution)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, len(solution))<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">if</span> solution[i - <span class="number">2</span>] + solution[i - <span class="number">1</span>] != solution[i]<span class="symbol">:</span></span><br><span class="line">                <span class="keyword">return</span> False</span><br><span class="line">        <span class="keyword">return</span> True</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">done</span><span class="params">(<span class="keyword">self</span>, solution, S, start)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> len(solution) &gt;= <span class="number">3</span> <span class="keyword">and</span> <span class="keyword">self</span>.is_fibonacci(solution) <span class="keyword">and</span> start &gt;= len(S)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial</span><span class="params">(<span class="keyword">self</span>, solution, S, start)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">return</span> len(solution) &lt; <span class="number">3</span> <span class="keyword">or</span> (<span class="keyword">self</span>.is_fibonacci(solution) <span class="keyword">and</span> start &lt; len(S) <span class="keyword">and</span> <span class="keyword">not</span> <span class="keyword">self</span>.exit)</span><br></pre></td></tr></table></figure>
<h1 id="黄金矿工">1219. 黄金矿工</h1>
<mark class="label warning">中等</mark>
<h2 id="解题思路-3">解题思路</h2>
<ol type="1">
<li>尝试网格中的所有位置，如果该位置上黄金为零则跳过，否则计算可以挖掘最多黄金的数量；</li>
<li>如果已经挖掘完毕，则返回黄金数量；</li>
<li>否则前进一格，具体为“上下左右”四个方向；
<ol type="1">
<li>如果前进一格之后的位置，是一个无效位置，则跳过；</li>
<li>否则递归；</li>
<li>计算走“上下左右”四个方向上，黄金数量最多的那个方向。注：我们只需要黄金的数量即可，并不需要记录路径。</li>
</ol></li>
</ol>
<figure class="highlight maxima"><table><tr><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def getMaximumGold(self, <span class="built_in">grid</span>: List[List[int]]) -&gt; int:</span><br><span class="line">        max_gold = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> which_row, <span class="built_in">row</span> <span class="keyword">in</span> enumerate(<span class="built_in">grid</span>):</span><br><span class="line">            <span class="keyword">for</span> which_column, gold <span class="keyword">in</span> enumerate(<span class="built_in">row</span>):</span><br><span class="line">                <span class="keyword">if</span> gold == <span class="number">0</span>:</span><br><span class="line">                    continue</span><br><span class="line">                solution = [[<span class="number">0</span> <span class="keyword">for</span> <span class="symbol">_</span> <span class="keyword">in</span> <span class="built_in">row</span>] <span class="keyword">for</span> <span class="built_in">row</span> <span class="keyword">in</span> <span class="built_in">grid</span>]</span><br><span class="line">                total_gold = self.getMaximumGold_(solution, <span class="built_in">grid</span>, (which_row, which_column))</span><br><span class="line">                <span class="keyword">if</span> total_gold &gt; max_gold: max_gold = total_gold</span><br><span class="line">        <span class="built_in">return</span> max_gold</span><br><span class="line">    </span><br><span class="line">    def getMaximumGold_(self, solution, <span class="built_in">grid</span>, pos):</span><br><span class="line">        i, j = pos[<span class="number">0</span>], pos[<span class="number">1</span>]</span><br><span class="line">        gold = <span class="built_in">grid</span>[i][j]</span><br><span class="line">        solution[i][j] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        max_gold = gold</span><br><span class="line">        <span class="keyword">if</span> self.done(solution, <span class="built_in">grid</span>, i, j):</span><br><span class="line">            <span class="built_in">return</span> gold</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">for</span> offset_i, offset_j <span class="keyword">in</span> [(-<span class="number">1</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>)]:</span><br><span class="line">                new_i, new_j = i + offset_i, j + offset_j</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> (<span class="number">0</span> &lt;= new_i &lt; len(<span class="built_in">grid</span>) <span class="keyword">and</span> <span class="number">0</span> &lt;= new_j &lt; len(<span class="built_in">grid</span>[<span class="number">0</span>])) <span class="keyword">or</span> solution[new_i][new_j] == <span class="number">1</span> <span class="keyword">or</span> <span class="built_in">grid</span>[new_i][new_j] == <span class="number">0</span>:</span><br><span class="line">                    continue</span><br><span class="line">                partial_gold = self.getMaximumGold_(solution, <span class="built_in">grid</span>, (new_i, new_j))</span><br><span class="line">                solution[new_i][new_j] -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> max_gold &lt; gold + partial_gold: max_gold = gold + partial_gold</span><br><span class="line">        <span class="built_in">return</span> max_gold</span><br><span class="line"></span><br><span class="line">    def done(self, solution, <span class="built_in">grid</span>, i, j):</span><br><span class="line">        <span class="keyword">for</span> offset_i, offset_j <span class="keyword">in</span> [(-<span class="number">1</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">0</span>), (<span class="number">0</span>, -<span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>)]:</span><br><span class="line">            new_i, new_j = i + offset_i, j + offset_j</span><br><span class="line">            <span class="keyword">if</span> <span class="number">0</span> &lt;= new_i &lt; len(<span class="built_in">grid</span>) <span class="keyword">and</span> <span class="number">0</span> &lt;= new_j &lt; len(<span class="built_in">grid</span>[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">grid</span>[new_i][new_j] &gt; <span class="number">0</span> <span class="keyword">and</span> solution[new_i][new_j] == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">return</span> False</span><br><span class="line">        <span class="built_in">return</span> True</span><br></pre></td></tr></table></figure>
<h1 id="拆分字符串使唯一子字符串的数目最大">1593. 拆分字符串使唯一子字符串的数目最大</h1>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(<span class="keyword">self</span>, )</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">self</span>.max_num = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">self</span>.solution = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxUniqueSplit</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">s:</span> str)</span></span> -&gt; <span class="symbol">int:</span></span><br><span class="line">        <span class="keyword">self</span>.maxUniqueSplit<span class="number">_</span>(s, <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">self</span>.max_num</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxUniqueSplit_</span><span class="params">(<span class="keyword">self</span>, s, i)</span></span><span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">self</span>.done(s, i)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">self</span>.max_num = max(<span class="keyword">self</span>.max_num, len(<span class="keyword">self</span>.solution))</span><br><span class="line">        elif <span class="keyword">self</span>.partial(s, i)<span class="symbol">:</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(s) + <span class="number">1</span>)<span class="symbol">:</span></span><br><span class="line">                piece = s[<span class="symbol">i:</span> j]</span><br><span class="line">                <span class="keyword">if</span> piece <span class="keyword">not</span> <span class="keyword">in</span> <span class="keyword">self</span>.<span class="symbol">solution:</span></span><br><span class="line">                    <span class="keyword">self</span>.solution.append(piece)</span><br><span class="line">                    <span class="keyword">self</span>.maxUniqueSplit<span class="number">_</span>(s, j)</span><br><span class="line">                    <span class="keyword">self</span>.solution.pop()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">done</span><span class="params">(<span class="keyword">self</span>, s, i)</span></span>: <span class="keyword">return</span> len(s) &lt;= i</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partial</span><span class="params">(<span class="keyword">self</span>, s, i)</span></span>: <span class="keyword">return</span> len(s) &gt; i</span><br></pre></td></tr></table></figure>
<h1 id="面试题-08.07.-无重复字符串的排列组合">面试题 08.07. 无重复字符串的排列组合</h1>
<mark class="label warning">中等</mark>
<h2 id="解题思路-4">解题思路</h2>
<p>挺简单的，就是一个全排列。</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">permutation</span><span class="params">(<span class="keyword">self</span>, <span class="symbol">S:</span> str)</span></span> -&gt; List[str]<span class="symbol">:</span></span><br><span class="line">        <span class="keyword">if</span> len(S) == <span class="number">1</span>: <span class="keyword">return</span> [S]</span><br><span class="line">        </span><br><span class="line">        solutions = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(S))<span class="symbol">:</span></span><br><span class="line">            partial_permutation = <span class="keyword">self</span>.permutation(S[: i] + S[i + <span class="number">1</span><span class="symbol">:</span>])</span><br><span class="line">            <span class="keyword">for</span> pp <span class="keyword">in</span> <span class="symbol">partial_permutation:</span></span><br><span class="line">                solutions.append(S[i] + pp)</span><br><span class="line">        <span class="keyword">return</span> solutions</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>回溯法</tag>
      </tags>
  </entry>
  <entry>
    <title>记录：hexo next主题的改动</title>
    <url>/posts/5d62ca7e.html</url>
    <content><![CDATA[<p><a href="https://github.com/theme-next/hexo-theme-next" target="_blank" rel="noopener">hexo-theme-next</a> 主题的 github 页面中提到了如何更新的问题。他们在教程中指出，在更新的过程中可能会遇到 <code>Commit your changes or stash them before you can merge</code> 的问题，其实这就是代表你修改过主题中的源码文件，所以不允许对 next 主题进行更新。这里的源码文件指代比较宽泛，大家最常改的应该是 <code>_config.yml</code> 文件。以下将介绍如何处理：</p>
<ol type="1">
<li><strong>前置操作：将自己的博客复制一份，以免修改错。</strong></li>
<li>使用 <code>git pull</code> 命令，如果出现问题，那就代表你更新成功了。如果出现了上面的 <code>Commit your changes or stash them before you can merge</code> 问题，那就往下看。</li>
<li>使用 <code>git stash</code>，重置自己的修改，再次使用 <code>git pull</code>，更新完成。</li>
<li><strong>hexo next 主题更新完成后，就代表你之前所有的自定义配置都没了。</strong>所以接下来的内容是将它们改回来。</li>
</ol>
<p>博客的路径如下所示： <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">D:.</span><br><span class="line">├─blog</span><br><span class="line">│  ├─.deploy_git</span><br><span class="line">│  ├─node_modules</span><br><span class="line">│  ├─...</span><br><span class="line">│  ├─source</span><br><span class="line">│  ├─themes</span><br><span class="line">│  │  ├─next</span><br><span class="line">│  │  │  ├─source</span><br><span class="line">│  │  │  ├─...</span><br><span class="line">│  │  │  ├─_config.yml</span><br><span class="line">│  ├─_config.yml</span><br><span class="line">├─blog_bakup</span><br></pre></td></tr></table></figure> <a id="more"></a></p>
<h1 id="config.yml-的处理">_config.yml 的处理</h1>
<p>如果自己改过 <code>_config.yml</code> 文件，更新之后，维护起来就比较麻烦了。我们可以使用 next 提供的方法来管理 <code>_config.yml</code> 中的配置信息。</p>
<p>首先在 <code>blog/source</code> 中创建 <code>_data</code> 文件，再在其中创建 <code>next.yml</code> 文件。</p>
<p>分别打开 blog 中 next 主题的 <code>_config.yml</code> 文件和 blog_backup 中的 next 主题的 <code>_config.yml</code> 文件。</p>
<p>blog_backup 中的配置文件是你之前自定义的配置，对照两份文件（或者如果自己有印象，可以不用对照）。将自定义的配置移入到 <code>blog/source/next.yml</code> 文件中。注意只需要移入更改过的配置即可，比如如下配置： <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">footer:</span></span><br><span class="line"><span class="attr">  since:</span> <span class="number">2015</span></span><br><span class="line"><span class="attr">  icon:</span></span><br><span class="line">	<span class="attr">name:</span> <span class="string">user</span></span><br><span class="line">	<span class="attr">animated:</span> <span class="literal">false</span></span><br><span class="line">	<span class="attr">color:</span> <span class="string">"#808080"</span></span><br><span class="line"><span class="attr">creative_commons:</span></span><br><span class="line"><span class="attr">  license:</span> <span class="string">by-nc-sa</span></span><br><span class="line"><span class="attr">  sidebar:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  post:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  language:</span></span><br></pre></td></tr></table></figure> 如果你只更改过 <code>since</code> 的配置，将其改为 2018。那么在 <code>blog/source/next.yml</code> 文件中，应该像下面这么写： <figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">footer:</span></span><br><span class="line"><span class="symbol">  since:</span> <span class="number">2018</span></span><br></pre></td></tr></table></figure> 其他的配置不需要更改。<a href="https://github.com/theme-next/hexo-theme-next/blob/master/docs/DATA-FILES.md" target="_blank" rel="noopener">此处</a>是官方文档，还有不懂的，可以去看文档。</p>
<h1 id="自定义代码">自定义代码</h1>
<h2 id="添加弹窗提示功能">添加弹窗提示功能</h2>
<p>首先下载一个自己喜欢的弹窗插件，可以去<a href="http://www.jq22.com/" target="_blank" rel="noopener">jQuery插件库</a>找。然后将css和js放在next主题下的source文件夹中，如下图所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/hexo/next%E4%B8%BB%E9%A2%98%E7%9B%AE%E5%BD%95.jpg" alt="next主题目录" /></p>
<p>css文件放入css文件，js文件放入js文件夹。我自己创了一个spop的文件夹，用于单独放置我的弹窗插件。</p>
<p>在 <code>themes/next/layout/_macro/post.swig</code> 中找到代码：<code>&lt;article itemscope itemtype=&quot;http://schema.org/Article&quot; class=&quot;post-block [% if is_index %]home[% endif %]&quot; lang=&quot;[[ post.lang or post.language or config.language ]]&quot;&gt;</code>，其实就在第 2 行。</p>
<p>在此行下面插入以下代码： <figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">[% <span class="keyword">for</span> tag <span class="keyword">in</span> post.tags.toArray() %]</span><br><span class="line">	[% <span class="keyword">if</span> tag.name == <span class="string">'学习笔记'</span> <span class="keyword">and</span> <span class="keyword">not</span> is_home() %]</span><br><span class="line">	&lt;link rel="stylesheet" <span class="keyword">type</span>="text/css" href="/lib/spop/spop.min.css"&gt;</span><br><span class="line">	《script <span class="keyword">type</span>="text/javascript" src="/lib/spop/spop.min.js"&gt;&lt;/script&gt;</span><br><span class="line">	&lt;!<span class="comment">--判断该文章是否为学习笔记--&gt;</span></span><br><span class="line">	《script&gt;</span><br><span class="line">	  spop(&#123;</span><br><span class="line">		<span class="keyword">template</span>: <span class="string">'&lt;h4 class="spop-title"&gt;注意&lt;/h4&gt;此文章仅为博主的学习笔记，并非教学，其中可能含有理论错误。'</span>,</span><br><span class="line">		<span class="keyword">group</span>: <span class="string">'tips'</span>,</span><br><span class="line">		position  : <span class="string">'bottom-center'</span>,</span><br><span class="line">		style: <span class="string">'success'</span>,</span><br><span class="line">		autoclose: <span class="number">5500</span>,</span><br><span class="line">		onOpen: <span class="keyword">function</span> () &#123;</span><br><span class="line">		  //这里设置灰色背景色</span><br><span class="line">		&#125;,</span><br><span class="line">		onClose: <span class="keyword">function</span>() &#123;</span><br><span class="line">		  //这里可以取消背景色</span><br><span class="line">		  spop(&#123;</span><br><span class="line">			<span class="keyword">template</span>: <span class="string">'ε = = (づ′▽`)づ'</span>,</span><br><span class="line">			<span class="keyword">group</span>: <span class="string">'tips'</span>,</span><br><span class="line">			position  : <span class="string">'bottom-center'</span>,</span><br><span class="line">			style: <span class="string">'success'</span>,</span><br><span class="line">			autoclose: <span class="number">1500</span></span><br><span class="line">		  &#125;);</span><br><span class="line">		&#125;</span><br><span class="line">	  &#125;);</span><br><span class="line">	&lt;/script&gt;</span><br><span class="line">	[% endif %]</span><br><span class="line">[% endfor %]</span><br></pre></td></tr></table></figure></p>
<p>其中相应的 css/js 文件需要自己去下载，并放入到 <code>themes/next/source/lib/</code> 文件夹下。</p>
<p>is_home()是next主题的方法，用于判断当前页面是否在主页。因为主页一次性加载了所有的文章，如果不加这个方法，会在主页弹出无数个弹窗。最终效果如下图所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/hexo/%E6%8F%90%E7%A4%BA%E5%BC%B9%E7%AA%97%E6%95%88%E6%9E%9C%E5%9B%BE.jpg" alt="提示弹窗效果图" /></p>
<h2 id="为学习笔记添加不同的颜色">为学习笔记添加不同的颜色</h2>
<p>如果需要为不同类型的博客在博客时间线中显示不同的颜色，可以做如下更改，在 <code>themes/next/layout/_macro/post-collapse.swig</code> 中，找到 <code>&lt;a class=&quot;post-title-link&quot; href=&quot;[[ url_for(post.path) ]]&quot; itemprop=&quot;url&quot;&gt;</code>，在 <code>&lt;a&gt;&lt;/a&gt;</code> 标签下面插入以下代码： <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 如果博文是学习笔记的话，后面加个小图标 --&gt;</span></span><br><span class="line">[% for tag in post.tags.toArray() %]</span><br><span class="line">	[% if tag.name == '学习笔记'%]</span><br><span class="line">		<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"notes-tag fas fa-book-reader"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span><br><span class="line">		《script&gt;</span><br><span class="line">			window.onload = function()&#123;</span><br><span class="line">				var notes = $('.notes-tag');</span><br><span class="line">				//碧螺春绿</span><br><span class="line">				notes.prev().children('span').css('color', '#867018');</span><br><span class="line">			&#125;</span><br><span class="line">		<span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">	[% endif %]</span><br><span class="line">[% endfor %]</span><br></pre></td></tr></table></figure></p>
<h2 id="开启不蒜子">开启不蒜子</h2>
<p>开启不蒜子。在 <code>source/_data/next.yml</code> 中设置如下属性，就算开启了： <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">busuanzi_count:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure> 开启之后，它默认只会显示三个统计数据，即总浏览量、文章浏览量和访客数量。它们的代码在 <code>themes/next/layout/_layout.swig</code> 的 footer 中，文章浏览量的代码在 <code>_macro/post.swig</code> 中。 如果要显示更多，可以在 <code>themes/next/layout/_partials/sidebar/site-overview.swig</code> 中修改代码（这个 <code>site-overview.swig</code> 是由 <code>themes/next/layout/_macro/sidebar.swig</code> 加载）。 <figure class="highlight cs"><table><tr><td class="code"><pre><span class="line">[<span class="meta">%- if theme.site_state %</span>]</span><br><span class="line">&lt;div <span class="keyword">class</span>=<span class="string">"site-state-wrap motion-element"</span>&gt;</span><br><span class="line">  &lt;nav <span class="keyword">class</span>=<span class="string">"site-state"</span>&gt;</span><br><span class="line">    ...</span><br><span class="line">	&lt;code&gt;</span><br><span class="line">  &lt;/nav&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">[<span class="meta">%- endif %</span>]</span><br></pre></td></tr></table></figure> 在文件中找到上面的代码，<code>&lt;nav&gt;&lt;/nav&gt;</code> 标签中有很多代码，将下面的代码添加到 <code>&lt;nav&gt;&lt;/nav&gt;</code> 标签内部的最后一行，即上面代码的 <code>&lt;code&gt;</code> 位置。 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">[%- if theme.busuanzi_count.enable %]</span><br><span class="line">  <span class="comment">&lt;!-- 不蒜子/busuanzi --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"site-state-item site-state-posts"</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"site-state-item-count"</span>&gt;</span>[[totalcount(site)]]<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"site-state-item-name"</span>&gt;</span>总字数<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">[%- endif %]</span><br></pre></td></tr></table></figure></p>
<h2 id="添加置顶标签">添加置顶标签</h2>
<p>不知道为什么 next 主题居然不为置顶文章添加置顶标签。如果不加这个标签，就无法察觉到此文章与其他文章有何区别，会造成一定的困扰。 可以搜索 <code>&lt;div class=&quot;post-meta&quot;&gt;</code> 快速定位到添加置顶标签的位置，在该代码下面添加以下代码，其中最上面三行代码是本来就存在的。 <figure class="highlight twig"><table><tr><td class="code"><pre><span class="line"><span class="xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="keyword">set</span></span> date_diff = <span class="name">date</span><span class="params">(post.date)</span> != <span class="name">date</span><span class="params">(post.updated)</span> %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="keyword">set</span></span> time_diff = time(post.date) != time(post.updated) %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="keyword">set</span></span> datetime_diff = date_diff or time_diff %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;%- <span class="name"><span class="keyword">if</span></span> post.top &gt; 1 %&#125;</span><span class="xml"></span></span><br><span class="line"><span class="xml">	<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">"fas fa-thumbtack"</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span></span><br><span class="line"><span class="xml">	<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-item-text"</span>&gt;</span>top<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml">	<span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"post-meta-divider"</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span><span class="template-tag">&#123;% <span class="name"><span class="keyword">endif</span></span> %&#125;</span><span class="xml"></span></span><br></pre></td></tr></table></figure></p>
<h2 id="更自由地使用font-awesome">更自由地使用Font Awesome</h2>
<div class="note danger"><p><strong>2020.06.14 更新：注意：NexT v8 已经将 Font Awesome 升级，本节的全部设置均可以作废。</strong></p>
<p>原文：</p>
<p><em>慎重修改，更改之后可能导致其他未被考虑到的地方出现无法显示 icons 的问题。</em></p>
</div>
<h3 id="修改sidebar的代码">修改sidebar的代码</h3>
<p>在 <code>themes/next/layout/_partials/sidebar/site-overview.swig</code> 中将 social icon 的代码进行替换，大约在 85 行的位置：<code>【%-set sidebarIcon = '&lt;i class=&quot;fa fa-fw fa-' + link.split('||')[1] | trim + '&quot;&gt;&lt;/i&gt;' %}</code>，<code>ctrl f</code> 搜索 <code>fa fa-fw fa-</code> 应该就能找到了。将其替换为： <figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">【%-set sidebarIcon = <span class="string">'&lt;i class="'</span> + link.split(<span class="string">'||'</span>)[<span class="number">1</span>] | <span class="keyword">trim</span> + <span class="string">'"&gt;&lt;/i&gt;'</span> %&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="修改categories的代码">修改categories的代码</h3>
<p>为了更自由地使用 Font Awesome，在 <code>themes/next/layout/_partials/header/menu-item.swig</code> 中，将第 11 行的 <figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">[%- <span class="keyword">if</span> theme.menu_settings.icons %]</span><br><span class="line">  [%- set menuIcon = <span class="string">'&lt;i class="fa fa-fw fa-'</span> + value.split(<span class="string">'||'</span>)[<span class="number">1</span>] | <span class="keyword">trim</span> + <span class="string">'"&gt;&lt;/i&gt;'</span> %]</span><br><span class="line">[%- endif %]</span><br></pre></td></tr></table></figure> 修改为 <figure class="highlight mel"><table><tr><td class="code"><pre><span class="line">[%- <span class="keyword">if</span> theme.menu_settings.icons %]</span><br><span class="line">  [%- set menuIcon = <span class="string">'&lt;i class="'</span> + value.split(<span class="string">'||'</span>)[<span class="number">1</span>] | <span class="keyword">trim</span> + <span class="string">'"&gt;&lt;/i&gt;'</span> %]</span><br><span class="line">[%- endif %]</span><br></pre></td></tr></table></figure></p>
<h3 id="将fontawesome的版本更至最新">将fontawesome的版本更至最新</h3>
<p>由于在后续又发现在其他地方也用到了icon，所以需要大量更改配置。<strong>如果不会写程序的还是别改了。</strong></p>
<p>next的fontawesome默认版本是4.6.2，在写本文时，fontawesome的最新版本是5.8.1。貌似fontawesome在5.0.0版本之后改版了。总之一直出现方框乱码。</p>
<p>后来发现，现在的fontawesome链接已经跟以前不一样了，它现在分为3大类别。</p>
<p>现在的使用方法是：在next主题的_config.xml中搜索fontawesome，并更改属性<code>fontawesome: //cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.1/css/all.min.css</code>，注意里面的文件是all.min.css，而不是font-awesom.min.css。（v7.7.1 可以在 <code>next.yml</code> 中修改 <code>vendors:  fontawesome:</code>）</p>
<p>但是这样更改之后还是会出现方框乱码，原因是next默认使用的fa的类，而有时候我们需要使用fab或其他的类。所以需要修改一下源代码。</p>
<p>找到layout/_macro/menu/menu-item.swig，定位class=&quot;menu-item-icon，将后面的“fa fa-fw fa-”删去。以后再修改icon不能只加一个名字了。可以像我这样修改：<code>assorted: /assorted || fa fa-fw fa-layer-group</code>。</p>
<p>可以看到我将icon的名称补全了。如果想用fab的类，可以像这样修改：<code>python: /python || fab fa-fw fa-python</code>。以此类推。</p>
<p>这样修改以后，如果不想用fontawesome了，想用其他的icon库，改起来也很方便。</p>
<p>layout/_macro/menu/menu-item.swig被layout/_partials/header/sub-menu.swig引用。</p>
<p>另外由于fontawesome版本改动，社交软件的icon也需要更改，在_config.xml中搜索github，将icon改为<code>fab fa-fw fa-github</code>。找到ayout/_macro/siderbar.swig，搜索fa fa-fw fa-，看看定位的地点上面是不是<code>{百分号  if theme.social_icons.enable 百分号}</code>。是的话将fa fa-fw fa-删除。</p>
<h1 id="注入代码">注入代码</h1>
<p>Next 支持将自定义的内容交给 Next 渲染。详见 <a href="https://theme-next.js.org/docs/theme-settings/custom-files.html" target="_blank" rel="noopener">官方文档</a>。简单来说，就是在 <code>_data</code> 文件夹中新建几个文件，然后添加想要的代码即可。一般来说，此项功能仅支持较为简单的自定义代码。例如在页脚加入几行文字，或者加入几行 js 代码。下一段介绍的内容可以支持更高难度的操作。</p>
<p>Next 还支持将自定义内容注入 next 源码中，这与上节所作的事类似，但是最大的不同是此节的做法类似于直接编写代码，甚至可以设置变量，例如 list。如果不懂编程，那么还是跳过这节吧。详见<a href="https://theme-next.js.org/docs/advanced-settings.html#Injects" target="_blank" rel="noopener">官方文档</a>。</p>
<h1 id="更新至next-v8">更新至next v8</h1>
<p>NexT 前段时间更新了一个大版本，不过由于组织内部问题，可能这次更新没以前那么简单。不过对于我来说好像没遇到什么大问题，总而言之，在 hexo 文件夹下使用 <code>git clone https://github.com/next-theme/hexo-theme-next themes/next-v8</code>，clone v8 版本，然后再到 hexo 的配置文件 <code>_config.yml</code> 中更改 next 主题为 next-v8 主题。 最后要做的是仅仅将以前改动过的文件，在 v8 中再进行改动一次即可。我这篇文章本身就是记录 NexT 主题的改动记录的，所以也没什么大问题。</p>
<h2 id="改用hexo-renderer-pandoc">改用hexo-renderer-pandoc</h2>
<p>NexT v8 声明 hexo-renderer-kramed 已经停止维护，现在推荐使用 hexo-renderer-pandoc。可以在 github 搜索 hexo-renderer-pandoc，它会教你怎么做。另外，由于我以前就在用 pandoc，但是我用的是可执行程序来运行 pandoc，所以文档里让我安装 pandoc，我有点懵逼。怎么安装？不是一个可执行程序吗？其实 pandoc 也是有安装版的，只需要在 pandoc 官网下载 msi 安装包就行了。</p>
<h1 id="出现的bug">出现的bug</h1>
<ol type="1">
<li>更新至最新版（v7.7.1）之后，<code>/categories</code> 路径失效了，我只要在 <code>menu</code> 中添加一条 <code>categories</code>，整个博客就无法运行。搞了一下午才试出来，只要不取 <code>categories</code> 这个名字即可，我将其改为 <code>分类</code>。</li>
<li>还有一个 bug 就是在 <code>categories</code> 路径中，最新版 next 主题不再显示二级目录，这应该是代码写的有问题。找到 <code>themes/next/layout/_partials/header/sub-menu.swig</code> 文件，将第三行的 <code>【%- if theme.menu and is_page() %】</code> 改为 <code>【%- if theme.menu and not is_home() and not is_post() %】</code> 即可。
<ul>
<li>由于博客本身的限制，请将“【】”替换为“{}”。</li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习500问笔记</title>
    <url>/posts/223b5ee4.html</url>
    <content><![CDATA[<h1 id="第三章-深度学习基础">第三章 深度学习基础</h1>
<h2 id="基本概念">基本概念</h2>
<ol type="1">
<li><strong>神经网络组成？</strong></li>
<li><strong>神经网络有哪些常用模型结构？</strong>
<ul>
<li><a href="https://www.asimovinstitute.org/neural-network-zoo/" target="_blank" rel="noopener">THE NEURAL NETWORK ZOO</a></li>
<li><a href="https://www.baidu.com/s?ie=UTF-8&amp;wd=a%20mostly%20complete%20chart%20of%20Neural%20Network&amp;" target="_blank" rel="noopener">a mostly complete chart of Neural Network</a></li>
</ul></li>
<li><strong>如何选择深度学习开发平台？</strong></li>
<li><strong>为什么使用深层表示？</strong> <div class="note info"><p>一些以前看过的资料： 1. <a href="https://yan624.github.io/·zcy/AI/dl/对神经网络整体的理解.html#为什么使用深度表示——Why-deep-representations">吴恩达 2017course 深度学习笔记：对神经网络整体的理解#为什么使用深度表示——Why-deep-representations</a> 2. <a href="#为什么要deep" class="uri">#为什么要deep</a></p>
</div>
<ol type="1">
<li>深度神经网络是一种<strong>特征递进式</strong>的学习算法，<strong>浅层的神经元</strong>直接从输入数据中学习一些低层次的简单特征，例如边缘、纹理等。而<strong>深层的特征</strong>则基于已学习到的浅层特征继续学习更高级的特征，从计算机的角度学习深层的语义信息。 <div class="note default"><p>如这段所说，浅层的神经元可以从数据中提取出一些低层次的特征。对于 CV 来说，首先提取图片的一部分，然后可能还可以继续通过这一部分图片进一步地提取信息。 但是对于 NLP 来说，第一层提取出的特征是低级的，那么第二层该如何从低级的特征中提取出高级的特征？从低级中提取出高级的东西，这逻辑说不通吧。所以我觉得可能可以加一层残差层（residual layer），将原始文本的特征也并入到低级特征中（可以用一个系数来权衡量级）。-&gt;Transformer</p>
</div></li>
<li>深层的网络隐藏单元数量相对较少，隐藏层数目较多，如果浅层的网络想要达到同样的计算结果则需要指数级增长的单元数量才能达到。 <a id="more"></a></li>
</ol></li>
<li><strong>为什么深层神经网络难以训练？</strong>
<ol type="1">
<li>梯度消失 梯度消失是指通过隐藏层从后向前看，梯度会变的越来越小，说明前面层的学习会显著慢于后面层的学习，所以学习会卡住，除非梯度变大。 梯度消失的原因受到多种因素影响，例如<strong>学习率的大小</strong>，<strong>网络参数的初始化</strong>，<strong>激活函数的边缘效应</strong>等。在深层神经网络中，每一个神经元计算得到的梯度都会传递给前一层，较浅层的神经元接收到的梯度受到之前所有层梯度的影响。如果计算得到的梯度值非常小，随着层数增多，求出的梯度更新信息将会以指数形式衰减，就会发生梯度消失。下图是不同隐含层的学习速率：</li>
<li>梯度爆炸</li>
<li>权重矩阵的退化导致模型的有效自由度减少</li>
</ol></li>
<li><strong>深度学习和机器学习有什么不同？</strong></li>
</ol>
<h2 id="超参数">超参数</h2>
<ol type="1">
<li><strong>什么是超参数？</strong></li>
<li><strong>如何寻找超参数的最优值？</strong> 在使用机器学习算法时，总有一些难调的超参数。例如权重衰减大小，高斯核宽度等等。这些参数需要人为设置，设置的值对结果产生较大影响。常见设置超参数的方法有：
<ol type="1">
<li>猜测和检查：根据经验或直觉，选择参数，一直迭代。</li>
<li>网格搜索：让计算机尝试在一定范围内均匀分布的一组值。</li>
<li>随机搜索：让计算机随机挑选一组值。</li>
<li>贝叶斯优化：使用贝叶斯优化超参数，会遇到贝叶斯优化算法本身就需要很多的参数的困难。</li>
<li>MITIE方法，好初始猜测的前提下进行局部优化。它使用BOBYQA算法，并有一个精心选择的起始点。由于BOBYQA只寻找最近的局部最优解，所以这个方法是否成功很大程度上取决于是否有一个好的起点。在MITIE的情况下，我们知道一个好的起点，但这不是一个普遍的解决方案，因为通常你不会知道好的起点在哪里。从好的方面来说，这种方法非常适合寻找局部最优解。稍后我会再讨论这一点。</li>
<li>最新提出的LIPO的全局优化方法。这个方法没有参数，而且经验证比随机搜索方法好。</li>
</ol></li>
<li><strong>超参数搜索一般过程？</strong></li>
</ol>
<h2 id="激活函数">激活函数</h2>
<ol type="1">
<li><p><strong>如何选择激活函数？</strong> <div class="note info"><ol type="1">
<li><a href="https://yan624.github.io/posts/b803ed7e.html#※-激活函数">对神经网络整体的理解#※-激活函数</a></li>
</ol>
</div></p></li>
<li><p><strong>为什么Tanh收敛速度比Sigmoid快？</strong> 首先看如下两个函数的求导： <span class="math display">\[
\begin{align}
 tanh^{\prime}(x) = &amp; 1-tanh(x)^{2}\in (0,1) \\
 s^{\prime}(x) = &amp; s(x)*(1-s(x))\in (0,\frac{1}{4}]
\end{align}
\]</span> 由上面两个公式可知tanh(x)梯度消失的问题比sigmoid轻，所以Tanh收敛速度比Sigmoid快。 <div class="note default"><p>tanh 梯度消失的问题要轻，自然而然参数更新的速度就要快，所以收敛的速度就要快。</p>
</div></p></li>
</ol>
<h2 id="batch-size">batch size</h2>
<h2 id="归一化">归一化</h2>
<ol type="1">
<li><strong>归一化含义？</strong></li>
<li>为什么要归一化？</li>
<li>为什么归一化能提高求解最优解速度？</li>
<li>3D图解未归一化</li>
<li><strong>归一化有哪些类型？</strong>
<ul>
<li>线性归一化</li>
<li>标准差标准化</li>
<li>非线性归一化</li>
</ul></li>
<li>局部响应归一化作用</li>
<li>理解局部响应归一化</li>
<li><strong>什么是批归一化（Batch Normalization）</strong></li>
<li><strong>批归一化（BN）算法的优点</strong></li>
<li><strong>批归一化（BN）算法流程</strong></li>
<li>批归一化和群组归一化比较</li>
<li><strong>Weight Normalization和Batch Normalization比较</strong></li>
<li><strong>Batch Normalization在什么时候用比较合适？</strong></li>
</ol>
<h2 id="预训练与微调fine-tuning">预训练与微调(fine tuning)</h2>
<ol type="1">
<li><strong>为什么无监督预训练可以帮助深度学习？</strong>
<ul>
<li>深度网络存在问题:
<ol type="1">
<li>网络越深，需要的训练样本数越多。若用监督则需大量标注样本，不然小规模样本容易造成过拟合。深层网络特征比较多，会出现的多特征问题主要有多样本问题、规则化问题、特征选择问题。</li>
<li>多层神经网络参数优化是个高阶非凸优化问题，经常得到收敛较差的局部解；</li>
<li>梯度扩散问题，BP算法计算出的梯度随着深度向前而显著下降，导致前面网络参数贡献很小，更新速度慢。</li>
</ol></li>
<li>解决方法：逐层贪婪训练，无监督预训练（unsupervised pre-training）即训练网络的第一个隐藏层，再训练第二个…最后用这些训练好的网络参数值作为整体网络参数的初始值。经过预训练最终能得到比较好的局部最优解。</li>
</ul></li>
<li><strong>什么是模型微调fine tuning</strong></li>
<li><strong>微调时候网络参数是否更新？</strong></li>
<li><strong>fine-tuning 模型的三种状态</strong>
<ol type="1">
<li>状态一：只预测，不训练。 特点：相对快、简单，针对那些已经训练好，现在要实际对未知数据进行标注的项目，非常高效；</li>
<li>状态二：训练，但只训练最后分类层。 特点：fine-tuning的模型最终的分类以及符合要求，现在只是在他们的基础上进行类别降维。</li>
<li>状态三：完全训练，分类层+之前卷积层都训练 特点：跟状态二的差异很小，当然状态三比较耗时和需要训练GPU资源，不过非常适合fine-tuning到自己想要的模型里面，预测精度相比状态二也提高不少。</li>
</ol></li>
</ol>
<h2 id="权重偏差初始化">权重偏差初始化</h2>
<ol type="1">
<li>全都初始化为 0</li>
<li>全都初始化为同样的值</li>
<li>初始化为小的随机数</li>
<li>用 $  $ 校准方差</li>
<li>稀疏初始化(Sparse Initialazation)</li>
<li>初始化偏差</li>
</ol>
<h2 id="学习率">学习率</h2>
<ol type="1">
<li>学习率的作用</li>
<li><strong>学习率衰减常用参数有哪些</strong></li>
<li>分段常数衰减</li>
<li>指数衰减</li>
<li>自然指数衰减</li>
<li>多项式衰减</li>
<li>余弦衰减</li>
</ol>
<h2 id="dropout-系列问题">Dropout 系列问题</h2>
<ol type="1">
<li><strong>为什么要正则化？</strong> 深度学习可能存在过拟合问题——高方差，有两个解决方法，一个是正则化，另一个是准备更多的数据，这是非常可靠的方法，但你可能无法时时刻刻准备足够多的训练数据或者获取更多数据的成本很高，但正则化通常有助于避免过拟合或减少你的网络误差。<br />
</li>
<li><strong>为什么正则化有利于预防过拟合？</strong></li>
<li><strong>理解dropout正则化</strong> Dropout可以随机删除网络中的神经单元，它为什么可以通过正则化发挥如此大的作用呢？ ​ - 直观上理解：不要依赖于任何一个特征，因为该单元的输入可能随时被清除，因此该单元通过这种方式传播下去，并为单元的四个输入增加一点权重，通过传播所有权重，dropout将产生收缩权重的平方范数的效果，和之前讲的L2正则化类似；实施dropout的结果实它会压缩权重，并完成一些预防过拟合的外层正则化；L2对不同权重的衰减是不同的，它取决于激活函数倍增的大小。
<ul>
<li>起平均作用：在不适用 dropout 的条件下，使用 5 个不同的神经网络去训练相同的数据集，那么我们可以使用少数服从多数的方法。比如 3 个神经网络的结果是 b，2 个神经网络的结果是 a，那么结果就是 b。同理，使用 dropout 就相当于训练了不同的神经网络。</li>
</ul></li>
<li><strong>dropout率的选择</strong></li>
<li><strong>dropout有什么缺点？</strong> dropout一大缺点就是代价函数J不再被明确定义，每次迭代，都会随机移除一些节点，如果再三检查梯度下降的性能，实际上是很难进行复查的。所以我们失去了调试工具来绘制这样的图片。</li>
</ol>
<p>参考文献： 1. <a href="https://zhuanlan.zhihu.com/p/38200980" target="_blank" rel="noopener">深度学习中Dropout原理解析</a></p>
<h1 id="第六章-循环神经网络rnn">第六章 循环神经网络（RNN）</h1>
<h2 id="为什么需要rnn">为什么需要RNN？</h2>
<h2 id="图解rnn基本结构">图解RNN基本结构</h2>
<ol type="1">
<li>vector-to-sequence：例如，输入图像输出一段话</li>
<li>sequence-to-vector：例如，输入一段话判断类别</li>
<li>Encoder-Decoder(seq2seq)：例如机器翻译等</li>
</ol>
<h2 id="rnns典型特点">RNNs典型特点？</h2>
<ol type="1">
<li>处理序列数据</li>
<li>当前步的输出与之前步的输出有关，因此被称为循环神经网络</li>
<li>隐藏层权重共享</li>
<li><strong>理论上，RNNs能够对任何长度序列数据进行处理。但是在实践中，为了降低复杂度往往假设当前的状态只与之前某几个时刻状态相关。</strong>（这句话是什么意思，基本的 RNN 不都是可以处理任意长的语句？只不过会出现梯度爆炸和梯度消失的问题。）</li>
</ol>
<h2 id="cnn和rnn的区别">CNN和RNN的区别？</h2>
<table>
<colgroup>
<col style="width: 9%" />
<col style="width: 90%" />
</colgroup>
<thead>
<tr class="header">
<th>类别</th>
<th>特点描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>相同点</td>
<td>1、传统神经网络的扩展。<br />2、前向计算产生结果，反向计算模型更新。<br />3、每层神经网络横向可以多个神经元共存,纵向可以有多层神经网络连接。</td>
</tr>
<tr class="even">
<td>不同点</td>
<td>1、CNN空间扩展，神经元与特征卷积；RNN时间扩展，神经元与多个时间输出计算<br />2、RNN可以用于描述时间上连续状态的输出，有记忆功能，CNN用于静态输出</td>
</tr>
</tbody>
</table>
<h2 id="rnns和fnns有什么区别">RNNs和FNNs有什么区别？</h2>
<h2 id="rnns训练和传统ann训练异同点">RNNs训练和传统ANN训练异同点？</h2>
<h2 id="为什么rnn训练的时候loss波动很大">为什么RNN训练的时候Loss波动很大</h2>
<p>由于RNN特有的memory会影响后面 time step 的计算，所以梯度时大时小，learning rate没法个性化的调整，导致RNN在train的过程中，Loss会震荡起伏，为了解决RNN的这个问题，在训练的时候，可以设置临界值，当梯度大于某个临界值，直接截断，用这个临界值作为梯度的大小，防止大幅震荡。</p>
<h2 id="标准rnn前向输出流程">标准RNN前向输出流程</h2>
<h2 id="bptt算法推导">BPTT算法推导</h2>
<h2 id="rnn中为什么会出现梯度消失">RNN中为什么会出现梯度消失？</h2>
<div class="note default"><ol type="1">
<li><a href="https://yan624.github.io/·zcy/AI/nlp/NLP模型训练分析.html#梯度爆炸">NLP模型训练分析#梯度爆炸</a> 虽然讲得是 clip gradient，但是结合了以前的笔记同时讲了<strong>梯度爆炸</strong>和<strong>梯度消失</strong>。</li>
</ol>
</div>
<h2 id="如何解决rnn中的梯度消失问题">如何解决RNN中的梯度消失问题？</h2>
<p>解决办法是将 sigmoid 函数替换为 tanh。注意，在 CNN 中的首选激活函数是 ReLu，但是对于 RNN 来说，首选是 tanh，因为 ReLu 的右半轴是 <code>y=x</code>，会导致 RNN 的 timestep 越往后输出值越大。</p>
<h2 id="lstm">LSTM</h2>
<div class="note default"><ol type="1">
<li><a href="https://yan624.github.io/posts/5e27260b.html#长短期记忆——Long-Short-term-Memory-LSTM">吴恩达李宏毅综合学习笔记：RNN入门#长短期记忆——Long-Short-term-Memory-LSTM</a></li>
<li><a href="https://yan624.github.io/posts/d5936d3s.html#LSTM">深度学习算法（三）：RNN 各种机制#LSTM</a></li>
</ol>
</div>
<h2 id="lstms与grus的区别">LSTMs与GRUs的区别</h2>
<h2 id="rnns在nlp中典型应用">RNNs在NLP中典型应用？</h2>
<h2 id="常见的rnns扩展和改进模型">常见的RNNs扩展和改进模型</h2>
<ol type="1">
<li>Simple RNNs(SRNs)</li>
<li>Bidirectional RNNs</li>
<li>Deep RNNs</li>
<li>Echo State Networks（ESNs）</li>
<li>Gated Recurrent Unit Recurrent Neural Networks</li>
<li>Bidirectional LSTMs</li>
<li>Stacked LSTMs</li>
<li>Clockwork RNNs(CW-RNNs)</li>
<li>CNN-LSTMs</li>
</ol>
<h1 id="第十三章-优化算法">第十三章 优化算法</h1>
<h1 id="第十四章-超参数调整">第十四章 超参数调整</h1>
<h1 id="第十六章-自然语言处理nlp">第十六章 自然语言处理（NLP）</h1>
<h1 id="第十七章-模型压缩及移动端部署">第十七章 模型压缩及移动端部署</h1>
<h1 id="第十八章-后端架构选型离线及实时计算">第十八章 后端架构选型、离线及实时计算</h1>
<h1 id="自己的疑问">自己的疑问</h1>
<h2 id="为什么mini-batch比普通的梯度下降快">为什么Mini-batch比普通的梯度下降快？</h2>
<h2 id="指数加权平均的作用">指数加权平均的作用</h2>
<h2 id="为什么要deep">为什么要deep</h2>
<div class="note primary"><p>学了有一段时间的深度学习，但是有个问题一直没想明白。那就是将hidden layer叠多层的意义是什么？</p>
</div>
<p>可以观察下图发现，确实越deep代价越小。左边的两列显示了，层数越多代价越小。右边两列显示即使整个神经网络参数类似，但是明显越deep代价越小。同一行代表hidden layer的参数接近。那个size指的是神经网络中的参数。再看最后一行，它显示即使参数暴增到16k，代价也不是很低。图中红框还显示了2层2k的model比1层16k的model好多了。 下图是由底下的论文的作者做的实验得出的结论。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/深度学习中的一些疑问总结/隐藏层层数对cost的影响.jpg" alt="隐藏层层数对cost的影响" /> <strong>那么为什么神经网络越深效果越好呢？</strong> 这其实归功于modularization——模块化。如下图所示，如果直接写一个model用于将4种人分类，那么可能会出现某类人的数据并不多的情况，比如长发的男生的数据可能并不多。那么分类的准确率可能会不是很高。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/深度学习中的一些疑问总结/解释why%20deep的例子.jpg" alt="解释why deep的例子" /> 下图中先将其分类为男女以及长短发，然后再进一步分类。虽然说长发男生的数据比较少，但是男女和长短发的数据有很多，我们可以得到一个很好的模型。之后我们再叠一层用于进一步分类，此时，由于我们已经做了上一步的分类，所以新的一层可以使用上一层的特征。 上一层的分类已经把难的事情——辨别男女，辨别长短发等解决了，所以后一层只要使用少量的数据就能进行分类。 <strong>没有使用模块化</strong>的那个模型，它是用少量的数据硬生生地去识别长发男生。<strong>使用模组化</strong>的模型是先识别男女以及长短发，再通过调用前一步的特征判断。下图4个分类器区别可能只是辨别的方式不同而已，比如权重不同。输入一张图片之后第一层已经可以辨别是男还是女，长发还是短发，然后后一层经过简单的运算就可以确定了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/深度学习中的一些疑问总结/模块化后.jpg" alt="模块化后" /> 经过上面的解释，可能已经大致理解是什么意思了。但是真要讲清还有点问题，尤其是模块化怎么做。 但是李宏毅老师说模块化其实是神经网络从数据中<strong>自动</strong>学到的。</p>
<h3 id="更多的例子">更多的例子</h3>
<p>用数电的逻辑门来举例，但是我没怎么学过数电，所以没有理解。 另一个比较贴近生活的例子，就是剪窗花。没有人会一瓣花一瓣花的去剪窗花，都是将纸先折好，然后一步剪完。这就是模块化了。</p>
<p>还有其他领域的人也有过解读，个人理解why deep这个问题可能到现在没有一个官方的回应，可能前辈也是误打误撞才发现deep learning很牛。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/深度学习中的一些疑问总结/其他领域对为什么要deep的解读.jpg" alt="其他领域对为什么要deep的解读" /></p>
<h3 id="吴恩达老师的解释">吴恩达老师的解释</h3>
<p><a href="https://mooc.study.163.com/learn/2001281002?tid=2001392029&amp;_trace_c_p_k2_=03442699ea78498a873a1dbe2fcfee40#/learn/content?type=detail&amp;id=2001701022" target="_blank" rel="noopener">该视频</a>也做了解释。</p>
<h2 id="词向量乘上权重以及做梯度下降有什么意义">词向量乘上权重以及做梯度下降有什么意义</h2>
<p><a href="https://mooc.study.163.com/learn/2001280005?tid=2001391038&amp;_trace_c_p_k2_=023fecd41c524f0d9485b18d2d773f53#/learn/content?type=detail&amp;id=2001770038" target="_blank" rel="noopener">本文灵感</a> 本文疑问： 1. 词向量在神经网络隐藏层中乘一个权重，这个权重有什么用？ 2. 神经网络训练完成后送入softmax中，这个输出层的权重又有什么用？ 3. 梯度下降到底在算什么东西，在算谁的最小值？ 4. 为什么它可以预测出应该填入juice？ 5. 它怎么预测其他句子？</p>
<h3 id="准备词向量">准备词向量</h3>
<p>假设有这么一句话：I want a glass of orange ___. 要做的是估计划线处应该填入什么词。答案是juice。 首先我们需要一个词典——vocabulary，每个单词对应一个索引，这是通用步骤。词表大小为10000。 然后将上述的句子，从单词转成索引形式。即： I want a glass of orange ---&gt; 4343 9665 1 3852 6163 6257 此外每一个单词都会对应一个词向量，而词表中所有单词的词向量就组合一个词嵌入矩阵。词表以及词向量都是可以找一些预训练的，比如<strong>GloVe</strong>。 梳理一遍就是： 单词:索引 索引:词向量 所以可以通过单词间接地获取到词向量。关于索引对应词向量，实际上是里面没有索引的因为一个矩阵它本身就有一个属性表示索引，如第0行就是代表第0个单词，第1行就是代表第一个单词。 总而言之，我们通过单词获取索引后，就能通过该索引直接获取词向量。伪代码可以表示为： <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">index = vocabulary.get_index('want') <span class="comment"># 索引为9665</span></span><br><span class="line">word_vector = embedding_matrix[index, :] <span class="comment"># 获得词向量</span></span><br></pre></td></tr></table></figure> <strong>对于词嵌入矩阵的行代表词向量，还是列代表词向量不必纠结。</strong>你要乐意可以改成 <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line">word_vector = embedding_matrix[:, index] <span class="comment"># 获得词向量</span></span><br></pre></td></tr></table></figure> 如果使用one hot编码来执行上述代码就是将9665转为one hot编码，即除了9665位置为1，其余位置全为0。然后<span class="math inline">\(word\_vector = embedding\_matrix^T * word\_one\_hot\)</span>。这样也能得到词向量，但是由于one hot编码全是0，算起来速度太慢了。 现在有了句子“I want a glass of orange”的所有词向量，接下来要做的是将这些词向量从头到尾拼在一起，接成一个更长的向量，也就是6倍长的向量。原词向量是300维，拼接完成后是1800维。然后将这个向量输入一个神经网络中，最后经过softmax函数进行预测，预测范围是在10000个单词中，看谁的概率大。</p>
<h3 id="意义">意义</h3>
<p>将词向量送入神经网络中当然还需要梯度下降进行迭代。这里会有很多疑问， 1. 词向量在神经网络隐藏层中乘一个权重，这个权重有什么用？ 2. 神经网络训练完成后送入softmax中，这个输出层的权重又有什么用？ 3. 梯度下降到底在算什么东西，在算谁的最小值？ 4. 为什么它可以预测出应该填入juice？ 5. 它怎么预测其他句子？</p>
<p>我进行逐一思考，本文仅为自己的理解。 首先其实有一件事很多视频没讲，可能他们认为这是一件很平常的事，所以没讲。 上述的这个步骤并不是预测步骤，而是在进行迭代，所以是一个训练步骤。人家之所以说<em>我们可以通过这个神经网络预测出单词为juice</em>，是因为逻辑上是这样的。 由于是训练步骤，所以我们有一个很重要的数据，最终结果。最终结果我们是知道的，然而我们初学者在考虑整个流程时，没把最终结果算进去，因为老师说<em>我们可以通过这个神经网络预测出单词为juice</em>，由于是<em>预测</em>，那么结果肯定没有啊。这很合乎逻辑。所以就陷入了一个思维的怪圈，<strong>正确的逻辑是：</strong> 1. 首先我们知道最终结果，所以当第一次迭代时，所有的权重都是随机初始化的，1、2两个问题也就没有意义了。第一次迭代完毕后，结果肯定稀巴烂，所以进行梯度下降。 2. 这里面我们又会碰到一个问题，就是梯度下降到底在算什么？其实这里的疑问来自我们的潜意识始终将句子当做文字在看，自然而然就意识不到梯度下降在干什么。而其实我们在几步之前就已经将文字转为词向量了。 词向量说白了就是一堆浮点型数字，而最终结果juice也是一个词向量，所以实际上就是将一个权重矩阵乘上一个1800维的向量，得到一个输出值（may be 激活值），然后将这个输出值和juice的向量放入代价函数中进行计算，接下来的梯度下降其实就是跟正常的步骤一样。 3. <strong>梯度下降就是在寻找一个合适的权重矩阵使得权重矩阵乘1800维向量得到的值接近juice的向量。</strong> 这里在解释第3个问题时，顺便也解释了第1、2个问题。<strong>权重值实际上就是用来使得预测值和实际结果越接近越好</strong> 4. 由于开头就说了我们实际上是知道划线处应该填juice，所以第4个问题压根不需要解答，因为我们本来就知道应该填juice，也没必要预测。之前之所以有这个问题，是因为我们潜意识觉得老师说<em>我们可以通过这个神经网络预测出单词为juice</em>。 5. 至于第5个问题如何预测其他句子。打个比方，现在预测一个新的句子：I want a glass of apple ___. 由于我们知道词嵌入矩阵是由很多单词的词向量组成的。而一个单词词向量其实就是一堆特征组成的，对比两个句子，apple和orange的词向量肯定很接近，因为它们都是水果，它们的特征（水多不多，好不好吃，是不是水果，有没有性别特征，是不是动词等）都类似。 而我们之前已经训练了一个神经网络，我们得到了所需要的权重值，我们直接把这个权重值乘上新句子的词向量，那么结果肯定和权重值乘上之前句子的词向量的结果很接近。因为它们之间的区别仅仅是apple和orange的词向量不同，并且apple和orange的词向量其实也并不是完全不同，只是略有不同。所以二者的结果自然也差不多。 最后经过softmax函数在10000个单词之中预测，输出的结果必然都是juice。</p>
<h3 id="其他">其他</h3>
<p>这里还会有一个问题，那么如果需要预测的句子单词数不一致怎么办？ 之前两个例子的句子都是6个单词，预测第7个单词。那要是前面有10个单词，我要预测第11个单词怎么办？ 其实可以只考虑划线处前几个单词，比如只考虑划线处前4个单词，这样输入的维度就相同了。 在本文开头的参考视频里，吴恩达老师讲得很清楚了。由古圣先贤总结，一般来说取前4个单词即可，当然你自己也可以用其他办法。</p>
]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Fully Statistical Neural Belief Tracking</title>
    <url>/posts/9b4471e8.html</url>
    <content><![CDATA[<h1 id="摘要翻译">摘要翻译</h1>
<p>本文提出 NBT 的改进。现有的 NBT 使用人工制作的 belief state update mechanism，每当模型被部署到新的对话领域，就要涉及到代价颇高的手动重新调整。我们证明，这种更新机制其实可以与 NBT 模型的语义解码和上下文建模部分进行联合学习，从而从 DST 框架中消除最后一个基于规则的模块。我们提出了两种不同的统计更新机制，并证明对话动态可以用非常少量的附加模型参数来建模。 <a id="more"></a></p>
<h1 id="方法论">方法论</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>NBT</tag>
      </tags>
  </entry>
  <entry>
    <title>A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling</title>
    <url>/posts/1dc2c7cd.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.xilesou.top/pdf/1812.10235.pdf" target="_blank" rel="noopener">论文地址</a>，作者是 Yu Wang et.al.，发表于 2018 年 12 月。</p>
</div>
<h1 id="摘要翻译">摘要翻译</h1>
<p><strong>意图检测和 slot filling 是构建 SLU 的两个主要任务</strong>。现在，多个基于深度学习的模型在这些任务上都取得了良好的效果。最有效的算法是基于 seq2seq（or encoder-decoder）的结构，并使用单独或联合的模型生成<strong>意图</strong>和<strong>语义标记</strong>（<strong>semantic tags</strong>）。然而，以往的研究大多将意图检测和 slot filling 作为两个独立的平行的任务来处理，或者使用 seq2seq 模型来生成语义标记和意图。这些方法大多采用一个（联合的（joint））神经网络模型（包括 encoder-decoder 结构）对两个任务进行建模，因此可能无法充分利用它们之间的交叉影响。本文设计了一种新的基于 <strong>Bi-model</strong> 的 <strong>RNN 语义框架解析神经网络结构</strong>（<strong>RNN semantic frame parsing network structures</strong>），利用两个有关联的双向 LSTMs（<strong>BLSTM</strong>）来将它们之间的相互影响考虑进去，共同完成意图检测和 slot filling 任务。我们的带 decoder 的 Bi-model 结构在 ATIS 上取得了一流的结果，意图准确率提高了0.5%，slot filling 准确率提高了0.9%。 <a id="more"></a></p>
<h1 id="引言">引言</h1>
<p>过去几十年内，SLU 上的研究进展迅速。 1. 意图识别做法：regression, SVM, deep NN 2. slot filling 做法：CRF, RNN</p>
<p>余下章节如下所述： 1. 第二节：已知的深度学习方法简要概述（意图检测和 slot filling） 2. 第三节：介绍 Bi-model 3. 第四节：展示不同数据集上的实验</p>
<h1 id="bi-model-rnn-structures-for-joint-semantic-frame-parsing">Bi-model RNN structures for joint semantic frame parsing</h1>
<p>尽管在这两个任务上使用 seq2seq 获得了成功，但是大多数方法仍旧在每个任务上使用单一的 RNN 模型。他们将意图检测和 slot filling 看作是两个独立的任务。本节，使用 B-model 考虑它俩的关联，从而进一步提高性能。</p>
<h2 id="bi-model-rnn-structures">Bi-model RNN Structures</h2>
<p>两个模型（a)Bi-model structure with a decoder; b)Bi-model structure without a decoder）的图例如图 1 所示。两个结构十分相似，图 1a 包含了一个基于 LSTM 的 decoder，因此除了有一个 encoder state <span class="math inline">\(h_t\)</span> 之外，还有一个额外的 decoder state <span class="math inline">\(s_t\)</span>。 <strong>注意：从多个模型/多模态中使用某些信息以实现更好性能的概念已经被广泛应用于深度学习、系统识别以及最近也有被用在强化学习领域之中。除开使用共用的信息，本论文，我们将引入一个全新的方法（通过分享它们之间的内部 state 信息）以异步地训练多个神经网络。</strong></p>
<h3 id="bi-model-structure-with-a-decoder">Bi-model structure with a decoder</h3>
<p>Bi-model structure with a decoder 如图 1a 所示，架构中有两个互联的 Bi-LSTMs(BLSTMs)，一个用于意图检测，一个用于 slot filling。每个 BLSTM 分别正向和反向地在输入语句序列（<span class="math inline">\(x_1, x_2, \cdots, x_n\)</span>）上读取信息，并且生成两个隐藏状态序列 <span class="math inline">\(hf_t\)</span> 和 <span class="math inline">\(hb_t\)</span>。然后将 <span class="math inline">\(hf_t\)</span> 和 <span class="math inline">\(hb_t\)</span> 拼接成在第 t 个时间步上的最终 BLSTM state <span class="math inline">\(h_t = [hf_t, hb_t]\)</span>。因此我们的双向 LSTM <span class="math inline">\(f_i(\cdot)\)</span> 生成了一个隐藏状态序列 <span class="math inline">\((h^i_1, h^i_2, \cdots, h^i_n)\)</span>，其中 i=1 对应神经网络的意图检测任务，i = 2 对应 slot filling 任务。 为了进行意图检测，隐藏状态 <span class="math inline">\(h^1_t\)</span> 与 slot filling 任务中 由<span class="math inline">\(f_2(\cdot)\)</span> 产生的 <span class="math inline">\(h^2_t\)</span> 组合在一起，以生成在第 t 个时间步由 <span class="math inline">\(g_1(\cdot)\)</span> 产生的状态 <span class="math inline">\(s^1_t\)</span>： <span class="math display">\[
s^1_t = \Phi(s^1_{t-1}, h^1_{n-1}, h^2_{n-1})\\
y^1_{intent} = \arg\max_{\hat{y}^1_n} P(\hat{y}^1_n | s^1_{n-1}, h^1_{n-1}, h^2_{n-1})
\]</span> 其中 <span class="math inline">\(\hat{y}^1_n\)</span> 包含在最后一个时间步 t 的所有意图标签的预测概率。 对于 slot filling 任务类似。 <div class="note danger"><p><span class="math inline">\(g_1(\cdot)\)</span> 和 <span class="math inline">\(g_2(\cdot)\)</span> 实际上就是 <strong>decoder</strong>。</p>
</div></p>
<h3 id="bi-model-structure-without-a-decoder">Bi-Model structure without a decoder</h3>
<p>就是没有 <span class="math inline">\(g(\cdot)\)</span> 产生的 s。</p>
<h3 id="asynchronous-training">Asynchronous training</h3>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>uber plato v0.2使用注意点（踩坑）</title>
    <url>/posts/f067676c.html</url>
    <content><![CDATA[<ol type="1">
<li><code>/plato/controller/basic_controller.py</code>，line 415 中，将三个 <code>'/'</code> 改成 <code>os.sep</code>，所有的 controller 都要改。否则会出现 <code>ValueError: Configuration file CamRest_text.yaml not found!</code> 的错误，这是因为 windows 电脑的分隔符是 <code>\\</code> 而不是 <code>'/'</code>。
<ul>
<li>类似的错误有很多，比如数据解析器，gui_controller 中，都需要改正</li>
<li>建议遇到错误的时候再改，要不然改起来太麻烦了 <a id="more"></a></li>
</ul></li>
<li><strong>如果使用 pycharm 运行 plato 而不是命令行</strong>，有几点需要注意（在命令行中运行时，加载文件都是从项目根目录找的）。本质上，Plato 在加载模型时，使用了相对路径。即默认程序会从项目根目录查找文件，但是在 pycharm 中，会从当前正在运行的模块中查找文件。以下是两种情况，分别为两种解决办法：
<ul>
<li>在运行 LudwigNLU（或自定义的预训练 NLU） 而不是 SlotFillingNLU 的情况下。在包 <code>applications/cambridge_restaurants</code> 中有一个模块为 <code>cambridge_restaurants_agent.py</code>，它可以供人直接运行（只需稍作更改）。但是这会报错 <code>Plato error! Ludwig nlu: Model directory models/camrest_nlu/sys/experiment_run/model not found</code>，这是因为在 <code>applications/cambridge_restaurants</code> 路径下运行程序，那么项目的根路径就变了 <code>plato/applications/cambridge_restaurants</code> 而不是 <code>plato</code>。所以在加载模型时，模型的路径错了。所以可以在 plato 项目的根路径下新建一个 py 文件，然后把 <code>cambridge_restaurants_agent.py</code> 的代码拷过去。</li>
<li>使用 multi-agent 时，也会产生类似的错误。在 <code>plato/agent/component/dialogue_policy/reinforcement_learning/wolf_phc_policy.py</code> 文件的 <code>load()</code> 方法中，加载 pkl 文件时，文件路径有问题，应该是当前文件并非处于根目录造成的，只要改为绝对路径即可。将 <code>if isinstance(path, str):</code> 内的代码更改为： <figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> plato</span><br><span class="line">plato_path = <span class="string">"/"</span>.join(plato.__file__.split(os.sep)[:<span class="type">-2</span>]) + <span class="string">'/'</span></span><br><span class="line"><span class="keyword">new</span><span class="type">_path</span> = plato_path + path</span><br><span class="line"><span class="keyword">if</span> os.path.isfile(<span class="keyword">new</span><span class="type">_path</span>):<span class="type"></span></span><br><span class="line"><span class="type">	with open</span>(<span class="keyword">new</span><span class="type">_path</span>, <span class="string">'rb'</span>) as file:<span class="type"></span></span><br><span class="line"><span class="type">		obj </span>= pickle.load(file)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> <span class="string">'Q'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.Q = obj[<span class="string">'Q'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'pi'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.pi = obj[<span class="string">'pi'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'mean_pi'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.mean_pi = obj[<span class="string">'mean_pi'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'state_counter'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.state_counter = obj[<span class="string">'state_counter'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'a'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.alpha = obj[<span class="string">'a'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'e'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.epsilon = obj[<span class="string">'e'</span>]</span><br><span class="line">		<span class="keyword">if</span> <span class="string">'g'</span> <span class="keyword">in</span> obj:<span class="type"></span></span><br><span class="line"><span class="type">			self</span>.gamma = obj[<span class="string">'g'</span>]</span><br><span class="line"></span><br><span class="line">		print(<span class="string">'WoLF-PHC dialogue_policy loaded from &#123;0&#125;.'</span></span><br><span class="line">			  .format(<span class="keyword">new</span><span class="type">_path</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:<span class="type"></span></span><br><span class="line"><span class="type">	print</span>(<span class="string">'Warning! WoLF-PHC dialogue_policy file %s not found'</span></span><br><span class="line">		  % <span class="keyword">new</span><span class="type">_path</span>)</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li>使用 ludwig 训练 NLU/DST/NLG 时，会出现找不到日志文件夹的错误，因为它没有自动创建 log 文件夹的上一级文件夹。个人认为是框架的 bug，所以在训练的时候应该要加上 <code>--skip_save_log</code> 跳过日志记录。</li>
</ol>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>plato</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Belief Tracker: Data-Driven Dialogue State Tracking</title>
    <url>/posts/f102a8ae.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">论文地址</a>，作者是 Nikola Mrkšić，发表于 2016 年。</p>
</div>
<h1 id="摘要">摘要</h1>
<p>现代口语对话系统的核心组成部分之一是 <strong>belief tracker</strong>，它可以在对话的每一步估计用户的目标。然而，目前大多数方法难以扩展到更大、更复杂的对话领域。这是由于他们依赖：<strong>a）</strong>口语理解（<strong>Spoken Language Understanding</strong>，<strong>SLU</strong>）模型，需要大量注释的训练数据；或者 <strong>b）</strong>手工制作的词汇表，用于捕捉用户语言中的一些词语变种。我们提出了一个新的 <strong>Neural Belief Tracking</strong>（<strong>NBT</strong>）框架，通过将模型建立在表征学习（最新进展的表征学习，即以前没有人用词向量去做过 DST）上以此克服了这些问题。NBT 模型对预训练的词向量进行推理，学习将它们组合成用户话语（user utterances）和对话上下文（dialogue context）的分布式表示。我们对两个数据集的评估表明……（你懂得，不翻译了）。 <a id="more"></a></p>
<h1 id="引言">引言</h1>
<p>口语对话系统（<strong>Spoken dialogue systems</strong>, <strong>SDS</strong>）允许用户通过交谈的方式与计算机进行交互。</p>
<ul>
<li>基于任务的系统帮助用户实现目标，比如找酒店或者预定航班。SDS 的其中一个模组 <strong>dialogue state tracking</strong> (<strong>DST</strong>) 用于解释用户输入并更新 <strong>belief state</strong>（系统对会话状态的内部表示（Young et al., 2010））。这是下游 <strong>dialogue manager</strong> 用于决定系统下一步应执行操作的 dialogue <strong>states</strong> 的概率分布（Su et al., 2016a,b）；然后 <strong>system action</strong> 由自然语言生成器（<strong>NLG</strong>）描述（Wen et al., 2015a,b; <a href="https://www.aclweb.org/anthology/P15-1044.pdf" target="_blank" rel="noopener">Dušek, Jurcicek, 2015</a>）。</li>
<li><strong>The Dialogue State Tracking Challenge</strong>（<strong>DSTC</strong>）系列公开任务提供了一个带标记数据集的通用评估框架(Williams et al., 2016)。该框架由 domain <strong>ontology</strong> 支持，ontology 定义一系列 <strong>slots</strong> 和 每个 slot 可采用的 <strong>values</strong>。系统必须跟踪用户表达的搜索约束（<strong>goals</strong> or <strong>informable slots</strong>）以及询问用户对搜索结果（<strong>request</strong>）的问题。这需要考虑每个用户的话语（通过语音识别器的输入）和对话上下文（<strong>dialogue context</strong>）（例如，系统刚刚说了什么）。图 1（<strong>博主注</strong>：我一般在论文笔记中不放图，但这张图可以对 DST 有一个直观的了解，推荐去原论文看一下）中给出了一个例子，DST 模块依赖于识别用户话语中的 ontology items。</li>
<li>在一个对话回合内，传统统计方法使用一个单独的 SLU 模组去处理词汇多样性的问题。然而，训练这些模型需要大量特定领域的标注。
<ul>
<li>另外，由 Henderson et al. (2014d) 所展示的，<strong>turn-level SLU</strong> 和 <strong>cross-turn DST</strong> 可以合并成单独一个模型以实现更好的 belief tracking 性能。<strong>这样的耦合模型通常依赖于人工构造的语义词典来识别所提到的多样的（词汇上或形态上） ontology items</strong>。图 2 给出了三个 slot-value 对的词典示例。</li>
</ul></li>
<li>本文提出了一个新模型——NBT，SLU 和 DST 的组合版</li>
</ul>
<h1 id="背景">背景</h1>
<h2 id="separate-slu">Separate SLU</h2>
<p>传统的 SDS 管道使用 SLU 解码器去探测在 ASR 输出中的 slot-value pair。然后下游 DST 模型将这一信息与上一轮的对话上下文结合，以此更新 belief state。</p>
<h2 id="joint-sludst">Joint SLU/DST</h2>
<p>Joint model 通常依赖一个被称为 delexicalisation 策略，凭此，文本中出现的 slots 和 values 被替换为通用的单词。</p>
<h1 id="neural-belief-tracker">Neural Belief Tracker</h1>
<ul>
<li>功能：在对话过程中，用于检测在给定轮次的情况下的 slot-value 对（即用户的目的）。</li>
<li>输入：它的输入是用户进行输入之前的 <strong>system dialogue acts</strong>，<strong>user utterance</strong> 以及一个候选 <strong>slot-value pair</strong>。</li>
<li>例子：模型也许要决定 <em>'I’m looking for good pizza'</em> 是否表达出了目的 <code>FOOD=ITALIAN</code>。要执行 belief tracking，NBT 模型要迭代所有的候选 slot-value pairs（由本体定义），并且做出决定刚才是否有一个 pair 被用户表达出来了。</li>
</ul>
<p>图 3 呈现了模型中的信息流程。NBT 架构的第一层在给定三个输入的情况下执行表征学习（<strong>representation learning</strong>），产生用户话语（user utterance） <strong>r</strong>，当前候选 slot-value <strong>c</strong> 以及 system dialogue acts <span class="math inline">\(t_q, t_s, t_v\)</span> 的向量表征。然后，学习到的向量表征通过 <strong>context modelling</strong> 和 <strong>semantic decoding</strong> 子模组交互，得到中间 interaction summary 向量 <span class="math inline">\(d_r, d_c\)</span> and d。它们被用作最终 <strong>decision-making</strong> 模组的输入，<strong>该模组决定用户是否表达了由候选 slot-value pair 表示的意图（即二元分类）</strong>。</p>
<h2 id="representation-learning">Representation Learning</h2>
<p>训练向量表征，以一个向量表示一句话。</p>
<ul>
<li>NBT-DNN：用 n-grams(1, 2, 3) 向量之和表示 utterance 向量。</li>
<li>NBT-CNN：使用 CNN 训练，得到 utterance 向量。</li>
</ul>
<h2 id="semantic-decoding">Semantic Decoding</h2>
<div class="note warning"><p><strong>博主注</strong>：Semantic Decoding 指的是用户的 utterance 和 一个 slot-value pair 进行计算，最后得到向量 d。然后再与向量 m 进行计算，得到一个二维的向量，以此来断定该 slot-value pair 是否与 utterance 有关。</p>
<p>其次，不管有无关系，都会执行下一次的匹配。即再次输入用户的 utterance 和下一个 slot-value pair 进行匹配。</p>
<p>以此反复，直到迭代完所有的 slot-value（预定义在系统中）。最后得到想要的多个/一个/零个 slot-value pair。</p>
</div>
<p>图 3 的 NBT 图示显示了 utterance 表征 <strong>r</strong> 和候选 slot-value pair <strong>c</strong> 直接通过 <strong>semantic decoding</strong> 模组交互。<strong>该组件决定用户是否清晰地表达出与当前候选对匹配的意图（即不考虑对话上下文）</strong>。</p>
<p>这种匹配的例子包括 <code>'I want Thai food'</code> 和 <code>'food=Thai'</code>，或者要求更高的食物，如 <code>a pricey restaurant</code> 和 <code>'price=expensive'</code>。</p>
<p>这是使用高质量的预训练词向量发挥的作用：delexicalisation-based model 可以处理前一个例子，但在后一种情况下是无能为力的，除非人类专家提供了一个语义词典来列出 domain ontology 中的每个值的所有可能的替换。</p>
<p>让候选对的 slot name and value 的向量空间表示 由 <span class="math inline">\(c_s\)</span> 和 <span class="math inline">\(c_v\)</span> 给出（多个单词的 slot name/value 向量相加）。NBT 模型学习将这个元组映射成一个向量 <strong>c</strong>，该向量的维数与 utterance 表征 <strong>r</strong> 相同。然后，这两个表征被强制交互，以学习一个相似性度量标准： <span class="math display">\[
c = \sigma(W^s_c(c_s + c_v) + b^s_c) \\
d = r \otimes c
\]</span></p>
<p>其中 <span class="math inline">\(\otimes\)</span>（<strong>博主注</strong>：论文中是用的这个符号，但是 Hadamard product 应该是使用 <span class="math inline">\(\circ\)</span> 或者 <span class="math inline">\(\odot\)</span>） 代表 <strong>element-wise</strong> 相乘（<strong>Hadamard 乘积</strong>）。点积，看起来像更直观的相似性度量，但是它会把 d 中丰富的特性集减少为单个标量（<strong>博主注</strong>：即向量点积的结果是一个值，而不是向量）。元素乘法允许下游网络通过学习 <strong>r</strong> 和 <strong>c</strong> 中特征集之间的非线性交互，更好地利用其参数。</p>
<h2 id="context-modelling">Context Modelling</h2>
<p>这个 decoder 还不足以从人机对话的 utterances 中提取意图，为了理解一些查询，belief tracker 必须注意 context，即 <code>the flow of dialogue leading up to the latest user utterance</code>。虽然所有之前的系统和用户的语句都很重要，但是最相关的一句是上一句系统语句，对话系统可以执行以下两个 system acts（除去其他的行为）中的一个：</p>
<ol type="1">
<li>System Requests：系统询问用户关于一个特定 slot <span class="math inline">\(T_q\)</span> 的值。如果系统的语句为：<code>'what price range whould you like?'</code>，而用户回答了 <code>any</code>，那么模型必须推断出 <code>price range</code> slot，而不是推断出其他的 slots，比如 <code>area</code> 或者 <code>food</code>。</li>
<li>System Confirm：系统询问用户以确认一个特定 slot-value pair(<span class="math inline">\(T_s, T_v\)</span>) 是否是他们所需约束的一部分。例如，如果用户对问题 <code>'how about Turkish food?'</code> 回复 <code>'yes'</code>，模型就必须感知到 system act 以准确更新 belief state。</li>
</ol>
<p>如果我们使马尔科夫决策只考虑最后一组 system act，我们就可以将 context modelling 纳入 NBT 中。使 <span class="math inline">\(t_q\)</span> 和 (<span class="math inline">\(t_s, t_v\)</span>) 作为 system request 和 confirm acts 的参数的词向量（如果没有，则为零向量）。该模型计算 system acts、候选对（<span class="math inline">\(c_s, c_v\)</span>）和 utterance 表征 <strong>r</strong> 之间的相似性，衡量标准如下所示： <span class="math display">\[
m_r = (c_s \cdot t_q) r \\
m_c = (c_s \cdot t_s) (c_v \cdot t_v) r
\]</span> 其中 <span class="math inline">\(\cdot\)</span> 表示 dot product。计算出的相似度项作为 <strong>gating mechanisms</strong>，<strong>只有当系统询问当前的候选 slot 或 slot-value pair 时，该机制才传递 utterance 表征</strong>。<font color='red'><strong>这种类型的交互对于确认 system act 特别有用：如果系统要求用户确认，用户可能不会提到任何 slot values，而只是肯定或否定。这意味着模型必须考虑 utterance，候选 slot-value pair 和系统提供的 slot value pair 三者之间的交互，如果（且仅当）后两者相同，二元决策才认为用户同意。</strong></font></p>
<div class="note primary"><ol type="1">
<li>比如系统询问：“你觉得中餐怎么样？”，用户回复：“可以。”。那么系统的 slot-value 就是 <code>food=chinese</code>，显而易见只有当<strong>候选</strong> slot-value 等于 <code>food=chinese</code> 时（<strong>博主注</strong>：NBT 模型的做法是迭代所有预定义的 slot-value 对），<span class="math inline">\((c_s \cdot t_s) (c_v \cdot t_v)\)</span> 的积才是最大的，所以语句“可以。”得以传入到二元决策层。在此可能有疑惑，电脑怎么知道“可以。”代表同意呢？实际上就是词向量那一套，在不断的训练之中，“可以。”就含有了同意的意思。</li>
<li>如果系统询问：“你觉得中餐怎么样？”，用户回复：“不行，我要吃意大利菜。”。逻辑是一样的，当<strong>候选</strong> slot-value 等于 <code>food=chinese</code> 时，才允许“不行，我要吃西餐。”通过。但是不要忘了用户的语句也要与候选 slot-value 进行计算。虽然 <span class="math inline">\(m_c\)</span> 蕴含了信息，但是 d 却匹配不通过，d 的 slot-value 必须是 <code>food=italian</code>。因此 <code>food=chinese</code> 二元决策输出“否”，即 <code>food=chinese</code> 不是当前对话状态的一部分。</li>
<li>以上解释了 <span class="math inline">\(m_c\)</span> 的用途，但是对于 <span class="math inline">\(m_r\)</span>，论文中并没有明确说明。我猜测是使用候选 slot <span class="math inline">\(c_s\)</span> 与系统请求语句 <span class="math inline">\(t_q\)</span> 进行语义匹配。只有 <span class="math inline">\(d\)</span>，<span class="math inline">\(m_r\)</span> 和 <span class="math inline">\(m_c\)</span> 的值都很大时才允许输出“是”。</li>
</ol>
</div>
<h3 id="binary-decision-maker">Binary Decision Maker</h3>
<p>中间表示通过另一个隐藏层，然后合并。如果 <span class="math inline">\(\phi_{dim}(x) = \sigma(Wx+b)\)</span> 是将输入向量 x 映射到 dim 大小向量的层，则输入到最终的 binary softmax（表决策）表示为： <span class="math display">\[y = \Phi_2 (\Phi_{100}(d) + \Phi_{100}(m_r) + \Phi_{100}(m_c))
\]</span></p>
<h1 id="belief-state-update-mechanism">Belief State Update Mechanism</h1>
<p>在 SDS 中，belief tracking 模型在 ASR 上进行操作。尽管语音识别有所改外，但是随着对话系统越来越频繁地在 noisy environments 中使用，目前仍有必要使用不完善的 ASR 系统。</p>
<p>本工作，我们定义了一个简单的 <strong>rule-based belief state</strong> 更新机制，可以应用到 <strong>ASR N-best lists</strong> 中（<strong>博主注</strong>：这样做的原因是来自 ASR 的不准确性，目前语音识别领域还不完善，所以语音识别总归还是有点差错。用户语句可能被语音识别系统预测出多个版本，我们需要根据这些版本的概率来估计 slot-value 的概率）。对于 dialogue turn <strong>t</strong>，令 <span class="math inline">\(sys^{t-1}\)</span> 表示之前的系统输出（即上一轮对话中，系统说的话），令 <span class="math inline">\(h^t\)</span> 表示后验概率为 <span class="math inline">\(p^t_i\)</span> 的 N 个 ASR 假设 <span class="math inline">\(h^t_i\)</span> 的列表。对于任意一个假设 <span class="math inline">\(h^t_i\)</span>，slot <strong>s</strong> 以及 slot value v <span class="math inline">\(\in V_s\)</span>，NBT 模型估计 <span class="math inline">\(\mathbb{P}(s, v | h^t_i, sys^{t-1})\)</span> 的概率，这是 (s, v) 在给定假设中表示的（turn-level）概率。对此类 N 个假设的预测如下所示进行相加： <span class="math display">\[\mathbb{P}(s,v | h^t, sys^{t-1}) = \sum^N_{i=1} p^t_i \mathbb{P}(s,v | h^t_i, sys^{t-1})
\]</span></p>
<div class="note warning"><p>按理说，到此步为止，就已经将 (s, v) 的概率计算出来了，即 <span class="math inline">\(\mathbb{P}(s,v | h^t, sys^{t-1})\)</span>。</p>
<p>但是上文中其实一直提到一个概念，即 turn-level。我们需要计算 turn level 的 (s, v) 的概率。所以我们还要继续计算，也就是下面的两步。最终结果为 <span class="math inline">\(\mathbb{P}(s,v | h^{1:t},sys^{1:t-1})\)</span>，意思是使用一个系数 <span class="math inline">\(\lambda\)</span> 将以前 turn-level 的概率都加起来。最后的概率才是 (s, v) 的概率。（虽然我不知道原理是什么，但是看起来有点像指数加权平均。此外该论文其实给出了参考文献，该文献貌似讲述了 turn-level 的概念。）</p>
</div>
<p>然后，这个 turn-level belief state estimate 与相加到时间 <code>(t-1)</code> 为止的 (cumulative) belief state 组合，以获得更新过的 belief state estimate： <span class="math display">\[\mathbb{P}(s,v | h^{1:t},sys^{1:t-1}) = \lambda \mathbb{P}(s,v | h^t, sys^{t-1}) + (1 - \lambda) \mathbb{P}(s,v | h^{1:t-1}, sys^{1:t-2})
\]</span></p>
<p><span class="math inline">\(\lambda\)</span> 是决定 turn-level 和 前一轮的 belief state estimate 的相对权重的系数。对于 slot <strong>s</strong>，在 turn <strong>t</strong> 时，它的 detected value 集合由下所示： <span class="math display">\[
V^t_s = \{v \in V_s | \mathbb{P}(s,v | h^{1:t},sys^{1:t-1}) \geq 0.5\}
\]</span></p>
<div class="note info"><p>上面的公式应该指的是用 NBT 进行二元分类所得到的所有 (s, v)，再一次经过 Belief State Update Mechanism 后，会产生一个新的概率，如果这个概率大于等于 0.5，那么我们就认为它是与用户输入的话相关的 (s,v)。</p>
<p>比如我们经过 NBT 二元分类得到 {(food, chinese), (food, italian), (pricerange, cheap)}，概率分别为 [0.7, 0.59, 0.67]。而经过 Belief State Update Mechanism 之后，概率变为 [0.8, 0.44, 0.53]。那么我们认为 {(food, chinese), (pricerange, cheap)} 就是我们想要的结果（由于 food=italian 小于 0.5 被剔除了）。</p>
</div>
<p>对于 informable slots（即 goal-tracking），￥%……&amp;*（&amp;……%￥。对于 requests，<span class="math inline">\(V^t_{req}\)</span> 中的所有 slots 都被视为已被请求。由于 requestable slots 用于模拟 single-turn 用户查询，因此它们在轮次中不需要 belief tracking。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>NBT</tag>
      </tags>
  </entry>
  <entry>
    <title>PLATO DIALOGUE SYSTEM: A FLEXIBLE CONVERSATIONAL AI RESEARCH PLATFORM</title>
    <url>/posts/22c7a34a.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/2001.06463v1.pdf" target="_blank" rel="noopener">论文地址</a>，论文作者 Alexandros Papangelis 等，发表于 2020 年。 注：由于该论文的重点是提出一个工具包，故以下将只翻译我认为比较重要的部分。</p>
</div>
<h1 id="本文主要内容">本文主要内容</h1>
<p>本论文中，我们提出了 Plato，一个用 Python 编写的灵活的对话 AI 平台，支持任何类型的会话代理架构。包括从标准架构到具有联合训练组件的架构、单方或多方交互，以及任何会话代理组件的离线或在线训练。Plato 被设计成易于理解和调试的形式，并且对训练每个组件的底层学习框架是不可知的（我直接机翻了，我推测大致意思应该是 Plato 支持任意的深度学习框架）。</p>
<h1 id="引言">引言</h1>
<p>传统上，对话式 AI 系统（Conversational AI systems）由语音识别（<strong>Automatic Speech Recognition</strong>, <strong>ASR</strong>），自然语言理解（<strong>Natural Language Understanding</strong>, <strong>NLU</strong>），对话状态追踪（<strong>Dialogue State Tracking</strong>, <strong>DST</strong>），对话管理（<strong>Dialogue Management</strong>, <strong>DM</strong>），自然语言生成（<strong>Natural Language Generation</strong>, <strong>LG</strong>），<strong>Text To Speech</strong>(<strong>TTS</strong>) 组成。 随着某些技术的发展，一系列的平台和工具包被提出，以构建对话式 AI 系统。每个工具包很大程度上都是被设计在某个特定的例子中，<strong>它们由于某些原因，似乎使得尖端研究与其在生产系统中的应用两部分失去关联</strong>。无论如何，对话式 AI 系统变得越来越有用，需要有一个工具包能够在研究与生产之间搭起一个桥梁，并且能够提供一个完整会话体验的快速原型，其需要拥有 ASR、NLU、DST/DM、NLG 和 TTS 功能。目前仅有几个工具包可以完成以上的需要，例如 RASA。 <a id="more"></a></p>
<h2 id="现存开源对话式-ai-系统">现存开源对话式 AI 系统</h2>
<p>一些工具包以及对话式 AI 平台在近期被提出。以下是一些一流、被广泛采用的平台： - <strong>PyDial</strong>：</p>
<h1 id="plato-架构">Plato 架构</h1>
<p>Plato 可以被用于创建、训练以及评估对话式 AI agents。它主要有四部分组件，即：1）<strong>dialogue</strong>：定义以及实现 dialogue acts 和 dialogue states；2）<strong>domain</strong>：包含对话的本体以及对话系统所需的数据库；3）<strong>controller</strong>：安排对话；4）<strong>agent</strong>：实现每个对话式 agent 的不同组件。四大组件如图 2 所示。<strong>在 Plato 中，每个组件都是使用 YAML 文件中的配置来实例化的</strong>。</p>
<h2 id="dialogue">Dialogue</h2>
<p>Plato 通过对话理论中定义明确的概念，如 dialogue states 和 dialogue acts，使 agents 之间的对话更便利。然而，一个 Plato agent 可能需要执行与对话没有直接关系的动作（例如调用一个 API）或使用言语以外的方式传递信息的动作（例如显示一个图像）。因此，Plato 把 Actions 和 States 建模成抽象的容器，以此从中产生 Dialogue Acts 和 Dialogue States。所以如果需要特定的应用（例如 multi-modal conversational agent），就可以有特定于任务的 Dialogue Acts and States。</p>
<h2 id="domain">Domain</h2>
<p>为了在 Plato 实现一个任务驱动的 slot-filling 对话系统，我们需要规定两种元素，即构成对话系统的 domain： 1. Ontology：在任务驱动的应用中，对于一次会话，ontology 决定了 informable slots（用户提供的信息），requestable slots（用户请求的信息），system requestable slots（系统请求的信息）。 2. Database：虽然 database 可能已经存在，但是 Plato 提供工具从数据中构建对话系统的 domain 和 database。</p>
<p>在酒店预订的对话 agent 例子中，“口味”被认为是一个 informable slot，database 包含了关于酒店不同口味、价格范围、地址等信息。对于非 slot-fliing 的应用，Plato ontologies 和 database 可以扩展以满足特定任务或领域的需求。</p>
<h3 id="domain-creation">Domain creation</h3>
<blockquote>
<p>Plato provides a utility that makes it easy to generate an ontology (a <code>.json</code> file) and a database (SQLite) from a <code>.csv</code> file, with columns representing item attributes and rows representing items (for an example, see <code>plato/example/data/flowershop.csv</code>). The main purpose of this utility is to help quick prototyping of conversational agents. The command <code>plato domain –config &lt;PATH/TO/CONFIG.YAML&gt;</code> calls the utility and generates the appropriate <code>.db</code> and <code>.json</code> files that define the domain. In the YAML configuration file, the user specifies details such as the path to the input <code>.csv</code> file, the columns that represent informable slots, etc.</p>
</blockquote>
<h2 id="controller">Controller</h2>
<p>略</p>
<h2 id="agent">Agent</h2>
<p>Plato 中每个对话应用都有一个或多个 agent。每个 agent 都有一个 role（助手、用户、旅客、导师等）以及一组组件，例如 NLU，DM，DST，dialogue policy，NLG。 每一个组件可以是 rule-based ，也可以是 trained 的。</p>
<h3 id="rule-based-modules">Rule-based modules</h3>
<p>Plato 提供 slot-filiing 对话 agent 的所有组件（rule-based）：<code>slot_filling_nlu</code>，<code>slot_filling_dst</code>，<code>slot_filling_policy</code>，<code>slot_filling_nlg</code>，以及一个 Agenda-Based User Simulator 的默认版本 <code>agenda_based_us</code>。这些可以用于 <strong>quick prototyping</strong>, <strong>baselines</strong>, or <strong>sanity checks</strong>。具体来说，所有这些组件都遵循基于给定本体的 rules or patterns，有时也遵循给定数据库的 rules or patterns，并且<strong>应该被视为每个组件的最基本版本</strong>。</p>
<h3 id="trained-modules">Trained modules</h3>
<p>Plato 支持以 online（交互期间）或者 offline（从数据中）的形式训练 agent 的组件，可以使用任意的机器学习框架。实际上，只要尊重 Plato 的输入/输出接口，任何模型都可以加载到 Plato 中。例如，如果是一个自定义 NLU 模型，仅需要继承 Plato 的 NLU 抽象类（<code>plato.agent.component.nlu</code>）并且实现必要的方法以及将数据打包/解包到自定义模型中并从中取出的功能即可。 - <strong>Plato internal experience</strong>：为了促进在线学习、调试和评估的能力， - <strong>Parsing data with Plato</strong>：Plato 为 DSTC2、MetaLWOZ 和 Taskmaster 数据集提供解析器。……。对于其他数据集，用户应该实现自定义解析器，将数据转换为 Plato 可读格式。……。 - <strong>Training components of conversational agents</strong>： - <strong>Model Training with Plato</strong>：除了监督模型，Plato 还提供了一些强化学习算法的实现 - <strong>Training with Ludwig</strong>：实际上，在 Plato 中，尽管任何框架都可以为对话式 agent 的不同组件构建和训练深度学习模型，但当目标是 quick prototyping 或出于教育目的时，Ludwig 是一个不错的选择，因为 Ludwig 允许用户在不编写任何代码的情况下训练模型。用户只需要将其数据解析为 <code>.csv</code> 文件，创建描述体系结构的 Ludwig YAML配置文件，然后在终端中运行命令。这允许 Plato 与 Ludwig 模型集成，即加载或保存模型，训练和查询它们。经过训练的模型可以通过配置文件加载到模块中。在 Plato 教程中，我们提供了使用 Ludwig 为 Plato 建立和训练 language understanding, generation, dialogue policy, and dialogue state tracking 模型的示例。 - <strong>Training with other frameworks</strong>：</p>
<h1 id="plato-settings">Plato Settings</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>plato</tag>
      </tags>
  </entry>
  <entry>
    <title>概率论（叶丙成）</title>
    <url>/posts/c689603c.html</url>
    <content><![CDATA[<h1 id="概率概论">概率概论</h1>
<p>概率与统计的差异：</p>
<ul>
<li>概率
<ul>
<li>概率模型已知，要学会怎么算某些事件的概率</li>
<li>Ex：已知一骰子为公平骰，看到偶数的概率为多少？</li>
</ul></li>
<li>统计
<ul>
<li>概率模型未知，要学会怎么从大量的实验结果中去建立概率模型</li>
<li>Ex：不知一骰是否灌铅，欲知各点出现的概率模型？ <a id="more"></a></li>
</ul></li>
</ul>
<h2 id="集合论概念名词">集合论概念/名词</h2>
<p>“学生上课不规矩”的概率 = 0.1，p(学生上课不规矩) = 0.1。</p>
<p><strong>概率函数的自变量是：事件，而事件是一种集合。</strong></p>
<p>概率论名词复习：</p>
<ul>
<li>元素（Element）
<ul>
<li>Ex：小黑、小冀、小湘、小鄂、小美</li>
</ul></li>
<li>集合（Set）
<ul>
<li>Ex：咸豆腐脑 A = {黑, 冀}</li>
<li>Ex：甜豆腐脑 B = {湘, 鄂}</li>
</ul></li>
<li>子集合（Subset）
<ul>
<li>嫌咸 C = {湘, 鄂, 美}</li>
<li>B 是 C 的子集，表示为 <span class="math inline">\(B \subset C\)</span></li>
</ul></li>
<li>全集（Universal Set）
<ul>
<li>Ex：S = {黑, 冀, 湘, 鄂, 美}</li>
</ul></li>
<li>空集（Empty Set）
<ul>
<li>Ex：<span class="math inline">\(\emptyset\)</span> = <span class="math inline">\(\{\}\)</span></li>
</ul></li>
<li>交集（Intersection）
<ul>
<li>Ex：喜欢甜豆腐脑<strong>且</strong>喜欢咸豆腐脑的人 = <span class="math inline">\(A \cap B = \{\} = \emptyset\)</span></li>
</ul></li>
<li>并集（Union）
<ul>
<li>Ex：喜欢甜豆腐脑<strong>或</strong>喜欢咸豆腐脑的人 = <span class="math inline">\(A \cup B = \{黑, 冀, 湘, 鄂\}\)</span></li>
</ul></li>
<li>补集（Complement）（绝对补集）（若给定全集 U，<span class="math inline">\(A \subseteq U\)</span>）
<ul>
<li>Ex：嫌咸 C = 咸 A 之于补集 <span class="math inline">\(C = A^C\)</span>（<strong>博主注</strong>：叶丙成老师是台湾人，我考研的时候使用的符号好像是 <span class="math inline">\(\bar{A}\)</span>，但是由于 mathjax 好像不是完全支持 bar 符号，所以以下将会混用）</li>
</ul></li>
<li>差集（Difference）（相对补集）：X - Y = {在 X 但不在 Y 中的东西}
<ul>
<li>嫌咸 - 甜 = {美}</li>
</ul></li>
<li>不相交（Disjoint）：如果 <span class="math inline">\(X \cap Y = \emptyset\)</span> =&gt; X，Y 不相交
<ul>
<li>Ex：甜 <span class="math inline">\(\cap\)</span> 咸 = <span class="math inline">\(\{\}\)</span></li>
</ul></li>
<li>互斥（Mutually Exclusive）：若有一<strong>群</strong>集合 <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span> 中任选两个集合 <span class="math inline">\(X_i, X_j\)</span> 都不相交（<span class="math inline">\(\emptyset\)</span>），则我们称 <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span> 这<strong>群</strong>集合互斥。</li>
</ul>
<p>De Morgan's Law 定理：<span class="math inline">\((A \cup B)^C = A^C \cap B^C\)</span>。证明： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/De%20Morgan&#39;s%20Law%20定理证明.jpg" alt="De Morgan&#39;s Law 定理证明" /></p>
<h2 id="概率名词">概率名词</h2>
<ul>
<li>实验（Experiment）
<ul>
<li>一个概率实验包含了：步骤（procedures）、模型（model）、观察（observations）</li>
<li>Ex：丢两个公平的骰子
<ul>
<li>步骤：……拿起两个骰子投入碗中，直到停止为止。</li>
<li>模型：(1, 1)、(1, 2)、……、(6, 6) 发生机会均等</li>
<li>观察：(6, 6)</li>
</ul></li>
</ul></li>
<li>结果（Outcome）：是实验中可能的结果
<ul>
<li>Ex：约心仪店员。成功/失败</li>
<li>Ex：看到华南虎。立体的/平面的</li>
<li>Ex：转幸运之轮</li>
</ul></li>
<li>样本空间（Sample Space）：是概率实验所有可能的结果的集合，通常用 S 表示
<ul>
<li>Ex：约心仪店员。S = {成功, 失败}</li>
<li>Ex：连丢三次铜板，记录正反面结果（正H，反T）。S = {HHH, HHT, HTH, HTT, THH, THT, TTH, TTT}</li>
<li>Ex：转幸运之轮一次。S = [0, 1)</li>
<li>Ex：转幸运之轮两次。S = [0, 1) * [0, 1)</li>
</ul></li>
<li>事件（Event）
<ul>
<li>事件是对于实验结果的某种叙述</li>
<li>概率是在讲实验结果符合某事件叙述的机会有多大</li>
<li>在数学上，“事件”可以看成是“结果”的集合，亦是“样本空间”的子集
<ul>
<li>Ex：台大学生上课出席情况
<ul>
<li>结果：准时，迟到，旷课</li>
<li>事件1：有出席；E1 = {准时, 迟到}</li>
<li>事件2：没规矩；E2 = {迟到, 旷课}</li>
</ul></li>
</ul></li>
</ul></li>
<li>事件空间（Event Space）
<ul>
<li>Ex：台大学生上课出席
<ul>
<li>S = {准时, 迟到, 旷课}</li>
</ul></li>
<li>事件空间 = { {}, {准时}, {迟到}, {旷课}, {准时, 迟到}, {迟到, 旷课}, {准时, 旷课}, {准时, 迟到, 旷课} }</li>
<li>事件空间是包含所有事件的集合</li>
<li>若样本空间有 S = {<span class="math inline">\(o_1, o_2, \cdots, o_n\)</span>} n 个结果，事件空间有 <span class="math inline">\(2^n\)</span> 个</li>
<li>概率是一个函数，其自变量是事件
<ul>
<li>p(事件) = 0.6</li>
</ul></li>
<li>所有概率可以看成一个映射</li>
</ul></li>
</ul>
<h1 id="概率公理性质">概率公理、性质</h1>
<ul>
<li><strong>公理</strong>（Axioms）
<ul>
<li>近代数学常以数条公理作为整套理论的基石
<ul>
<li>Ex：线性代数。8 公理，公理 1：a + b = b + a ……</li>
</ul></li>
<li>这样的好处？ 头过身就过</li>
<li>公理可否被证明？公理常是能被证明的基本性质</li>
<li>公理为何常被当废话？公理常是非常基本的性质</li>
<li>什么样的数学最厉害？公理越少条、公理越基本，越厉害！</li>
</ul></li>
</ul>
<h2 id="概率三公理axioms-of-probability">概率三公理（Axioms of Probability）</h2>
<ul>
<li><strong>公理 1</strong>：对任何事件 A 而言，P(A) <span class="math inline">\(\geq\)</span> 0</li>
<li><strong>公理 2</strong>：P(S) = 1</li>
<li><strong>公理 3</strong>：事件 <span class="math inline">\(A_1, A_2, \cdots\)</span> 互斥 =&gt; <span class="math inline">\(P(A_1 \cup A_2 \cup A_3 \cdots) = P(A_1) + P(A_2) + P(A_3) + \cdots\)</span>
<ul>
<li>公理 3 搭起了集合运算和概率运算的桥梁</li>
</ul></li>
</ul>
<h2 id="公理衍生之概率性质">公理衍生之概率<strong>性质</strong></h2>
<ul>
<li>Ex：从一幅 52 张的扑克牌中抽出一张，结果为 Ace 的概率为多少？
<ul>
<li>考虑“抽了一张，结果为 Ace”的事件，如下图所示。由于我们只抽一次，所以不可能一次既抽到黑桃 A，又抽到红桃 A。所以可以按照公理 3 进行计算。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/抽了一张，结果为Ace的事件.jpg" alt="抽了一张，结果为Ace的事件" /></li>
</ul></li>
<li>若 E = {<span class="math inline">\(o_1, o_2, \cdots, o_n\)</span>}，则 P(E) = P(<span class="math inline">\({o_1}\)</span>) + P(<span class="math inline">\({o_2}\)</span>) + <span class="math inline">\(\cdots\)</span> + P(<span class="math inline">\({o_n}\)</span>)。E：事件，o：outcome。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/公理衍生之概率性质证明.jpg" alt="公理衍生之概率性质证明" /></li>
<li>P(<span class="math inline">\(\emptyset\)</span>) = 0 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/空集的概率是0的证明.jpg" alt="空集的概率是0的证明" /></li>
<li>P(A) = 1 - P(<span class="math inline">\(\bar{A}\)</span>) <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/P（A）=1-P（A%20bar）证明.jpg" alt="P(A)=1-P(A bar)证明" /></li>
<li>P(A) = P(A - B) + P(A <span class="math inline">\(\cap\)</span> B)
<ul>
<li>证明：A = (A - B) <span class="math inline">\(\cup\)</span> (A <span class="math inline">\(\cap\)</span> B) =&gt; P(A) = P(A - B) + P(A <span class="math inline">\(\cap\)</span> B)</li>
</ul></li>
<li>P(A <span class="math inline">\(\cup\)</span> B) = P(A) + P(B) - P(A <span class="math inline">\(\cap\)</span> B)</li>
<li>若 <span class="math inline">\(C_1, C_2, \cdots, C_n\)</span> 互斥且 <span class="math inline">\(C_1 \cup C_2 \cup \cdots \cup C_n = S\)</span>，则对任何事件 A：P(A) = P(<span class="math inline">\(A \cap C_1\)</span>) + P(<span class="math inline">\(A \cap C_2\)</span>) + <span class="math inline">\(\cdots\)</span> + P(<span class="math inline">\(A \cap C_n\)</span>)（<strong>切面包定理</strong>） 自证： P(A) = P(A <span class="math inline">\(\cap\)</span> S) = <span class="math inline">\(P(A \cap (C_1 \cup C_2 \cup \cdots \cup C_n))\)</span> = <span class="math inline">\(P((A \cap C_1) \cup (A \cap C_2) \cup \cdots \cup (A \cap C_n))\)</span> <span class="math inline">\(\because (A \cap C_1), (A \cap C_2), \cdots, (A \cap C_n)\)</span> 互斥 <span class="math inline">\(\therefore P((A \cap C_1) \cup (A \cap C_2) \cup \cdots \cup (A \cap C_n))\)</span> = <span class="math inline">\(P(A \cap C_1) + P(A \cap C_2) + \cdots + P(A \cap C_n)\)</span>. <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/切面包定理例子.jpg" alt="切面包定理例子" /></li>
<li>若 <span class="math inline">\(A \subset B\)</span>，则 P(A) &lt; P(B)
<ul>
<li>证明：自证</li>
<li>证： <span class="math inline">\(\because\)</span> (B - A) <span class="math inline">\(\cup\)</span> A = B 则 P((B - A) <span class="math inline">\(\cup\)</span> A) = P(B)，且 (B - A) 与 A 互斥 <span class="math inline">\(\therefore\)</span> 根据公理 3 得 P(B - A) + P(A) = P(B) <span class="math inline">\(\therefore\)</span> P(A) <span class="math inline">\(\leq\)</span> P(B) 又 <span class="math inline">\(\because A \subset B\)</span>，故 B 不为 <span class="math inline">\(\emptyset\)</span>，则 B - A 也不为 <span class="math inline">\(\emptyset\)</span>，即 P(B - A) &gt; 0 <span class="math inline">\(\therefore\)</span> P(A) &lt; P(B)</li>
</ul></li>
<li>对任意 n 个事件 <span class="math inline">\(A_1, A_2, \cdots, A_n\)</span> 而言，<span class="math inline">\(P(\bigcup^n_{i=1} A_i) \leq \sum^n_{i=1} P(A_i)\)</span>。（<span class="math inline">\(\bigcup^n_{i=1} A_i\)</span> 表示 <span class="math inline">\(A_1 \cup A_2 \cup \cdots \cup A_n\)</span>）
<ul>
<li>证明：自证</li>
</ul></li>
<li>Bonferroni's 不等式：对任意 n 个事件 <span class="math inline">\(A_1, A_2, \cdots, A_n\)</span> 而言，<span class="math inline">\(P(\bigcap^n_{i=1} A_i) \geq 1 - \sum^n_{i=1} P(\bar{A}_i)\)</span>。
<ul>
<li>证明：自证</li>
</ul></li>
</ul>
<h1 id="条件概率">条件概率</h1>
<ul>
<li>条件概率的表示法：P(X|Y)
<ul>
<li>|: given，X: 所关心的事件，Y：条件（观察到的，已发生的事件）</li>
</ul></li>
<li>条件概率怎么算？
<ul>
<li><a href="https://www.bilibili.com/video/av18918088?p=11" target="_blank" rel="noopener">5:00</a>
<ul>
<li><strong>延伸：若某实验结果 <span class="math inline">\(o_i\)</span> 与某条件 Y 不相交，则 P(<span class="math inline">\(o_i\)</span>|Y) = 0</strong></li>
</ul></li>
<li>延伸：若某条件事件 Y 包含数个实验结果：Y = {<span class="math inline">\(o_1, o_2, \cdots, o_n\)</span>}。<span class="math inline">\(P(o_i|Y) = \frac{P(o_i)}{P(o_1) + P(o_2) + \cdots + P(o_n)} = \frac{P(o_i)}{P(Y)}\)</span>
<ul>
<li>考虑某事件 X = {<span class="math inline">\(o_1, o_2, q_1, q_2\)</span>}，已知条件事件 Y = {<span class="math inline">\(o_1, o_2, o_3\)</span>} 发生了，则 <span class="math inline">\(P(X|Y) = P(o_1|Y) + P(o_2|Y) = \frac{P(o_1)}{P(Y)} + \frac{P(o_2)}{P(Y)} = \frac{P(\{o_1, o_2\})}{P(Y)} = \frac{P(X \cap Y)}{P(Y)}\)</span></li>
</ul></li>
<li>终极延伸：<strong>若已知某条件事件 Y 发生了，则对与任何事件 X，我们可计算其条件概率：P(X|Y) = <span class="math inline">\(\frac{P(X \cap Y)}{P(Y)}\)</span></strong>
<ul>
<li><span class="math inline">\(P(X \cap Y)\)</span> = P(X|Y) <span class="math inline">\(\cdot\)</span> P(Y)</li>
<li><span class="math inline">\(P(X \cap Y)\)</span> = P(Y|X) <span class="math inline">\(\cdot\)</span> P(X)</li>
</ul></li>
</ul></li>
<li>条件概率性质：对于任何事件 X 及任何条件事件 Y，我们有：
<ul>
<li>性质 1：P(X|Y) = <span class="math inline">\(\frac{P(X \cap Y) \geq 0}{P(Y) \geq 0} \geq 0\)</span></li>
<li>性质 2：P(Y|Y) = <span class="math inline">\(\frac{P(Y \cap Y)}{P(Y)} = \frac{P(Y)}{P(Y)} = 1\)</span></li>
<li>性质 3：A，B 互斥 =&gt; <span class="math inline">\(P(A \cup B|Y) = \frac{P(A)}{P(Y)} + \frac{P(B)}{P(Y)}\)</span> = P(A|Y) + P(B|Y)</li>
</ul></li>
<li><strong>Total Probability 定理</strong>：若 <span class="math inline">\(C_1, C_2, \cdots, C_n\)</span> 互斥且 <span class="math inline">\(C_1 \cup C_2 \cup \cdots \cup C_n = S\)</span>，则对任意事件 A，有 P(A) = P(A|<span class="math inline">\(C_1\)</span>)P(<span class="math inline">\(C_1\)</span>) + P(A|<span class="math inline">\(C_2\)</span>)P(<span class="math inline">\(C_2\)</span>) + <span class="math inline">\(\cdots\)</span> + P(A|<span class="math inline">\(C_n\)</span>)P(<span class="math inline">\(C_n\)</span>)（<strong>切面包定理翻版</strong>）</li>
<li><strong>Bayes' 定理</strong>：若 <span class="math inline">\(C_1, C_2, \cdots, C_n\)</span> 互斥且 <span class="math inline">\(C_1 \cup C_2 \cup \cdots \cup C_n = S\)</span>，则对任意事件 A，有 P(<span class="math inline">\(C_j|A\)</span>) = <span class="math inline">\(\frac{P(A|C_j)P(C_j)}{P(A|C_1)P(C_1) + P(A|C_2)P(C_2) + \cdots + P(A|C_n)P(C_n)}\)</span> = <span class="math inline">\(\frac{P(A|C_j)P(C_j)}{P(A)}\)</span> （<span class="math inline">\(\frac{P(C_j \cap A)}{P(A)} = \frac{P(A|C_j) \cdot P(C_j)}{\sum^n_{i=1} P(A|C_i) \cdot P(C_i)}\)</span>，<span class="math inline">\(P(A|C_j) \cdot P(C_j) = P(A \cap C_j)\)</span>，P(A) = <span class="math inline">\(\sum^n_{i=1} P(A|C_i) \cdot P(C_i)\)</span>）
<ul>
<li>例子：“宪哥的逆袭”。解答：<a href="https://www.cnblogs.com/elaron/p/3408190.html" target="_blank" rel="noopener">宪哥的逆袭 - 叶炳成 -概率论</a></li>
</ul></li>
</ul>
<h1 id="概率的独立性">概率的独立性</h1>
<ul>
<li>常见定义：若两事件 A、B 的概率满足： <span class="math display">\[P(A \cap B) = P(A) \cdot P(B)
\]</span> 则 A、B 两事件称为概率上的独立事件
<ul>
<li><strong>另一个更好的定义</strong>：若两事件 A、B 的概率满足： <span class="math display">\[P(A|B) = P(A)
  \]</span> 则 A、B 两事件称为概率上的独立事件</li>
</ul></li>
<li>在两个定义中，公式其实是一样的。<span class="math inline">\(P(A|B) = \frac{P(AB)}{P(B)} = P(A)\)</span> =&gt; <span class="math inline">\(P(AB) = P(A) \cdot P(B)\)</span></li>
<li>例子：已知学生历史课作业表现与概率课作业表现相互<strong>独立</strong>。若历史课作业未做概率为 0.2，概率课作业未做概率为 0.3。问两科作业同时未做的概率为？答：0.2 <span class="math inline">\(\times\)</span> 0.3 = 0.06</li>
<li>另外一个例子，个人认为这个例子可以比较清楚的理解独立性，并且能够体会到人类从直觉上对概率的感觉比较模糊。如下图所示（<em>古锥姊</em>在台湾是可爱的妹子的意思。图中有个词是“阿辈”，其实是打错了，应该是“阿伯”）：
<ul>
<li>先介绍一下背景：台湾大学的学生骑自行车上学，但是又乱停乱放，所以有阿伯会来处理这些自行车，自行车会被阿伯<strong>回收</strong>，那么在被回收时，如果主人看到了自然会求情。已知阿伯被人求情时，会放行的概率为 0.2。</li>
<li>下图中阿伯给古锥姊的<strong>自行车放行</strong>的概率是 0.05（古锥姊在上课未能求情） 和 0.09（古锥姊及时求情），怎么看都很低。但是实际上在古锥姊求情的条件下，阿伯放行的概率高达 90%！乍一看可能无法理解到底为什么。<strong>请注意 P(古锥姊未能及时求情且车放行) = 0.05 求的是事件(古锥姊未求情)和事件(车放行)交集的概率。而(在古锥姊求情的条件下，阿伯放行的概率)是条件概率，两者所求并不相同。</strong></li>
<li><strong>那么如何求呢？</strong>首先在事件的概率为独立的情况下，P(古锥姊未能求情且车放行) = P(古锥姊未能求情) <span class="math inline">\(\times\)</span> P(车放行)。但是题目中并没有说两事件独立，所以需要先计算两事件是否独立。</li>
<li><strong>下图中已经计算出实际上两事件并不独立！</strong>那么阿宅认为阿伯在给古锥姊放水是否成立呢？只需计算在古锥姊求情的情况下，车放行的概率即可。</li>
<li>下图中其实已经计算出 P(古锥姊求情) = P(古锥姊求情且车未放行 <span class="math inline">\(\cup\)</span> 古锥姊求情且车放行) = 0.01 + 0.09 = 0.1。故 P(车放行|古锥姊求情) = <span class="math inline">\(\frac{P(古锥姊求情且车放行)}{P(古锥姊求情)} = \frac{0.09}{0.1}\)</span> = 0.9</li>
<li>发现居然如此的高！阿伯在放水！那么为什么呢？感觉人类无法直观的理解这一概念。其实如果无法进行直观的理解，那就别理解了。换种思维，大家看 P(古锥姊求情) = 0.1，是不是特别低？也就是说首先古锥姊不来求情，阿伯不知道车是谁的，自然大概率不会放行。其次古锥姊不经常求情，所以阿伯自然大概率也不放行。这就导致了为何下图中古锥姊放行的概率如此低，是因为样本量太大了！而其实只要古锥姊求情，阿伯 90% 都会放行。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/概率的独立性例子.jpg" alt="概率的独立性例子" /></li>
</ul></li>
</ul>
<h2 id="多事件独立">多事件独立</h2>
<ul>
<li>若事件 <span class="math inline">\(A_1, A_2, \cdots, A_n\)</span> 满足下列条件，则称此 n 事件独立（n &gt; 2）：从中任选 m 事件 <span class="math inline">\(A_{i_1}, A_{i_2}, \cdots, A_{i_m}\)</span> 均满足 <span class="math inline">\(P(A_{i_1} \cap A_{i_2} \cap \cdots \cap A_{i_m}) = P(A_{i_1})P(A_{i_2}) \cdots P(A_{i_m})\)</span>，m = 2, 3, <span class="math inline">\(\cdots\)</span>, n.（也就是说每一种组合的事件（一种组合包含 2-n 个事件）都必须使得等式成立，才算多事件独立） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/多事件独立例子.jpg" alt="多事件独立例子" /></li>
</ul>
<h1 id="图解复杂概率">图解复杂概率</h1>
<p>当碰到很复杂的概率问题时：</p>
<ul>
<li>先观察这个问题的实验结构</li>
<li>这实验是否能分解成数个子实验</li>
<li>若可以，则利用图解法</li>
</ul>
<p>下面给出一个例子： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/图解法例子.jpg" alt="图解法例子" /></p>
<p>解： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/图解法例子答案.jpg" alt="图解法例子答案" /></p>
<h1 id="数数算概率">数数算概率</h1>
<ul>
<li>古典概率常假设实验结果（outcome）发生概率相同。
<ul>
<li>Ex：包子摊肉包、菜包、豆沙包产量相同，外表一致。则 P(咸包子) = <span class="math inline">\(\frac{1}{3} \times\)</span> 2</li>
</ul></li>
<li>故计算某事件概率的问题等同于计算此事件包含多少实验结果（outcome）。故计算概率等价于数数问题！</li>
<li><strong>数数基本原则</strong>
<ul>
<li><strong>若某种实验有 n 种不同结果，而另一种实验有 m 种不同结果。若操作此两实验将有 nm 种不同结果</strong></li>
</ul></li>
<li>数数前的重要判断
<ul>
<li>所有的物件是否可区分？（Distinguishable）</li>
<li>实验中抽选的物件是否放回供下次抽选（With/Without Replacement？）</li>
<li>实验中被抽选的东西，抽选循序是否有差异？（Order matters or not？）</li>
</ul></li>
</ul>
<h2 id="排列permutation">排列（Permutation）</h2>
<p>礼拜六算一个实验，礼拜天算另一个实验 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/排列（Permutation）.jpg" alt="排列（Permutation）" /></p>
<ul>
<li>一般化：若有 n 异物，从中依序取出 k 物共有多少种结果？答：<span class="math inline">\(\frac{n!}{(n - k)!}\)</span>（意味着物品的取出是具有顺序的） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/排列公式一般化推理.jpg" alt="排列公式一般化推理" /></li>
</ul>
<h2 id="重复选取choose-with-replacements">重复选取（Choose with Replacements）</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/重复选取（Choose%20with%20Replacements）.jpg" alt="重复选取（Choose with Replacements）" /><figcaption>重复选取（Choose with Replacements）</figcaption>
</figure>
<ul>
<li>一般化：若有 n 异物，从中选取一物，每次取完放回。依序选取 k 次，共有多少种结果？答：<span class="math inline">\(n^k\)</span></li>
</ul>
<h2 id="组合combination">组合（Combination）</h2>
<p>先从 3 个人中找一个人，再从 2 个人中找一个人，共有 3 <span class="math inline">\(\times\)</span> 2 种可能，但是由于其中有重复的组合，所以结果不是这个。一共需要选取 2 人，所以重复的组合次数为 2!，所以 3 <span class="math inline">\(\times\)</span> 2 除以 2! 才是最后的次数。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/组合（Combination）.jpg" alt="组合（Combination）" /></p>
<ul>
<li><p>一般化：若有 n 异物，从中选取 k 物共有多少种结果？答：<span class="math inline">\(\frac{n!}{(n - k)!k!}\)</span>（意味着物品的取出是无序的） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/组合公式一般化推理.jpg" alt="组合公式一般化推理" /></p></li>
<li>※<span class="math inline">\(\begin{pmatrix}n\\k\\\end{pmatrix}\)</span>：二项式系数（binomial coefficients）
<ul>
<li>来自<em>二项式定理</em>：<span class="math inline">\((x + y)^n = \sum^n_{k=0} \begin{pmatrix}n\\k\\\end{pmatrix} x^k y^{n-k}\)</span></li>
</ul></li>
</ul>
<h2 id="多项组合multinomial">多项组合（Multinomial）</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/多项组合（Multinomial）.jpg" alt="多项组合（Multinomial）" /><figcaption>多项组合（Multinomial）</figcaption>
</figure>
<ul>
<li>一般化： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/多项组合（Multinomial）一般化.jpg" alt="多项组合（Multinomial）一般化" /></li>
</ul>
<h2 id="数数如何应用在算概率上">数数如何应用在算概率上？</h2>
<p>若一事件包含数个实验结果（outcome）且每个实验结果发生的概率都一样 - 先计算任一实验结果的概率 - 再计算该事件包含多少个实验结果 - 两者相乘便得到该事件的概率</p>
<h3 id="例子">例子</h3>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/多项组合例子（古典概率）.jpg" alt="多项组合例子（古典概率）" /><figcaption>多项组合例子（古典概率）</figcaption>
</figure>
<h1 id="随机变量random-variable-r.v.">随机变量（Random Variable, R.V.）</h1>
<ul>
<li><a href="https://www.bilibili.com/video/av18918088?p=21" target="_blank" rel="noopener">0-04:56</a> 讲了为什么要以 P(X = 1) = 0.3 来表示随机变量的概率</li>
<li>随机变量是一个用来把实验结果数字化的表现方式，目的是可以让概率的推导更数学、更简明。X 就是所谓的随机变量。</li>
<li>探究它的本质：随机变量本质是函数 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/随机变量的本质例子.jpg" alt="随机变量的本质例子" /></li>
</ul>
<h2 id="随机变量的种类">随机变量的种类</h2>
<ul>
<li>离散随机变量（Discrete R.V.）：值是有限个，或是“可数的”无穷多个
<ul>
<li>Ex：宅 vs. 店员：X(微笑) = 0, X(不笑) = 1 =&gt; X = 0, X = 1</li>
<li>Ex：小美选男友：X(明) = 0, X(华) = 1, X(袁) = 2 =&gt; X = 0, X = 1, X = 2</li>
<li>Ex：小明告白多少次才成功：X(0次) = 0, X(1次) = 1, X(2次) = 2,... =&gt; X = 0, X = 1, X = 2,...</li>
</ul></li>
<li>连续随机变量（Continuous R.V.）：值有无穷多个，而且是“不可数的”无穷多个
<ul>
<li>幸运之轮：X 可以是 0 到 1 之间内的任意数字</li>
</ul></li>
</ul>
<h2 id="什么是可数什么是不可数">什么是可数？什么是不可数？</h2>
<ul>
<li>可数：代表它包含的东西是可以被一个一个数的。不管用什么样的方法，它里面的东西总会被数到。比如正偶数集合。</li>
<li>不可数：代表包含的东西是无法被一个一个数的。不管用什么样的方法，它里面一定有一样你没数到。比如 0 - 1 之间所有数字的集合是不可数的。
<ul>
<li>证明 0-1 之间的数字集合是不可数的：<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/证明0-1之间的数字集合是不可数的.jpg" alt="证明0-1之间的数字集合是不可数的" /></li>
</ul></li>
</ul>
<h2 id="随机变量的函数">随机变量的函数</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/随机变量的函数.jpg" alt="随机变量的函数" /><figcaption>随机变量的函数</figcaption>
</figure>
<h1 id="累积分布函数分布函数cumulative-distribution-function">累积分布函数/分布函数（Cumulative Distribution Function）</h1>
<p>对于任一个随机变量 X，我们定义其 CDF 为函数： <span class="math display">\[F_X(x) = P(X \leq x)
\]</span> 函数 <span class="math inline">\(F_X(x)\)</span> 代表随机变量 X 小于等于 x 的概率。 Ex：幸运之轮：<span class="math inline">\(F_X(0.5) = P(X \leq 0.5) = \frac{1}{2}\)</span> - CDF 有什么用？计算 X 落在某范围内的概率 + P(3 &lt; X <span class="math inline">\(\leq\)</span> 5) = P(-<span class="math inline">\(\infty\)</span> &lt; X <span class="math inline">\(\leq\)</span> 5) - P(-<span class="math inline">\(\infty\)</span> &lt; X <span class="math inline">\(\leq\)</span> 3) = P(X <span class="math inline">\(\leq\)</span> 5) - P(X <span class="math inline">\(\leq\)</span> 3) = <span class="math inline">\(F_X(5) - F_X(3)\)</span> + 一般化：P(a &lt; X <span class="math inline">\(\leq\)</span> b) = <span class="math inline">\(F_X(b) - F_X(a)\)</span> * P(a <span class="math inline">\(\leq\)</span> X <span class="math inline">\(\leq\)</span> b) = <span class="math inline">\(F_X(b) - F_X(a)\)</span> + P(X = a)</p>
<h2 id="离散随机变量的-cdf">离散随机变量的 CDF</h2>
<ul>
<li>长什么样？
<ul>
<li>Ex：X 为骰子的点数，故 P(X = 1) = P(X = 2) = <span class="math inline">\(\cdots\)</span> = P(X = 6) = <span class="math inline">\(\frac{1}{6}\)</span>
<ul>
<li>CDF: <span class="math inline">\(F_X(x) = P(X \leq x)\)</span></li>
<li>比如 <span class="math inline">\(F_X(0.3) = 0 \quad F_X(0.8) = 0 \quad F_X(1) = \frac{1}{6} \quad F_X(1.9) = \frac{1}{6} \quad F_X(2) = \frac{2}{6} \, \cdots\)</span></li>
<li>计算 <span class="math inline">\(P(3 &lt; X \leq 5) = F_X(5) - F_X(3) = \frac{5}{6} - \frac{3}{6} = \frac{2}{6}\)</span></li>
<li>计算 <span class="math inline">\(P(3 &lt; X &lt; 5) = F_X(5^-) - F_X(3) = F_X(5) - P(X = 5) - F_X(3) = \frac{1}{6}\)</span></li>
</ul></li>
<li>CDF 呈阶梯状</li>
</ul></li>
</ul>
<h2 id="连续随机变量的-cdf">连续随机变量的 CDF</h2>
<ul>
<li>长什么样？
<ul>
<li>Ex：X 为幸运之轮所停下的数字，X <span class="math inline">\(\in\)</span> [0, 1)
<ul>
<li>CDF: <span class="math inline">\(F_X(x) = P(X \leq x)\)</span></li>
<li>比如 <span class="math inline">\(F_X(-0.1) = 0 \quad F_X(0.1) = P(0 \leq X \leq 0.1) = 0.1 \quad F_X(1) = 1 \quad F_X(1.7) = 1 \, \cdots\)</span></li>
<li><span class="math inline">\(P(0.3 &lt; X \leq 0.5) = F_X(0.5) - F_X(0.3)\)</span> = 0.5 - 0.3 = 0.2</li>
<li><span class="math inline">\(P(0.3 &lt; X &lt; 0.5) = F_X(0.5^-) - F_X(0.3)\)</span> = 0.5 - 0.3 = 0.2</li>
</ul></li>
<li>CDF 呈连续型</li>
</ul></li>
</ul>
<h2 id="cdf-性质">CDF 性质</h2>
<ul>
<li>离散随机变量 CDF <span class="math display">\[
F_X(x^+) = F_X(x) \\
F_X(x^-) = F_X(x) - P(X = x) \\
\]</span></li>
<li>连续随机变量 CDF <span class="math display">\[F_X(x^-) = F_X(x) = F_X(x^+)
\]</span></li>
<li>共同性质 <span class="math display">\[
F_X(-\infty) = P(X \leq -\infty) = 0 \\
F_X(\infty) = P(X \leq \infty) = 1 \\
0 \leq F_X(x) \leq 1 \\
\]</span></li>
</ul>
<h1 id="概率质量函数probability-mass-function">概率质量函数（Probability Mass Function)</h1>
<ul>
<li>对于一个整数值的离散随机变量 X，我们定义其 PMF 为函数： <span class="math display">\[p_X(x) = P(X = x)
\]</span>
<ul>
<li>Ex：X 为公平骰子的点数，<span class="math inline">\(p_X(3) = P(X = 3) = \frac{1}{6}\)</span></li>
</ul></li>
<li>PMF 和 CDF 的关系 <span class="math display">\[
\begin{align}
  F_X(2.5) = &amp; P(X \leq 2.5)\\
  = &amp; P(X = 2) + P(X = 1) + P(X = 0) + P(X = -1) + \cdots \\
  = &amp; \sum^{2 = \llcorner 2.5 \lrcorner}_{n = -\infty} P(X = n)
\end{align}
\]</span>
<ul>
<li>对于任何 x： <span class="math display">\[F_X(x) = \sum^{\llcorner x \lrcorner}_{n = -\infty} p_X(n)
  \]</span></li>
</ul></li>
<li>任何一个 PMF 都称作是一种<strong>概率分布</strong></li>
</ul>
<h1 id="离散概率分布">离散概率分布</h1>
<h2 id="bernoulli-概率分布伯努利分布0-1分布">Bernoulli 概率分布/伯努利分布（0-1分布）</h2>
<p><strong>特点</strong>：1 次实验，2 种结果，在意某结果发生与否。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Bernoulli概率分布例子.jpg" alt="Bernoulli概率分布例子" /> 一般化: <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Bernoulli概率分布一般化.jpg" alt="Bernoulli概率分布一般化" /></p>
<h2 id="binomial-概率分布二项分布n-重伯努利分布">Binomial 概率分布/二项分布（n 重伯努利分布）</h2>
<p><strong>特点</strong>：n 次实验，1 个概率，在意 n 次实验出现某结果 k 次的概率 - Example + 阿宅鼓起勇气搭讪 10 人，若每次搭讪成功概率为 0.6，10 次成功 8 次的概率为？ <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Binomial概率分布.jpg" alt="Binomial概率分布" /> + 一周 5 天午餐在&amp;*&amp;#%汉堡，若每次制作超时的概率为 0.9，5 天中有 3 天制作超时的概率为？ + 一周有 3 晚会，乱停车 3 此，若每次被阿伯拖走的概率为 0.8，那么 3 次被拖 2 次的概率为？ - 一般化： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Binomial概率分布一般化.jpg" alt="Binomial概率分布一般化" /></p>
<h2 id="uniform-概率分布均匀分布">Uniform 概率分布/均匀分布</h2>
<p><strong>特点</strong>：1 次实验，n 种结果，各结果概率均等，在意某结果发生与否。 - Example + 丢公平骰：1 到 6 各点数出现<strong>概率均等</strong> + 混哥考试：作答 A，B，C，D <strong>概率均等</strong> + 狡兔三窟：出现在窟 1，窟 2，窟 3 <strong>概率均等</strong> - 一般化： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Unifrom概率分布一般化.jpg" alt="Unifrom概率分布一般化" /></p>
<h2 id="geometric-概率分布几何分布">Geometric 概率分布/几何分布</h2>
<p><strong>特点</strong>：实验中出现某结果概率已知，重复操作实验至该结果出现为止。在意某结果是在第几次实验才首次出现。 - Example + 阿宅告白：成功概率为 0.3，不成功誓不休。问第 5 次告白成功的概率为？ + 孙文革命：已知革命成功的概率为 0.1，不成功誓不休。问第 11 次成功的概率为？ + 六脉神剑：已知段誉打出六脉神剑的概率为 0.1。他在第 10 次才打出六脉神剑的概率为？ <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Geometric概率分布例子.jpg" alt="Geometric概率分布例子" /> - 一般化： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Geometric概率分布一般化.jpg" alt="Geometric概率分布一般化" /> - 有失忆性</p>
<h2 id="pascal-概率分布">Pascal 概率分布</h2>
<p><strong>特点</strong>：实验中出现某结果概率已知，重复实验至该结果出现第 k 次为止。在意到底第几次实验才结束。（第 n 次成功发生在第 x 次的概率）</p>
<h2 id="poisson-概率分布">Poisson 概率分布</h2>
<p>未看</p>
<h1 id="概率密度函数probability-density-function">概率密度函数（Probability Density Function）</h1>
<ul>
<li>以幸运之轮为例 <span class="math inline">\(X~[0, 1)\)</span>，<span class="math inline">\(p_X(0.7) = ?\)</span>
<ul>
<li>[0, 1) 中每个数字发生概率均等，令其为 p</li>
<li>[0, 1) 中有没有超过 <span class="math inline">\(10^6\)</span> 个数字？有！ =&gt; <span class="math inline">\(10^6 \times p \leq 1\)</span> =&gt; <span class="math inline">\(p \leq 10^{-6}\)</span></li>
<li>[0, 1) 中有没有超过 <span class="math inline">\(10^8\)</span> 个数字？有！ =&gt; <span class="math inline">\(10^8 \times p \leq 1\)</span> =&gt; <span class="math inline">\(p \leq 10^{-8}\)</span></li>
<li>所以 <span class="math inline">\(p_X(0.7) = p = 0 ?\)</span></li>
</ul></li>
<li>连续随机变量和 PMF 注定没办法在一起，每个数字发生的概率都是 0！那么还是想知道某个数字发生的机会多大，怎么办？ <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/PMF-先看一个例子.jpg" alt="PMF-先看一个例子" /></li>
<li>对随机变量 X 而言，其概率密度 PDF： <span class="math display">\[
\begin{align}
  f_X(x) = &amp; \lim_{\Delta \rightarrow 0} \frac{P(x \leq X \leq x + \Delta x)}{\Delta x} \\
  = &amp; \lim_{\Delta \rightarrow 0}\frac{F_X(x + \Delta x) - F_X(x)}{\Delta x} \\
  = &amp; F^{\prime}_X(x)
\end{align}
\]</span> 所以 CDF 和 PDF 的关系为： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/CDF和PDF的关系.jpg" alt="CDF和PDF的关系" /></li>
</ul>
<p>那么我们如何将它和概率联结呢？ <span class="math display">\[
\begin{align}
P(a &lt; X \leq b) = &amp; F_X(b) - F_X(a) \\
= &amp; \int^b_{-\infty} f_X(x)dx - \int^a_{-\infty} f_X(x)dx \\
= &amp; \int^b_a f_X(x)dx
\end{align}
\]</span></p>
<h2 id="pdf-性质">PDF 性质</h2>
<ul>
<li><span class="math inline">\(f_X(x) = F^{\prime}_X(x)\)</span></li>
<li><span class="math inline">\(F_X(x) = \int^x_{-\infty} f_X(u)du\)</span></li>
<li><span class="math inline">\(P(a \leq X \leq b) = \int^b_a f_X(x)dx\)</span></li>
<li><span class="math inline">\(\int^{\infty}_{-\infty} f_X(x)dx = 1\)</span></li>
<li><span class="math inline">\(f_X(x) \geq 0\)</span></li>
</ul>
<h1 id="连续概率分布">连续概率分布</h1>
<h2 id="uniform-概率分布">Uniform 概率分布</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Unifrom连续概率分布.jpg" alt="Unifrom连续概率分布" /><figcaption>Unifrom连续概率分布</figcaption>
</figure>
<h2 id="exponential-概率分布">Exponential 概率分布</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/Exponential概率分布.jpg" alt="Exponential概率分布" /><figcaption>Exponential概率分布</figcaption>
</figure>
<ul>
<li>有失忆性</li>
</ul>
<h2 id="erlang-概率分布">Erlang 概率分布</h2>
<p>未看</p>
<h2 id="normal-概率分布正态分布">Normal 概率分布/正态分布</h2>
<ul>
<li>在自然界很常出现：
<ul>
<li>Ex：人口身高分布、体重分布（无法证明为什么服从正太分布）</li>
</ul></li>
<li>亦常被用作“很多随机变量的总和”的概率模型
<ul>
<li>Ex：100 人吃饭时间总和（100 人的吃饭时间都不一样）（可以证明）</li>
<li>原因：来自最后会讲到的“中央极限定理”</li>
</ul></li>
<li>也被称为高斯（Gaussian）分布</li>
<li>X <span class="math inline">\(\sim\)</span> Gaussian(<span class="math inline">\(\mu, \sigma\)</span>)
<ul>
<li>PDF： <span class="math display">\[f_X(x) = \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x - \mu)^2}{2\sigma^2}}
  \]</span></li>
<li>CDF： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/正态分布CDF.jpg" alt="正态分布CDF" /></li>
</ul></li>
</ul>
<h3 id="标准正态分布">标准正态分布</h3>
<p><span class="math inline">\(Z \sim Gaussian(0, 1)\)</span> <span class="math display">\[f_Z(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}
\]</span> CDF 表示为 <span class="math inline">\(\Phi(z) = \int^z_{-\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{u^2}{2}} du\)</span>。<span class="math inline">\(\Phi(z)\)</span> 一般专指标准正态分布。 <span class="math inline">\(\Phi(z)\)</span> 性质： <span class="math display">\[\Phi(-z) = 1 - \Phi(z)
\]</span></p>
<p>任意 <span class="math inline">\(\mu\)</span>，<span class="math inline">\(\sigma\)</span>下的 CDF： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/任意mu,sigma下的CDF.jpg" alt="任意mu,sigma下的CDF" /></p>
<h1 id="期望值">期望值</h1>
<p>大数法则：想知道一件事发生的概率？就做很多次实验。当实验接近无穷是，这个比例就会越来越接近实际概率。 <span class="math display">\[P(A) = \lim_{N-&gt;\infty} \frac{N_A}{N}
\]</span> 期望值的作用：做随机实验时，我们希望能有某种估算。平均值是比较常用的估算值，但是做实验得出的值，计算出平均值之后，该平均值依旧是一个<strong>随机变量</strong>！所幸，当做实验次数接近无穷多次时，这个平均值会收敛到一个常数，我们就可以把它当做这个概率分布的估算值。</p>
<h2 id="离散变量的期望值">离散变量的期望值</h2>
<p>例如：现考虑某概率分布，做很多次实验若随机变量的样本空间为 <span class="math inline">\(\{1, 2, \cdots, n\}\)</span>。做实验 <span class="math inline">\(n\)</span> 次，记录各结果出现的次数，分别为 <span class="math inline">\(N_1, N_2, \cdots, N_n\)</span>。假设实验的结果为 <span class="math inline">\(3,7,3,5,\cdots,6\)</span>。 那么平均值的计算方式是：<span class="math inline">\(mean = \frac{3+7+3+5+\cdots+6}{N} = \sum^n_{x=1} \frac{x \cdot N_x}{N}\)</span>。 观察上式，发现它可以使用大数法则： <span class="math display">\[\lim_{N \to \infty} \frac{N_x}{N} = P_X(x) \Rightarrow \lim_{N \to \infty} mean = \lim_{N \to \infty} \sum^n_{x=1} x \cdot \frac{N_x}{N} = \sum^n_{x=1} x \cdot P_X(x)
\]</span> 对离散随机函数而言，我们定义其期望值为： <span class="math display">\[E[X] = \mu_X = \sum^{\infty}_{x=-\infty} x \cdot P_X(x)
\]</span> 对于任一随机变量 X 而言，其任意函数 <span class="math inline">\(g(X)\)</span> 也是随机变量，所以也有期望值。定义为： <span class="math display">\[E(g(X)) = \sum^{\infty}_{-\infty} g(x) \cdot P_X(x)
\]</span></p>
<h3 id="性质">性质</h3>
<p><span class="math display">\[
\begin{align}
    E[\alpha g(X)] &amp; = \alpha \cdot E[g(X)] \\
    E[\alpha g(X) + \beta h(X)] &amp; = \alpha \cdot E[g(X)] + \beta \cdot E[h(X)] \\
    E[\alpha] &amp; = \alpha
\end{align}
\]</span> X 的方差（variance）定义为 <span class="math inline">\(E[(X - \mu_X)^2] = \sum^{\infty}_{x=-\infty} (x - \mu_x)^2 \cdot P_X(x)\)</span>。X 减去 X 取期望值的平方再取期望值。</p>
<h3 id="variance">Variance</h3>
<p>Variance 通常用符号 <span class="math inline">\(\sigma^2_X = E[(X-\mu_X)^2]\)</span> 表示。它隐含着关于随机变量 X 多“乱”的信息。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/通过方差看随机变量是否“乱”.jpg" alt="通过方差看随机变量是否“乱”" /> 方差开根方就是标准差（standard deviation）：<span class="math inline">\(\sigma_X\)</span> 方差的便利算法： <span class="math display">\[
\begin{align}
    \sigma^2_X &amp; = E[(X - \mu_X)^2] \\
    &amp; = E[X^2 - 2\mu_X \cdot X + \mu^2_X]
\end{align}
\]</span></p>
<h3 id="常见离散分布的期望值及方差">常见离散分布的期望值及方差</h3>
<ul>
<li><span class="math inline">\(X \sim POI(\alpha)\)</span>
<ul>
<li><span class="math inline">\(\mu_X = \alpha\)</span></li>
<li><span class="math inline">\(\sigma^2_X = \alpha\)</span></li>
</ul></li>
<li><span class="math inline">\(X \sim UNIF(a, b)\)</span>
<ul>
<li><span class="math inline">\(\mu_X = \frac{a+b}{2}\)</span></li>
<li><span class="math inline">\(\sigma^2_X = \frac{1}{12}(b-a)(b-a+2)\)</span></li>
</ul></li>
</ul>
<h2 id="连续变量的期望值">连续变量的期望值</h2>
<h1 id="随机变量的函数-1">随机变量的函数</h1>
<h1 id="条件概率分布及失忆性">条件概率分布及失忆性</h1>
<h1 id="联合概率分布">联合概率分布</h1>
<p>什么是联合分布？ - X：小美 facenook/QQ 离线时间，X~UNIF(8, 12) - Y：小华 facenook/QQ 离线时间，X~UNIF(8, 12) - Z：小袁 facenook/QQ 离线时间，X~UNIF(8, 12) - 假设 X,Y,Z 都是离散随机变量 - 若将小美离线时间 X 与小华离线时间 Z 一起看呢？ - 画出 P(X=x, Z=z)： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/联合概率分布示意图.jpg" alt="联合概率分布示意图" /> - 若将小美离线时间 X 与小袁离线时间 X 一起看呢？ - 赫然发现： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/联合概率分布示意图2.jpg" alt="联合概率分布示意图2" /> - 同时将多个随机变量的行为一起拿来看，我们可以看出更多以往看不到的资讯！</p>
<h2 id="联合-pmf">联合 PMF</h2>
<p><span class="math inline">\(p_{X, Y}(x, y) = P(X=x 且 Y=y)\)</span>。假如看上面的例子的 X，Y 变量，那么 <span class="math inline">\(P_{X, Y}(9, 10) = 0\)</span></p>
<h3 id="性质-1">性质</h3>
<ul>
<li><span class="math inline">\(0 \leq p_{X, Y}(x, y) \leq = 1\)</span></li>
<li><span class="math inline">\(\sum^{\infty}_{x=-\infty} sum^{\infty}_{y=-\infty} p_{X, Y}(x, y) = 1\)</span></li>
<li>X，Y 独立。 <span class="math display">\[
\begin{align}
  P_{X, Y}(x, y) = &amp; P(X=x, Y=y) \\
  = &amp; P(X=x) \cdot P(Y=y) \\
  = &amp; P_X(x)P_Y(y) \\
\end{align}
\]</span></li>
<li>对于任何事件 B：<span class="math inline">\(P(B) = \sum_{(x, y) \in B} P_{X, Y}(x, y)\)</span>
<ul>
<li>Ex：B：美、华下线时间不晚于 10 点</li>
<li>P(B) = <span class="math inline">\(P_{X, Y} = (8, 8) + P_{X, Y} = (9, 9) + P_{X, Y} = (10, 10)\)</span></li>
<li><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/PMF性质.jpg" title="fig:" alt="PMF性质" /></li>
</ul></li>
</ul>
<h2 id="联合-cdf">联合 CDF</h2>
<p><span class="math display">\[F_{X, Y}(x, y) = P(X \leq x 且 Y \leq y) = P(X \leq x, Y \leq y)
\]</span> 那么如何算 <span class="math inline">\(F_{X, Y}(10, 10) = ?\)</span>，其实就是 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/概率论（叶丙成）/PMF性质.jpg" alt="PMF性质" /></p>
<h3 id="性质-2">性质</h3>
<ul>
<li><span class="math inline">\(0 \leq F_{X, Y}(x, y) \leq 1\)</span></li>
<li>若 <span class="math inline">\(x_1 \leq x_2\)</span> 且 <span class="math inline">\(y_1 \leq y_2\)</span>，则 <span class="math inline">\(F_{X, Y}(x_1, y_1) \leq F_{X, Y}(x_2, y_2)\)</span></li>
<li><span class="math inline">\(F_{X, Y}(x, \infty) = P(X \leq x, Y \leq \infty) = P(X \leq x) = F_X(x)\)</span></li>
<li><span class="math inline">\(F_{X, Y}(\infty, y) = P(X \leq \infty, Y \leq y) = P(Y \leq y) = F_Y(y)\)</span></li>
<li><span class="math inline">\(F_{X, Y}(\infty, \infty) = P(X \leq \infty, Y \leq \infty) = 1\)</span></li>
<li><span class="math inline">\(F_{X, Y}(x, -\infty) = P(X \leq x, Y \leq -\infty) \leq P(Y \leq -\infty) = 0\)</span></li>
<li><span class="math inline">\(F_{X, Y}(-\infty, y) = P(X \leq -\infty, Y \leq y) \leq P(X \leq -\infty) = 0\)</span></li>
</ul>
<h1 id="中央极限定理">中央极限定理</h1>
]]></content>
      <tags>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>各种乘法的表示符号</title>
    <url>/posts/c05e7547.html</url>
    <content><![CDATA[<p>设 <span class="math display">\[
m = [a_1, a_2, \cdots, a_n] \\
n = [b_1, b_2, \cdots, b_n] \\
\]</span> 设 f(x)，g(x) 是 <span class="math inline">\(R_1\)</span> 上的两个可积函数。</p>
<h1 id="向量点积">向量点积</h1>
<p>英文中叫做 dot product，又被称为<strong>点乘</strong>、<strong>内积</strong>、<strong>数量积</strong>。</p>
<p>则 <span class="math inline">\(m \cdot n = a_1 * b_1 + a_2 * b_2 + \cdots a_n * b_n\)</span>。</p>
<p>也可以写作<span class="math inline">\(m \bullet n = a_1 * b_1 + a_2 * b_2 + \cdots a_n * b_n\)</span>。 <a id="more"></a></p>
<h1 id="向量叉乘">向量叉乘</h1>
<p>又叫<strong>向量积</strong>、<strong>外积</strong>、<strong>叉积</strong>。 <span class="math display">\[
m \times n = 
\]</span></p>
<h1 id="矩阵相乘">矩阵相乘</h1>
<p>矩阵相乘可以省略乘号： <span class="math display">\[A_{3 \times 4}B_{4 \times 100} = C_{3 \times 100}
\]</span></p>
<h1 id="矩阵对应元素相乘">矩阵对应元素相乘</h1>
<p>英语中叫做 <strong>element-wise multiplication</strong>，也被称为 Hadamard 乘积（Hadamard product）。有以下几种符号表示： <span class="math display">\[
A_{3 \times 1} \circ B_{3 \times 1} = C_{3 \times 1} \\
A_{3 \times 4} \circ B_{3 \times 4} = C_{3 \times 4} \\
A_{3 \times 1} \odot B_{3 \times 1} = C_{3 \times 1} \\
\]</span></p>
<h1 id="张量积">张量积</h1>
<p>英语中叫做 tensor product，对于向量而言张量积与外积等价。有以下符号表示： <span class="math display">\[A_{4 \times 1} \otimes B_{1 \times 3} = C_{4 \times 3}
\]</span></p>
<h2 id="克罗内克积">克罗内克积</h2>
<p>英语中叫做 Kronecker product，克罗内克积是张量积的特殊形式。表示为： <span class="math display">\[A_{m \times n} \otimes B_{p \times q} = C_{mp \times nq}
\]</span></p>
<h1 id="卷积">卷积</h1>
<p>英语中叫做 convolution。表示为： <span class="math display">\[h(x)=(f \ast g)(x) = \int^{\infty}_{-\infty} f(\tau)g(x - \tau)d\tau
\]</span></p>
<h1 id="参考资料">参考资料</h1>
<ol type="1">
<li><a href="https://blog.csdn.net/jdbc/article/details/82753391" target="_blank" rel="noopener">【收藏】各种乘法的区别 “点积、外积、数乘...等”</a></li>
<li><a href="https://blog.csdn.net/dcrmg/article/details/52416832" target="_blank" rel="noopener">向量点乘（内积）和叉乘（外积、向量积）概念及几何意义解读</a></li>
<li><a href="https://baike.baidu.com/item/%E5%90%91%E9%87%8F%E7%A7%AF?fromtitle=cross+product&amp;fromid=18082286" target="_blank" rel="noopener">向量积</a></li>
<li><a href="https://baike.baidu.com/item/%E5%93%88%E8%BE%BE%E7%8E%9B%E7%A7%AF/18894493?fr=aladdin" target="_blank" rel="noopener">哈达玛积</a></li>
<li><a href="https://baike.baidu.com/item/%E5%BC%A0%E9%87%8F%E7%A7%AF/7540845?fr=aladdin" target="_blank" rel="noopener">张量积</a></li>
<li><a href="https://baike.baidu.com/item/%E5%85%8B%E7%BD%97%E5%86%85%E5%85%8B%E7%A7%AF/6282573?fr=aladdin" target="_blank" rel="noopener">克罗内克积</a></li>
<li><a href="https://www.zhihu.com/question/22298352/answer/637156871" target="_blank" rel="noopener">如何通俗易懂地解释卷积？</a></li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>李宏毅预训练模型学习笔记</title>
    <url>/posts/77a5bc5a.html</url>
    <content><![CDATA[<div class="note info"><p>视频来自 <a href="https://www.bilibili.com/video/av56235038" target="_blank" rel="noopener">此处</a>，或者 <a href="https://www.bilibili.com/video/av46561029?p=61" target="_blank" rel="noopener">此处</a>，<a href="https://www.bilibili.com/video/BV1MZ4y1W7mw" target="_blank" rel="noopener">此处</a>是一个讲解得更详细的视频。</p>
<ol type="1">
<li>4:56 A word can have multiple senses.</li>
<li>11:24 ELMO</li>
<li>19:08 BERT</li>
<li>49:23 GPT(-2)</li>
</ol>
</div>
<h1 id="elmo">ELMO</h1>
<p>Embedding from Language Model(ELMO) 可以做到每个 word token 分配不同的 embedding，它是一个 RNN-based model。如下图所示，在提取“潮水退了”这四个字的词向量时，先使用一个 RNN 捕获信息。首先输入单词的词向量，然后将“退了”的 output 作为新的词向量。如果捕获“臣退了”三个字的特征，由于上下文的单词不同，使用 RNN 之后输出的 output 也不同，所以“退了”拥有不同 embeddng。“高烧退了”同理。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/ELMO示意图.jpg" alt="ELMO示意图" /></p>
<a id="more"></a>
<p>但是这样做可能没有捕获到句子的后文的信息，那么只需要再 train 一个反向的 RNN，然后将两个正反向的 embedding 拼起来就得到了单词的词向量。</p>
<p>此外，现在我们 train model 都是 deep 的，那么我们的这个 RNN 也可以是 depp 的。但是当 deep 之后会碰到问题，那就是每一层都有 embedding，我们应该哪一层的 embedding 当做词向量。ELMO 的做法是“我全都要”。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/我全都要.jpg" alt="我全都要.jpg" /></p>
<p>现在每一层都有一个 contextualized embedding，ELMO 的做法是把所有的 embedding 通通加起来变成一个 embedding。但是不是普通的加法，而是 <span class="math inline">\(new \, embedding = \alpha_1 * embed_1 + \alpha_2 * embed_2\)</span>，其中的 <span class="math inline">\(\alpha\)</span> 是 learn 出来的。但是 <span class="math inline">\(\alpha\)</span> 在不同的任务下实际上选值也不同，详见视频 16:20 或者看论文。</p>
<h1 id="bert">BERT</h1>
<p>Bidirectional Encoder Representations from Transformers(BERT)，BERT 用的是 Transformer 的 encoder。</p>
<p>BERT 实际做的是输入一个句子进去，每个单词都会输出一个 embedding。至于 BERT 内部的架构其实跟 Transformer 的 encoder 是一样的。</p>
<p>BERT 有两种训练方法：</p>
<ul>
<li>Masked LM：输入给 BERT 的句子有 15% 的机会随机被置换成一个特殊的 token [MASK]，现在的任务是 BERT 去猜测这些被盖住的地方是哪一个词汇。在预测时，把输出的 embedding 丢到一个 Linear Multi-class classifier，让它预测被 mask 掉的词汇是哪一个。因为这个 classifier 是一个 linear 的，所以它的能力是很弱的。所以如果要成功预测出正确的词汇，那么 BERT 可能要很深，比如要 24/48 层，我们需要 BERT 抽取出一个很好的表征。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/Masked%20LM.jpg" alt="Masked LM" /></li>
<li>Next Sentence Prediction：比如输入“醒醒吧[SEP]你没有妹妹”，我们需要预测这两句话是否是相接的。另外我们需要在句子的首部加上 token [CLS]，然后将 [CLS] 的 embedding 输入到 Linear Binary Classifier 中去预测两个句子是否相接。但是问题来了，为什么要把 [CLS] 放在句子的开头呢？因为 BERT 的内部是一个 Transformer，所以一个 token 放在句子的开头和末尾影响不大，如果是一个 RNN 结构，那么可能应该放在末尾。
<ul>
<li>[SEP]：是两个句子的界限符号</li>
<li>[CLS]：输出分类结果的位置 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/Next%20Sentence%20Prediction.jpg" alt="Next Sentence Prediction" /></li>
</ul></li>
</ul>
<p>这两个方法是需要同时使用的，这样 BERT 会学得最好。</p>
<p>最后 BERT 也一直被人改进，有许多新版的 BERT 可以分别适用不同的任务，《BERT 的演进和应用》[1]介绍了几种新型的 BERT。</p>
<h2 id="如何使用bert">如何使用BERT</h2>
<p>已经知道了 BERT 的训练方法，那么现在该如何使用呢？可以向 ELMO 一样，把 BERT 当做提取特征的工具，使我们获得词向量。但是 BERT 论文中他不止做了这样的事情，他说可以将 BERT 和你要解的任务一起做训练。</p>
<p>下图介绍了一种例子。如果我们的任务是输入一个句子，输出一个类别，那么我们可以在输入的句子的开头加上一个 [CLS]，然后将 [CLS] 的 embedding 输入到一个 Linear classifier 中就可以预测类别。也就是说我们将 BERT 下下来后，其实只需要定义我们的 classifier，然而调整 classifier 的参数即可，BERT 的参数仅仅需要微调，因为它已经被预训练过了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/How%20to%20use%20BERT%20-%20Case%201.jpg" alt="How to use BERT - Case 1" /></p>
<p>第二种例子是输入一个句子，输出每一个单词的类别，比如说 slot filling。这个跟上一个差不多。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/How%20to%20use%20BERT%20-%20Case%202.jpg" alt="How to use BERT - Case 2" /></p>
<p>第三种例子是输入两个句子，输出一个类别，比如说 Natural Language Inference。这个也差不多，就是加了一个 [SEP]。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/How%20to%20use%20BERT%20-%20Case%203.jpg" alt="How to use BERT - Case 3" /></p>
<p>第四种例子是 QA 问题，而且是 extraction-based QA(E.g. SQuAD)。即给 model 一篇文章，然后问它一个问题，期望得到一个答案。但是这里放水了，就是说答案中出现的词汇一定会出现在文章中。具体来说就是输入文章 D 和问题 Q，输出 s 和 e，其中 s 和 e 指的是文章 D 中的某个区间中单词。如果 s 和 e 矛盾，即 s &gt; e，那么回答“此题无解”。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/How%20to%20use%20BERT%20-%20Case%204.jpg" alt="How to use BERT - Case 4" /></p>
<p>具体做法： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/How%20to%20use%20BERT%20-%20Case%204-2.jpg" alt="How to use BERT - Case 4-2" /></p>
<h2 id="bert学到了什么">BERT学到了什么</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/深度学习算法（五）：预训练模型/What%20does%20BERT%20learn.jpg" alt="What does BERT learn" /><figcaption>What does BERT learn</figcaption>
</figure>
<h2 id="multilingual-bert">Multilingual BERT</h2>
<h1 id="ernie">ERNIE</h1>
<p>Enhanced Representation through Kownledge Integration(ERNIE)，它是特别为中文设计的。</p>
<h1 id="gpt">GPT</h1>
<p>Generative Pre-Training(GPT)，GPT 是 transformer 的 decoder。GPT 与 BERT 类似。 56:45 讲了第一个位置的 attention token。</p>
]]></content>
      <categories>
        <category>notes</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>系列</tag>
        <tag>学习笔记</tag>
        <tag>ELMO</tag>
        <tag>BERT</tag>
        <tag>ERNIE</tag>
        <tag>GPT</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅强化学习算法笔记</title>
    <url>/posts/871c22e7.html</url>
    <content><![CDATA[<h1 id="强化学习导论">强化学习导论</h1>
<div class="note info"><p>强化学习导论部分视频来自<a href="https://www.bilibili.com/video/av58458003" target="_blank" rel="noopener">此处</a>。</p>
<p>其余部分均来自<a href="https://www.bilibili.com/video/BV1JE411g7XF" target="_blank" rel="noopener">此处</a></p>
</div>
<p>下图是强化学习的一个场景，Agent 对 environment 进行观察（Observation，其实常见的说法是 State，但是 State 的表述可能不太好，李宏毅老师将其改为观察），然后 Agent 做出 action 去改变环境，最后环境对 action 做出反馈（reward）。比如，现在有一杯水，Agent 将其打翻，environment 得到了 negative reward，因为人告诉它“不要这么做”。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/Scenario%20of%20Reinforcement%20Learning%201.jpg" title="Scenario of Reinforcement Learning 1" alt="Scenario of Reinforcement Learning 1" /> <a id="more"></a></p>
<p>那么水被打翻之后，又去把它才干净，这就得到了 positive reward。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/Scenario%20of%20Reinforcement%20Learning%202.jpg" title="Scenario of Reinforcement Learning 2" alt="Scenario of Reinforcement Learning 2" /></p>
<p>如果以 Alpha GO 为例。Environment 就是你的对手，你每做出一步 action，你的对手都会有反应。但是其实下围棋还是一个比较复杂的情形，因为在大多数的情况下你得到的 reward 都是 0，只要在输赢时才能得到 reward。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/Alpha%20GO%20为例的强化学习场景.jpg" alt="Alpha GO 为例的强化学习场景" /></p>
<p>Supervised v.s. Reinforcement： - Supervised: Learning from teacher - Reinforcement Learning: Learning from experience</p>
<p>但是 Reinforcement Learning 要求机器和对手下棋直到分出胜负才能得到一个 reward，比如要下 3000w 盘才能学习到一个不错结果，但是没人愿意跟机器下 3000w 盘。所以 AlphaGo 用的是 Supervised Learning + Reinforcement Learning。让机器和另一个机器去下。</p>
<h2 id="learning-a-chat-bot">learning a chat-bot</h2>
<p>常用的是 seq2seq model，但是其实 RL 也可以使用在聊天机器人领域。但是显然也要大量的训练才行，如同 AlphaGO 一样。所以我们也需要训练两个机器人让他们互相对话。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/learning%20a%20chat-bot%20-Supervised%20v.s.%20Reinforcement.jpg" alt="learning a chat-bot -Supervised v.s. Reinforcement" /></p>
<p>但是跟围棋不一样，chat-bot 领域比较难定义 reward。因为没人能告诉它，它的言语是否正确，而围棋只需要一个简单的程序即可判断胜负。所以现在的方法就是人为定义了一个 reward，详见 <a href="https://arxiv.org/pdf/1606.01541v3.pdf" target="_blank" rel="noopener">论文</a>。</p>
<h2 id="more-applications">more applications</h2>
<p>14:03-16:10</p>
<h2 id="playing-video-game">Playing Video Game</h2>
<p>现在在 RL 领域最成功的案例就是打游戏。</p>
<h2 id="rl-outline">RL outline</h2>
<p>强化学习大致分为两大方法：Policy-based 和 Value-based。Value-based 方法先于 Policy-based 方法。下图是 RL 领域中目前最好的方法——A3C的示意图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/outline.jpg" alt="outline" /></p>
<p>如果想要学习更多的 RL 知识，可以参考下图资源。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/学习更多的RL.jpg" alt="学习更多的RL" /></p>
<h2 id="a3c">A3C</h2>
<p>之后全是 A3C 算法教学。29:40 开始此节。</p>
<h1 id="policy-gradient">Policy Gradient</h1>
<p>RL 中有三个主要的 component：Actor，Env，Reward Function。下图是两个例子，Video Game 的 Actor 是手柄，Env 是主机，Reward Function 是“杀一只怪得 20 分”。围棋类似。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/basic%20component.jpg" alt="basic component" /></p>
<p>在 RL 中，Env 和 Reward Function 是不可控制的，它们在开始训练之前就已经被定义了。唯一能做的是调整 Actor 中的 Policy。 Policy <span class="math inline">\(\pi\)</span> 是一个 network，它具有参数 <span class="math inline">\(\theta\)</span>。比如在打电玩，网络的 input 就是游戏的画面（机器观察到的东西被视为一个向量或矩阵），output 就是每个 action 对应的输出层中的每个神经元。比如电玩中的 action 是“left，right，fire”三个神经元。 以 observation <span class="math inline">\(s_1\)</span> 开始，做出的 Action 以 <span class="math inline">\(a_1\)</span> 表示，获得的 reward 以 <span class="math inline">\(r_1\)</span> 表示。以此类推直到许多轮后，游戏结束。将这一过程称之为 episode。那么 <span class="math inline">\(Total \  reward = \sum^T_{t=1} r_t\)</span>。Actor 存在的目的就是想要 maximize total reward。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/example：%20video%20game.jpg" alt="example: video game" /></p>
<p>下图是 Actor, Environment, Reward 的关系，Env 和 Actor 可以看成是神经网络（Env 不一定是方程，也可以是 rule-based），那么所有的输入输出可以看成一个 <strong>Trajectory</strong> <span class="math inline">\(\tau\)</span>，我们可以计算它的条件概率 <span class="math inline">\(p_{\theta}(\tau)\)</span>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/Actor,%20Environment,%20Reward.jpg" alt="Actor, Environment, Reward" /></p>
<p>最后还剩下 Reward，我们实际计算的是 expected Reward <span class="math inline">\(\bar{R_{\theta}}\)</span>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/学习笔记/李宏毅强化学习算法笔记/Reward.jpg" alt="Reward" /></p>
<p>之前说过我们需要对 Reward 进行最大化，实际上我们是对 expected Reward（reward 期望值）进行最大化。自然而然想到的方法是 gradient ascend。 <strong>21:00</strong>。</p>
<h2 id="tips">tips</h2>
<ul>
<li>Add a Baseline。39:35。</li>
<li>Assign Suitable Credit。35:00
<ul>
<li>add discount factor</li>
</ul></li>
</ul>
<h1 id="ppo">PPO</h1>
<p>首先要区分 on-policy 和 off-policy： - on-policy: 我们 learn 的 agent 和与环境交互的 agent 是同一个 - off-policy: 不是同一个</p>
<h1 id="q-learning">Q-learning</h1>
]]></content>
      <categories>
        <category>notes</category>
        <category>rl</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>rl</tag>
      </tags>
  </entry>
  <entry>
    <title>UML中的组成、聚合等关系</title>
    <url>/posts/32ea36c0.html</url>
    <content><![CDATA[<p>个人认为 UML 中的组成（composition）以及聚合（aggregation）的关系十分混乱，比如网上的一些版本。human 和 head 是一个 composition 关系因为 human 不能脱离 head 而独立存在。但是如果不严格来讲，其实 human 是可以脱离 head 存在的，并且现实的业务中并没有如此严格的设定，表示某一样事物不能离开某物存活。 另外认为 car 和 engine 是一个 aggregation 的关系，因为 car 即使脱离了 engine 也能独立存在。但是又不严格的来讲，car 其实脱离了 engine 就无法行驶了，这到底是否还算 car 存在？由于脱离 engine，car 的最主要的功能消失了，这还能算脱离 engine 依旧可以存在吗？ 那么现在的问题就是能否独立存在（head 之于 human，engine 之于 car）的概念该如何定义？这是一个很模糊的概念。human 脱离 head 之后，虽然 human 无法存活，但是 human 作为一件实体，它还是会继续存在在这个世界上。难道以是否能存活来区分吗？那么如果下次改为鸡呢？大家知道有只鸡即使已经脱离了头部，它也依旧存活了数月。那么这个概念到底该如何定义呢？我觉可以暂时使用以下的方式： - 物体拥有多个功能性组件定义为 aggregation + 如果物体只有一个功能性组件定义为 composition。如 PolicyManager 的功能是管理 Policy + 如果物体拥有多个功能性组件但是拥有主要（关键）功能，那么将主要功能组件（可多个组件）定义为 composition，其他为 aggregation。如 car 的主要功能是行驶，那么 engine 和 car 肯定是 composition 的关系，而车载音响不过是 aggregation 的关系。 - 物体的属性定义为 composition。Tree 拥有 Node 属性</p>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>UML</tag>
      </tags>
  </entry>
  <entry>
    <title>分析PyDial toolkit各个包的功能</title>
    <url>/posts/bc5ab764.html</url>
    <content><![CDATA[<div class="note warning"><p>此篇基于 <a href="https://yan624.github.io/·论文笔记/55.%20PyDial：A%20Multi-domain%20Statistical%20Dialogue%20System%20Toolkit.html">PyDial：A Multi-domain Statistical Dialogue System Toolkit 论文笔记</a> 和 <a href="https://yan624.github.io/·论文笔记/dilogue/task-oriented/54.%20A%20Benchmarking%20Environment%20for%20Reinforcement%20Learning%20Based%20Task%20Oriented%20Dialogue%20Management.html">A Benchmarking Environment for Reinforcement Learning Based Task Oriented Dialogue Management 论文笔记</a>。 PyDial 的官方文档在 <a href="http://www.camdial.org/pydial/Docs/" target="_blank" rel="noopener">此处</a>。</p>
</div>
<h1 id="语音对话系统架构">语音对话系统架构</h1>
<p>PyDial 的论文中已经描述了系统的架构，本文最上面的 alert 中也已经给出了两篇论文笔记。我在这里做个总结： PyDial 的总体架构如下图所示。其中主要组件被称为 <strong>Agent</strong>，它封装了所有对话系统模块，以实现基于文本的交互。对话系统模块依赖于由一个<strong>本体</strong>（<strong>Ontology</strong>）定义的领域规范。为了与环境交互，PyDial 提供了三个接口：<strong>Dialogue Server</strong>【允许语音型交互】、<strong>Texthub</strong>【允许输入型交互】和 <strong>User Simulation system</strong>。交互的性能由<strong>评估</strong>（<strong>Evaluation</strong>）组件监视。 下图总计<strong>四</strong>大部分，将在下面的小节中分别阐述。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/the%20general%20architecture%20of%20PyDial.jpg" title="The general architecture of PyDial" alt="The general architecture of PyDial" /></p>
<h2 id="agent">Agent</h2>
<p>主要关注 <strong>Agent</strong> 部分。Agent 负责对话交互，因此内部的架构类似于下图中的内容。Agent 还维护 dialogue sessions。因此，可以通过实例化多个 agents 来支持多个对话。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/Architecture%20of%20a%20modular%20Spoken%20Dialoug%20System.jpg" title="Architecture of a modular Spoken Dialoug System" alt="Architecture of a modular Spoken Dialoug System" /></p>
<ul>
<li>Semantic Parser/Semantic Decoder：将文本输入转化为一个语义表征。PyDial 提供了一个基于规则（使用正则表达式）的实现，以及一个基于 SVM 的统计模型，即 the Semantic Tuple Classifier。对于后者，只提供了 CamRestaurants 领域的模型</li>
<li>Belief Tracker：负责维护一个被称为 belief state 的对话状态表征，可用 <strong>the rule-based focus tracker</strong> 实现。该实现与领域无关。所有特定领域的信息都是从本体中提取的</li>
<li>Policy：将 belief state 映射到适合的 system dialogue act。有两种实现方式：<strong>1）</strong>人工制定的策略（应该适用于所有领域）；<strong>2）</strong>Gaussian process (GP) reinforcement learning policy。对于多领域对话来说，策略管理器可以像处理所有其他模块一样处理策略。给定每个用户的输入的领域，然后选择相应的领域策略； 3）此外，还可以选择 Gasic et al.(2015b) 提出的 Bayesian committee machine(BCM) 处理程序；4）博主注：目前（2020.1）已经不止这三种方法，还有十数种强化学习策略可供选择。</li>
<li>Semantic Output/Language Generator：将 system dialogue act 转化为文本表示。PyDial 提供了两个实现组件：<strong>1）</strong>对于所有领域来说，提供了一个基于模板（定义规则）的语言生成；2）此外 Wen et al. (2015) 提出了基于 LSTM 的语言生成器，里面包含了 CamRestaurants 领域的预训练模型</li>
<li>Topic Tracker：对于多域功能，需要 topic tracker。如果 Topic Tracker 已为某些用户输入标识了领域，那么它将继续使用该领域，直到识别了新的领域。<strong>因此，并非每个用户输入都必须包含相关关键字</strong>。如果 Topic Tracker <strong>无法在开始时识别领域</strong>，那么它将创建与用户的 meta-dialogue，直到确定初始领域或达到最大重试次数。 <a id="more"></a></li>
</ul>
<h2 id="与环境交互">与环境交互</h2>
<p>为了与环境交互，PyDial 提供了三个接口：Dialogue Server【允许语音型交互】、Texthub【允许输入型交互】和 User Simulation system。 - Texthub：只需将 Agent 连接到终端 - Dialogue Server：要启用基于语音的对话，Dialogue Server 允许连接到外部语音客户端。此客户端负责使用 ASR 将输入语音信号映射到文本，并使用语音合成将输出文本映射到语音。注意，语音客户端不是 PyDial 的一部分。PyDial 目前连接到 DialPort（Zhao等人，2016）。 - User Simulation：支持在语义层面进行对话模拟。使用的是 agenda-based 用户模拟器（Schatzmann et al., 2006）。</p>
<h2 id="evaluation">Evaluation</h2>
<p>用于计算对话的评估度量（例如 Task Success）。对于基于强化学习的对话模块来说，评估组件还负责提供 reward。</p>
<h2 id="ontology">Ontology</h2>
<p>Ontology 封装了对话域规范以及对后端数据库（例如，一组餐厅及它们的属性）的访问。它被建模为一个全局对象，大多数对话系统模块和用户模拟器使用它来获取用户的相关信息。</p>
<h1 id="目录">目录</h1>
<p>按照如下顺序分析： <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">PyDial</span><br><span class="line">├─belieftracking</span><br><span class="line">├─cedm</span><br><span class="line">├─config</span><br><span class="line">├─curiosity</span><br><span class="line">├─Docs</span><br><span class="line">├─evaluation</span><br><span class="line">├─ontology</span><br><span class="line">├─policy</span><br><span class="line">├─resources</span><br><span class="line">├─scripts</span><br><span class="line">├─semanticbelieftracking</span><br><span class="line">├─semi</span><br><span class="line">├─semo</span><br><span class="line">├─tasks</span><br><span class="line">├─tests</span><br><span class="line">├─topictracking</span><br><span class="line">├─Tutorials</span><br><span class="line">├─usersimulator</span><br><span class="line">├─utils</span><br><span class="line">├─__init__.py</span><br><span class="line">├─Agent.py</span><br><span class="line">├─conf.py</span><br><span class="line">├─DialogueServer.py</span><br><span class="line">├─pydial.py</span><br><span class="line">├─Simulate.py</span><br><span class="line">└─Texthub.py</span><br></pre></td></tr></table></figure></p>
<h1 id="semanticbelieftracking">semanticbelieftracking</h1>
<p>如果你仔细看过 PyDial 就会发现里面还有一个 <code>semanticbelieftracking</code> 包，两个包有点关联，所以此处将两个包放在一起讲解。 由于 <code>semanticbelieftracking</code> 包相对于 <code>belieftracking</code> 包只是多了一个 semantic，所以我一度认为 <code>semanticbelieftracking</code> 继承自 <code>belieftracking</code>，但是后来发现并不是。<code>semanticbelieftracking</code> 包将 semantic decode 和 belief track 视为两个独立问题。<strong>即 SemanticBeliefTracking 由 semantic decode 和 belief track 两部分组成。</strong> 它们的关系大致如上述所示，但是有一点不太好。PyDial 类与类之间的关系太乱了，明明有一个类可以继承另一个类，非要将这个类重写一遍，导致我在阅读代码时产生了极大的困扰。另外还有一点就是类的命名问题，我真的看不懂。我不知道为啥要叫 <code>semanticbelieftracking</code>。。。 所以两个包的关系大致如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/SemanticBeliefTracking.jpg" title="SemanticBeliefTracking.jpg" alt="SemanticBeliefTracking" /></p>
<h1 id="cedm">cedm</h1>
<p>cedm 的全称是 The Conversational Entity Dialogue Model，是一个新颖的对话模型，旨在<strong>解决传统</strong>的单个/多个领域对话<strong>模型在</strong>对复杂对话结构（如关系，relations）<strong>建模能力上的限制</strong>。详见 <a href="https://arxiv.xilesou.top/abs/1901.01466" target="_blank" rel="noopener">Ultes et al., 2019.1</a>。 请注意，已被设计出来的 CEDM 原型实现，在某种程度上，是在尽可能地利用 PyDial 的结构和实现。因此，在实现上有一些限制，将在未来的版本中解决。 CEDM 默认是关闭的，使用方法详见文档。</p>
<h1 id="config">config</h1>
<div class="note warning"><p>我并没有介绍全，其他的配置文件待补充。</p>
</div>
<p>一堆配置文件。PyDial 的文档并没有明确地在某个文档中指出 config 文件夹的用法，只介绍了某一个模块的配置文件该如何配置。但是这样写得太杂了，不易理解，接下来写下自己的理解。 Tut 代表 Tutorials，bcm 代表 Bayesian committee machine，gp 代表 Gaussian Process，hdc 代表 Handcrafted。在官方的教程中经常会看到类似 Tut-gp-CamRestaurants.cfg 的配置文件，这些其实是用于教程的配置文件。 PyDial 的基准环境在 config/pydial_benchmarks 下，由 <a href="https://arxiv.xilesou.top/pdf/1711.11023.pdf" target="_blank" rel="noopener">此篇论文</a> 引进。其中一共有 6 个环境，每个环境下又有三个领域。环境：不同的环境拥有不同的训练参数，领域：不同的领域拥有不同场景，如剑桥餐厅、笔记本电脑和洛杉矶餐厅。</p>
<h1 id="evaluation-1">evaluation</h1>
<p>用于评估对话的性能。</p>
<h1 id="policy">policy</h1>
<p>policy 是 Agent 中的一部分。 policy 包中包含许多 policy 实现，它们都是历年论文的实现。我估计论文 <strong>《A Benchmarking Environment for Reinforcement Learning Based Task Oriented Dialogue Management》</strong> 使用这些 policy 实现从而提供了 6 个基准测试环境。 policy 包中的各个类的关系大致如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/policy.jpg" title="policy.jpg" alt="policy" /></p>
<p>其中 GPPolicy 的关系如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/GPPolicy.jpg" title="GPPolicy.jpg" alt="GPPolicy" /></p>
<h1 id="semi">semi</h1>
<p>semi 全名 Semantic input parser。所有的领域都有一个基于规则的 semantic decoder，但是 CamRestaurants 领域有一个基于统计的 decoder，在该包下可以发现一个 <code>SVMSemi.py</code> 文件，所以实际上是基于 SVM 的。 semi 的各类关系大致如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/SemI.jpg" title="Semantic input parser/Semantic Decoder" alt="SemI" /></p>
<h1 id="semo">semo</h1>
<p>semo 全名 Semantic Output。为大多数领域提供了基于模版的语言生成，但是为 CamRestaurants 提供了一个基于 LSTM 的生成器。 semo 的各类关系大致如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/SemO.jpg" title="Semantic Output/Language Generator" alt="SemO" /></p>
<h1 id="topictracking">topictracking</h1>
<p>用于在多领域下追踪主题。各类关系大致如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/topictracking.jpg" alt="topictracking" /></p>
<h1 id="usersimulator">usersimulator</h1>
<p>对话模拟。</p>
<h1 id="总结">总结</h1>
<p>经过分析发现，所有的模块最终都是由一个 *Manager 的类来管理的。并且在第一节中，我就介绍了 Agent 由 5 个部分组成，即 Semantic Parser/Semantic Decoder(SemI), Belief Tracker, Policy, Semantic Output/Language Generator(SemO), Topic Tracker。在 belieftracking 一节中已经介绍过，SemI 与 belieftracking 已经合并称为 semanticbelieftracking。所以 Agent 实际上只需管理四个 Manager 即可。 正巧，在 pydial 工具包根目录中发现了 Agent.py 模块，那么可想而知该模块就是 Agent 的管理。它管理的 Manager 如下所示： - TopicTrackingManager - SemanticBeliefTrackingManager - PolicyManager - SemOManager - EvaluationManager</p>
<p>由于需要评估对话，所以多了一个 EvaluationManager。总得来说，agent 中各类的关系如下所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/project/分析PyDial%20toolkit各个包的功能/Agent.jpg" alt="Agent" /></p>
<p>以上已经是 PyDial 所有的功能，观察上图可以发现，所有功能最终的管理者有三类：ConsoleHub、DialogueServer、SimulationSystem。其中 DialogueServer 用于语音输入，SimulationSystem 用于模拟对话，我们暂且不管。 那么最后就只剩下了 ConsoleHub，它用于处理文本型输入。而 ConsoleHub 由 pydial.py 管理，至此 PyDial 的所有模块几乎都已经理清了，还有个别几个模块我没有整理过，但是它们大部分都只有几个类，并且目前暂时用不上，所以先不整理了。</p>
<h1 id="pydial.py">pydial.py</h1>
]]></content>
      <categories>
        <category>project</category>
      </categories>
      <tags>
        <tag>pydial</tag>
      </tags>
  </entry>
  <entry>
    <title>A Benchmarking Environment for Reinforcement Learning Based Task Oriented Dialogue Management</title>
    <url>/posts/65cbbd31.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.xilesou.top/pdf/1711.11023.pdf" target="_blank" rel="noopener">论文地址</a>，论文作者 Casanueva I 等，发表于 2017 年。 此论文基于 PyDial，所以可能需要先看 <a href="https://yan624.github.io/·论文笔记/55.%20PyDial：A%20Multi-domain%20Statistical%20Dialogue%20System%20Toolkit.html">这篇</a>博文。</p>
</div>
<h1 id="本文出现的名词">本文出现的名词</h1>
<ul>
<li>自动语音识别——Automatic Speech Recognition, ASR</li>
<li>自然语言理解——Natural Language Understanding, NLU</li>
<li>基于开放域聊天的系统（open-domain chat-based systems）：涉及一般性话题的非目标驱动对话</li>
<li>面向任务的对话系统（task-oriented dialogue systems）：将其做成一个小型电子设备附有非常吸引人的界面，旨在通过自然语言帮助用户实现特定目标。</li>
<li>语音对话系统——Spoken Dialogue Systems, SDS</li>
<li>对话管理——Dialogue Management, DM：belief state tracking and policy
<ol type="1">
<li>state tracking</li>
<li>策略模型</li>
</ol></li>
<li>自然语言生成——Natural Language Generation, NLG</li>
<li>语音合成——speech synthesis</li>
<li>本体（ontology）：本体是系统数据库的结构化表示，定义了 requestable slots, informable slots and database entries（即用户可以与之交互的实体类型及其属性）</li>
<li>强化学习——Reinforcement Learning, RL</li>
<li>试错过程（trial-and-error process）</li>
<li>高斯过程——Gaussian Process, GP</li>
<li>策略梯度（policy gradients）</li>
<li>Q-learning</li>
<li>通用口语对话测试平台（common testbed for spoken dialogue）</li>
<li>基准测试环境（benchmarking environments）</li>
<li>对话状态跟踪挑战——Dialogue State Tracking Challenges, DSTC</li>
<li>马尔科夫决策过程（MDP）</li>
</ul>
<h1 id="论文摘要翻译">论文摘要翻译</h1>
<p>对话助理正迅速成为不可或缺的日常助手。 <a id="more"></a></p>
<h1 id="引言">1 引言</h1>
<p>近年来，随着自动语音识别（<strong>Automatic Speech Recognition</strong>, <strong>ASR</strong>）、自然语言理解（<strong>Natural Language Understanding</strong>, <strong>NLU</strong>）和机器学习技术的发展，对话系统受到了学术界和工业界的广泛关注。两个方向已经被深入研究：基于开放域聊天的系统（<strong>open-domain chat-based systems</strong>）和面向任务的对话系统（<strong>task-oriented dialogue systems</strong>）。前者涉及一般性话题的非目标驱动对话。后者将它做成一个小型电子设备附有非常吸引人的界面，其旨在通过自然语言帮助用户实现特定的目标。 <strong>在<u>语音驱动</u>的场景下</strong>，语音对话系统（ <strong>Spoken Dialogue Systems</strong>, <strong>SDS</strong>）通常基于模块化架构（图1），由输入处理模块（<strong>ASR</strong> 和 <strong>NLU</strong> 模块）、对话管理（<strong>Dialogue Management</strong>, <strong>DM</strong>）模块（belief state tracking and policy）和输出处理模块（自然语言生成（<strong>Natural Language Generation</strong>, <strong>NLG</strong>）和语音合成（<strong>speech synthesis</strong>））组成。<strong>SDS</strong> 的领域由本体（<strong>ontology</strong>）定义，本体是系统数据库的结构化表示，定义了 <strong>requestable slots</strong>, <strong>informable slots</strong> and <strong>database entries</strong>（即用户可以与之交互的实体类型及其属性）。这种架构中的对话流程的一部分在附录 A 中的图 2 进行解释。 <div class="note primary"><p>图中并没有画出 DM，所以 DM 是什么？</p>
</div></p>
<p><strong>DM</strong> 模块是 <strong>SDS</strong> 的核心部分，控制对话的会话流程。<strong>传统的方法大多是基于手工构建的决策树</strong>（对应于 PyDial 论文中的描述，<em>PyDial 包含用于所有领域的基于规则的 semantic decoder……</em>），这覆盖所有可能的对话结果。然而，这种方法不能扩展到更大的领域，也无法适应因 ASR 或 NLU 的误差而引起的噪声输入。因此，人们提出了<strong>数据驱动的方法来自动学习策略</strong>，这无论是从对<em>话语料库中</em>学习或者直接从<em>与人类用户的交互中</em>学习都可以。 <div class="note primary"><p>那么到底是哪一种方法呢？下面介绍一种尚有缺陷的方法。</p>
</div></p>
<p><strong>监督学习</strong>可用于学习对话策略，<strong>训练策略模型</strong>以“模拟”训练语料库中观察到的响应。然而，这种方法有几个缺点。 1. 在口语对话场景中，不能保证训练语料库代表最佳行为。如果不考虑<em>采取某个行动会对未来对话进程造成影响</em>，就可能会导致次优行为。 2. 此外，<strong>由于对话状态空间较大，训练数据集可能缺乏足够的覆盖范围</strong>。</p>
<div class="note primary"><p>那么如何解决这些缺点呢？使用强化学习。</p>
</div>
<p>为了解决上述问题，该任务经常被归结为规划（控制）问题，使用<strong>强化学习</strong>（<strong>Reinforcement Learning</strong>, <strong>RL</strong>）解决。在这个框架中，系统通过一个由 <em>potentially delayed reward signal</em> 控制的试错过程（<em>trial-and-error process</em>）来学习。因此，<strong>DM</strong> 模块学习计划行动以最大化最终结果。基于高斯过程（<strong>Gaussian Process</strong>, <strong>GP</strong>）的 RL 和 deep RL 等方法的最新进展导致了数据驱动对话建模的重大突破（<em>significant progress</em>），这表明策略梯度（<strong>policy gradients</strong>）和 <strong>Q-learning</strong> 等通用算法可以在具有挑战性的对话场景中取得良好的性能。 <div class="note primary"><p>那么在对话领域是否可行呢？下一段说明了原因，<strong>动机与相关工作</strong>一节进行了进一步的解释。</p>
</div></p>
<p>然而，与其他 RL 领域相比，通用口语对话测试平台（<em>common testbed for spoken dialogue</em>）的缺乏使得比较不同的算法变得困难。最近的 RL 进展很大程度上受到基准测试环境（<strong>benchmarking environments</strong>）的发布的影响，<strong>基准测试环境允许对在类似条件下运行的不同 RL 算法进行公平的比较</strong>。 <div class="note success"><p>就是说其他 RL 领域取得进展很大程度上取决于基准测试环境的发布，但是在对话领域，目前并没有这种基准测试环境。 <strong>而本篇论文的实验产物其实就是开发了这样一个环境</strong>。</p>
</div></p>
<p>本着同样的精神，基于最近发布的 <strong><a href="https://www.aclweb.org/anthology/P17-4013/" target="_blank" rel="noopener">PyDial</a></strong> 多领域 <strong>SDS</strong> 工具包，<strong>本文旨在为开发和评估对话模型提供一套测试平台环境</strong>。为了解释不同场景的巨大变化性，这些环境跨越了 <em>different size domains, different user behaviours and different input channel performance</em>。为了提供一些基线，对一组最具代表性的 DM 强化学习算法进行了评估。基准测试（<strong>benchmark</strong>）和环境实现是在线的，允许开发、实施和评估新的算法和任务。</p>
<h1 id="动机与相关工作">2 动机与相关工作</h1>
<p>在过去的十年中，一些强化学习算法被应用到对话策略优化的任务中。然而，由于缺乏一个通用的基准环境，这些算法的评估结果很难进行比较。此外，它们通常只在少数环境中进行评估，因此很难评估它们推广到不同环境的潜力。 在其他领域，如视频游戏（<em>video game playing</em>）和持续控制（<em>continuous control</em>），公共基准环境的发布对该领域的研究起到了极大的推动作用，实现了诸如人类水平的游戏操作或在围棋游戏中击败世界冠军等成就。 <div class="note info"><p>以下指出对话领域<strong>没有通用的试验台的原因</strong>，以及指出<strong>前些年</strong>部分团队/公司<strong>提出的解决方案有些许瑕疵</strong>。</p>
</div></p>
<p>回溯历史，对话策略优化任务没有一个通用的试验台，这有几个原因。 1. ……</p>
<p>为了解决这些问题，提出了模拟用户和模拟输入处理信道。这些模型近似<strong>真实用户的行为</strong>和<strong>由 ASR 或 NLU 误差引入的输入信道噪声</strong>。然而，<strong>处理模块的开发需要创建一个模拟对话环境，这需要付出巨大的努力</strong>。尽管一些模拟环境是公开可用的，但它们覆盖的对话领域非常小，而且它们之间缺乏一致性，因此无法进行大规模测试。 <div class="note success"><blockquote>
<p>处理模块的开发需要创建一个模拟对话环境，这需要付出巨大的努力</p>
</blockquote>
<p>上段话的意思是在做科研时，如果我们致力于研究对话系统的处理模块（如研究语义解析），那么我们还需要一个对话环境以此模拟现实场景（因为只有在现实存在的场景下进行语义解析才有意义）。但是问题是当我们做处理模块时，我们一般都是只专精于该领域，所以我们无法提供一个模拟环境。一般来说我们都会去找一个第三方的模拟环境。但是这样就会造成一个问题。如果有很多团队都在做处理模块的研究，而使用的模拟环境又不是统一的，那么不同团队做出的不同模型就无法进行对比。所以我们需要一个统一的平台。</p>
</div></p>
<p>对话任务需要一个共同的试验台，这在对话界是一个众所周知的问题，诸如对话状态跟踪挑战（<strong>Dialogue State Tracking Challenges</strong>, <strong>DSTC</strong>）1 至 5 等倡议是最突出的问题。由于有一个明确的评估标准，这些挑战是可能的。最近，BABI 对话任务和 DSTC6（更名为 dialogue Systems Technology Challenge）旨在为基于端到端文本的对话管理创建一个测试平台。然而，这些任务要么集中在端到端的有监督学习，要么集中在基于 RL 的问答任务中，其中奖励信号（<em>reward signal</em>）在时间上仅延迟几步。</p>
<h1 id="强化学习的对话管理">3 强化学习的对话管理</h1>
<p>讲解 RL 算法，略。</p>
<h2 id="pydial">3.3 Pydial</h2>
<p>PyDial 是一个开源的统计语音对话系统工具包，它提供了图 1 所示的所有对话系统模块的域无关实现，同样也有模拟用户和模拟错误模型的功能（<em>as well as simulated users and simulated error models</em>）。因此，该工具包有希望在相同条件下，创建一组基准环境来比较不同 RL 算法。<strong>PyDial 的主要关注的是面向任务的对话，即根据一些约束条件用户必定找到其匹配的实体</strong>。例如，系统需要向用户提供满足特定需求的笔记本电脑（商店中有的）的描述。<strong><font color='#f07c82'>本工作中，PyDial 被用于定义不同的环境，当然 PyDial 的论文中提供了指定这些环境的配置文件</font></strong>。 <div class="note warning"><p>正如本文最前部分的 alert 中所述。关于 PyDial 可以看<a href="https://yan624.github.io/·论文笔记/55.%20PyDial：A%20Multi-domain%20Statistical%20Dialogue%20System%20Toolkit.html">这篇</a>博文</p>
</div></p>
<h1 id="基准测试任务">4 基准测试任务</h1>
<p>基于 RL 的 DM 研究通常只在单个或非常小的一组环境中进行评估。这样的测试并没有揭示出算法对不同设置的泛化能力，并且可能容易对特定情况过度拟合。为了测试算法在不同环境中的能力，我们定义了一组任务，它们通过许多维度横跨了广泛的环境，环境的多种维度如下所示： - Domain：环境中的第一个维度是领域，定义了三个拥有不同大小的数据库的本体，相当于一个信息搜索任务（即剑桥/洛杉矶餐厅、笔记本电脑这三个）。详见表 2。 - Input error： - User model： - Masking mechanism：最后，为了测试算法的学习能力，PyDial 中提供的 action mask 机制在两个任务中被禁用。</p>
<p>18 个不同环境的配置详见表 3。</p>
<h1 id="实验设置">5 实验设置</h1>
<p>本节将解释用于运行基准测试任务的实验设置。 1. Simulated user and input channel 2. <strong>Summary actions and action masks</strong> 3. Model hyperparameters 4. Handcrafted policy 5. Reward function and performance metrics</p>
<h1 id="结果与讨论">6 结果与讨论</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>pydial</tag>
        <tag>benchmarking environment</tag>
      </tags>
  </entry>
  <entry>
    <title>PyDial: A Multi-domain Statistical Dialogue System Toolkit</title>
    <url>/posts/65623ba8.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://www.aclweb.org/anthology/P17-4013/" target="_blank" rel="noopener">论文地址</a>，论文作者 S Ultes 等，发表于 2017 年。 此文中出现了许多专业名词，可参考 <a href="https://yan624.github.io/·论文笔记/dilogue/task-oriented/54.%20A%20Benchmarking%20Environment%20for%20Reinforcement%20Learning%20Based%20Task%20Oriented%20Dialogue%20Management.html">此处</a> 加以理解。</p>
</div>
<h1 id="摘要翻译">摘要翻译</h1>
<p>统计口语对话系统（<em>Statistical Spoken Dialogue Systems, Statistical SDS, 统计 SDS</em>）已经存在多年了。然而，访问这些系统一直很困难，因为仍然没有公开的端到端系统实现。为了缓解这个问题，我们提出了 PyDial，一个开源的端到端统计语音对话系统工具包，它为<strong>所有对话系统模块</strong>提供<strong>统计方法</strong>的实现。此外，它还被扩展为提供多领域会话功能。它提供了各个对话系统模块的简单配置、易扩展性和域无关（<em>domain-independent</em>）的实现。该工具包可在 Apache2.0 许可下下载。</p>
<h1 id="引言">1 引言</h1>
<p>针对机器去设计语音接口（凭此人机交互）是多年来的研究热点。这些语音对话系统（SDSs）通常<strong>基于模块化的架构</strong>，包括<strong>语音识别</strong>（<em>speech recognition</em>）和<strong>语义解码</strong>（<em>semantic decoding</em>）的<strong>输入处理模块</strong>（<em>input processing modules</em>）、<strong>信念跟踪</strong>（<em>belief tracking</em>）和<strong>策略</strong>（<em>policy</em>）的<strong>对话管理模块</strong>（<em>dialogue management modules</em>）、<strong>语言生成</strong>（<em>language generation</em>）和<strong>语音合成</strong>（<em>speech synthesis</em>）的<strong>输出处理模块</strong>（<em>output processing modules</em>）（见图 1）。 <div class="note success"><p>以上介绍了 SDS 的架构。下一段介绍了一些 SDS 中不同组件的统计方法示例。</p>
</div></p>
<p>统计 SDS 是一个语音接口，其中所有 SDS 模块都基于统计模型（从数据中学习）（与人工规则相比）。对话系统中<strong>不同组件的统计方法</strong>例子可以在以下中找到： - ……（若干论文），详见原论文 Introduction 第二段。 <a id="more"></a></p>
<p>尽管对统计 SDS 的研究非常丰富，但是仍然没有通用的平台和开放的工具包。其他工具包实现通常集中在单个模块上（例如：<em>略，详见论文</em>）。提供专门针对统计对话系统（<em>statistical dialogue systems</em>）的工具包将使新进入该领域的人员能够更容易地参与进来，结果更容易比较，研究人员能够专注于他们的特定研究问题，而不是重新实现算法（例如，评估（<em>v.</em>）交互功能中的理解或生成组件的性能）。 因此，为了促进研究，以及使人们更容易参与统计口语对话系统的研究，我们提出了一个多领域统计口语对话系统工具包 <strong>PyDial</strong>。PyDial 是用 Python 实现的，剑桥对话系统团队（<em>Cambridge Dialogue Systems Group</em>）正在积极使用它。 <div class="note default"><p>那么什么是 PyDial 呢？</p>
</div></p>
<p>PyDial 支持多领域的应用程序，在这些应用程序中，对话可能涉及多个不同的主题。这引入了许多新的研究课题，包括广义信念跟踪（<em>generalised belief tracking</em>）（论文略），<em>rapid policy adaptation and parallel learning</em> 和自然语言生成（<em>natural language generation</em>）。 论文的余下部分安排如下： 1. 第 2 节介绍了 PyDial 的总体架构（并且将 SDS 架构扩展到多个领域）和 PyDial 的主要应用规范； 2. 第 3 节包含各个对话系统模块的实现细节； 3. 第 4 节列出了可用的领域，其中有两个领域用于第5节中的示例交互； 4. 第 6 节总结了该工具包的主要贡献。</p>
<h1 id="pydial-架构">2 PyDial 架构</h1>
<p>本节介绍 PyDial 的结构及其与环境的接口方式。随后，描述了在单个领域上功能的扩展，以允许在多个领域上进行对话。最后，我们讨论了 PyDial 设计的三个关键原则。</p>
<h2 id="总体系统架构">2.1 总体系统架构</h2>
<p>PyDial 的总体架构如图 2 所示。其中主要组件被称为 <strong>Agent</strong>，它位于系统的核心。它封装了所有对话系统模块，以实现基于文本的交互，即输入和输出。对话系统模块依赖于由一个<strong>本体</strong>（<strong>Ontology</strong>）定义的领域规范。为了与环境交互（<strong>博主注</strong>：这里的“与环境交互”应该指的是机器与外部环境交互，如机器与餐厅环境交互、与旅游环境交互、与服装商场进行交互等），PyDial 提供了三个接口：<strong>Dialogue Server</strong>【允许语音型交互】、<strong>Texthub</strong>【允许输入型交互】和 <strong>User Simulation system</strong>。交互的性能由<strong>评估</strong>（<strong>Evaluation</strong>）组件监视。 - Agent：负责对话交互，因此内部的架构类似于图 1 中的内容。<strong>Agent</strong> 还维护 dialogue sessions，即确保每个输入都<u>发送到</u>（<em>is routed to</em>）正确的对话。因此，<strong>可以通过实例化多个 agents 来支持多个对话</strong>。 1. semantic parser：将文本输入转化为一个语义表征 2. belief tracker：负责维护一个被称为 <strong>belief state</strong> 的对话状态表征（<em>dialogue state representation</em>） 3. policy：将 <strong>belief state</strong> 映射到适合的 <strong>system dialogue act</strong> 4. semantic output：将 <strong>system dialogue act</strong> 转化为文本表示 5. topic tracker：对于多域功能，需要 <strong>topic tracker</strong>，其功能将在第 2.2 节中解释 - User Simulation：支持在语义层面进行对话模拟，即不使用任何语义解析器或语言生成。这是一种广泛应用于训练和评估基于强化学习算法的技术，因为它避免了昂贵的数据收集练习（<em>data collection exercises</em>）和用户试验（<em>user trials</em>）。它当然只提供了一个近似的真实用户行为，所以通过模拟获得的结果应该谨慎看待！ - 与环境交互：为了使 Agent 能够与其环境进行通信，PyDial 提供了两种模式：语音和文本 + Texthub：只需将 Agent 连接到终端 + Dialogue Server：要启用基于语音的对话，<strong>Dialogue Server</strong> 允许连接到外部语音客户端。此客户端负责使用 ASR 将输入语音信号映射到文本，并使用语音合成将输出文本映射到语音（<em>text to speech</em>, <strong>TTS</strong>）。语音客户端通过 HTTP 交换 JSON 消息连接到对话服务器。请注意，语音客户端不是 PyDial 的一部分。基于云的 ASR 和 TTS 服务可以从 <a href="https://cloud.google.com/speech" target="_blank" rel="noopener">Google</a>、<a href="https://www.microsoft.com/cognitive-services/en-us/speech-api" target="_blank" rel="noopener">Microsoft</a>或 <a href="http://www.ibm.com/watson/developercloud/speech-to-text.html" target="_blank" rel="noopener">IBM</a>等提供商处获得。PyDial 目前连接到 DialPort（Zhao等人，2016），其允许基于语音的交互。 - Ontology：除了 <strong>Agent</strong> 和接口组件之外，还有 <strong>Ontology</strong>，Ontology 封装了对话域规范以及对后端数据库（例如，一组餐厅及它们的属性）的访问。它被建模为一个全局对象，大多数对话系统模块和用户模拟器使用它来获取有关用户 <em>actions, slots, slot values, and system actions</em> 的相关信息。 - Evaluation：用于计算对话的评估度量（例如 <strong>Task Success</strong>）。对于基于强化学习的对话模块来说，评估组件还负责提供 <em>reward</em></p>
<h2 id="多领域对话系统架构">2.2 多领域对话系统架构</h2>
<p>Agent -&gt; <strong>topic tracker</strong></p>
<h2 id="主要原则">2.3 主要原则</h2>
<p>为了使 PyDial 能够轻松地应用于新问题，PyDial 体系结构的设计支持三个关键原则： - Domain Independence - Easy Configurability - Extensibility</p>
<h1 id="实现">3 实现</h1>
<p>PyDial 工具包是一个不断开发的研究系统。可从Apache2.0许可下的<a href="http://pydial.org" target="_blank" rel="noopener">网站</a>免费下载。在最初的版本中可以使用以下各种系统模块的实现，不过，到时候会有更多的实现。 - <strong>Semantic Decoder</strong>：为了对输入语句（或n个最佳语句列表，or n-best-list of sentences）进行语义解码，PyDial 提供了一个基于规则（使用正则表达式）的实现，以及一个基于 SVM 的统计模型，即 the Semantic Tuple Classifier（Mairess et al., 2009）。对于后者，只提供了 CamRestaurants 领域的模型。 - <strong>Belief Tracker</strong>：为了跟踪 belief state，可用 <strong>the rule-based focus tracker</strong>（Henderson et al., 2014）。该实现与领域无关。所有特定领域的信息都是从本体中提取的。 - <strong>Policy</strong>：负责 policy 的决定执行模块有两种实现方式：<strong>1）</strong>人工制定的策略（应该适用于所有领域）；<strong>2）</strong>Gaussian process (GP) reinforcement learning policy（Gasic and Young, 2014）。对于多领域对话，策略管理器可以像处理所有其他模块一样处理策略。给定每个用户的输入的领域，然后选择相应的领域策略。 此外，还可以选择 Gasic et al.(2015b) 提出的 Bayesian committee machine(BCM) 处理程序：<strong>当处理一个领域的 belief state 时，参考其他领域的策略来选择最终的系统操作</strong>。为了实现这一点，belief state 被映射到一个抽象表示，然后允许所有策略访问它。在 PyDial 中，经过训练的策略可以在 committee-based handler 和 standard policy manager handler 之间移动。即在 committee 外部（在单域或多域设置中）接受训练的策略可以在 committee 内部使用，反之亦然。 - <strong>Language Generator</strong>：为了将 semantic system action 映射为文本，PyDial 提供了两个实现组件：<strong>1）</strong>对于所有领域来说，提供了一个基于模板（定义规则）的语言生成；<strong>2）</strong>此外 Wen et al. (2015) 提出了基于 LSTM 的语言生成器，里面包含了 CamRestaurants 领域的预训练模型 - <strong>Topic Tracker</strong>：PyDial 提供了一个基于关键字的 Topic Tracker 实现。如果 Topic Tracker 已为某些用户输入标识了领域，那么它将继续使用该领域，直到识别了新的领域。<strong>因此，并非每个用户输入都必须包含相关关键字</strong>。如果 Topic Tracker <strong>无法在开始时识别领域</strong>，那么它将创建与用户的 meta-dialogue，直到确定初始领域或达到最大重试次数。 - <strong>Evaluation</strong>：为了评估对话，目前已经实现了两个 success-based 模块。（下面的话部分看不懂，索性不翻了--） &gt; The objective task success evaluator compares the constraints and requests the system identifies with the true values. The latter may either be derived from the user simulator or, in real dialogues, by specifying a predefined task. For real dialogues, a subjective task success evaluator may also be applied which queries the user about the outcome of the dialogue. - <strong>User Simulation</strong>：模拟用户的实现使用 agenda-based 用户模拟器（Schatzmann et al., 2006）。该模拟器包含 user model 和 error model，从而创建 a n-best-list of user acts 来模拟噪声语音信道。通过使用一组普遍适用的参数，模拟器可以应用于所有领域。领域特定的信息取自本体。</p>
<h1 id="一些领域">4 一些领域</h1>
<p><strong>PyDial 的主要关注的是面向任务的对话，即根据一些约束条件用户必定找到其匹配的实体</strong>。找到实体后，用户可以请求其他信息。为应付这些场景，PyDial 预先加载了总共十个不同复杂度的领域： - 略</p>
<p>如前所述，所有 <strong>policy</strong> 实现以及 <strong>belief tracker</strong> 和 <strong>user simulator</strong> 的实现都独立于领域之外。因此，在<strong>所有领域</strong>都可以进行交互的模拟。此外，<strong>semantic decoder</strong> 和 <strong>language generator</strong> 在某种程度上依赖于特定领域的实现。PyDial 包含用于<strong>所有领域</strong>的基于规则的 <strong>semantic decoder</strong> 和一个用于 <strong>CamRestaurants</strong> 的统计解码器（<em>statistical decoder</em>）。此外，PyDial 还为<strong>大多数领域</strong>提供了基于模板的语言生成，并为 <strong>CamRestaurants</strong> 提供了基于 LSTM 的生成器。因此，在 CamRestaurants 领域，实现统计对话完全有可能。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>pydial</tag>
      </tags>
  </entry>
  <entry>
    <title>2019年度文章总结</title>
    <url>/posts/4ae4ba87.html</url>
    <content><![CDATA[<div class="note info"><p>2019年写了很多博文或者学习笔记，此文章记录一些比较重要的博文，以供未来查阅。</p>
</div>
<h1 id="博文">博文</h1>
<ul>
<li><a href="https://yan624.github.io/categories/paper">论文笔记</a></li>
<li><a href="https://yan624.github.io/categories/algorithm/">数据结构与算法学习</a></li>
<li><a href="https://yan624.github.io/categories/assorted/conference/">参加的会议</a></li>
<li><strong>学习路线</strong>
<ol type="1">
<li>【2019-04-12】<a href="https://yan624.github.io/posts/b803ed7e.html">对神经网络整体的理解</a> <div class="note success"><p>通常学习深度学习从一个最简单的神经网络开始，但是由于是零基础学深度学习，所以需要同时学习大量算法以及其原理，比如梯度下降，Momentum，Adam，RMSprop，adagrad等等算法。所以写了一篇文章记录一下大部分的算法以及原理。</p>
</div></li>
<li><a href="https://yan624.github.io/·学习笔记/AI/dl/《神经网络与深度学习》学习笔记：反向传播算法中weight的表示问题.html">《神经网络与深度学习》学习笔记：反向传播算法中weight的表示问题</a> <div class="note success"><p>由于神经网络中参数太多，而有些参数的表现形式太过复杂， 比如文中权重 <span class="math inline">\(w^l_{ji}\)</span> 有太多上标下标，所以写了一篇文章记录一下。</p>
</div></li>
<li><strong><a href="https://yan624.github.io/·zcy/AI/ml/梯度下降算法的推导.html">梯度下降算法的推导</a></strong> <div class="note success"><p>学会了最基本的神经网络之后，开始理解反向传播算法。之前仅仅是在使用，现在想要理解它到底在干什么。所以自己推导了一遍。发现其实就是链式求导。</p>
</div> <a id="more"></a></li>
<li><a href="https://yan624.github.io/posts/5e27260b.html">吴恩达李宏毅综合学习笔记：RNN入门</a> <div class="note success"><p>学习完神经网络之后，可以学习其他的神经网络模型。由于本人初步决定学习 nlp，所以基本没有看 CNN，直接学了 RNN。本文就是学习 RNN 的记录，包括了许多算法以及技术。 one hot representation, RNN(双向、深层), GRU, LSTM, RNN反向传播, seq2seq, 计算图, language model, Pointer Network</p>
</div></li>
<li><strong>深度学习</strong>：
<ol type="1">
<li><a href="https://yan624.github.io/AI/dl/深度学习算法（一）：simple%20NN（前馈神经网络的正反向推导）.html">深度学习算法（一）：simple NN（前馈神经网络的正反向推导）</a>：手磕梯度下降算法</li>
<li><a href="https://yan624.github.io/posts/b2bd11c2.html">深度学习算法（二）：simple RNN 推导与理解</a></li>
<li><a href="https://yan624.github.io/posts/d5936d3.html">深度学习算法（三）：RNN 各种机制</a></li>
<li><a href="https://yan624.github.io/posts/16ad4ed4.html">深度学习算法（四）：Transformer</a></li>
</ol></li>
<li><em><a href="https://yan624.github.io/·学习笔记/AI/nlp/吴恩达深度学习学习笔记：自然语言处理与词嵌入.html">吴恩达深度学习学习笔记：自然语言处理与词嵌入</a></em> <div class="note success"><p>学习完RNN之后，就可以学习 NLP 的概念了，这里面讲得虽然还是神经网络，但是其实都是 NLP 领域的知识。</p>
</div></li>
<li>nlp：
<ul>
<li><a href="https://yan624.github.io/AI/nlp/【NLP算法】（零）NLP基础算法.html">【NLP算法】（零）NLP基础算法</a></li>
<li><a href="https://yan624.github.io/AI/nlp/【NLP算法】（一）word2vec.html">【NLP算法】（一）word2vec</a></li>
<li><a href="https://yan624.github.io/·zcy/AI/nlp/【NLP算法】（三）条件随机场CRF.html">【NLP算法】（三）条件随机场CRF</a></li>
<li><a href="https://yan624.github.io/·zcy/AI/KG/【知识图谱】（一）从概念到实战.html">【知识图谱】（一）从概念开始</a></li>
</ul></li>
<li>此篇文章已删除，转到《<a href="https://yan624.github.io/·zcy/AI/深度学习500问笔记.html">深度学习500问</a>》笔记中。 <div class="note success"><p>深度学习入门后必然有很多疑问待解答，此篇解决疑问。</p>
</div></li>
<li><em><a href="https://yan624.github.io/·学习笔记/AI/nlp/CS224n学习笔记.html">CS224n学习笔记</a></em></li>
<li><a href="https://yan624.github.io/·学习笔记/AI/nlp/【读书笔记】：《自然语言处理综论》（第二版）.html">【读书笔记】：《自然语言处理综论》（第二版）</a></li>
<li>【 2019-11-05】多领域的语义解析实验 <div class="note danger"><del>
虽说此篇文章是我做实验的笔记，但是由于是我第一次做实验。所以我在其中记录了大量的笔记/炼丹技巧/原理分析、遇到的问题/bug。
</del>
<p>本文已被分割成众多知识点。</p>
</div></li>
</ol></li>
<li>学习笔记
<ul>
<li><a href="https://yan624.github.io/·学习笔记/git学习记录.html">git学习记录</a></li>
<li><a href="https://yan624.github.io/IT-stuff/python/Python爬虫学习记录（一）：正则表达式.html">Python爬虫学习记录（一）：正则表达式</a></li>
<li><a href="https://yan624.github.io/·zcy/AI/ml/特征工程：笔记.html">特征工程：笔记</a></li>
</ul></li>
<li>机器学习
<ul>
<li><a href="https://yan624.github.io/·zcy/AI/ml/代价函数.html">代价函数</a></li>
<li><a href="https://yan624.github.io/posts/5cbfe6f6.html">机器学习算法（一）：线性回归</a></li>
<li><a href="https://yan624.github.io/posts/cf91ea54.html">机器学习算法（二）：逻辑回归</a></li>
<li><a href="https://yan624.github.io/posts/f20f80c0.html">机器学习算法（三）：决策树</a></li>
<li><a href="https://yan624.github.io/posts/77f173b6.html">机器学习算法（四）：K均值（K-means）</a></li>
<li><a href="https://yan624.github.io/posts/d68d7c63.html">机器学习算法（五）：PCA</a></li>
<li><a href="https://yan624.github.io/posts/5e193242.html">机器学习算法（六）：SVM</a></li>
<li><a href="https://yan624.github.io/posts/be345b28.html">机器学习算法（七）：K-NN</a></li>
<li><a href="https://yan624.github.io/posts/4a4c67dc.html">机器学习算法（八）：Adaboost</a></li>
<li><a href="https://yan624.github.io/posts/5c11ca38.html">【机器学习算法】半监督学习</a></li>
<li><a href="https://yan624.github.io/posts/1fa4521c.html">机器学习的下一步</a></li>
</ul></li>
</ul>
<h1 id="学习视频的笔记">学习视频的笔记</h1>
<ul>
<li><a href="https://yan624.github.io/posts/5e27260b.html">吴恩达李宏毅综合学习笔记：RNN入门</a> <div class="note success"><p>当时在学深度学习的时候，看了两个人的视频，本来是分开记录笔记的。但是由于相似度比较高，所以将二者合并了。另外由于吴恩达机器学习的课程是大四寒假的时候看的，是用纸质笔记本记录的，所以机器学习的笔记没有在博客中。</p>
</div></li>
<li><a href="https://yan624.github.io/·学习笔记/AI/nlp/吴恩达深度学习学习笔记：自然语言处理与词嵌入.html">吴恩达深度学习学习笔记：自然语言处理与词嵌入</a> <div class="note success"><p>这是吴恩达深度学习的课程，里面涉及到了诸多知识点，但是在此之前我其实已经看过此类的视频了。所以这里只记录了有关 NLP 的知识点。</p>
</div></li>
<li><a href="https://yan624.github.io/·学习笔记/AI/nlp/CS224n学习笔记.html">CS224n学习笔记</a> <div class="note success"><p>斯坦福大学 NLp 的课程，大部分都是了解过的。有部分专属于 NLP 领域的知识点还未有所了解。</p>
</div></li>
</ul>
]]></content>
      <categories>
        <category>coding</category>
        <category>timeline</category>
      </categories>
  </entry>
  <entry>
    <title>在使用完文件后，未调用close()导致数据一直有问题</title>
    <url>/posts/425ed54.html</url>
    <content><![CDATA[<p>在使用完文件后，未调用close()。貌似导致了最后一条数据没有写入文件，我在核对数据的条数时，一直显示少了点，但是不知道哪里有问题，最后加上close()之后发现数据没问题了。</p>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title>A Sketch-Based System for Semantic Parsing</title>
    <url>/posts/80041b2d.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.xilesou.top/pdf/1909.00574.pdf" target="_blank" rel="noopener">论文地址</a>，论文作者 Zechang Li 等，发表于 2019 年 9 月。</p>
</div>
<h1 id="论文介绍">论文介绍</h1>
<a id="more"></a>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
        <tag>MSParS</tag>
        <tag>sketch-based</tag>
      </tags>
  </entry>
  <entry>
    <title>A Transformer-based Semantic Parser for NLPCC-2019 Shared Task 2</title>
    <url>/posts/e58e6cf.html</url>
    <content><![CDATA[<div class="note info"><p><a href="http://tcci.ccf.org.cn/conference/2019/papers/EV15.pdf" target="_blank" rel="noopener">论文地址</a>，论文作者 D Ge 等，发表于 2019 年。</p>
</div>
<h1 id="结论">结论</h1>
<p>使用 BPE、Sharing Vocab、Synthetic Training Instance 极大地提高了准确率。</p>
<h1 id="概要">概要</h1>
<p>seq2seq 方法将语义解析形式化为一个翻译任务，即将一个句子转换为其对应的 lf（logical form）。然而，在缺少大规模标注过的数据集的情况下，即使在一流的 seq2seq 模型（如 Transformer）中也会遇到数据稀疏的问题。为了解决这个问题，本文探索了<strong>三种广泛应用于<u>神经机器翻译</u>的技术</strong>，以更好地适应 seq2seq 模型的语义分析任务。 1. byte pair encoding (<strong>BPE</strong>): 将单词分割成子词（subword），将稀有单词转换成高频的子词； 2. 我们在 source 和 target 共享词表（<strong>Sharing Vocab</strong>）； 3. 我们定义启发式规则生成合成的实例，以提高训练集的覆盖率（<strong>Synthetic Training Instance</strong>）。 <a id="more"></a></p>
<h1 id="建立基准模型">建立基准模型</h1>
<p>使用 Transformer 建立基准模型。</p>
<h2 id="预处理数据">预处理数据</h2>
<p>在 MSParS 数据集中的每一个实例都是一个包含 4 个元素的元组，包括 question, its logical form, parameters, and question type。在本论文中我们只使用问题和其对应的 lf 来训练我们的解析模型，忽视 parameters and question type，因为它们没有被评估过。实验步骤是：question --fed-into--&gt; encoder, lf --fed-into--&gt; decoder。 <strong>注意在 lf 中，一个实体被表示一个由多个单词组成并以“_”相连的字符串</strong>。在预处理中，我们将实体分割成它对应的单词和“_”。例如，lf: <code>( lambda ?x ( mso:film.film.art director “ i see you ” from avatar ?x ) )</code>，在后处理中，我们只需要将“ _ ”替换为“_”即可。 我们还尝试将实体类型的字符串拆分为多个片段。例如，<code>mso:film.film.art director</code>被分为<code>mso : film . film . art director</code>。然而，我们的初步实验表明，这对性能有轻微的影响。</p>
<h2 id="seq2seq-model">seq2seq model</h2>
<p>介绍什么是 Transformer，略。</p>
<h2 id="生成合成的训练实例">生成合成的训练实例</h2>
<p>监督机器学习算法容易出现数据不平衡问题。在 MSParS 数据集中，我们发现实体类型包含<strong>偏态分布</strong>(Skewed distribution)，例如，实体类型 mso:film.actor.film 包含大多数实体实例，共有 1832 个，而实体类型 mso:barball.batting statistics.slugging_pct 只有一个实体实例。<strong>在这样一种数据集上训练的 seq2seq 模型可能会被数量多的实体类型的训练实例所淹没，而数量小的实体类型的参数则没有很好的学习</strong>。由于泛化能力有限，所得到的模型容易在测试集上获得相对较差的性能。 为了解决这一数据不平衡的问题，我们从以下两个角度生成<strong>合成的训练实例</strong>。 - Entity-based: 给定一个来自原训练集中的一个句子和其对应的 lf，我们选择句子中的一个实体 A，将其替换成一个随机的实体 B，A 与 B 拥有相同的实体类型（<strong>博主注</strong>：原文中是 entity type，但是我认为用 entity type 不恰当，因为在 MSParS 中确实存在着一个 entity type，与前面提到的重名了，我觉得叫 realation 或者 predicate 更合适）。如： <strong>Original pair</strong> Sentence: movies jim bob duggar has done Logical Form: ( lambda ?x ( mso:film.actor.film jim_bob_duggar ?x ) ) <strong>Synthetic pair</strong> Sentence: movies marisa tomei has done Logical Form: ( lambda ?x ( mso:film.actor.film marisa_tomei ?x ) ) - Labeled-based: 选择一个拥有多个实体类型的实体，将其的实体类型替换为其他一个有效的实体。如下所示，<code>&quot;_i_see_you_&quot;_from_avatar</code> 拥有多个实体类型，我们随机的选择另一个实体类型（不能是 film.film.art_director）进行替换。 <strong>Original pair</strong> Sentence: who is film art directors of &quot; i see you &quot; from avatar Logical Form: ( lambda ?x ( mso:film.film.art_director &quot;_i_see_you_&quot;_from_avatar ?x ) ) <strong>Synthetic pair</strong> Sentence: who is film art directors of &quot; i see you &quot; from avatar Logical Form: ( lambda ?x ( mso:film.film.editor &quot;_i_see_you_&quot;_from_avatar ?x ) )</p>
<h1 id="实验">实验</h1>
<p>本节中，1）我们首先介绍使用的<strong>数据集</strong>。2）然后描述了实验中我们<strong>模型的设置</strong>。3）之后，将我们的系统与其他参与的系统进行了<strong>比较研究</strong>。（博主注：数据集的介绍和模型的设置我直接跳过了）</p>
<h2 id="实验设置">实验设置</h2>
<p>测试集未提供给参赛队伍，组织者根据某一标准将测试集分割，选择一个 hard subset。所以每个团队都有两个结果：full set score and hard subset score。 评估标准为 accuracy(ACC)，即生成的逻辑形式与正确的逻辑形式完全吻合。 参数设置略。为了克服数据稀疏的问题，在所有的问题中，我们跟随 <a href="https://www.ijcai.org/proceedings/2019/0691.pdf" target="_blank" rel="noopener">Ge et al</a>，在输入和输出都<strong>共享词表</strong>。为了解决稀有单词的翻译，我们通过 <strong>BPE</strong>（这篇论文暂时找不到） 将单词分割为 subword。我们对最后 20 个模型的参数进行平均，以提高性能。</p>
<h2 id="实验结果">实验结果</h2>
<p>对语义解析来说，这显示了对解决数据稀疏的问题有两个办法。<strong>BPE</strong> 和 <strong>vocabulary sharing</strong>。</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>ACC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Baseline</td>
<td><strong>85.93</strong></td>
</tr>
<tr class="even">
<td>-BPE</td>
<td>54.90</td>
</tr>
<tr class="odd">
<td>-Sharing Vocab.</td>
<td>84.00</td>
</tr>
<tr class="even">
<td>-Both</td>
<td>52.47</td>
</tr>
</tbody>
</table>
<p>生成合成的训练实例的方法从本质上增加了我们训练集实例的数量。如下表所示，添加生成合成的训练实例的方法后，数量几乎翻了一倍，并且两种方法都取得了相似的性能提升，这表明我们的两种方法在提高训练实例覆盖率方面是有效的。（<strong>博主注</strong>：ACC 几乎与 baseline 相等，训练集翻了 3 倍多，我佛了）然而，这两种方法的覆盖率存在重叠。在一种方法存在的情况下，另一种方法实现有限或无改进。</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th># Instances</th>
<th>ACC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Original</td>
<td>63,826</td>
<td>85.93</td>
</tr>
<tr class="even">
<td>+Entity-based</td>
<td>137,198</td>
<td>86.78</td>
</tr>
<tr class="odd">
<td>+Label-based</td>
<td>140,485</td>
<td>86.94</td>
</tr>
<tr class="even">
<td>+Both (our final model)</td>
<td>213,857</td>
<td><strong>86.96</strong></td>
</tr>
</tbody>
</table>
<p>我们还将我们的最终系统与表4中其他参与者的系统进行了比较。从结果可以看出，我们的最终系统达到了最高的性能，特别是在 hard subset 上。这说明了我们的基于 seq2seq 的语义分析是可行和有效的。</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>ACC on full set</th>
<th>ACC on hard subset</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Soochow_SP (this paper)</td>
<td>85.68</td>
<td>57.43</td>
</tr>
<tr class="even">
<td>NP-Parser</td>
<td>83.73</td>
<td>51.93</td>
</tr>
<tr class="odd">
<td>WLIS</td>
<td>82.53</td>
<td>47.83</td>
</tr>
<tr class="even">
<td>Binbin Deng</td>
<td>68.82</td>
<td>35.41</td>
</tr>
<tr class="odd">
<td>kg_nlpca_ai_lr</td>
<td>30.79</td>
<td>14.89</td>
</tr>
<tr class="even">
<td>TriJ</td>
<td>26.77</td>
<td>14.49</td>
</tr>
</tbody>
</table>
<h1 id="错误分析">错误分析</h1>
<p>分析为什么预测出错。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
        <tag>MSParS</tag>
      </tags>
  </entry>
  <entry>
    <title>Enriching Word Vectors with Subword Information</title>
    <url>/posts/4ae0b9a6.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/abs/1607.04606.pdf" target="_blank" rel="noopener">论文地址</a>，作者 Piotr Bojanowski et al.，发表于 2016 年。</p>
</div>
<h1 id="论文概要">论文概要</h1>
<p>现在流行的模型对单词表征的学习忽视了词法（morphology of word），它们直接给单词分配了不同的向量。这有一定的局限性，尤其对大规模词表并且含有大量稀有单词的语言。本论文提出基于 <strong>skipgram model</strong> 的方法，每个单词都被表示为一个 <strong>character n-grams</strong>（博主注：注意是 character，不是 word）词袋。每个 character n-grams 有一个向量，而单词由这些表征相加表示（即 e(where) = e(wh) + e(whe) + e(her) + e(ere) + e(re)，e() 表示 character n-grams 对应的向量）。 模型<strong>快</strong>，且可以计算那些不<strong>在训练数据中的单词表征</strong>（OOV 单词）。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p>介绍了很多关于词嵌入的工作，可以参考。</p>
<h2 id="morphological-word-representations">Morphological word representations</h2>
<h2 id="character-level-features-for-nlp">Character level features for NLP</h2>
<h1 id="模型">模型</h1>
<p>首先提出通用模型，阐述我们如何训练词向量。然后提出 subword 模型，最终描述我们如何处理 character n-grams 的词表。</p>
<h2 id="通用模型">通用模型</h2>
<h2 id="subword模型">Subword模型</h2>
<p><strong>对每一个单词赋予一个不同的向量这忽视了单词内在的结构</strong>。为了考虑这一信息，本节提出一个不同的<strong>评分函数</strong>（scoring function） <strong>s</strong>。 <strong>1）</strong>每一个单词 w 都被表示为一个 character n-gram 的词袋。<strong>2）</strong>我们在单词的开始和结尾增加了特殊的边界符号 <code>&lt;</code> 和 <code>&gt;</code>，以便<strong>区分来自其他单词的前缀和后缀</strong>。<strong>3）</strong>我们也将单词 w 本身放入了它的 n-grams 集合，以学习每一个单词（除了 character n-grams）的表征。以单词 <em>where</em> 和 <span class="math inline">\(n = 3\)</span> 为例，它被表示为该 character n-grams： <span class="math display">\[
&lt;wh, whe, her, ere, re&gt;
\]</span> 以及它的特殊序列： <span class="math display">\[
&lt;where&gt;
\]</span> 注意序列 <code>&lt;her&gt;</code> 对应于单词 <em>her</em>。单词 <em>her</em> 不同于来自单词 <em>where</em> 的 trigram <em>her</em>。在实践中，我们提取所有 <span class="math inline">\(3 &lt;= n &lt;= 6\)</span> 的 n-grams（<strong>博主注</strong>：如果我没理解错，是提取了所有的 3~6-grams）。这是一种非常简单的方法，并且可以考虑不同的 n-grams 集合（<strong>博主注</strong>：为什么可以考虑不同的 n-grams？因为一个单词他们提取了所有的 3~6-grams），例如取所有前缀和后缀。 假设给出一个 G 大小 n-grams 词表。给定一个单词 w，将其表示为 <span class="math inline">\(G_w \subset \{1, \dots, G\}\)</span>，其中 n-grams 集合 <span class="math inline">\(G_w\)</span> 会出现在 w 中。我们将一个向量表征 <span class="math inline">\(\boldsymbol{z_g}\)</span> 与每一个 n-gram <span class="math inline">\(g\)</span> 关联。而一个单词由其 n-grams 的向量表征相加表示。因此我们获得评分函数（<strong>博主注</strong>：这应该在计算相似度）： <span class="math display">\[
\boldsymbol{
    s(w,c) = \sum_{g \in G_w} z^T_g v_c
}
\]</span> 这个简单的模型允许<strong>跨单词共享</strong>表征，从而允许学习<strong>稀有单词</strong>可靠的表征。（<strong>博主注</strong>：由于每个单词都被拆分开来，这样一个稀有单词就有很大概率可以由细碎的 n-grams 表示） <strong>为了限制我们模型的内存需求</strong>，巴拉巴拉，我没看懂什么意思，大致意思是由于 n-grams 诞生的 token 太多了，所以需要使用 hash 的技巧来缩小存储空间。使用一个 token 来查找其对应的索引非常耗时，而使用 hash 算法就快多了。参考了： - <a href="https://www.jiqizhixin.com/articles/2018-06-05-3" target="_blank" rel="noopener">fastText，智慧与美貌并重的文本分类及向量化工具</a></p>
<h1 id="实验设置">实验设置</h1>
<ol type="1">
<li>baseline：几乎所有实验的基线都为 C 实现的 <a href="https://code.google.com/archive/p/word2vec" target="_blank" rel="noopener">word2vec 包</a>，除了论文中的 5.3 节；</li>
<li>optimization：对前面（<strong>博主注</strong>：通用模型一节中）提出的负对数似然估计，进行 <strong>SGD</strong> 优化。在基线的 skipgram 模型中，我们使用<strong>基于步长的线性衰减</strong>。给定一个包含 T 个单词的训练集，并且在上传递的次数等于 P，则 t 时刻的步长等于 <span class="math inline">\(\gamma_0 (1 - \frac{t}{TP})\)</span>，其中 <span class="math inline">\(\gamma_0\)</span> 是一个固定的参数（<strong>博主注</strong>：<strong>这部分的线性衰减没看懂什么意思</strong>）。我们通过使用 <strong><a href="http://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent" target="_blank" rel="noopener">Hogwild</a></strong>（Recht et al., 2011）并行地执行优化，所有线程以异步方式共享参数和更新向量；</li>
<li>实现细节：</li>
<li>datasets：</li>
</ol>
<h1 id="结果">结果</h1>
<p>在以下几个方面评估我们的模型： 1. Human similarity judgement 2. Word analogy tasks 3. Comparison with morphological representations：与顶尖模型的比较 4. Effect of the size of the training data 5. Effect of the size of n-grams 6. 从我们的模型中获取到的词向量在语言模型任务中的评估</p>
<h1 id="定性分析">定性分析</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>fasttext</tag>
      </tags>
  </entry>
  <entry>
    <title>特征工程：笔记</title>
    <url>/posts/ecc0049d.html</url>
    <content><![CDATA[<h1 id="特征工程入门与实践">《特征工程入门与实践》</h1>
<h1 id="特征增强清洗数据">3、特征增强：清洗数据</h1>
<h2 id="填充缺失值">填充缺失值</h2>
<p>通常数据集会因为各种原因有所缺失。必须尽可能地了解数据集，以便找到使用<strong>其他符号填充的</strong>确实数据。<strong>公开数据集的文档</strong>里面有可能会提到缺失数据的问题。 如果没有文档，缺失值的常见填充方法有： - 0（数值型） - unknown 或 Unknown（类别型） - ?（类别型） <a id="more"></a></p>
<h3 id="处理缺失值">处理缺失值</h3>
<p>如果 pandas 将缺失值自动填充了 0（需要自行判断 0 是否缺失值），那么可以先用 python 的 None 填充缺失值，以便使用 pandas 的 fillna, dropna and isnull 等方法。 现在开始介绍方法，处理缺失值的主要办法是：1. 删除缺失值的行；2. 填充缺失值。 1. 最常见也是最容易的方法大概是直接删除存在缺失值的行。通过这种操作，我们会留下具有数据的完整数据点。可以使用 pandas 的 dropna 方法获取新的 DataFrame。 但是我们可能会丢失大量的原始数据（书中的例子使用的是《皮马印第安人糖尿病预测数据集》，丢失 51% 的行）。从机器学习的角度考虑，尽管数据都有值、很干净，但是我们没有利用尽可能多的数据。经书中使用 pandas 分析，某些数据的均值下降严重，所以<strong>我们应该保留下尽可能多的数据</strong>。 然后此书的作者使用去除缺失值的数据集运行了一个 KNN 模型，最终得到最好的结果为：k=7，acc=74.5%。但是如果用到所有的数据，会不会更好？ 2. 填充缺失值是一种更复杂的方法。<strong>填充</strong>指用现有的知识/数据来确定缺失的数量值，并填充的行为。 我们有几种选择，最常见的是用<strong>此列其余部分的均值</strong>填充缺失值。可以使用 pandas 的 fillna(mean_value) 方法即可填充，但是这有点麻烦，我们可以选用 scikit-learn 预处理类的 Imputer 模块，它更简单。只需指定策略 <span class="math inline">\(Imputer = Imputer(strategy=&#39;mean&#39;)\)</span>，再调用 <span class="math inline">\(pima_imputed = imputer.fit_transform(pima)\)</span> 即可。 那么来验证一下这样填充的 acc 如何。首先全部填充 0 用来充当对照组，发现 KNN 模型的 acc=73.31%，明显低于 74.5%。然后填充均值，发现 acc=65.625%，居然更低了。 这里需要解释一点，其实使用上述的方法去填充缺失值是错误的。我们<strong>将整个数据集的一列的均值去填充对应列的缺失值</strong>实际上犯了一个错误，即<strong>当预测测试集的响应值（即 y）时，不能假设我们已经知道了整个数据集的均值</strong>。所以我们应该<strong>使用训练集的均值去填充训练集和测试集的缺失值</strong>。注：我们假设测试集是未知的，所以它并没有均值，并且我们使用了训练集的信息去训练，所以我们需要使用训练集的均值去填充测试集的缺失值。 <strong>但是</strong>最 sao 的是，此书中用正确的填充方法，最后得到的 acc=73.18%，比直接填充 0 还低。另外使用<strong>中位数</strong>填充得到的 acc=73.57%，始终没有高于<strong>直接删除缺失值</strong>得到的 acc。</p>
<h2 id="标准化与归一化">标准化与归一化</h2>
<p>仔细观察数据，我们发现数据的大小差别很大。而某些机器学习模型受数据尺度（scale）的影响很大。数据工程师可以选用某种归一化操作。我们将重点关注 3 种归一化方法，<strong>前两个方法特别用于调整特征，第三个方法虽然操作行，但效果与前两个相当</strong>。 - z 分数标准化 - min-max 标准化 - 行归一化</p>
<p><strong>z 分数标准化</strong>是最常见的标准化技术，即均值归一化。使得输出会被重新缩放，使<strong>均值为 0、标准差为 1</strong>。公式为： <span class="math display">\[
    z = \frac{x - \mu}{\sigma}
\]</span> - z 是新的值 - x 是单元格中原来的值 - <span class="math inline">\(\mu\)</span> 是该列的均值 - <span class="math inline">\(\sigma\)</span> 是列的标准差</p>
<p><strong>min-max 标准化</strong>与 z 分数标准化类似，它也用一个公式替换列中的每个值。它会使得每一列的值都位于 [0,1] 。公式为： <span class="math display">\[
    m = \frac{(x - x_{min})}{x_{max} - x_{min}} 
\]</span> - m 是新的值； - x 是单元格原来的值； - <span class="math inline">\(x_{min}\)</span> 是该列的最小值； - <span class="math inline">\(x_{max}\)</span> 是该列的最大值。</p>
<p><strong>行归一化</strong>是关于行的，而不是关于列的。它不是计算每列的统计值（均值、最小值、最大值），而是保证每行都有<strong>单位范数</strong>，意味着每行的向量长度相同。计算方式如下所示，即 L2 范数，其他范数方式这里不讨论。 <span class="math display">\[
    ||x|| = \sqrt{(x^2_1 + x^2_2 + \dots + x^2_n)}
\]</span></p>
<h2 id="整合">整合</h2>
<p>最后我们将填充缺失值的方法和标准化（或归一化）的方法结合起来用，在 pima 数据集上发现使用<strong>均值填充 + min-max 标准化</strong>的交叉验证准确率最高。</p>
<h1 id="特征构建我能生成新特征吗">4、特征构建：我能生成新特征吗</h1>
<ol type="1">
<li>填充分类特征</li>
<li>编码分类变量</li>
<li>扩展数值特征：多项式</li>
<li>针对文本：词袋模型、TF-IDF...</li>
</ol>
<h1 id="特征选择对坏属性说不">5、特征选择：对坏属性说不</h1>
<h1 id="特征转换数学显神通">6、特征转换：数学显神通</h1>
<h1 id="特征学习以ai促ai">7、特征学习：以AI促AI</h1>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>特征工程</tag>
      </tags>
  </entry>
  <entry>
    <title>Improved Representation Learning for Question Answer Matching</title>
    <url>/posts/185ad01f.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p>自从短文级别（passage-level）的问答匹配需要有效的表征以捕获问题与答案之间复杂的语义关联开始，它就成为一个巨大的挑战。本文我们提出一系列的深度学习模型去解决如何选择短文答案。 将短文答案与符合语义关系的问题相匹配，不同于之前的大多数工作，即只使用一个深度学习结构。我们开发了一个混合模型去处理文本，其中用到了 CNN 和 RNN，结合了两种结构提取语言信息的优点。 此外，还开发了简单而有效的注意力机制。在两个数据集 InsuranceQA and TREC-QA 上显示此模型超出基线。 <a id="more"></a></p>
<h1 id="导读">导读</h1>
<p>短文级别的答案选择是 QA 系统的重要组成部分之一。它的定义如下所示：给定一个问题和一群候选短文，挑选出包含候选答案的短文。 一个回答优于另一个回答取决于多种因素。尤其是不同于其他 NLP 对匹配任务，问题与答案之间语言上的相似度对我们的任务既可能有用也可能没用，这取决于问题。此外，虽然一个好的回答必须与问题相关联，但是它们之间没有共通的词汇单元。 因此，与基于深度学习的方法相比，这些挑战使得手工制作的特征变得不那么理想。此外，它们还要求我们的系统学习如何区分有用的片段和不相关的片段，其中更关注前者。</p>
<h1 id="approach">approach</h1>
<p>作者开发一个模型，同时使用到了 CNN 和 RNN，并且还加上 attention 机制。 1. LSTM - q 和 a 分别输入 bi-LSTM - 拼接 bi-LSTM 的正反向向量 - 对输出向量做平均（因为序列中有多个词向量，所以需要取平均） - 做 max pooling 2. CNN 3. Attention LSTM</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>论文笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>SQLNet: Generating Structured Queries From Natural Language Without Reinforcement Learning</title>
    <url>/posts/3b42b60f.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p>主要描述一下该论文 column attention。</p>
<h1 id="sequence-to-set">Sequence-to-set</h1>
<p>直观地说，<strong>where 子句</strong>中出现的列名是<strong>所有列名</strong>的子集。因此，我们可以仅仅预测子集中的列名，而不是生成列名序列（<strong>博主注</strong>：他的意思可能是，不要将 sql 语句中 &quot;select Column A, Column B, Column C...&quot; 的 &quot;Column A, Column B, Column C...&quot; 当做<strong>生成序列</strong>的任务，而是将其当做 slot filling）。我们把这个想法称为 <em>sequence-to-set</em> 的预测。 尤其是我们计算 <span class="math inline">\(P_{wherecol}(col|Q)\)</span>，其中 col 是列名，q 是自然语言问题。为此，将计算 <span class="math inline">\(P_{wherecol}(col|Q)\)</span> 表达为 <span class="math display">\[
    P_{wherecol}(col|Q) = \sigma(u^T_c E_{col} + u^T_q E_Q) 
\]</span> 其中 <span class="math inline">\(\sigma\)</span> 是 sigmoid 函数，<span class="math inline">\(E_{col}\)</span> 和 <span class="math inline">\(E_Q\)</span> 分别是 column name 和自然语言问题的嵌入， <span class="math inline">\(u_c\)</span> 和 <span class="math inline">\(u_q\)</span> 是两个可训练的列向量。。。（<em>后面还有一大段话省略了，主要看 column attention</em>） <a id="more"></a></p>
<h1 id="column-attention">Column attention</h1>
<p>上一节的 <span class="math inline">\(P_{wherecol}(col|Q)\)</span> 的计算公式在使用 <span class="math inline">\(E_Q\)</span> 上有一个问题，因为只计算了自然语言语句的隐藏状态，它也许不能记住在预测<strong>特定</strong>列名时有用的<strong>特定</strong>信息。。。（后面举了个例子） 为了融入这一直觉，我们设计了 column attention 机制去计算 <span class="math inline">\(E_{Q|col}\)</span> 来代替 <span class="math inline">\(E_Q\)</span>。假定 <span class="math inline">\(H_Q\)</span> 是 dxL 的矩阵，L 代表自然语言问题的长度。<span class="math inline">\(H_Q\)</span> 的第 i 列代表问题中对应的第 i 个 token 的 LSTM 的隐藏状态输出。 我们对<strong>问题中的每一个 token</strong> 都计算 attention weight w，w 是 L 维的列向量（博主注：此处应该指的是在计算一个 token 的情况下，论文中未详细指明，仅为猜测）。计算公式如下： <span class="math display">\[
\begin{aligned}
    w &amp; = softmax(v) \\
    v_i &amp; = (E_{col})^T W H^i_Q \qquad \forall i \in {1, \dots, L} \\ 
\end{aligned}
\]</span> <span class="math inline">\(v_i\)</span> 表示 v 的第 i 维，<span class="math inline">\(H^i_Q\)</span> 表示 <span class="math inline">\(H_Q\)</span> 的第 i 列，W 是一个 dxd 大小的可训练矩阵。 在 attention weights w 被计算出来之后，我们可以基于 w 计算 <span class="math inline">\(E_{Q|col}\)</span>，作为每个 token 的隐藏输出的加权和，此处的隐藏状态指 LSTM 上的（这句话极其的绕，懒得解释了。只需要注意一点，这句话是在计算一个单词的情况下，而并非计算整个 question）。 <span class="math display">\[
E_{Q|col} = H_Q w
\]</span> 在 <strong>Sequence-to-set</strong> 中的表达式，我们可以将 <span class="math inline">\(E_Q\)</span> 替换为 <span class="math inline">\(E_{Q|col}\)</span>，以获得 column attention model。 <span class="math display">\[
    P_{wherecol}(col|Q) = \sigma(u^T_c E_{col} + u^T_q E_{Q|col}) 
\]</span> （下面的略）</p>
<h1 id="博主注">博主注</h1>
<p>论文中似乎没有很明确地说明 column 的 embedding 是如何训练的。但是这一环很重要，因为这篇论文是关于 wikiSQL 数据集，训练 seq2sql 的比较前的论文，也就是说后面的论文有一些就是使用这篇论文的方法。所以这一点没搞懂，导致也看不懂其他的论文。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>seq2sql</tag>
      </tags>
  </entry>
  <entry>
    <title>TypeSQL: Knowledge-based Type-Aware Neural Text-to-SQL Generation</title>
    <url>/posts/7a71725f.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<div class="note info"><p><a href="https://arxiv.gg363.site/pdf/1804.09769.pdf" target="_blank" rel="noopener">论文地址</a>，发表于 2018 年。 - 所用数据集 + WikiSQL</p>
</div>
<p>对 text-sql 任务提出了 TypeSQL 模型，将问题视为 slot filiing task，使用 type（详见下面内容） 信息以更好的理解输入中稀有实体和和数字。 对关系型数据库构建一个自然语言接口是一个重要且具有挑战的问题（(Li and Jagadish, 2014; Pasupat and Liang, 2015; Yin et al., 2016; Zhong et al., 2017; Yaghmazadeh et al., 2017; Xu et al., 2017; Wang et al., 2017a）。本论文使用 WikiSQL，它是 <strong>text-to-SQL</strong> 问题的一个巨大的<strong>基准数据集</strong>。对于该任务，具体来说是给定一个关于数据表的自然语言问题及其协议，系统需要生成与该问题对应的 SQL 查询。 本文基于之前的 state-of-the-art SQLNet（<a href="https://openreview.net/pdf?id=SkYibHlRb" target="_blank" rel="noopener">Xu et al., 2017: Sqlnet: Generating structured queries from natural language without reinforcement learning</a>），TYPESQL 使用一个 <strong>sketch-based</strong> 方法，并将此任务视为 slot filing 问题。 进一步，特定于一个数据库的情况下，自然语言问题通常会包含不常见的实体和数字。之前的一些工作 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.93.4408&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Agrawal and Srikant, 2003: Searching with numbers</a> 已经展示了这些词汇对许多下游任务起着重要作用，但是在预训练词嵌入模型中，大部分词汇缺乏准确的 embeddings。为了解决这一问题，无论单词来自知识图谱、数据库的列还是数字，TYPESQL 为每一个单词分配一个 type。例如，在图 1 中，我们将“mort drucker”作为 PERSON，对应于我们的知识图谱；将“spoofed title”，“artist”和“issue” 作为 COLUMN，因为它们是数据的列名；最后将 “88.5” 作为 FLOAT。结合这一发明，TYPESQL 进一步提高了 WiKiSQL 上的性能。 此外，先前大部分工作假定用户的查询包含准确的列名和实体，但是这是不切实际的。为了解决这一问题，……。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<h1 id="方法">方法</h1>
<p>类似 SQLNet，我们使用了 sketch-based 方法，并且将该任务视为 slot filling。首先预处理问题输入，识别 type。然后使用两层 bi-directional LSTMs 去 encode 问题的单词，encode 时分别利用了 type 和列名（数据库）。最后用 LSTMs 输出的隐藏状态预测 SQL sketch 中 slot 的值。</p>
<h2 id="type-recognition-for-input-preprocessing">Type Recognition for Input Preprocessing</h2>
<p><strong>首先将每个问题分为长度 2-6 的 n-gram 语法，然后在 table scheme 中使用它们进行搜索</strong>（这步很关键，但是我觉得用 n-gram 语法可能会错过一些列名吧），并且将问题中出现的任意列名打上 COLUMN 标签。其他类别做类似操作，转换如下所示（以下 type 均来自 Freebase）： 1. 问题中出现的列名 -&gt; COLUMN 2. 问题中的数字和日期 -&gt; INTEGER, FLOAT, DATE, and YEAR 3. 命名体 -&gt; PERSON, PLACE, COUNTRY, ORGANIZATION, and SPORT</p>
<p>五种类别的命名体以及涵盖了数据集中的大部分实体，因此不再使用 Freebase 提供的其他实体类型。</p>
<h2 id="input-encoder">Input Encoder</h2>
<p>如图 1 所示，我们的 input encoder 由 bi-LSTM 组成，分别为：<span class="math inline">\(\text{Bi-LSTM}^{QT}\)</span> 和 <span class="math inline">\(\text{Bi-LSTM}^{COL}\)</span>。为了编码问题中的一对 word 和 type，<strong>我们将 word 和对应的 type 的嵌入拼接起来，然后将它们输入进 <span class="math inline">\(\text{Bi-LSTM}^{QT}\)</span></strong>。最后分别输出隐藏状态 <span class="math inline">\(\text{H}_{QT}\)</span> 和 <span class="math inline">\(\text{H}_{COL}\)</span>。 为了<strong>编码列名</strong>，SQLNet 使用 Bi-LSTM 对每一个列名编码。我们首先平均具有 COLUMN 类型的单词的嵌入，然后只使用<strong>一个</strong> <span class="math inline">\(\text{Bi-LSTM}^{COL}\)</span> 编码。这样的编码方法提高了 1.5% 的性能，并且使得时间减半。<em>我感觉这篇论文写得好乱，有点读不懂这部分</em>。可能需要看一下 SQLNet</p>
<h2 id="slot-filling-model">Slot-Filling Model</h2>
<p>接下来，我们预测 SQL sketch 中 slots 的值。 文章<strong>沿用</strong>了 SQLNet 的 <strong>Column Attention</strong> 机制，即将 question 输入 Bi-LSTM 后得到的 <span class="math inline">\(H_{QT}\)</span> 和 column 的 <span class="math inline">\(H_{COL}\)</span> 做 Attention。关于列的编码部分，上面说了看不懂。计算过程为： <span class="math display">\[
\begin{aligned}
    \alpha_{QT/COL} &amp; = softmax(H_{COL} W_{ct} H^T_{QT}) \\
    H_{QT/COL} &amp; = \alpha_{QT/COL} H_{QT} \\
\end{aligned}
\]</span> 最后我们就得到了 <span class="math inline">\(H_{QT/COL}\)</span> 隐藏状态。然后使用这个隐藏状态进行预测。具体公式为 <strong>MODEL COL-$SELECT COL</strong>： <span class="math display">\[
\begin{aligned}
    s &amp; = V^{sel} tanh(W^{sel}_c H^T_{COL} + W^{sel}_{qt} H^T_{QT/COL}) \\
    P_{sel_col} &amp; = softmax(s) \\
\end{aligned}
\]</span> <span class="math inline">\(P_{sel_col}\)</span> 就是每个单词的概率，我们可以使用 argmax() 函数得到最大概率的索引。</p>
<p><strong>MODEL COL-$COND#</strong>： 。。。略</p>
<p>对于不同的模型，论文中都有说明，就不一一记录了。 <div class="note info"><p>之前理解错了，还以为跟 encoder-decoder 一模一样，现在才知道原来 slot filling 是这样的。 跟语义解析来比较，就是说大致的生成语句已经给你写好了，剩下的几个空，用 attention 的方法来填充，可以理解为不需要 decoder 部分了。</p>
</div></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>seq2sql</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Semantic Parsing over Multiple Knowledge-bases</title>
    <url>/posts/cf3d2f60.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<div class="note info"><p><a href="https://arxiv.gg363.site/pdf/1702.01569.pdf" target="_blank" rel="noopener">论文地址</a>，发表于 2017 年。</p>
</div>
<p>思想：将不同领域的数据集合并，以提高训练集大小。 语义分析被认为是将语言语句翻译为可执行的逻辑形式的技术。要做到普遍使用语义分析的一个基本阻碍是<strong>在新领域标注逻辑形式的代价太大</strong>。为了解决这一问题，先前工作的策略有从 denotations、paraphrases、m declarative sentences 训练。 本论文提出一个正交解：将来自不同域中的多个数据集的样本合并到一起，每个数据集对应一个单独的知识库（KB），并在所有示例上训练模型。这次方法由于观察到知识库在实体和属性上有所不同，但语言组合的结构在领域之间重复，所以由此启发而来。例如，语言中的“最大”对应于“argmax”，动词后跟一个名词通常表示连接操作。与仅在单个领域上训练的模型相比，跨域共享信息的模型可以提高泛化能力。 最近 <a href="https://arxiv.gg363.site/pdf/1606.03622.pdf" target="_blank" rel="noopener">Jia and Liang, 2016: Data recombination for neural semantic parsing</a> 以及 <a href="https://arxiv.gg363.site/pdf/1601.01280.pdf" target="_blank" rel="noopener">Dong and Lapata, 2016: Language to logical form with neural attention</a> 提出了用于语义分析的 seq2seq 模型。将语言和逻辑形式简单地表示为向量形式，这些神经网络模型大致上能促进信息共享。我们以他们的工作为基础，研究了在语言编码和逻辑形式解码过程中跨领域共享表示的模型（即研究语言和逻辑形式在不同领域如何表示，如医学和旅游业）。我们最终发现，<strong>通过向解码器提供领域的表征，我们可以在多个领域上训练单个模型，并且与在每个领域上分别训练的模型相比，大大提高了准确性</strong>。在 Overnight 数据集上提高了性能，并减少了网络参数。 <a id="more"></a></p>
<h1 id="设置">设置</h1>
<p>seq2seq + attention.</p>
<h1 id="多个-kb-上的模型">多个 KB 上的模型</h1>
<p>本文，我们强调一项设置：我们访问来自不同领域的训练集 K，每个领域对应不同的 KB。所有领域的输入都是自然语句，标签都是逻辑形式（<strong>我们假定被标注逻辑形式可以被转换为单个形如 lambda-DCS 的形式语言</strong>）。虽然从单词到 KB 常量的映射在每个域都是特定的，但是我们期望语言所表达的意义可以跨域共享。下面开始描述模型架构。</p>
<h2 id="one-to-one-model">One-to-one model</h2>
<p>此模型类似于 <strong>Section 2</strong> 所描述的模型（Jia and Liang, 2016），如 Figure 2 所示。它由一个 encoder 和一个 decoder 组成，可以用于生成所有领域的输出。因此，模型所有参数由所有领域共享，并且模型从所有样本中训练。</p>
<h2 id="many-to-many-model">Many-to-many model</h2>
<h2 id="one-to-many-model">One-to-many model</h2>
<p>单个 encoder 共享，但是为每个领域设置一个独立的 decoder。共享的 encoder 捕获每个领域输入的英语单词序列的事实，特定领域的 decoder 学习来自正确领域下词表的输出标记（tokens）。</p>
<h1 id="实验">实验</h1>
<ul>
<li>数据集：Overnight</li>
</ul>
<h2 id="实现">实现</h2>
<p>复制了 Jia and Liang, 2016 的实验配置，使用相同的超参数。。。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural network-based question answering over knowledge graphs on word and character level</title>
    <url>/posts/c6a446e9.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<div class="note info"><p><a href="https://www.researchgate.net/publication/315769814_Neural_Network-based_Question_Answering_over_Knowledge_Graphs_on_Word_and_Character_Level" target="_blank" rel="noopener">论文地址</a>，发表于 2017 年。</p>
</div>
<p>基于向量建模的方法。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p><a href="https://arxiv.org/pdf/1506.02075.pdf" target="_blank" rel="noopener">A. Bordes, 2015: Large-scale simple question answering with memory networks</a> <a href="https://arxiv.org/pdf/1604.00727.pdf" target="_blank" rel="noopener">D. Golub and X. He, 2016: Character-level question answering with attention</a> <a href="https://arxiv.org/pdf/1606.03391.pdf" target="_blank" rel="noopener">W. Yin, 2016: Simple question answering by attentive convolutional neural network</a> <a href="https://arxiv.org/pdf/1606.01994.pdf" target="_blank" rel="noopener">Z. Dai, 2016: Cfo: Conditional focused neural question answering with large-scale knowledge bases</a></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
    <url>/posts/d3098fa9.html</url>
    <content><![CDATA[<div class="note info"><p><a href="https://arxiv.org/pdf/1709.00103.pdf" target="_blank" rel="noopener">论文地址</a>，发表于 2017 年。 这篇论文发布了 wikisql 数据集，同时提出了 seq2sql 任务。</p>
</div>
<h1 id="论文概要">论文概要</h1>
<p>本文主要做出两项贡献：1）提出 Seq2SQL，将自然语言问题翻译为其对应的 SQL queries。2）发布 WikiSQL 语料库，其包含 80654 个人工标注的自然语言问题实例， SQL queries 以及从 24241 张 HTML 网页中提取的 SQL 表（网页来自 Wikipedia）。<em>WikiSQL 比以前提供给 logical forms 和自然语句的语义分析数据集大一个数量级</em>。发布 WikiSQL 的同时，我们还发布了一个此数据库的查询引擎（query execution engine） <div class="note primary"><p>本论文将自然语言转为 SQL，关系型数据库。而知识图谱是非关系型数据库存储的。</p>
</div> 关系型数据库存储了大量的信息并用此构建了许多应用，但是访问关系型数据库需要使用 sql 语句并且很难精通它。于是 Natural language interfaces(NLI) 寻求一条路径使得人类和计算机交互成为可能，即将自然语言翻译为 sql 语句。 balabala... 在 wikisql 数据集上，seq2sql 比先前 Dong &amp; Lapata(2016) 做的语义解析模型效果要好。 <a id="more"></a></p>
<h1 id="model">2 Model</h1>
<p>我们的基准模型是 Dong &amp; Lapata(2016) 做的 seq2seq + attention 的模型，它在未使用人工语法的语义解析数据集上实现了最高的性能。<strong>但是这个 seq2seq 模型的 softmax 的输出空间对于这个任务太大了</strong>。（博主注：生成 sql 语句时，并不需要在整个字典中找。sql 语句在某些地方是固定的。比如 select balabala from balabala，格式都是固定的，比如 select，count 等）因此我们可以将生成序列的输出空间限制为 <strong>table schema, question utterance, and SQL key words的并集</strong>。最终模型类似于加入了 augmented inputs 的 <strong>pointer network</strong>。我们 1. 首先描述 augmented pointer network model； 2. 其次说明我们定义 seq2sql 的局限性，特别是在生成<em>无序查询条件</em>方面。</p>
<h2 id="augmented-pointer-network-model">augmented pointer network model</h2>
<h2 id="seq2sql">seq2sql</h2>
<h1 id="博主注">博主注</h1>
<p>论文提出了 seq2sql 模型，为后面的工作铺垫了基础。基线模型是 Dong 2016 年提出的 seq2seq + attention 模型，seq2sql 为第二个模型。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>seq2sql</tag>
      </tags>
  </entry>
  <entry>
    <title>论文复现：Language to Logical Form with Neural Attention</title>
    <url>/posts/a328575.html</url>
    <content><![CDATA[<h1 id="论文介绍">论文介绍</h1>
<p>论文的地址<a href="https://arxiv.org/pdf/1601.01280.pdf" target="_blank" rel="noopener">在此</a>，作者使用了 Lua 语言实现，代码地址<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="noopener">在这</a>，然而我不会 Lua 语言，于是找了找是否有 Python 的实现版本。还真有，Python 版本代码地址<a href="https://github.com/Alex-Fabbri/lang2logic-PyTorch" target="_blank" rel="noopener">在这</a>。 但是 Python 版本的代码<strong>篇幅太长</strong>，且<strong>几乎没有注释</strong>，于是我将其重写了一遍，一些工具类是直接复制别人的，但是核心代码我改写了一下，并添加了一些注释。 <div class="note info"><p>我将里面的数据获取模块移除了。</p>
</div> <a id="more"></a></p>
<h1 id="论文实现">论文实现</h1>
<p>论文共用了两个办法：1）普通 seq2seq 模型；2）作者自创的 seq2tree 模型。其中每个模型又分别有 <strong>lstm 实现</strong>和 <strong>lstm + attention 实现</strong>两种版本。虽然两个版本使用的技术不同，但是说到底也只是同一个模型。以下讲解原理。</p>
<h2 id="seq2seq-模型">seq2seq 模型</h2>
<h3 id="rnn">RNN</h3>
<p>论文中使用 LSTM 实现 seq2seq 模型，训练之后，accuracy 大约在 70%。</p>
<h3 id="transformer">Transformer</h3>
<p>我自己用了 Transformer 改写了一下，并且调了几天的参数，发现效果出奇的差，accuracy 最好只有 18%。然后我还发现，对于短句子几乎是百分比预测正确，对于长句子百分比预测错误。所以<strong>我怀疑是否是位置编码那产生的问题，考虑到一个逻辑形式它并不是纯粹的线性结构，它的内部是由很多括号的</strong>。 经调参后得到最好的一组参数如下： 1. learning rate: 0.001 2. dim_feedforward: 随意（我设置为 256） 3. h_model: 256 4. nhead: 4 5. encoder_layer/decoder_layer: 1 6. dropout: 0.4 7. batch_size: 32（16 的效果可能更好） 8. epoch: 95（epoch 可以进一步修改） 9. src_mask: False 10. tgt_mask: True 11. memory_mask: False</p>
<h2 id="seq2tree-模型">seq2tree 模型</h2>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>论文复现</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习的下一步</title>
    <url>/posts/1fa4521c.html</url>
    <content><![CDATA[<ul>
<li>机器学习能不能知道“我不知道” 机器学习的 classifier 可以判断一张图片是不是猫，但是能不能判断出“我不知道这是什么”？这项技术叫做 <strong>Anomaly Detection</strong>。</li>
<li>机器说出为什么“我知道”
<ul>
<li>神马汉斯的例子</li>
<li>马辨识器的例子。机器只是辨识了英文字母 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/机器学习的下一步/说出为什么“我知道”.jpg" alt="说出为什么“我知道”" /></li>
</ul></li>
<li>机器的错觉？
<ul>
<li>adversarial attack。感觉是 CV 里的技术 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/机器学习的下一步/机器的错觉.jpg" alt="机器的错觉" /></li>
</ul></li>
<li>终身学习（Life-long Learning） 机器能否终身学习。现在模型一般只能对应一个任务，如果让一个模型去学习下围棋，之后再让它去学习玩星海。那么它就不会下围棋了。这被为 <strong>Catastrophic Forgetting</strong>。</li>
<li>学习如何学习 如何写一个<strong>能够写出具有学习能力的程序</strong>的程序。这被称为 <strong>Meta-learning/Learn to learn</strong>。</li>
<li>一定需要很多训练数据吗？
<ul>
<li>Few-shot learning</li>
<li>Zero-shot learning</li>
</ul></li>
<li>Reinforcement learning</li>
<li>神经网络压缩（Network Compression）
<ul>
<li>把大神经网络路缩小</li>
<li>参数二元化</li>
<li>所有的参数都变成 +1 或 -1</li>
</ul></li>
<li>如果训练数据和测试数据长得不一样
<ul>
<li>对于 CV 来说，训练数据和测试数据长得差不多，比如手写体识别。但是如果在真实场景中，测试数据是彩色的，可能会出现准确率骤降的情况。那么如何解决呢？ <a id="more"></a></li>
</ul></li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>【机器学习算法】半监督学习</title>
    <url>/posts/5c11ca38.html</url>
    <content><![CDATA[<h1 id="概念">概念</h1>
<p>半监督学习就是在已有的带标签的数据之后，还有一组不带标签的数据。一般来说，在做无监督学习时，unlabeled data 远大于 labeled data。 半监督学习一般分为两种： - Transductive learning：unlabeled data 就是你的 testing sdata - Inductive learning：unlabeled data 不是你的 testing sdata <a id="more"></a></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/【机器学习算法】半监督学习/导读.jpg" alt="导读" /><figcaption>导读</figcaption>
</figure>
<h2 id="为什么做半监督学习">为什么做半监督学习</h2>
<p>有人说机器学习训练数据很少，其实不完全对。因为只是 labeled data 少，unlabeled data 随处可见。所以如果能将这些 unlabeled data 运用进去就好了。原因如下： - 搜集数据很简单，但是搜集 labeled data 代价昂贵 - 生活中，我们自己也在做半监督学习</p>
<h1 id="semi-supervised-learning-for-generative-model">Semi-supervised Learning for Generative Model</h1>
<h1 id="low-density-separation-assumption">Low-density Separation Assumption</h1>
<h1 id="smoothness-assumption">Smoothness Assumption</h1>
<h1 id="better-representation">Better Representation</h1>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>系列</tag>
      </tags>
  </entry>
  <entry>
    <title>Coarse-to-Fine Decoding for Neural Semantic Parsing</title>
    <url>/posts/2b05bdcf.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p>提出一个结构感知的神经架构，将语义解析过程分解为如下两个步骤：给定一个输入语句，1）首先生成它含义的粗略草图（a rough sketch of its meaning），其中低级信息<strong>被掩盖</strong>（如<strong>变量名和参数</strong>）。2）然后考虑输入本身和草图来填充丢失的细节。 RNN 在多种 NLP 任务中的成功应用对 seq2seq 的语义解析产生了强大的冲击力，如<a href="https://arxiv.org/pdf/1606.03622.pdf" target="_blank" rel="noopener" title="Data recombination for neural semantic parsing">Jia and Liang, 2016</a>; Dong and Lapata, 2016; <a href="https://arxiv.org/pdf/1603.06744.pdf" target="_blank" rel="noopener" title="Latent predictor networks for code generation">Ling et al., 2016</a>。 我们认为，这种方法至少有三个优点。首先，分解步骤<strong>将高级语义信息与低级语义信息分离开来</strong>，使译码器能够在不同的粒度级别对语义进行建模。其次，模型可以明确地为具有相同草图（即基本含义）的示例共享粗糙结构的知识，即使它们的实际含义表示不同（例如，由于不同的细节）。第三，在生成草图后，解码器知道语句的基本含义是什么，<strong>模型可以将其作为全局上下文来改进对最终细节的预测</strong>。 使用如下数据集： 1. GEO 2. ATIS 3. DJANGO 4. WikiSQL <a id="more"></a></p>
<h1 id="问题阐释">问题阐释</h1>
<p>定义 <span class="math inline">\(x = x_1 \dots x_{|x|}\)</span> 为自然语句，<span class="math inline">\(y = y_1 \dots y_{|y|}\)</span>为意义表示，<span class="math inline">\(a = a_1 \dots a_{|a|}\)</span>为 sketch 表示。<del>注意 <strong>sketch 的定义为</strong>：一个中间变量，如将自然语句转化为 Logical Form，Source Code，SQL，noSQL，SPARQL等表示，这些表示都算是一个 sketch。</del>下图论文架构： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Coarse-to-Fine%20Decoding%20for%20Neural%20Semantic%20Parsing/Coarse2Fine架构.jpg" alt="Coarse2Fine架构" /></p>
<h2 id="sketch-generation">Sketch Generation</h2>
<p>encoder 将自然语句编码为向量，decoder 去计算 <span class="math inline">\(p(a|x)\)</span> 从而通过encoding 向量 生成 sketch a。具体来讲，<strong>Input Decoder</strong> 将字转为词向量，并使用 Bi-LSTM 训练。<strong>Coarse Meaning Decoder</strong> 生成 sketch a，也使用 LSTM 并且加上 attention 机制。</p>
<h2 id="meaning-representation-generation">Meaning Representation Generation</h2>
<p>Meaning representation 由输入 x 以及生成的 sketch a 预测产生，具体就是计算 <span class="math inline">\(p(y|x,a)\)</span>。<strong>Sketch Encoder</strong> 与 Input Decoder 类似，使用 Bi-LSTM 并将 sketch a 映射为词向量。<strong>Fine Meaning Decoder</strong> 与 Coarse Meaning Decoder 类似。</p>
<h2 id="总结">总结</h2>
<p>总的来说就是先用自然语句生成 coarse sketch，然后再用 coarse sketch 生成 fine sketch。一共使用了两个 encoder-deocder 模型，但是将这两个模型连起来用。</p>
<h1 id="三个语义分析任务">三个语义分析任务</h1>
<p>为了证明我们的框架适用于跨域和意义表示，我们为三个任务开发了模型，即将自然语言解析为逻辑形式、Python 源代码和 SQL 查询。对于每一个任务，我们都描述了使用的数据集以及 sketch 提取的提取步骤。</p>
<h1 id="实验部分">实验部分</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
        <tag>sketch-based</tag>
      </tags>
  </entry>
  <entry>
    <title>【知识图谱】（一）从概念开始</title>
    <url>/posts/c9c1ae69.html</url>
    <content><![CDATA[<h1 id="知识图谱描述">知识图谱描述</h1>
<p>知识图谱是一种新型的<strong>数据库</strong>，是一种基于图的数据结构。每个节点表示现实世界中存在的“实体”，每条边为实体与实体之间的“关系”。以下为知识图谱的几点作用： - 从“关系”分析问题 - 把不同种类的信息连接在一起 - 一个关系网络</p>
<p>学习知识图谱首先得掌握以下几种技能： 1. <strong>基础知识</strong>：自然语言处理、图数据库操作知识、基本编程能力：Python、SQL； 2. <strong>领域知识</strong>：知识图谱构建方法、知识图谱推理方法； 3. <strong>行业知识</strong></p>
<h1 id="知识图谱的构建步骤">知识图谱的构建步骤</h1>
<ol type="1">
<li>数据收集(持续收集与更新)（<strong>关键词抽取</strong>、<strong>命名体识别</strong>、<strong>关系抽取</strong>、<strong>事件抽取</strong>）
<ol type="1">
<li>原始数据，通常可能是一篇文章
<ol type="1">
<li>爬虫技术
<ol type="1">
<li>垂直爬虫</li>
<li>搜索引擎相关的爬虫</li>
</ol></li>
</ol></li>
<li>语料数据，通常词库，词典，同义词</li>
<li>开源的第三方知识图谱，例如搜狗人物关系图</li>
<li>开源的训练好的词向量(word2vec)模型,tfidf</li>
</ol></li>
<li>图谱设计
<ol type="1">
<li>实体定义(本体) 实体：实体类型
<ol type="1">
<li>属性 例如,手(长度，面积)，类别：身体器官</li>
</ol></li>
<li>属性定义</li>
<li>关系定义
<ol type="1">
<li>关系也需要定义类别</li>
<li>需要评估关系可以覆盖的数据量，一般服从28 原则，20%的关系，覆盖80%数据 <a id="more"></a></li>
</ol></li>
</ol></li>
<li>知识清洗
<ol type="1">
<li><strong>实体消歧</strong></li>
<li><strong>实体统一</strong></li>
</ol></li>
<li>知识融合(实体链接)
<ol type="1">
<li>实体与关系的融合</li>
<li>实体扩充(融合外部知识图谱或者数据)（<strong>知识合并</strong>）</li>
</ol></li>
<li><strong>知识存储</strong>-图数据库</li>
</ol>
<h2 id="知识图谱的架构与设计">知识图谱的架构与设计</h2>
<p>略</p>
<h2 id="知识源数据的获取">知识源数据的获取</h2>
<p>略。可以使用爬虫等技术，或者直接网上搜现成的数据。</p>
<h2 id="信息抽取">信息抽取</h2>
<p>包括关键词抽取、命名体识别、关系抽取，事件抽取等技术。</p>
<h3 id="关键词抽取">关键词抽取</h3>
<h4 id="分词">分词</h4>
<p>分类算法中的流程： 分词--&gt;(自然语言处理,与,知识,图谱,知识图谱)--&gt;去停词--&gt;(自然语言处理,知识,图谱,知识图谱)--&gt;建立索引--&gt;(1,2,3,432,66)--&gt;one hot--&gt;word2vec--&gt;</p>
<h4 id="语料库">语料库</h4>
<p>jieba 分词同时基于一些<strong>语料库</strong>和手写的<strong>规则</strong>（如隐马尔科夫模型）。 如果想要加入自己的语料库可以使用下面的代码，语料库的格式可在 github jieba 上找到。 <figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">jieba.load_userdict(<span class="string">'/home/python/dictionary.txt'</span>)</span><br><span class="line">seg_list = jieba.cut(text, cut_all=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="string">' '</span>.<span class="keyword">join</span>(seg_list))</span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>词库
<ul>
<li>医药知识图谱
<ul>
<li>语料库（网上有现成的，不用自己爬，如：医药行业专业词典）
<ul>
<li>医院的名称</li>
<li>疾病的名称</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h4 id="文本特征提取">文本特征提取</h4>
<p>文本数据的表示模型： - 布尔模型（boolean model） - 向量空间模型（vector space model） - 概率模型（probabilistic model） - 图空间模型（graph space model）等</p>
<p>以下为几种主要的模型，它们的目标都是：建立文档的向量（矩阵）模型。加粗代表是现在常用的模型 1. <strong>TF-IDF</strong> 2. LDA 3. LSA/LSI 4. <strong>Word2Vec</strong> 5. one-hot 6. BERT 7. ...</p>
<h5 id="tf-idf">TF-IDF</h5>
<p>TF：词频 IDF：逆文档频率。 权重 = TF * IDF TF-IDF 可能会漏掉一些词。比如一篇文章只出现一次“周杰伦”，但是它已经表示了这篇文章的主旨。可是 TF-IDF 无法为该词分配较高的权重。 另外 jieba 中其实可以直接使用 TF-IDF。导入<code>jieba.analyse</code>即可使用。（TF-IDF 其实就是提取句子的标签） <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">import jieba.analyse <span class="keyword">as</span> ja</span><br><span class="line">ja.extract<span class="constructor">_tags(<span class="params">sentence</span>, <span class="params">topK</span>=3,<span class="params">withWeight</span>=False, <span class="params">allowPOS</span>=()</span>)</span><br></pre></td></tr></table></figure></p>
<h5 id="word2vec">word2vec</h5>
<p>TF-IDF 只考虑单个文字，忽略了句子中的上下文信息。而word2vec 考虑了上下文，输入值为某个单词的前几个单词、后几个单词和其本身。 word2vec 现成的工具包有：1)gensim；2)tensorflow；3)keras。 另外 QA 系统等应用可能不适合使用 word2vec 训练出来的单词。因为它训练出来的词向量没有捕获到<strong>太多</strong>的上下文信息。众所众知，QA 系统和对话系统等应用需要经常使用到很多上下文信息。</p>
<h3 id="命名体识别ner">命名体识别——NER</h3>
<p>所谓的命名体（named entity）就是人名、机构名、地名以及其他所有以名称为标识的实体。更广泛的实体还包括数字、日期、货币、地址等等。 难点：1)<strong>同义词、歧义词等</strong>；2)<strong>未登录词判定</strong>。 一般流程：1)<strong>基于规则的方法</strong>；2)<strong>基于模型的方法</strong>，常见的序列标注模型包括 <strong>HMM</strong>（Hidden Markov Model）、<strong>CRF</strong>（Conditional random field）、<strong>RNN</strong>。不过虽然基于模型的方法技术比较新颖，但是由于太过复杂以及太难解释，所以公司还是用基于规则的方法比较多。</p>
<h4 id="序列标注">序列标注</h4>
<ul>
<li>基于HMM</li>
<li>基于CRF <div class="note danger"><p>上课的时候没听明白。</p>
</div></li>
<li>基于RNN 要做命名体识别，首先要做序列标注的任务。目前有以下几种公认的标注体系： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/标注体系.png" alt="标注体系" /></li>
</ul>
<h3 id="关系抽取特征工程">关系抽取（特征工程）</h3>
<ol type="1">
<li><strong>文本特征提取</strong>，采用 tf-idf</li>
<li><strong>关键字抽取</strong>，比如转让，收购，整合等等</li>
<li><strong>句法特征提取</strong>，主要是与核心词之间的关系，包括企业实体本身和前后词与核心词之间的关系，距离等。即抽取（实体，关系，实体）<strong>三要素</strong>特征
<ul>
<li>依存句法分析
<ul>
<li>依存树，<a href="http://ltp.ai/demo.html" target="_blank" rel="noopener">demo</a></li>
<li>CCG</li>
</ul></li>
<li>分类器</li>
</ul></li>
<li>如果使用 NN 训练，可以拼接三要素和 tf-idf 特征</li>
</ol>
<h3 id="事件抽取">事件抽取</h3>
<p>略，培训中未提到，估计跟关系抽取差不多。</p>
<h2 id="知识融合">知识融合</h2>
<h3 id="实体链接">实体链接</h3>
<h4 id="实体统一实体对齐">实体统一/实体对齐</h4>
<p><strong>注：另一种说法是实体统一和实体对齐并不是同一件事。此处姑且当它们是同一件事。</strong> 对同一实体具有多个名称的情况进行实体统一，将多个名称统一替换成一个命名实体。比如，“河北银行股份有限公司”和“河北银行”可以统一成“河北银行”。 大致来说这个应用是使用规则来做实体统一。目前（2019 年 7 月）来说，基于规则的做法大概能解决 70% 左右的问题。还可以使用余弦相似度，分类等算法进行融合使用。 - 分离出地名，比如河北，北京 - 去除后缀，比如有限公司，集团 - 提取经营范围，比如医疗，化学 - 剩余部分为中间字段 - 最后选择以上四个部分的某些部分进行拼接，成为一个唯一的命名实体，如果有中间字段，则仅使用中间字段即可，并对某些特殊的经营范围做补充，比如银行；否则，优先使用地名加经营范围，其次是地名加后缀。</p>
<p><strong>更新命名体：在做完实体统一之后，将原数据中的实体进行替换即可</strong>。</p>
<h4 id="实体消歧">实体消歧</h4>
<p>与实体统一不同。实体统一是将两个不一样名称的实体统一起来，而实体消歧是将同一个名称的实体在不同语境下区分开来，比如：苹果在不同的语境下分别有水果和手机的意思。 中文的不怎么好做，主要运用规则。</p>
<h3 id="知识合并">知识合并</h3>
<p><a href="https://102.alibaba.com/downloadFile.do?file=1518508273059/CoLink%20An%20Unsupervised%20Framework%20for%20User%20Identity%20Linkage.pdf" target="_blank" rel="noopener">阿里巴巴实体合并框架</a></p>
<h2 id="知识加工">知识加工</h2>
<h2 id="知识存储与检索">知识存储与检索</h2>
<h2 id="知识应用">知识应用</h2>
<h1 id="汉语处理的难点">汉语处理的难点</h1>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/汉语处理的难点.jpg" alt="汉语处理的难点" /><figcaption>汉语处理的难点</figcaption>
</figure>
<h1 id="nlp-工具包">NLP 工具包</h1>
<p>略。详见此<a href="https://yan624.github.io/assorted/conference/2019%20普开培训.html#NLP-工具包">博客</a></p>
<h1 id="项目实战">项目实战</h1>
<p>以上为知识图谱的大致概述，以下以几个例子大致地将构建步骤串联起来。首先给出知识图谱的总结<strong>思维导图</strong>，可以按照图中的内容自行对应查找知识点。思维导图的阅读顺序是<strong>从上至下</strong>，<strong>从右至左</strong>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/知识图谱总结.png" alt="知识图谱总结" /></p>
<h2 id="医疗命名体识别">医疗命名体识别</h2>
<p><a href="https://github.com/liuhuanyong/MedicalNamedEntityRecognition" target="_blank" rel="noopener">项目地址</a>，使用了基于字向量的<strong>四层双向 LSTM</strong> 与 <strong>CRF 模型</strong>的网络。 本项目大致使用了<strong>信息抽取</strong>-&gt;<strong>命名体识别</strong>的技术。项目中有一个名为 data_origin 的文件夹，其结构为： <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">data_origin</span><br><span class="line">  ├─一般项目</span><br><span class="line">  │  ├─一般项目-<span class="number">1</span>.txt</span><br><span class="line">  │  ├─一般项目-<span class="number">1</span><span class="selector-class">.txtoriginal</span><span class="selector-class">.txt</span></span><br><span class="line">  │  └─。。。</span><br><span class="line">  ├─出院情况</span><br><span class="line">  ├─病史特点</span><br><span class="line">  └─诊疗经过</span><br></pre></td></tr></table></figure> <em>一般项目-1.txt</em> 文件包含了由<strong>人工标注</strong>过的数据，<em>一般项目-1.txtoriginal.txt</em> 包含了原始数据，即未经过任何处理的数据。类似以下的格式。第 2 列和第 3 列代表该命名体在原始数据中的开始和结束的索引。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/原始数据.jpg" alt="原始数据" /></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/人工标注后的数据.jpg" alt="人工标注后的数据" /><figcaption>人工标注后的数据</figcaption>
</figure>
<p>以上的数据为项目的原数据（那个由人工标注过的数据也算原数据），我们需要使用一套标注体系（本项目使用 BIO 体系）来将原数据处理一下，以下是处理结果。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/使用%20BIO%20标注后的数据.jpg" alt="使用 BIO 标注后的数据" /></p>
<p>你可能会疑惑 DISEASE-* 之类的东西是什么意思，以及它是怎么出来的。其实十分简单，如下所示，都是预先定义好的。以 B 结尾，代表一个命名体的开始，以 I 结尾，代表一个命名体的结束。而产生数据的过程也只是写死的一套逻辑，使用 if else 进行判断罢了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/标签字典.jpg" alt="标签字典" /></p>
<h3 id="训练之前的准备工作">训练之前的准备工作</h3>
<ol type="1">
<li>定义标签</li>
<li>人工将数据一条一条地标注命名体、起始位置以及标签</li>
<li>选择一套标注体系</li>
<li>将<strong>每一份</strong>原数据使用标注体系处理后，存入<strong>一份</strong>文件</li>
</ol>
<h3 id="训练">训练</h3>
<p>代码中以 <code>['。','?','!','！','？']</code> 符号作为一份病历的结束。然后将训练数据重新拆分成多分训练样本。我倒是认为在原数据处理完毕合并时，就做一些处理不行吗？如果以那些符号作为判断条件，可能有些不太准。 1. 加载字向量； 2. 以 <code>['。','?','!','！','？']</code> 符号作为一份病历的结束，重新切分数据为多份训练样本； 3. 每一个字都有一个标注，比如训练样本：[感, 染, 风, 寒]和标注：[CHECK-B, CHECK-I, DISEASE-B, DISEASE-I]--转换为--&gt;[32, 8454, 676, 934]和[7, 8, 10, 9]； 4. 程序定义有 150 个时间步，第一层 BiLSTM 为 128 维，第二层的 BiLSTM 为 64 维，各层之间的 Dropout 取 0.5； 5. 将训练样本输入 RNN，RNN 的输出输入 CRF，CRF 输出一个 11 维的向量，即每一个字都会输出一个 11 维的向量。所以可以看做是一个 11 元分类模型，即判断一个字属于哪一类的标注，也就是序列标注的含义——为字标注属性； 6. 训练结束，就完成了一个序列标注模型。</p>
<h3 id="总结">总结</h3>
<p>此项目实现了<strong>命名体识别</strong>的功能，使用了 <strong>LSTM</strong> 以及 <strong>CRF</strong> 的技术，原数据采用了<strong>人工标注</strong>的处理方式，原数据转为训练样本采用了<strong>规则模版</strong>的方式。总的来说，没有太大难度。对于此项目，我们需要理解 LSTM 和 CRF 的算法，整个过程的难点就在人工标注上，费时费力。</p>
<h2 id="中文人物关系知识图谱">中文人物关系知识图谱</h2>
<p><a href="https://github.com/liuhuanyong/PersonRelationKnowledgeGraph" target="_blank" rel="noopener">项目地址</a>。此项目代码结构有点复杂，涉及了很多爬虫，我对爬虫不是很了解。</p>
<h3 id="总结-1">总结</h3>
<p>此项目实现了<strong>关系抽取</strong>的功能，具体使用了什么技术<strong>未知</strong>。</p>
<h2 id="判断两个企业实体是否存在投资关系">判断两个企业实体是否存在投资关系</h2>
<p><a href="https://github.com/rlistengr/Entity-relationship-extraction" target="_blank" rel="noopener">项目地址</a>。</p>
<h3 id="总结-2">总结</h3>
<p>此项目实现了<strong>关系抽取</strong>和<strong>实体统一</strong>的功能，基本上使用了人工模版去判断两个企业是否<strong>统一</strong>。是否存在投资关系也是用规则判断的。</p>
<h2 id="金融问答项目">金融问答项目</h2>
<p>此项目（<strong>实验21-1-FinancialKGQA</strong>）实现了一个简单的金融问答项目，前提项目为<strong>实验19-neo4j构建简单的金融知识图谱</strong>，旨在使用爬虫技术构建一个金融知识图谱。数据和代码已经由 2019.6.27 普开知识图谱培训机构提供。</p>
<h3 id="总结-3">总结</h3>
<p>从下图可以看出，只是简单的关键词匹配。然后通过 neo4j 的 CQL 语句进行查询。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%5B知识图谱%5D（一）概述/金融问答示例代码.jpg" alt="金融问答示例代码" /></p>
<h2 id="企业经营退出风险预测">企业经营退出风险预测</h2>
<p><a href="https://github.com/xiaorancs/business-exit-risk-forecast" target="_blank" rel="noopener">项目地址</a>，还没研究过。同一个项目，<a href="https://github.com/ShawnyXiao/2017-CCF-BDCI-Enterprise" target="_blank" rel="noopener">另一个人的项目地址</a></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>KG</category>
      </categories>
      <tags>
        <tag>知识图谱</tag>
        <tag>系列</tag>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>2019 普开培训</title>
    <url>/posts/97a14fe9.html</url>
    <content><![CDATA[<h1 id="第一天">第一天</h1>
<h2 id="概述">概述</h2>
<p>知识图谱是一种新型的<strong>数据库</strong>，是一种基于图的数据结构。每个节点表示现实世界中存在的“实体”，每条边为实体与实体之间的“关系”。以下为知识图谱的几点作用： - 从“关系”分析问题 - 把不同种类的信息连接在一起 - 一个关系网络</p>
<p>学习知识图谱首先得掌握以下几种技能： 1. <strong>基础知识</strong>：自然语言处理、图数据库操作知识、基本编程能力：Python、SQL； 2. <strong>领域知识</strong>：知识图谱构建方法、知识图谱推理方法； 3. <strong>行业知识</strong></p>
<p>现在知识图谱领域中比较火热的是：风控。<strong>企查查</strong>可以查询企业的状态。 知识图谱<strong>核心技术</strong>可分为（大致就是一本书的目录）： 1. 知识图谱的架构与设计 2. 知识图谱核心技术-<strong>知识源数据的获取</strong> 3. 知识图谱核心技术-信息抽取-<strong>关键词抽取</strong>(属性与数值) 4. 知识图谱核心技术-信息抽取-<strong>实体识别</strong>（深度学习+经典方案） 5. 知识图谱核心技术-信息抽取-<strong>关系抽取</strong>（深度学习+经典方案） <a id="more"></a> 6. 知识图谱核心技术-信息抽取-<strong>事件抽取</strong>（深度学习+经典方案） 7. 知识图谱核心技术-知识融合概述 8. 知识图谱核心技术-知识融合-实体链接-<strong>实体统一</strong>（深度学习+经典方案） 9. 知识图谱核心技术-知识融合-实体链接-<strong>实体消岐</strong>（深度学习+经典方案） 10. 知识图谱核心技术-知识融合-<strong>知识合并</strong> 11. 知识图谱核心技术-知识加工概述 12. 知识图谱核心技术-知识加工-<strong>本体构建</strong> 13. 知识图谱核心技术-<strong>知识存储与检索</strong> 14. 知识图谱核心技术-知识加工-<strong>知识推理</strong> 15. 知识应用-智能问答，风控，营销.... 16. 知识图谱核心技术-知识加工-知识更新 17. 知识图谱核心技术-知识加工-质量评估</p>
<p><strong>基本任务</strong>和<strong>主要研究方向</strong>： - 机器翻译 - 自动摘要 - 文本分类与信息过滤 - 信息检索 - 信息抽取与文本挖掘 + 实体抽取：命名体识别 + 关系抽取：关系抽取算法 + 事件抽取 * 地区、时间、过程 * 文本分类（为事件分类） - 情感分析 - 自动问答 - ……</p>
<p>自然语言处理与知识图谱的<strong>处理步骤</strong>： 0. 分词、语料库、文本分类、文本聚类、文本词性分析。。。 1. 信息抽取 2. 知识融合阶段 - 实体统一 - 实体消歧</p>
<h2 id="分词">分词</h2>
<p>分类算法中的流程： (自然语言处理与知识图谱)--&gt;分词--&gt;(自然语言处理,与,知识,图谱,知识图谱)--&gt;去停词--&gt;(自然语言处理,知识,图谱,知识图谱)--&gt;建立索引--&gt;(1,2,3,432,66)--&gt;one hot--&gt;word2vec--&gt;</p>
<h3 id="语料库">语料库</h3>
<p>jieba 分词同时基于一些<strong>语料库</strong>和手写的<strong>规则</strong>（如隐马尔科夫模型）。 如果想要加入自己的语料库可以使用下面的代码，语料库的格式可在 github jieba 上找到。 <figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">jieba.load_userdict(<span class="string">'/home/python/dictionary.txt'</span>)</span><br><span class="line">seg_list = jieba.cut(text, cut_all=<span class="keyword">True</span>)</span><br><span class="line"><span class="keyword">print</span>(<span class="string">' '</span>.<span class="keyword">join</span>(seg_list))</span><br></pre></td></tr></table></figure></p>
<ol type="1">
<li>词库
<ul>
<li>医药知识图谱
<ul>
<li>语料库（网上有现成的，不用自己爬，如：医药行业专业词典）
<ul>
<li>医院的名称</li>
<li>疾病的名称</li>
</ul></li>
</ul></li>
</ul></li>
</ol>
<h3 id="文本特征提取">文本特征提取</h3>
<p>文本数据的表示模型： - 布尔模型（boolean model） - 向量空间模型（vector space model） - 概率模型（probabilistic model） - 图空间模型（graph space model）等</p>
<p>以下为几种主要的模型，它们的目标都是：建立文档的向量（矩阵）模型。加粗代表是现在常用的模型 1. <strong>TF-IDF</strong> 2. LDA 3. LSA/LSI 4. <strong>Word2Vec</strong> 5. one-hot 6. BERT 7. ...</p>
<h4 id="tf-idf">TF-IDF</h4>
<p>TF：词频 IDF：逆文档频率。 权重 = TF * IDF TF-IDF 可能会漏掉一些词。比如一篇文章只出现一次“周杰伦”，但是它已经表示了这篇文章的主旨。可是 TF-IDF 无法为该词分配较高的权重。 另外 jieba 中其实可以直接使用 TF-IDF。导入<code>jieba.analyse</code>即可使用。（TF-IDF 其实就是提取句子的标签） <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">import jieba.analyse <span class="keyword">as</span> ja</span><br><span class="line">ja.extract<span class="constructor">_tags(<span class="params">sentence</span>, <span class="params">topK</span>=3,<span class="params">withWeight</span>=False, <span class="params">allowPOS</span>=()</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="word2vec">word2vec</h4>
<p>TF-IDF 只考虑单个文字，忽略了句子中的上下文信息。而word2vec 考虑了上下文，输入值为某个单词的前几个单词、后几个单词和其本身。 word2vec 现成的工具包有：1)gensim；2)tensorflow；3)keras。 另外 QA 系统等应用可能不适合使用 word2vec 训练出来的单词。因为它训练出来的词向量没有捕获到<strong>太多</strong>的上下文信息。众所众知，QA 系统和对话系统等应用需要经常使用到很多上下文信息。</p>
<h3 id="汉语处理的难点">汉语处理的难点</h3>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/汉语处理的难点.jpg" alt="汉语处理的难点" /><figcaption>汉语处理的难点</figcaption>
</figure>
<h2 id="nlp-工具包">NLP 工具包</h2>
<ul>
<li>中文分词工具（粗体推荐使用，其他随意）
<ul>
<li><strong>jieba</strong>：<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">下载地址</a>。分词、ti-idf、标注。。。
<ul>
<li>全模式：把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；</li>
<li>精确模式：试图将句子最精确地切开，适合文本分析；</li>
<li>搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。</li>
</ul></li>
<li>snownlp：<a href="https://github.com/isnowfy/snownlp" target="_blank" rel="noopener">下载地址</a>。这个有点慢</li>
<li><strong>Hanlp</strong>：<a href="https://github.com/hankcs/pyhanlp" target="_blank" rel="noopener">下载地址</a>。功能较多，比如：
<ul>
<li>中文分词</li>
<li>词性标注（pos）</li>
<li>命名实体识别（ner）</li>
<li>关键词提取</li>
<li>自动摘要</li>
<li>短语提取</li>
<li>拼音转换</li>
<li>简繁转换</li>
<li>依存句法分析</li>
<li>word2vec</li>
</ul></li>
<li>pkuseg：<a href="https://github.com/lancopku/pkuseg-python" target="_blank" rel="noopener">下载地址</a>。支持细领域分词，比如海洋、新闻、医药等。MIT 许可证，所以不可商用</li>
<li>THULAC：<a href="https://github.com/thunlp/THULAC-Python" target="_blank" rel="noopener">下载地址</a></li>
<li>fudannlp：不怎么更新了
<ul>
<li>fastNLP：复旦新开发的一个工具，做了很多模型的集成，如 BERT。</li>
</ul></li>
</ul></li>
<li>英文分词工具
<ul>
<li>gensim：分词、主题分析等</li>
<li><strong>spaCy</strong>：<a href="https://spacy.io/usage/models" target="_blank" rel="noopener">文档</a></li>
</ul></li>
</ul>
<h2 id="ner">NER</h2>
<p>所谓的命名体（named entity）就是人名、机构名、地名以及其他所有以名称为标识的实体。更广泛的实体还包括数字、日期、货币、地址等等。 难点：1)<strong>同义词、歧义词等</strong>；2)<strong>未登录词判定</strong>。 一般流程：1)<strong>基于规则的方法</strong>；2)<strong>基于模型的方法</strong>，常见的序列标注模型包括 <strong>HMM</strong>（Hidden Markov Model）、<strong>CRF</strong>（Conditional random field）、<strong>RNN</strong>。不过虽然基于模型的方法技术比较新颖，但是由于太过复杂以及太难解释，所以公司还是用基于规则的方法比较多。</p>
<h3 id="序列标注">序列标注</h3>
<p>要做命名体识别，首先要做序列标注的任务。目前国家有以下几种标注体系： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/标注体系.png" alt="标注体系" /> - 基于HMM - 基于CRF <div class="note danger"><p>上课的时候没听明白。</p>
</div> - 基于RNN</p>
<h1 id="第二天">第二天</h1>
<h2 id="医疗命名体识别">医疗命名体识别</h2>
<p>使用 BIO 标注体系。 命名体识别模型训练步骤： 1. 准备数据：<strong>原始数据，即自然语言语句</strong> 1. <strong>定义大类</strong>，如 BODY、SIGN、DISEASE。使用数据抽样的方法，2-3 周 2. 对原始数据进行标注：<strong>对原始数据进行人工标注，如<code>右髋部    21  23  身体部位</code>、<code>疼痛   27  28  症状和体征</code></strong>。data_orign 文件夹中有 *.txt 和 *.txtoriginal.txt 文件。其中 *.txtoriginal.txt 文件中是医生诊断的原始数据，*.txt 中是将原始数据中的特征标注出来（此步骤是人工操作。不过如果有很多数据，其实可以偷个懒，因为<strong>有些特征差不多，在一份病历中标注一次就够了</strong>。比如风寒会出现很多次，其实只要在一份病历中标注一次，之后就可以被程序识别到了，当然多标注几份也行），<strong>如果已经有字典，比如网上下载的，可以不进行此步</strong>。 3. 设置标注格式：如 IO、BIO、BMEWO 等体系。 4. 编写转换程序：<strong>将所有标注的病历数据按标注体系转换，并且合并在一份文件中。如：<code>肺   DISEASE-B</code>、<code>炎   DISEASE-I</code>。详见：transfer_data.py</strong>。在 data/train.txt中。<strong>注：此标注方法不需要进行分词，因为它以字为级别</strong>。 5. 算法模型：LSTM 和 CRF 如何结合？请看下图。不管多大项目，词向量一般选 300 维 - LSTM - CRF <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/BiLSTM%20+%20CRF.png" alt="BiLSTM + CRF" /> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/LSTM+CRF例子.jpg" alt="LSTM+CRF例子" /> 6. 算法预测：预测结果较差，可能是因为数据较少。</p>
<p>CRF 并不擅长提取属性，比如病人的受伤面积，可以使用正则表达式。 端到端训练就是一个模型到另一个模型的训练，比如LSTM + CRF。</p>
<h2 id="中国人物关系图谱">中国人物关系图谱</h2>
<h2 id="讲到的技术">讲到的技术</h2>
<ul>
<li>命名体识别</li>
<li>关系抽取</li>
</ul>
<h1 id="第三天">第三天</h1>
<h2 id="实体分词">实体分词</h2>
<p>重要内容提示:●交易简要内容:中海(海南)海盛船务股份有限公司将散货船“百花山”轮作为废钢船出售给江门市银湖拆船有限公司，出售价格为人民币17，183，633.49元。 ----分词为----&gt; 重要内容, 提示, 交易, 简要内容, 中海, 海南, 海盛船务股份有限公司, 。。。 ## 命名体识别 识别所有命名体。 ### 企业实体识别 利用 foolnltk 工具包，对每个新闻做命名实体识别，并对企业命名实体做实体统一，最后将每个新闻中的企业实体替换为统一的企业实体。</p>
<h2 id="实体统一实体对齐">实体统一/实体对齐</h2>
<p>对同一实体具有多个名称的情况进行实体统一，将多个名称统一替换成一个命名实体。比如，“河北银行股份有限公司”和“河北银行”可以统一成“河北银行”。 大致来说这个应用是使用规则来做实体统一。目前（2019 年 7 月）来说，基于规则的做法大概能解决 70% 左右的问题。还可以使用余弦相似度，分类等算法进行融合使用。 - 分离出地名，比如河北，北京 - 去除后缀，比如有限公司，集团 - 提取经营范围，比如医疗，化学 - 剩余部分为中间字段 - 最后选择以上四个部分的某些部分进行拼接，成为一个唯一的命名实体，如果有中间字段，则仅使用中间字段即可，并对某些特殊的经营范围做补充，比如银行；否则，优先使用地名加经营范围，其次是地名加后缀。</p>
<h3 id="更新命名体">更新命名体</h3>
<p><strong>在做完实体统一之后，将原数据中的实体进行替换即可</strong>。</p>
<h2 id="特征工程关系抽取">特征工程（关系抽取）</h2>
<ol type="1">
<li><strong>文本特征提取</strong>，采用 tf-idf</li>
<li><strong>关键字抽取</strong>，比如转让，收购，整合等等</li>
<li><strong>句法特征提取</strong>，主要是与核心词之间的关系，包括企业实体本身和前后词与核心词之间的关系，距离等。即抽取（实体，关系，实体）三要素特征
<ul>
<li>依存句法分析
<ul>
<li>依存树，<a href="http://ltp.ai/demo.html" target="_blank" rel="noopener">demo</a></li>
<li>CCG</li>
</ul></li>
<li>分类器</li>
</ul></li>
<li>拼接三要素 + tf-idf 特征</li>
</ol>
<h2 id="训练">训练</h2>
<p>将特征工程提取到的特征做 onehot 编码（不一定要是 onehot），利用随机森林进行模型拟合。使用贝叶斯超参数调优，调优参数为【决策树数量，决策树的最大深度，随机数生成器】。或者可以使用深度学习的算法，如神经网络。</p>
<h2 id="补充">补充</h2>
<h3 id="实体消歧">实体消歧</h3>
<p>中文的不怎么好做，主要运用规则。</p>
<h3 id="知识融合">知识融合</h3>
<p>实体扩充(融合外部知识图谱或者数据)。<a href="https://102.alibaba.com/downloadFile.do?file=1518508273059/CoLink%20An%20Unsupervised%20Framework%20for%20User%20Identity%20Linkage.pdf" target="_blank" rel="noopener">阿里巴巴实体链接框架</a></p>
<h2 id="知识图谱构建步骤总结">知识图谱构建步骤总结</h2>
<ol type="1">
<li>数据收集(持续收集与更新)（<strong>关键词抽取</strong>、<strong>命名体识别</strong>、<strong>关系抽取</strong>、<strong>事件抽取</strong>）
<ol type="1">
<li>原始数据，通常可能是一篇文章
<ol type="1">
<li>爬虫技术
<ol type="1">
<li>垂直爬虫</li>
<li>搜索引擎相关的爬虫</li>
</ol></li>
</ol></li>
<li>语料数据，通常词库，词典，同义词</li>
<li>开源的第三方知识图谱，例如搜狗人物关系图</li>
<li>开源的训练好的词向量(word2vec)模型,tfidf</li>
</ol></li>
<li>图谱设计
<ol type="1">
<li>实体定义(本体) 实体：实体类型
<ol type="1">
<li>属性 例如,手(长度，面积)，类别：身体器官</li>
</ol></li>
<li>属性定义</li>
<li>关系定义
<ol type="1">
<li>关系也需要定义类别</li>
<li>需要评估关系可以覆盖的数据量，一般服从28 原则，20%的关系，覆盖80%数据</li>
</ol></li>
</ol></li>
<li>知识清洗
<ol type="1">
<li><strong>实体消歧</strong></li>
<li><strong>实体统一</strong></li>
</ol></li>
<li>知识融合(实体链接)
<ol type="1">
<li>实体与关系的融合</li>
<li>实体扩充(融合外部知识图谱或者数据)（<strong>知识合并</strong>）</li>
</ol></li>
<li><strong>知识存储</strong>-图数据库</li>
</ol>
<h1 id="前三天的总结">前三天的总结</h1>
<ol type="1">
<li>知识图谱的架构与设计</li>
<li>知识图谱核心技术-知识源数据的获取</li>
<li>知识图谱核心技术-信息抽取-关键词抽取(属性与数值)</li>
<li>知识图谱核心技术-信息抽取-实体识别（深度学习+经典方案）
<ol type="1">
<li>目的：抽取数据中的实体信息，例如人名</li>
<li>方法：
<ol type="1">
<li>规则：（正则等）</li>
<li>模型：传统方法CRF，深度学习BiLSTM+CRF</li>
</ol></li>
<li>过程：
<ol type="1">
<li>按照CRF要求定义好实体的分类与标注体系</li>
<li>标注训练数据</li>
<li>编写BiLSTM+CRF模型</li>
<li>使用模型预测</li>
<li>组合预测的结果</li>
<li>纠错预测的结果</li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-信息抽取-关系抽取（深度学习+经典方案）
<ol type="1">
<li>目的：抽取实体与实体间的关系，例如：出生于</li>
<li>方法：
<ol type="1">
<li>规则，例如：通过关键词，进行匹配</li>
<li>模型
<ol type="1">
<li>传统
<ol type="1">
<li>分类
<ol type="1">
<li>基于CRF+LSTM，需要将实体标签变成关系类别的标签，进行预测</li>
</ol></li>
<li>基于语法树
<ol type="1">
<li>依托于语法规则，识别关系属于哪两个实体，要求是句子结构要短一点，如果很长，规则不好定义</li>
</ol></li>
<li>BootStrapping</li>
</ol></li>
<li>深度学习</li>
</ol></li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-信息抽取-事件抽取（深度学习+经典方案）
<ol type="1">
<li>目的：抽取内容中的事件，以及他们的关系</li>
<li>事 件关系的类型：</li>
<li>因果事件 某一事件导致某一事件发生 A导致B<br />
</li>
<li>事件预警 因果溯源 由因求果 &lt;地震,房屋倒塌&gt; 条件事件 某事件条件下另一事件发生 如果A那么B<br />
</li>
<li>事件预警 时机判定 &lt;限制放宽,立即增产&gt; 反转事件 某事件与另一事件形成对立 虽然A但是B 预防不测 反面教材 &lt;起步晚,发展快&gt;</li>
<li>顺承事件 某事件紧接着另一事件发生 A接着B 事件演化 未来意图识别 &lt;去旅游,买火车票&gt;</li>
<li>主要的方法：</li>
<li>规则</li>
</ol></li>
<li>知识图谱核心技术-知识融合概述
<ol type="1">
<li>目的：将信息抽取中，抽取的实体与关系，进行融合 例如，(曹操，父子，曹丕) （曹操，父子，曹植）</li>
<li>融合的层次-实体链接
<ol type="1">
<li>实体与实体的融合</li>
<li>实体与外部数据的融合</li>
<li>知识图谱与知识图谱的融合</li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-知识融合-实体链接-实体统一（深度学习+经典方案）
<ol type="1">
<li>目的：统一实体的名称，例如杭州阿里巴巴集团，阿里巴巴</li>
<li>统一的方法：
<ol type="1">
<li>规则：例如去掉杭州阿里巴巴集团的集团，与地区，比较与简称的差距</li>
<li>基于模型：如入A与B，判断是否为一个实体</li>
<li>基于文本相似度：例如使用余弦定理，</li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-知识融合-实体链接-实体消岐（深度学习+经典方案）
<ol type="1">
<li>目的：消除实体间的歧义</li>
<li>方法：
<ol type="1">
<li>结合语境， 例如该文章类别如果是3c数码类文章，那么小米指的是小米 然后进行实体补全</li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-知识融合-知识合并
<ol type="1">
<li>实体与实体的融合</li>
<li>实体与外部数据的融合</li>
<li>知识图谱与知识图谱的融合</li>
</ol></li>
<li>知识图谱核心技术-知识加工概述</li>
<li>知识图谱核心技术-知识加工-本体构建</li>
<li>知识图谱核心技术-知识存储与检索 - Neo4j create
<ul>
<li>(:Movie {title:&quot;驴得水&quot;,released:2016}) return p;</li>
<li>(p1:Person {name:'Alice'}) -[:KNOWS][-&gt;(p2:Person {name:'Bob'})</li>
</ul></li>
<li>知识图谱核心技术-知识加工-知识推理</li>
<li>知识应用-智能问答，风控，营销....</li>
<li>智能问答应用 1. 如何实现基于知识图谱的智能问答？
<ol type="1">
<li>对用户输入的问题进行语义分析</li>
<li>问题分类
<ol type="1">
<li>问题的类型分类：例如，冬天下雨怎么办，是咨询类问题</li>
<li>问题的问形式上的分类，例如，怎么办，如何办，去哪办</li>
</ol></li>
<li>问句解析
<ol type="1">
<li>实体提取，例如，中国移动真不错，提取了中国移动实体</li>
<li>意图的预测，例如，万达怎么去，预测客户是想买东西</li>
<li>问题补全，例如，周末去哪吃比较好----&gt;周末去哪(万达附近)吃饭比较好</li>
<li>其他重要词汇识别</li>
</ol></li>
<li>将解析过的语句，转换成：cql等图数据查询语句</li>
<li>将查到的结果，结合之前的问题分类与模版，进行模板填充，反馈给客户</li>
<li>风控</li>
<li>营销
<ol type="1">
<li>亲人圈发现</li>
<li>朋友圈发现</li>
</ol></li>
</ol></li>
<li>知识图谱核心技术-知识加工-知识更新</li>
<li>知识图谱核心技术-知识加工-质量评估</li>
</ol>
<h1 id="第四天">第四天</h1>
<p>等于没学。搞了一天的环境配置。</p>
<h1 id="第五天">第五天</h1>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/普开培训/图谱构建流程概览.png" alt="图谱构建流程概览" /> 图谱构建流程在第十五讲 PPT。</p>
<h1 id="第六天">第六天</h1>
<p>第十六讲实验步骤。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>conference</category>
      </categories>
      <tags>
        <tag>青岛</tag>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>2. 两数相加</title>
    <url>/posts/cbe0ef88.html</url>
    <content><![CDATA[<h1 id="题目">题目</h1>
<h1 id="有问题的解法1">有问题的解法1</h1>
<p>代码 <figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">class</span> <span class="symbol">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123;</span><br><span class="line">        <span class="built_in">int</span> nextNodeCarryValue = <span class="number">0</span>;</span><br><span class="line">        ListNode sum = new ListNode(nextNodeCarryValue);</span><br><span class="line">        ListNode s = sum;</span><br><span class="line">        </span><br><span class="line">        ListNode t1 = l1, t2 = l2;</span><br><span class="line">        <span class="built_in">int</span> a = <span class="number">0</span>;</span><br><span class="line">        <span class="built_in">int</span> b = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(t1 != <span class="literal">null</span> || t2 != <span class="literal">null</span>)&#123;</span><br><span class="line">            <span class="comment">// 计算和</span></span><br><span class="line">            <span class="built_in">int</span> res = t1.val + t2.val;</span><br><span class="line">            </span><br><span class="line">            <span class="built_in">int</span> nodeValue = res % <span class="number">10</span>;</span><br><span class="line">            nextNodeCarryValue = res / <span class="number">10</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 先创建下一个节点</span></span><br><span class="line">            ListNode nextNode = new ListNode(nextNodeCarryValue);</span><br><span class="line">            </span><br><span class="line">            s.val += nodeValue;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 移动节点</span></span><br><span class="line">            t1 = t1.next;</span><br><span class="line">            t2 = t2.next;</span><br><span class="line">            </span><br><span class="line">            <span class="comment">// 顺便处理最后一个节点，这里的代码十分难理解</span></span><br><span class="line">            <span class="keyword">if</span>((t1 != <span class="literal">null</span> || t2 != <span class="literal">null</span>) || nextNodeCarryValue != <span class="number">0</span>)&#123;</span><br><span class="line">                s.next = nextNode;</span><br><span class="line">                s = s.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 进最后一位</span></span><br><span class="line">        <span class="comment">// if(nextNodeCarryValue != 0)&#123;</span></span><br><span class="line">        <span class="comment">//     s.next = new ListNode(nextNodeCarryValue); </span></span><br><span class="line">        <span class="comment">// &#125;</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//处理两个 ListNode 不等长的情况</span></span><br><span class="line">        ListNode t = <span class="literal">null</span>;</span><br><span class="line">        <span class="keyword">if</span>(t1 != <span class="literal">null</span>)&#123;</span><br><span class="line">            t = t1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            t =t2;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(t != <span class="literal">null</span>)&#123;</span><br><span class="line">            s.next = new ListNode(t.val);</span><br><span class="line">            t = t.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> <a id="more"></a></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>1. 两数之和</title>
    <url>/posts/b55528ce.html</url>
    <content><![CDATA[<h1 id="题目">题目</h1>
<p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 <strong>示例</strong>： &gt; 给定 nums = [2, 7, 11, 15], target = 9 &gt; 因为 nums[0] + nums[1] = 2 + 7 = 9 &gt; 所以返回 [0, 1] <a id="more"></a></p>
<h1 id="暴力破解">暴力破解</h1>
<ul>
<li>时间复杂度：O(<span class="math inline">\(n^2\)</span>)</li>
<li>空间复杂度：O(1)</li>
<li>用时 39ms</li>
</ul>
<p>首先想到了暴力破解的方法，但是后来发现其实没必要遍历整个数组，内部的循环从 0 开始遍历会浪费时间，与将 <code>for(int j = 0; j &lt; len; j++)</code> 改为了 <code>for(int j = i + 1; j &lt; len; j++)</code>。</p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="symbol">Solution</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="built_in">int</span>[] twoSum(<span class="built_in">int</span>[] nums, <span class="built_in">int</span> target) &#123;</span><br><span class="line">        <span class="built_in">int</span> len = nums.length;</span><br><span class="line">        <span class="built_in">int</span>[] res =&#123;<span class="number">0</span>, <span class="number">0</span>&#125;;</span><br><span class="line">        <span class="keyword">for</span>(<span class="built_in">int</span> i = <span class="number">0</span>; i &lt; len; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="built_in">int</span> j = i + <span class="number">1</span>; j &lt; len; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] + nums[j] == target)&#123;</span><br><span class="line">                    res[<span class="number">0</span>] = i; res[<span class="number">1</span>] = j;</span><br><span class="line">                    <span class="keyword">return</span> res;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="两遍哈希表">两遍哈希表</h1>
<p>暴力破解的办法时间复杂度较高，还有一种方法可以减少时间复杂度，但是会增加空间复杂度。创建一个 Map 来暂存数据。 - 时间复杂度：O(n) - 空间复杂度：O(n) - 用时 10ms</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; <span class="built_in">map</span> = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> len = nums.length;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++)&#123;</span><br><span class="line">            <span class="built_in">map</span>.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> diff = target - nums[i];</span><br><span class="line">            Integer j = <span class="built_in">map</span>.get(diff);</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">map</span>.containsKey(diff) &amp;&amp; j != i)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;i, j&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ArithmeticException(<span class="string">"无解"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="一遍哈希表">一遍哈希表</h1>
<ul>
<li>时间复杂度：O(n)</li>
<li>空间复杂度：O(n)</li>
<li>用时 6ms</li>
</ul>
<p>一遍就能做完题目看似不可能，因为看似无法遍历完所有组合，但是实际上可以，只需要仔细思考一下。 <figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; <span class="built_in">map</span> = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> diff = target - nums[i];</span><br><span class="line">            <span class="keyword">if</span>(<span class="built_in">map</span>.containsKey(diff))&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;i, <span class="built_in">map</span>.get(diff)&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">map</span>.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ArithmeticException(<span class="string">"无解"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>Complex Sequential Question Answering: Towards Learning to Converse Over Linked Question Answer Pairs with a Knowledge Graph</title>
    <url>/posts/2d072ec8.html</url>
    <content><![CDATA[<div class="note warning"><p><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17181/15750" target="_blank" rel="noopener">论文地址</a>。 <strong>凉了。读完论文，发现论文中的实验是使用 python2 写的，而且由于没有 VPN 无法下载实验附带的数据，训练数据有 17G，我都不想下了。</strong></p>
</div>
<h1 id="引子">引子</h1>
<p>人机对话时，人们通常会提出许多问题，其中大部分都可以通过大规模的 KG 回答。为此，我们提出了 Comples Sequential QA（CSQA） 任务，它由以下两种任组成： 1. 在拥有百万个实体的 KG 上进行复杂的推理从而回答事实性问题； 2. 通过一系列连贯的链接问答对去学习交谈。</p>
<p>接着还让工作人员创建了一个数据集，包括总共 1.6M 轮的 200k 的对话数据。我们还要求数据集含有<strong>逻辑推理</strong>（logical），<strong>定量推理</strong>（quantitative）以及<strong>比较推理</strong>（comparative ）的能力（此三种能力下面有详解）。因此这就迫使我们的模型要做到： 1. 解析复杂的自然语言问题； 2. 使用对话上下文解析表达中的<strong>共指</strong>（coreferences ）、<strong>省略</strong>（ellipsis ）问题； 3. 要求理清<strong>含糊不清</strong>（ambiguous ）的问题； 4. 检索相关的 KG 的子图去回答这些问题。</p>
<p>说明： - <strong>共指问题</strong>（coreferences）：就是说一个代词指向多个对象，机器人无法理解具体指向哪个 - <strong>省略问题</strong>（ellipsis）：表达没问题，但是表达中省略了一部分信息，需要人自己去上文中推测 - <strong>含糊不清的问题</strong>（ambiguous）：（与 1 类似，请看 1） <a id="more"></a></p>
<h1 id="本文贡献">本文贡献</h1>
<ol type="1">
<li>引入 CSQA 的概念；</li>
<li>展示一流的 QA 和对话系统的处理方法在解决这些任务时的不足之处；</li>
<li>对 CSQA 提出了一个模型，由一流的 hierarchical conversation model（<strong>HRED</strong>）（<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11957/12160" target="_blank" rel="noopener">Serban 2016a</a>，<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/viewFile/14567/14219" target="_blank" rel="noopener">Serban 2017</a>） 和 key value（<strong>KV</strong>） based memory network model（<a href="https://arxiv.org/pdf/1606.03126.pdf" target="_blank" rel="noopener">Miller 2016</a>） 组成。</li>
</ol>
<h1 id="数据集创建">数据集创建</h1>
<p>论文花了很大的篇幅描写了数据集是如何创建的。使用 14-Nov-2016 的 wiki data 创建，其中包含了 5.2k 的 relation（谓语），12.8M entity（主语），52.3M facts（宾语）。但是省略了像“ISO 3166-1 alpha-2 code”、“NDL Auth ID”等 relation，因为不期望用户会问这些模糊的问题。接着论文分别描述了 Simple Questions、Complex Questions 和 Linked Sequential QA 是如何创建的。</p>
<h2 id="simple-questions">Simple Questions</h2>
<p>为了发现问题，我们要求 annotators 自己提出问题并用 KG 中的<strong>单个</strong>三元组进行回答。后来 annotators 认为对于个三元组，主要有三种类型的问题： 1. 基于宾语（object）的问题，问题中包含三元组中的主语和关系，答案包含三元组中的宾语； 2. 基于主语（subject）的问题，问题中包含三元组中的宾语和关系，答案包含三元组中的主语； 3. 基于关系（relation）（理解成谓语也可以）的问题。后来在创建的数据集中发现，此类问题没有多大的意义。比如，数据集中有人问了一个很不自然的问题“Q:How is Himalayas related to India? A:located in”。<strong>所以论文只关注前两个问题</strong>。</p>
<h2 id="complex-questions">Complex Questions</h2>
<p>接下来要求 annotators 建立一些逻辑推理（Logical Reasoning）、定量推理（Quantitative Reasoning）、比较推理（Comparative Reasoning）类型的问题。 1. 逻辑推理：考虑问题“哪些河流流经中国和印度？”，为了回答这个问题首先需要创建两组集合i){flowthrough, India, river}，ii){flowthrough, China, river}。最后求交集。此类问题可由 Simple Questions 修改得到，如 <strong>AND</strong> 操作：<strong>“哪些河流流经印度”</strong>修改为<strong>“哪些河流流经印度”+“和中国”</strong>；<strong>OR</strong>操作：<strong>“哪些河流流经印度”</strong>修改为<strong>“哪些河流流经印度”+“或中国”</strong>。全部的操作包括以下三种： - AND - OR - NOT 2. 定量推理：如遇到max、min、count、at least/almost/approxmately/equal to N 等问题需要做定量推理。中文类似。 3. 比较推理：基于某一个关系的问题需要做推理。如：“哪个国家拥有的河流比印度多？”</p>
<h2 id="linked-sequential-qa">Linked Sequential QA</h2>
<p>现在开始通过上述的 QA 对创建连续的对话，简单来说，如果两个问题共享一个 relation 或者 entity，那么就将两个问题放在一起。</p>
<h1 id="模型">模型</h1>
<p>CSQA 由对话和 QA 组成，我们提出的模型由 <strong>HRED</strong> 模型和 <strong>key value memory network</strong> 模型组合而成。其中 HRED 模型是对话系统中的一流模型，key value memory network 模型是 QA 系统中的一流模型。我们的模型由以下组件构成： 1. <strong>Hierarchical Encoder</strong>： 2. <strong>Handling Large Vocabulary</strong> 3. <strong>Candidate generation</strong> 4. <strong>Key Value Memory Network</strong> 5. <strong>Decoder</strong></p>
<p>其中 1234 是 encoder，5是 decoder。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/复杂的连续问答：使用知识图谱在关联的问答对上学习交谈能力/提出的模型架构.jpg" alt="提出的模型架构" /></p>
<h1 id="结果">结果</h1>
<p>使用 <strong>Adam</strong> 算法作为优化算法。 然后调整以下超参数：<strong>learning rate</strong> <span class="math inline">\(\in\)</span> {1e-3, 4e-4}， <strong>RNN hidden unit size</strong>、 <strong>word embeddingsize</strong>、 <strong>KG embedding size</strong> <span class="math inline">\(\in\)</span> {256, 512}，<strong>batch size</strong> <span class="math inline">\(\in\)</span> {32, 64}，<strong>dialog context size</strong> as 2。 使用 Precision 和 Recall 作为评估指标。对于验证和计数的问题我们使用 accuracy 作为评估指标，此类问题会产生 YES/NO 或者 counts 的结果。最后对于需要阐明（clarification）的问题，系统产生自然语言回应，这通常是 KG 实体和非 KG 单词的序列，因此使用 Precision/Recall 作为 KG 实体的预测，使用 BLEU 作为语义相似度的衡量指标。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/复杂的连续问答：使用知识图谱在关联的问答对上学习交谈能力/实验结果.jpg" alt="实验结果" /></p>
<h1 id="讨论">讨论</h1>
<p>根据表 4 中的结果，我们讨论了现有方法的一些缺点，并提出了未来研究的领域。 1. <strong>Simple v/s Complex Questions</strong>：很明显在我们的模型上，与简单问题相比，复杂问题的性能非常差。改进点有很多，i)不确定现在逻辑函数是否可以处理定量、比较和逻辑推理问题；ii)不清楚现有的 encoder（HRED + key value memory network）是否能够有效地解析复杂问题并为 encoder 提供良好的表示。 2. <strong>Direct v/s Indirect Questions</strong>：用表 4 中的第 3、4 行跟第 2 行比较，发现在处理不完整的问题时，模型性能有所下降，这些问题都需要依赖上下文才能解决共指、省略等难点。即使现在的对话系统（HRED）确实捕捉到了上下文，也没有什么作用。因为其中的一个<em>关键点</em>是<strong>对于我们创建的数据集有一个巨大的挑战</strong>：数据集里的 <strong>named entities</strong> 和 <strong>relations</strong> 比上下文中<strong>其他单词更重要</strong>，所以我们需要一个更好的模型，可以在训练时标出 relations 和 entities 的重要性（例如：<strong>注意力机制</strong>）。 3. <strong>Candidate Generation</strong>： 4. <strong>Better organization of the memory</strong>：对于某些问题，特别是设计多个实体和逻辑操作的复杂问题，不可避免地需要使用大量的内存存储元组。大约有 15% 的问题需要超过 100k 个候选元组。这会使 GPU 超负荷，并且也会使 softmax 的计算开销巨大，所以需要i)更好的内存组织方式，ii)SoftMax 函数的近似方法。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（八）：Adaboost</title>
    <url>/posts/4a4c67dc.html</url>
    <content><![CDATA[<h1 id="组合">组合</h1>
<p>分类算法有很多，比如逻辑回归、kNN 算法、决策树、朴素贝叶斯算法、支持向量机等，它们各有优缺点。我们自然可以<strong>将不同的分类器组合起来</strong>，而这种组合结果则被称为<strong>集成方法</strong>（ensemble method）或者元算法（meta-algorithm）。使用形式多种多样，可以是不同算法的集成，还可以是相同算法不同配置的集成，也可以自行发挥。</p>
<h1 id="bagging">bagging</h1>
<p>自举汇聚法（bootstrap aggregating），也称为 bagging 方法。是从原始数据集选择 S 次后得到 S 个新数据集的一种技术。新数据集与原数据集的大小相等。 在 S 个数据集建好之后，将某个学习算法分别作用域每个数据集就得到了 S 个分类器。使用这 S 个分类器进行分类，然后将结果中最多的类别作为最后的分类结果。 当然还有一些更先进的 bagging 方法，比如随机森林（random forest）。 <a id="more"></a></p>
<h1 id="boosting">boosting</h1>
<p>boosting 方法拥有多个版本，这里只关注其中一个最流行的版本 AdaBoost。</p>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>Adaboost</tag>
      </tags>
  </entry>
  <entry>
    <title>代价函数</title>
    <url>/posts/c778cce0.html</url>
    <content><![CDATA[<h1 id="总结">总结</h1>
<table>
<thead>
<tr class="header">
<th>代价函数</th>
<th>选择</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>binary cross entropy</td>
<td>典型选择：二元分类</td>
</tr>
<tr class="even">
<td>cross entropy</td>
<td>典型选择：多元分类</td>
</tr>
<tr class="odd">
<td>mse</td>
<td>典型选择：线性回归</td>
</tr>
</tbody>
</table>
<h1 id="softmax-loss">Softmax Loss</h1>
<p>Softmax Loss 是由 softmax 和 cross entropy loss 组合而成，在 pytorch，caffe，tensorflow 等开源框架的实现中，直接将二者合并在一层。如在 pytorch 中不需要再输出层加上 softmax 层用于分类，直接使用 cross entropy loss 即可。 <a id="more"></a></p>
<h1 id="各类代价函数">各类代价函数</h1>
<p><a href="https://blog.csdn.net/cqfdcw/article/details/78173839" target="_blank" rel="noopener">方差、协方差、标准差、均方差、均方根值、均方误差、均方根误差</a> <a href="https://www.cnblogs.com/shujuxiong/p/9339916.html" target="_blank" rel="noopener">L1正则和L2正则的比较分析详解</a></p>
<h1 id="各类距离公式">各类距离公式</h1>
<p><a href="https://blog.csdn.net/guojingjuan/article/details/50396254" target="_blank" rel="noopener">python 各类距离公式实现</a></p>
<h1 id="补充">补充</h1>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>名称</th>
<th>英文</th>
<th>公式</th>
<th>别称</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>残差平方和 SSE</td>
<td>Sum of Squares for Error</td>
<td>SSE = <span class="math inline">\(\sum^m_{i=1}(y_i - \hat{y}_i)^2\)</span></td>
<td>剩余平方和 RSS</td>
</tr>
<tr class="even">
<td>回归平方和 SSR</td>
<td>Sum of Squares for Regression</td>
<td>SSR = <span class="math inline">\(\sum^m_{i=1}(\hat{y}_i - \bar{y})^2\)</span></td>
<td>解释平方和 ESS</td>
</tr>
<tr class="odd">
<td>总离差平方和 SST</td>
<td>Sum of Squares for Total</td>
<td>SST = <span class="math inline">\(\sum^m_{i=1}(y_i - \bar{y})^2\)</span></td>
<td>总离差平方和 TSS</td>
</tr>
</tbody>
</table>
<p>三者之间的关系是 SST = SSR + SSE <span class="math inline">\(R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}\)</span></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>代价函数</tag>
      </tags>
  </entry>
  <entry>
    <title>Neural Enquire: Learning to Query Tables in Natural Language</title>
    <url>/posts/453404ab.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p>我们提出使用一种神经网络结构结合知识库来回答自然语言（NL）问题。与之前端到端的语义解析器不同，NEURAL ENQUIRER 是完全“神经化”的：它提供查询和 KB 表的分布式表示，并通过一系列可微的操作执行查询。该模型可以通过 end-to-end 和 step-by-step 的监督进行梯度下降训练。在训练期间，查询和 KB 表的表示将与查询执逻辑（query execution logic）一起进行优化。实验表明，该模型可以学习对结构丰富的 KB 表执行复杂的 NL 查询。</p>
<h1 id="论文内容介绍">论文内容介绍</h1>
<a id="more"></a>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision</title>
    <url>/posts/bb52c93a.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p>本文介绍了一种神经符号机（Neural Symbolic Machine, NSM）</p>
<h1 id="论文内容介绍">论文内容介绍</h1>
<a id="more"></a>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
  </entry>
  <entry>
    <title>Sequence-to-Action: End-to-End Semantic Graph Generation for Semantic Parsing</title>
    <url>/posts/ecdf3755.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzI2NjkyNDQ3Mw==&amp;mid=2247486979&amp;idx=2&amp;sn=2d95556630820c853f2ca9b2855dd60a&amp;chksm=ea87f6d5ddf07fc3cc8477d3a0cd5142e9191d91ff3161847524c37539b372b306a8f9b700a8&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">某篇解析</a>；<a href="http://tongtianta.site/paper/11795" target="_blank" rel="noopener">某篇解析</a> <a href="https://arxiv.org/pdf/1809.00773.pdf" target="_blank" rel="noopener">论文地址</a>。 本文提出一种神经语义分析方法——Sequence-to-Action，将语义分析当做一个端到端的<strong>语义图生成</strong>的过程。我们同时使用了最近语义分析两个有前途的方向，<strong>首先</strong>我们的模型使用了一个语义图来表示一个句子的含义，该语义图与知识库紧密相关（博主注：<strong>即可以将语义图看作是知识库的一个子图</strong>）。<strong>其次</strong>，利用神经网络强大的表示学习和预测能力，提出一种 RNN 模型，能够有效的将句子映射到动作序列，从而生成语义图（博主注：<strong>此动作序列就是指生成语义图的动作，将这些动作看作是一个序列</strong>）。实验表明该方法在 OVERNIGHT 数据集上展现了一流的性能，在 GEO 以及 ATIS 数据集上得到了有一定竞争力的性能。 语义分析旨在<strong>将自然语言句子映射为逻辑形式</strong>（Zelle andMooney, 1996; Zettlemoyer and Collins, 2005;Wong and Mooney, 2007; Lu et al., 2008;Kwiatkowski et al., 2013）。例如“Which states border Texas?”将会被映射为 <em>answer (A, (state (A),nextto (A, stateid ( texas ))))</em>。 语义分析器需要两个函数，一个处理结构预测，另一个处理语义基础。传统的语义解析器通常基于复合语法，如 CCG（Zettlemoyer and Collins, <a href="https://arxiv.org/pdf/1207.1420" target="_blank" rel="noopener">2005</a>, <a href="https://www.aclweb.org/anthology/D07-1071" target="_blank" rel="noopener">2007</a>），DCS（<a href="https://www.aclweb.org/anthology/P11-1060" target="_blank" rel="noopener">Liang et al., 2011</a>）等。不幸的是，设计语法和学习精确的词汇仍是一个挑战，特别是在开放域。而且设计有效的特性往往很困难，它的学习过程也不是端到端的。为了解决上述问题，本文提出了两种有前途的研究方向：<strong>基于语义图</strong>的方法和<strong>基于 seq2seq</strong> 方法。 <a id="more"></a> 基于语义图的方法(Reddy et al.,2014, 2016; Bast and Haussmann, 2015; Yih et al.,2015)将句子的含义表示为语义图（即知识库的子图，参考图 1 中的例子）并<strong>将语义分析视为语义图匹配/生成过程</strong>。<strong>与逻辑形式相比，语义图与知识库有着紧密的关系</strong>(Yih et al., 2015), ，与句法结构有许多共性（Reddy et al.,2014）。基于语义图的句法分析的主要挑战是如何有效地构造句子的语义图，目前语义图是通过与模式匹配（Bast and Haussmann, 2015），从依赖树转换（Reddy et al., 2014, 2016），或者通过 staged heuristic search algorithm（Yih et al.,2015）构建的。这些方法都是基于人工设计的构造过程，它们很难处理开放/复杂的情况。 近年来，得益于 RNN 模型有较强的表示能力和预测能力，其在 Seq2Seq 模型上取得了成功，比如机器翻译。许多 Seq2Seq 模型也用于语义分析（Xiaoet al., 2016; Dong and Lapata, 2016; Jia and Liang, 2016），不需要高质量的词典、人工构建的语法和特性。这些模型通过端到端的训练，利用注意力机制（Bahdanauet al., 2014; Luong et al., 2015）学习句子和逻辑形式之间的软对齐。 本文提出了一种新的神经语义分析框架——Sequence-to-Action。它可以同时利用语义图表示的优点和 seq2seq 模型强大的预测能力。具体来说，我们将语义分析建模为一个端到端的语义图生成过程。例如，在图 1 中，我们的模型将通过生成一系列变量[add variable:a，addtype:state，…]来解析“which states border Texas”这句话。为了实现上述目标，我们首先设计了一个动作集，对语义图的生成过程进行编码（包括节点动作：add variable,add entity,add type，边动作：add edg 以及操作动作：argmin,argmax,count,sum 等）然后我们设计了一个 RNN 模型，该模型可以生成一个动作序列来构造句子的语义图。最后，我们在解码过程中合并结构和语义约束来进一步增强解析。</p>
<h1 id="论文内容介绍">论文内容介绍</h1>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
        <tag>seq2action</tag>
      </tags>
  </entry>
  <entry>
    <title>Language to Logical Form with Neural Attention</title>
    <url>/posts/521b57a9.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<div class="note info"><p><a href="https://arxiv.org/pdf/1601.01280.pdf" target="_blank" rel="noopener">论文地址</a>，发表于 2016 年。</p>
</div>
<p>语义分析的目的是将自然语言映射到机器可解释的有意义表示。传统的方法依赖于高质量的词汇、人工构建的模板以及特定领域或特定表示的语言特征，本文提出了一种注意力增强的 encoder-decoder 通用模型。将输入的话表示为向量形式，并通过调节输出序列或者树生成逻辑形式（总结来说，就是<strong>将话语转为逻辑形式</strong>，详情请看图 1）。 下图将一句话转为了逻辑形式，不同于以前的方法，它是通过神经网络生成的，而以前的方法依赖于手写的规则。图片取自 <a href="https://www.aclweb.org/anthology/W00-1317" target="_blank" rel="noopener" title="Automated construction ofdatabase interfaces: Intergrating statistical and rela-tional learning for semantic parsing">Tang and Mooney200</a>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Language%20to%20Logical%20Form%20with%20Neural%20Attention/语句转为逻辑形式.jpg" alt="语句转为逻辑形式" /></p>
<p>基于 RNN 的 encoder-decoder 已成功应用于各种 NLP 任务，图 1 中使用了 LSTM，我们的做法是提出了两个变体模型。<strong>第一个模型</strong>将语义解析视为普通的序列转换任务，<strong>第二个模型</strong>配备了层次树解码器，该解码器明确地捕获逻辑形式的组合结构。我们还引入了<strong>注意力机制</strong>，并提出一个识别步骤来<strong>识别很少提到的实体</strong>和<strong>数字</strong>。 对<strong>四个数据集</strong>的实验结果表明，我们的方法在不使用人工设计特征的情况下具有竞争力，并且易于迁移。 我们的工作综合了两种标准研究，即<strong>语义分析</strong>和 <strong>encoder-decoder 架构的神经网络</strong>。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p>学习语义解析器的问题引起了广泛的关注，可以追溯到 Woods（1973年）。。。。</p>
<h1 id="任务定义">任务定义</h1>
<p>我们的目标是学习一个模型，将<u><strong>自然语言输入 <span class="math inline">\(q = x_1 \dots x_{|q|}\)</span></strong></u> 映射为其含义的<u><strong>逻辑形式（logical form）表示 <span class="math inline">\(a = y_1 \dots y_{|a|}\)</span></strong></u>。条件概率被分解为： <span class="math display">\[
\begin{align}
    p(a|q) &amp; = \prod^{|a|}_{t=1} p(y_t|y_{&lt;t},q) \tag 1\\
    y_{&lt;t} &amp; = y_1 \dots y_{t-1}
\end{align}
\]</span> 我们的模型包含一个编码器和一个解码器，编码器负责将输入的自然语言 q 编码成向量，解码器负责生成 <span class="math inline">\(y_1 \dots y_{|a|}\)</span>。下面将仔细描述。</p>
<h2 id="seq2seq">Seq2Seq</h2>
<p>对于普通的 Seq2Seq 任务，使用 LSTM 来计算，如下图所示。<span class="math inline">\(h^l_t\)</span> 代表第 l 层的第 t 个时间步的隐藏层，公式为： <span class="math display">\[
\begin{align}
    h^l_t = \text{LSTM}(h^l_{t-1},h^{l-1}_t) \tag 2
\end{align}
\]</span> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Language%20to%20Logical%20Form%20with%20Neural%20Attention/Seq2Seq.jpg" alt="Seq2Seq" /> 在实验中，遵循 <a href="https://arxiv.org/pdf/1409.2329.pdf" target="_blank" rel="noopener" title="RECURRENT NEURAL NETWORK REGULARIZATION">Zaremba et al. 2015</a> 提出的架构。不过，使用其他类型的门控激活函数也是可以的（例如<a href="https://arxiv.org/pdf/1406.1078.pdf" target="_blank" rel="noopener" title="Learning phrase representations using RNN encoder-decoder for statistical machine translation">Cho et al. 2014</a>）。<strong>对于 encoder</strong>，<span class="math inline">\(h^0_t = W_qe(x_t)\)</span>（注：此公式是第 0 层的运算步骤，即输入层）是 RNN 中输入的词向量，<span class="math inline">\(W_q \in \mathbb{R}^{n \times |V_q|}\)</span> 代表输入层的权重值矩阵，e(·) 代表对应 token 的索引。<strong>对于 decoder</strong>，<span class="math inline">\(h^0_t = W_ae(y_{t-1})\)</span> 代表前一个预测词的词向量，其中 <span class="math inline">\(W_a \in \mathbb{R}^{n \times |V_a|}\)</span>。接下来，最后的 LSTM <span class="math inline">\(h^L_t\)</span> 被用于预测 <span class="math inline">\(t\)</span>-th 输出 token，计算公式为： <span class="math display">\[
\begin{align}
    p(y_t|y_t,q) = softmax(W_oh^L_t)^T e(y_t) \tag 3
\end{align}
\]</span> <strong>该公式用于预测每一个 token</strong>。另外补充一点，增加了 “start-of-sequence” <code>&lt;s&gt;</code> 和 “end-of-sequence” <code>&lt;/s&gt;</code>。 该模型总的来说，就是 LSTM 的计算方法，也没什么好说的。</p>
<h2 id="seq2tree">Seq2Tree</h2>
<p>Seq2Seq 模型有一个<strong>缺点</strong>就是它<strong>忽略了逻辑形式的层次结构</strong>。所以，要改良的话，它需要记住各种辅助信息（比如括号对），以此生成格式良好的输出。如下图 3 所示，是一个层次树 decoder： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Language%20to%20Logical%20Form%20with%20Neural%20Attention/Seq2Tree模型.jpg" alt="Seq2Tree模型" /></p>
<p>Seq2Tree 与 Seq2Seq 的编码器类似，不同的是解码器。Seq2Tree 以自上而下的方式生成逻辑，为了定义树结构，我们定义了一个表示子树的 “nonterminal” <code>&lt;n&gt;</code> 标记。如图 3 所示，将<strong><em>逻辑形式 “lambda $0 e (and (&gt;(departure_time $0) 1600:ti) (from $0 dallas:ci))”</em></strong>预处理为树，方法是<strong>用 nonterminal 替换括号对之间的标记</strong>（token）。<strong>特殊记号 <code>&lt;s&gt;</code> 和 <code>&lt;(&gt;</code> 分别表示序列和 nonterminal 序列的开头</strong>（由于缺少空间，图3中省略了），<strong>记号 <code>&lt;/s&gt;</code> 代表序列结束</strong>。具体步骤是： 1. 编码输入值 q； 2. 层次树解码器使用 RNN 在逻辑形式 a（在<strong>任务定义</strong>中已经说明了 q 和 a 的含义）的对应部分的子树中生成 tokens（注意这里的 token 带了 s）； 3. 如果预测的 token 为 <code>&lt;n&gt;</code>，则通过调节 nonterminal 的隐藏向量来解码序列。（博主注：举个例子理解一下：看图 3 的第一层，先是使用 encoder 进行编码，接着开始对逻辑形式进行解码，逻辑形式就是上面的斜体部分。接下来预测到了 token<code>&lt;n&gt;</code> 于是调用 nonterminal 的隐藏向量来进行解码，即生成一棵子树。以此类推，碰到 toekn <code>&lt;n&gt;</code> 就开始解码） 4. 与 Seq2Seq 解码器不同，当前的隐藏状态不仅仅取决于上一个时间步，为了更好地利用 parent nonterminal 的信息，我们引入了一个 parent-feeding 的连接，其中 parent nonterminal 的隐藏向量与输入连接（concatenated）并喂入 LSTM。</p>
<p>再举个例子帮助理解一下，如图 4 所示。逻辑形式为 <strong><em>A B (C)</em></strong>，其中 <span class="math inline">\(y_1 \dots y_6\)</span> 代表不同的时间步，<strong><em>(C)</em></strong> 对应子树。解码一共有<strong>两个步骤</strong>：一旦输入值 q 被编码，首先在深度为 1 处生成 <span class="math inline">\(y_1 \dots y_4\)</span>，直到 token <code>&lt;/s&gt;</code> 被预测到；接下来通过调节 nonterminal <span class="math inline">\(t_3\)</span> 的隐藏向量来生成 <span class="math inline">\(y_5, y_6\)</span>，<span class="math inline">\(p(a|q)\)</span> 的概率是这<strong>两个序列解码步骤</strong>的乘积： <span class="math display">\[
p(a|q) = p(y_1 y_2 y_3 y_4 | q) p(y_5 y_6 | y_{\leq 3},q)
\]</span> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Language%20to%20Logical%20Form%20with%20Neural%20Attention/一个简单的Seq2Tree的例子.jpg" alt="一个简单的Seq2Tree的例子" /></p>
<h2 id="attention-机制">Attention 机制</h2>
<p><strong><em>Attention 的原理</em></strong>。</p>
<h2 id="训练模型">训练模型</h2>
<p>我们的目标是<strong>最大化</strong>由自然语言语句作为输入时产生的逻辑形式的可能性，所以目标函数为： <span class="math display">\[
\text{minimize} - \sum_{(q,a) \in D} logp(a|q)
\]</span> 其中 <span class="math inline">\(D\)</span> 是所有自然语言逻辑形式训练对的集合，<span class="math inline">\(p(a|q)\)</span> 按式（1）计算。采用 <strong>RMSProp</strong> 算法解决了这一非凸优化问题。此外，使用 <strong>Dropout</strong> 进行正则化。</p>
<h2 id="推论">推论</h2>
<p>暂时略。</p>
<h2 id="参数识别">参数识别</h2>
<p>大多数的语义分析数据集都是为问答开发的。在经典的系统中，问题被映射乘逻辑形式，并在知识库中获取答案。由于问答任务的性质，许多自然语言的语句都包含实体或数字，它们通常被解析为逻辑形式的参数。其中不可避免地会有一些罕见或者根本不会出现在数据集中的实体或数字（对于小规模数据集尤其如此）。传统的序列编码器只是简单地用一个特殊的位置单词符号替换稀有单词（<a href="https://arxiv.org/pdf/1410.8206.pdf" target="_blank" rel="noopener" title="Addressing the Rare Word Problem in Neural Machine Translation">Luong et al. 2015a</a>; <a href="https://arxiv.org/pdf/1412.2007.pdf" target="_blank" rel="noopener" title="On Using Very Large Target Vocabulary for Neural Machine Translation">Jean et al. 2015</a>），这对语义分析是有害的。 为此开发了一个简单的参数识别程序。具体来说就是在输入的问题中标识实体和数字，并用它们的<strong>类型</strong>和<strong>唯一 id</strong> 替换它们。例如，将训练样本“<em>jobs with a salary of 40000</em>”及其逻辑形式“job(ANS), salary_greater_than(ANS,40000, year)”预处理为“jobs with a salary of <em><span class="math inline">\(num_0\)</span></em>”和“job(ANS), salary_greater_than(<em>ANS</em>,<em><span class="math inline">\(num_0\)</span></em>,<em>year</em>)”。一旦解码完毕，后处理步骤就会将所有标记 <span class="math inline">\(type_i\)</span> 恢复到它们以前的实体或数字。</p>
<h1 id="实验">实验</h1>
<p>我们将我们的方法在四个数据集上分别与以前的多个系统进行比较，下面将描述这些数据集。代码可在此处获得<a href="https://github.com/donglixp/lang2logic" target="_blank" rel="noopener" class="uri">https://github.com/donglixp/lang2logic</a>（lua 版，官方），<a href="https://github.com/Alex-Fabbri/lang2logic-PyTorch" target="_blank" rel="noopener" class="uri">https://github.com/Alex-Fabbri/lang2logic-PyTorch</a>（python 版，非官方）。</p>
<h2 id="数据集">数据集</h2>
<p><strong>JOBS</strong> 工作 <strong>GEO</strong> Geoquery data <strong>ATIS</strong> Airline Travel Information System（航空旅行信息系统） <strong>IFTTT</strong> if this then that（<a href="https://ifttt.com/" target="_blank" rel="noopener">地址</a> <a href="https://baike.baidu.com/item/ifttt/8378533" target="_blank" rel="noopener">百度百科介绍</a>），<a href="https://www.aclweb.org/anthology/P15-1085" target="_blank" rel="noopener">Quirk et al.2015</a> 从 IFTTT 网站提取大量的 if-this-then-that 来创建此数据库 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Language%20to%20Logical%20Form%20with%20Neural%20Attention/数据集介绍.jpg" alt="数据集介绍" /></p>
<h2 id="设置">设置</h2>
<p>自然语言语句是小写的，并且使用基于维基百科的常见拼写错误列表来纠正拼写错误。使用 NLTK 来限制词汇（[Bird et al.2009] Natural Language Processing with Python. O’Reilly Media.），对于 IFTTT 过滤了在训练集中出现少于五次的 token，channels 和 functions。对于其他数据集，过滤了在训练集中至少两次没有出现的输入词，但保留了逻辑形式中的所有 token。并且使用了<strong>参数识别</strong>，当然也可以使用更复杂的办法。 超参数在 JOBS 和 GEO 上使用了交叉验证，使用了 ATIS 和 IFTTT 作为标准开发集（就是验证集，不同的叫法而已 development/validation）。 - <strong>RMSProp</strong>：batch size = 20；parameter = 0.95； - <strong>梯度修剪</strong>为 5 以缓解梯度爆炸（<a href="http://proceedings.mlr.press/v28/pascanu13.pdf" target="_blank" rel="noopener">Pascanu et al.2013</a>）； - <strong>参数</strong>从均匀分布 <span class="math inline">\(U(-0.08, 0.08)\)</span> 中随机初始化； - 两层 <strong>LSTM</strong> 用于 IFTTT，单层 LSTM 用于其他数据集； - <strong>dropout</strong> <span class="math inline">\(\in\)</span> {0.2,0.3,0.4,0.5}； - 隐藏向量和词嵌入<strong>维度</strong>从 {150, 200, 250} 选择； - <strong>early stopping</strong>； - 输入句子在进入编码器之前被反转（<a href="http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf" target="_blank" rel="noopener">Sutskever et al.2014</a>）； - <strong>贪婪搜索</strong>生成逻辑形式； - <strong>softmax</strong> 用于分类。</p>
<h2 id="结果">结果</h2>
<p>Attention 机制可以提高性能，对于小数据集<strong>参数识别</strong>至关重要。</p>
<h2 id="错误分析">错误分析</h2>
<h1 id="数据格式">数据格式</h1>
<p><a href="http://www.cs.columbia.edu/~mcollins/papers/uai05.pdf" target="_blank" rel="noopener" title="Learning to Map Sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammars">论文</a>使用 Logical Form 对基准数据集做实验，数据集包括 Geo880 和 Jobs640，论文中使用的是 Logical Form 的其中一种表示——<strong>PCCG</strong>，它是 CCG 的改进版。他们将数据集分割为训练集和测试集，Language to Logical Form with Neural Attention 沿用了此分割方式（比如说将 GEO 分割为 680 个训练样本，200 个测试样本），并且采用此论文的思想，即：将自然语言映射为 Logical Form。 虽然 PCCG 的 Logical Form 效果不错，但是作者没有使用他，而是使用了 <a href="https://www.aclweb.org/anthology/D11-1140" target="_blank" rel="noopener">lambda-caculus</a>。<strong>作者将 Geo880 等数据集改写为了 lambda-calculus 的形式</strong>。<em>在<a href="https://github.com/yuxuan1995liu/Semantic-Parsing-Data-Pre-Processing" target="_blank" rel="noopener">此处</a>可找到全部数据，但是这里面的格式不是 lambda-calculus。我有点搞不懂他提供的数据到底是什么意思</em>。<strong>19.09.16 补充</strong>：经过多方查找，终于找到了 geo880 最初的<a href="https://link_springer.gg363.site/content/pdf/10.1007/3-540-44795-4_40.pdf" target="_blank" rel="noopener" title="Using Multiple Clause Constructors in Inductive Logic Programming for Semantic Parsing">论文</a>，在<a href="https://www.cs.utexas.edu/~ml/publications/year/2001" target="_blank" rel="noopener">此处</a>找到的。GEO880 最初版本并不是 lambda calculus。 作者将数据改写为 lambda-calcullus 形式是我估计的。因为全文找不到数据的来源，格式转换的说明也找不到。只是在 Section 4.1 Datasets 中说到： &gt; <strong>GEO 有 880 个示例，将其分割为 680 个训练样本以及 200 个测试样本（Zettlemoyer and Collins, 2005）， 我们使用了基于 lambda-calculus 的具有相同含义的表示</strong>。</p>
<p>所以我推测作者应该是将原本的 PCCG 表示的 GEO 改成了 lambda-calculus 表示。 <a href="https://arxiv.org/pdf/1805.04793" target="_blank" rel="noopener" title="Coarse-to-Fine Decoding for Neural Semantic Parsing">论文</a>是作者对 Language to Logical Form with Neural Attention 的改进版。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>语义解析KBQA</tag>
        <tag>seq2tree</tag>
      </tags>
  </entry>
  <entry>
    <title>Large-scale Simple Question Answering with Memory Network</title>
    <url>/posts/d87c2736.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://arxiv.org/pdf/1506.02075v1.pdf" target="_blank" rel="noopener">论文地址</a>，发表于 2015 年。 开放域问答系统的目的是在不受域限制的情况下，为用自然语言表达的问题提供准确的答案。问答系统有很长的历史，它们搜索文本文档或在网络上提取答案（see e.g.(Voorhees and Tice, 2000; Dumais et al., 2002)）。最近在公开的大型知识库（KBS）方面也取得了进展，如 Freebase 知识库。然而，尽管最近大家都在关注设计一个具有推理能力的系统，它可以检索并使用 KB 中的<strong>多重事实</strong>进行问答。但是其实只涉及 <strong>KB 中单个事实的简单问答</strong>都还没被解决，本论文中将其称为 Simple Question Answering。 KBQA 现存的方法：1）将 question 转为结构化的 KB 查询语句（Berant et al. 2013）；或者 2）学习将 question 以及 facts 嵌入到低维向量空间中，然后在这些向量中通过计算相似度检索答案（<a href="https://arxiv.org/pdf/1406.3676.pdf" target="_blank" rel="noopener">Bordes et al., 2014a</a>）。 本文贡献有二： - 其一，为了<strong>研究现有系统</strong>以及<strong>通过多任务学习在不同数据源上同时训练</strong>成为可能，我们收集了第一个基于知识库的大规模的问答数据集，称为 SimpleQuestions。包含了人类编写和 Freebase facts 相关的超过 10 万个问题，另外现有的基准数据集 WebQuestions 包含的问题少于 6 千个，这些问题是使用 google suggest api 自动创建的。 - 其二，提出了一种基于词嵌入的问答系统，在 Memory Networks (MemNNs)（<a href="https://arxiv.org/pdf/1410.3916.pdf" target="_blank" rel="noopener">Weston et al., 2015</a>;<a href="https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" target="_blank" rel="noopener">Sukhbaatar et al., 2015</a>） 框架下开发而成。</p>
<p>虽然我们的模型与之前的 QA 嵌入模型（<a href="https://arxiv.org/pdf/1406.3676.pdf" target="_blank" rel="noopener">Bordes et al., 2014a</a>;<a href="https://arxiv.org/pdf/1404.4326.pdf" target="_blank" rel="noopener">Bordes et al., 2014b</a>）相似，但使用 MemNNs 的框架为未来工作中更复杂的推理方案提供了思路，因为 MemNNs 在复杂的推理问答任务上表现了很好的性能（<a href="https://arxiv.org/pdf/1410.3916.pdf" target="_blank" rel="noopener">Weston et al., 2015</a>）。 <a id="more"></a></p>
<h1 id="论文内容介绍">论文内容介绍</h1>
<ol type="1">
<li>Sections 3, 4：介绍了基于词嵌入的问答系统；</li>
<li>Section 5：相关工作；</li>
<li>Section 6：实验结果。</li>
</ol>
<h1 id="memory-network-for-simple-qa">Memory Network for Simple QA</h1>
<p>Memory network 由一个 memory（一个索引对象数组）和一个神经网络组成。神经网络由 Input map(I), Generalization(G), Output map(O) and Response(R) 构成。其工作流如下所示： 1. Storing Freebase：第一阶段。解析 Freebase（可以是 FB2M 或 FB5M，取决于配置）并且将它存进 memory。它使用 Input module 去预处理数据； 2. Training：第二阶段。训练 MemNN 去回答问题。此处使用 Input, Output and Response modules，训练主要关注核心 Output module 嵌入模型的参数； 3. Connecting Reverb：第三阶段。将来自 Reverb 的 new facts 添加到 memory 中。这是在训练完毕后进行的，为了测试 MemNNs 在不需要重新训练的情况下处理 new facts 的能力。它使用 Input module 去预处理 Reverb facts 并且使用 Generalization module 将它们和已经被存储的 facts 连接。</p>
<h2 id="input-module">Input module</h2>
<p>此组件预处理 3 种类型的数据，它们会被输入进神经网络： 1. Freebase facts：用于填充 memory； 2. questions：系统需要回答的问题； 3. Reverb facts：在 workflow 第二阶段中，我们用它扩展 memory。</p>
<h3 id="preprocessing-freebase">preprocessing Freebase</h3>
<p>Freebase 数据最初存储原子 facts，包括将单个实体作为主语或者宾语，再在它们之间加上一个联系（即谓语）。<strong>但是这样的存储需要从两个方面与 QA 任务适应</strong>。 1. 为了回答不止有一个答案的问题，我们将 fact 重新定义为一个三元组，其包含 subject，relationship 以及通过 relationship 连接至 subject 的一组 objetcs 。这个分组过程将 atomic facts 转为 grouped facts，以下将其简单的称为 facts。Table 2 显示了这样分组可以减少 facts 的数量。 2.</p>
<h3 id="preprocessing-freebase-facts">Preprocessing Freebase facts</h3>
<h3 id="preprocessing-questions">Preprocessing questions</h3>
<h3 id="preprocessing-reverb-facts">Preprocessing Reverb facts</h3>
<h2 id="generalization-module">Generalization module</h2>
<p>此模块负责将新的元素增加到 memory 中。在我们的例子中，memory 具有一个 multigraph 结构，其中每个节点都是 Freebase 的一个实体，multigraph 中被标记的 arcs 是 Freebase 中的 relationships：预处理之后，所有 Freebase 的 facts 都使用此结构存储。</p>
<p>为了将 Reverb 的 subject 和 object 链接到 Freebase 实体，我们使用 precomputed entity links (<a href="https://www.aclweb.org/anthology/W12-3016.pdf" target="_blank" rel="noopener">Lin et al., 2012</a>)。。。。</p>
<h2 id="output-module">Output module</h2>
<p>Output 模块通过给定 input ，在 memory 中执行查表（lookup）操作，返回该问题的 supporting facts。在我们的 simple QA 例子中，此模块只返回一个 supporting fact。为了避免为所有存储的 facts 评分（即为了避免时间代价太大），我们先执行一步<em>近似实体链接</em>（proximate entity linking），以生成一个小的候选 facts 集合。最后， supporting fact 指的是与嵌入模型中的问题最相似的候选 fact。</p>
<h3 id="candidate-generation">Candidate generation</h3>
<p>略。</p>
<h3 id="scoring">Scoring</h3>
<p>略。</p>
<h2 id="response-module">Response module</h2>
<p>在 memory network 中，Response 模块对 Output 模块的结果进行后处理操作，以计算预期的答案。在我们的例子中，它返回被挑选出来的 supporting fact 的对象集（博主注：这个对象集我猜测是 KG 中的三元组）。 注：不必纠结 Response 模块的具体功能，可以自己定制，必然在<a href="https://zhuanlan.zhihu.com/p/29590286" target="_blank" rel="noopener">记忆网络之Memory Networks</a>中写到最初的 memory network 的 response 模块只是简单地将向量转成单词。</p>
<h1 id="推荐阅读">推荐阅读</h1>
<p><a href="https://blog.csdn.net/liuchonge/article/details/78128238" target="_blank" rel="noopener">记忆网络之open-domain QA 应用</a>，csdn 的一篇博客，也对此论文的训练方法做了总结。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>memory network</tag>
      </tags>
  </entry>
  <entry>
    <title>An End-to-End Model for Question Answering over Knowledge Base with Cross-Attention Combining Global Knowledge</title>
    <url>/posts/2663d18d.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<div class="note info"><p><a href="https://www.aclweb.org/anthology/P17-1021" target="_blank" rel="noopener">论文地址</a>，发表于 2017 年。</p>
</div>
<p>随着知识库数量的增加，人们越来越希望寻找到一些有效的方法来获取这些资源。现在有几种专门为<strong>查询 KBs</strong> 设计的<strong>语言</strong>：SPARQL（<a href="https://www.w3.org/TR/2008/REC-rdf-sparql-query-20080115/" target="_blank" rel="noopener">rudhommeaux and Seaborne, 2008</a>）。但要使用这些语言，用户不仅需要熟悉它们，还要了解 KBs 的体系结构。相比之下，<strong>以自然语言为查询语言</strong>的 KB-QA 是一种更友好的方案，近年来已成为研究热点。这项任务<strong>以前</strong>有两个主流的研究方向： 1. 基于语义解析（semantic parsing-base, SP-based） 2. 基于信息检索（information retrieval-based, IR-based）</p>
<p><strong>现在</strong>随着神经网络方法的发展，基于神经网络的 KB-QA 已经取得了令人瞩目的成果。其中至关重要的步骤就是计算<strong>问题和候选答案</strong>之间的相似性分数，这一步骤的<strong>关键一点</strong>就是学习它们的表示。然而以往的研究更注重<strong>答案的学习表示</strong>。例如，<a href="https://arxiv.org/pdf/1406.3676.pdf" target="_blank" rel="noopener">Bordes et al. 2014a</a> 考虑候选答案子图的重要性，<a href="https://www.aclweb.org/anthology/P15-1026" target="_blank" rel="noopener">Dong et al. 2015</a>利用上下文和答案的类型。无论如何，<strong>问题的表示</strong>终究还是表达不全。现有的方法 <a href="https://arxiv.org/pdf/1406.3676.pdf" target="_blank" rel="noopener">Bordes et al., 2014a,</a> <a href="https://arxiv.org/pdf/1404.4326.pdf" target="_blank" rel="noopener">b</a> 使用 bag-of-word 模型将问题表示为一个向量，但是这样<strong>问题与答案的关联性</strong>还是被忽视了。我们认为一个问题应该根据回答时不同的侧重面来表示（注：<em>其实就是想用注意力机制</em>，回答的侧重面可以是答案实体本身、答案类型、答案上下文等）。 因此本文提出了一个端到端的神经网络模型，通过 <strong>cross-attention</strong> 机制，根据不同的候选答案动态地表示问题及对应的分数。此外还利用了 KB 中的全部知识，旨在将 KB 中丰富的知识集成到答案中，以此缓解 out-of-vocabulary(<strong>OOV</strong>) 的问题，从而帮助 cross-attention 更精确地表示问题。最后实验结果表明了该方法确实有效。 <a href="https://www.aclweb.org/anthology/P15-1026" target="_blank" rel="noopener" title="Question Answering over Freebase wit hMulti-Column Convolutional Neural Networks">论文</a>（<a href="https://yan624.github.io/·论文笔记/dialogue/QA/KBQA/23、Question%20Answering%20over%20Freebase%20with%20Multi-Column%20Convolutional%20Neural%20Networks.html">论文笔记地址</a>）中的方法很有启发性，但是由于简单地选择三个独立的 CNN ，因此过于机械化。所以我们使用了基于 cross-attention 的神经网络模型。 模型架构如下，步骤与之前的论文的步骤类似。<strong>1)</strong>先找到问题的主题（main entity/topic entity）；<strong>2)</strong>然后在知识库中找到主题相连的节点作为候选答案，<strong>3)</strong>最后送入 score layer 进行评分，排序分数选出分数最高的候选答案作为正确答案。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/KBQA论文笔记/MCCNN总览.jpg" alt="MCCNN总览" /></p>
<p>为了方便描述，我们将任何一种基本元素称为资源（resource），无论是实体还是关系。比如 (/m/0f8l9c,location.country.capital,/m/05qtj) 的描述是法国的首都是巴黎，其中的 <em>/m/0f8l9c</em> 和 <em>/m/05qtj</em> 分别代表法国和巴黎，<em>location.country.capital</em> 是一种关系。 <a id="more"></a></p>
<h1 id="我们的方法">我们的方法</h1>
<h2 id="候选者生成">候选者生成</h2>
<p>略，我已经写过无数遍了。使用 Freebase API 构建的。</p>
<h2 id="the-neural-cross-attention-model">The Neural Cross-Attention Model</h2>
<p>下图是模型的架构： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文/KBQA论文笔记/MCCNN架构.jpg" alt="MCCNN架构" /></p>
<ul>
<li>问题表示（图 2 中左侧部分显示了处理步骤）
<ol type="1">
<li>使用向量表示问题中的每个单词，这跟其他 NLP 任务差不多，不过它是随机初始化的词嵌入矩阵 <span class="math inline">\(E_w \in \mathbb{R}^{d \text{x} v_w}\)</span>，然后取出对应单词的词向量。d 代表词向量的维度，<span class="math inline">\(v_w\)</span> 代表词表的大小。</li>
<li>将词向量送入 LSTM，值得注意的是我们没有使用单向 LSTM，因为这样一个单词表示只会捕获到之前的单词的信息而不会包含之后的单词。为此我们使用了双向 LSTM 外加 Bahdanau（<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank" rel="noopener" title="Neural machine translation by jointly learning to align and translate">Bahdanau, 2014</a>） attention 的处理；</li>
<li>这样就会获得两个表示 <span class="math inline">\((\overrightarrow{h_1}, \overrightarrow{h_2}, \dots, \overrightarrow{h_n})\)</span> 以及 <span class="math inline">\((\overleftarrow{h_1}, \overleftarrow{h_2}, \dots, \overleftarrow{h_n})\)</span>，然后将两个表示拼接起来组成 [<span class="math inline">\(\overrightarrow{h_i};\overleftarrow{h_i}\)</span>]，正反向 LSTM 单元的大小都是 <span class="math inline">\(\frac{d}{2}\)</span>。</li>
</ol></li>
<li>回答的不同侧面表示（图 2 中右侧下方部分）
<ol type="1">
<li>直接使用 KB 的嵌入矩阵 <span class="math inline">\(E_k \in \mathbb{R}^{d \text{x} v_k}\)</span>，其中 <span class="math inline">\(v_k\)</span> 代表知识库中资源的大小，该嵌入矩阵随机初始化并在训练时学习表示，使用全局信息对表示的进一步提高将在 3.3 节 Combining Global Knowledge（原论文）描述。具体来说我们使用回答的四个方面：问答实体 <span class="math inline">\(a_e\)</span>，回答关系 <span class="math inline">\(a_r\)</span>，回答类型 <span class="math inline">\(a_t\)</span>，回答上下文 <span class="math inline">\(a_c\)</span>。它们的嵌入被分别表示为 <span class="math inline">\(e_e\)</span>, <span class="math inline">\(e_r\)</span>, <span class="math inline">\(e_t\)</span>, <span class="math inline">\(e_c\)</span>；</li>
<li>值得注意的是问答上下文由多个 KB 资源组成，我们将它们定义为 (<span class="math inline">\(c_1, c_2, \dots, c_m\)</span>)，首先获得它们的嵌入 (<span class="math inline">\(e_{c_1}, e_{c_2}, \dots, e_{c_m}\)</span>)，然后计算它们的平均值 <span class="math inline">\(e_c = \frac{1}{m} \sum^m_{i=1} e_{c_i}\)</span></li>
</ol></li>
<li>Cross-Attention model（图 2 中右侧上方部分以及最上方部分），详见 3.2.3 Cross-Attention model</li>
</ul>
<h2 id="combining-global-knowledge">Combining Global Knowledge</h2>
<p>Combining Global Knowledg，利用TransE得到knowledge embedding。</p>
<h1 id="模型描述">模型描述</h1>
<ol type="1">
<li>使用了 Bahdanau Attention 处理；</li>
<li>使用了双向 LSTM，会得到两个向量，最后将这两个向量拼接在一起，就是 BiLSTM 这层的最终向量。另外正反的 LSTM 的长度都是 <span class="math inline">\(\frac{d}{2}\)</span>；</li>
<li>回答通过问答实体 <span class="math inline">\(a_e\)</span>，回答关系 <span class="math inline">\(a_r\)</span>，回答类型 <span class="math inline">\(a_t\)</span>，回答上下文 <span class="math inline">\(a_c\)</span> 四个方面来表示，其中 ac 是所有词向量的平均值。</li>
</ol>
<h1 id="相关工作">相关工作</h1>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1404.4326" target="_blank" rel="noopener" title="Open question answering with weakly supervised embedding models">Antoine Bordes 等 2014b</a>；</li>
<li><a href="https://arxiv.org/pdf/1406.3676" target="_blank" rel="noopener" title="Question Answering with Subgraph Embeddings">Antoine Bordes 等 2014a</a>；</li>
<li><a href="https://www.aclweb.org/anthology/P14-2105" target="_blank" rel="noopener" title="Semantic Parsing for Single-Relation Question Answering">Yih W 等 2014</a>，实际上是基于语义解析的，但是用了词向量；</li>
<li><a href="https://www.aclweb.org/anthology/D14-1071" target="_blank" rel="noopener" title="Joint relational embeddings for knowledge-based question answering">Min-Chul Yang 等 2014</a>，实际上是基于语义解析的但是用了词向量；</li>
<li><a href="https://www.aclweb.org/anthology/P15-1026" target="_blank" rel="noopener" title="Question Answering over Freebase with Multi-Column Convolutional Neural Networks">Dong 等 2015</a>，这篇是跟我们的文章最相近的（使用了 CNN 而非 RNN + Attention）；</li>
<li><a href="https://www.aclweb.org/anthology/C16-1226" target="_blank" rel="noopener" title="Hybrid Question Answering over Knowledge Base and Free Text">Kun Xu 等 2016b</a>；<a href="https://arxiv.org/pdf/1603.00957.pdf" target="_blank" rel="noopener" title="Question Answering on Freebase via Relation Extraction and Textual Evidence">Xu K 等 2016a</a>。</li>
</ol>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Question Answering over Freebase with Multi-Column Convolutional Neural Networks</title>
    <url>/posts/43d20159.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://www.aclweb.org/anthology/P15-1026" target="_blank" rel="noopener">论文地址</a>，发表于 2015 年。 大多数现有的系统通常依靠人工制作的特性和规则来进行<em>问题理解</em>以及<em>答案排序</em>。此外，一些方法（<a href="https://arxiv.org/pdf/1406.3676.pdf" target="_blank" rel="noopener" title="Question Answering with Subgraph Embeddings">Bordes et al., 2014a</a>; <a href="https://arxiv.org/pdf/1404.4326.pdf" target="_blank" rel="noopener" title="Open Question Answering with Weakly Supervised Embedding Models">Bordeset al., 2014b</a>）使用问题的词嵌入的总和来表示问题，但是这忽略了<strong>词序信息</strong>，无法处理复杂问题，例如 who killed A 和 who A killed 两个问题的表示是一样的。本文介绍了 multi-column convolutional neural networks (MCCNNs)，从三个方面（<strong>回答路径（Answer Type），回答上下文（Answer Context），回答类型（Answer Path）</strong>）理解问题。使用 Freebase 作为知识库，在 WebQuestions 数据集上进行了广泛的实验。最终表明，此方法拥有更好的性能。 神经网络训练步骤： 1. MCCNNs 从输入的问题中使用不同 column networks 去提取<strong>回答路径，回答上下文，回答类型</strong>。跟 Bordes 的论文一样，该论文知识库（本文就是 FreeBase）中的实体和关系也由向量表示。 2. 然后评分层（score layer）根据问题和候选答案的表示进行排序（点积）。</p>
<h1 id="处理步骤">处理步骤</h1>
<p>给定一个自然语言问题 <span class="math inline">\(q = w_1 \dots w_n\)</span>，从 FreeBase 中检索相应的实体和属性，然后将它们作为候选答案 <span class="math inline">\(C_q\)</span>。比如，问题 <em>when did Avatar release in UK</em> （阿凡达在英国的发行时间）的答案是 <em>2009-12-17</em>。需要注意的是对于该问题也许有一系列的正确答案。以下数据将被使用到：<strong>WebQuestions</strong>，<strong>FreeBase</strong>，<strong>WikiAnswers</strong>。 MCCNN 概览如图 1 所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Question%20Answering%20over%20Freebase%20with%20Multi-Column%20Convolutional%20Neural%20Networks/MCCNN概览.jpg" alt="MCCNN概览" /> <a id="more"></a></p>
<p>比如说，对于问题 whendid Avatar release in UK，从 FreeBase 中查询 <strong>Avatar</strong>（可以称为 <strong>main entity</strong> 或者 <strong>topic entity</strong>） 的<strong>相连节点</strong>（related nodes），这些相连节点被认为是候选答案（<span class="math inline">\(C_q\)</span>）。然后对于每个候选答案 a，模型将会预测一个分数 S(q,a) 以判断 a 是否为正确答案。 对于问题的三个侧面的向量表示分别以 <span class="math inline">\(f_1(q)\)</span> <span class="math inline">\(f_2(q)\)</span> <span class="math inline">\(f_3(q)\)</span> 表示，同理答案的三个侧面分别以 <span class="math inline">\(g_1(a)\)</span> <span class="math inline">\(g_2(a)\)</span> <span class="math inline">\(g_3(a)\)</span> 表示。<span class="math inline">\(f_i(q)\)</span> 和 <span class="math inline">\(g_i(a)\)</span>拥有相同的维度。使用这些问答的表示，我们可以计算问答对 (q,a) 的分数。具体来说，评分函数 S(q,a) 定义为（如图 1 所示，评分层计算分数并将其加起来）： <span class="math display">\[
S(q,a) = \underbrace{f_1(q)^Tg_1(a)}_{\text{answer path}} + \underbrace{f_2(q)^Tg_2(a)}_{\text{answer context}} + \underbrace{f_3(q)^Tg_3(a)}_{\text{answer type}}
\]</span></p>
<h2 id="候选者生成">候选者生成</h2>
<p>训练神经网络的<strong>第一步是</strong>从 FreeBase 中为问题检索候选答案。用户提出的问题应该包含一个<strong>可识别</strong>的实体，该实体与知识库相连。我们使用 <strong>Freebase Search API</strong>（<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.538.7139&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener" title="Freebase: a collaboratively created graph database for structuringhuman knowledge">Bollacker et al., 2008)</a>） 查询问题中的命名体。如果没有任何命名体，则查询名词短语，我们使用调用 API 返回的列表中的第一个实体。这个实体解决办法也被 <a href="https://www.aclweb.org/anthology/P14-1090" target="_blank" rel="noopener" title="Information Extraction over Structured Data: Question Answering with Freebase">Yao and Van Durme, 2014)</a> 使用，还可以研发更好的办法，但不是本论文的关注点。<strong>最后关联实体的所有 2-hops（应该是周围的意思，我没有查到是什么意思，但是在<a href="https://yan624.github.io/·论文笔记/dialogue/QA/KBQA/20、Open%20Question%20Answering%20with%20Weakly%20supervised%20Embedding%20Models.html#论文总结">博客笔记</a>中有所总结） 节点被认为是候选答案</strong>。并把问题 q 的候选答案集合称为 <span class="math inline">\(C_q\)</span>。</p>
<h2 id="mccnns-for-question-understanding">MCCNNs for Question Understanding</h2>
<p>MCCNNs 使用多列（<strong>列</strong>指的是图 1 中左侧那三片）卷积网络从字嵌入中学习不同方面。使用 <a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf" target="_blank" rel="noopener" title="Natural Language Processing (Almost) from Scratch">Collobert R 等 2011</a> 的方法解决语言长度不一的问题。具体的做法可参考原论文 <strong>4.2 MCCNNs for Question Understanding</strong>。</p>
<h1 id="总结">总结</h1>
<p>未来的探索方向： 1. 整合更多的外部知识源，如clueweb； 2. 以多任务学习方式训练MCCNN； 3. 由于我们的模型能够检测到问题中最重要的单词，因此使用结果挖掘有效的问题模式将是非常有趣的。</p>
<!-- more -->
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Joint Relational Embeddings for Knowledge-based Question Answering</title>
    <url>/posts/cae3e784.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://www.aclweb.org/anthology/D14-1071" target="_blank" rel="noopener">论文地址</a>，发表于 2014 年。 将自然语言（natural language，NL）问题转换为对应的逻辑形式（logical form，LF）是基于知识库问答（KB-QA）任务的核心任务，转换问题也被称作语义分析。<del>在 KB-QA 任务领域，与以往（Mooney, 2007; Liang et al., 2011;Cai and Yates, 2013; Fader et al., 2013; Berant etal., 2013; Bao et al., 2014）<u>基于词汇化短语（lexicalized phrases）和逻辑谓语（logical predicates）之间的映射作为词汇触发器（lexical trigger）来执行语义分析中的转换任务</u>不同（其中 Fader 2013 提出的论文在<a href="https://yan624.github.io/·论文笔记/dilogue/QA/KBQA/20、Open%20Question%20Answering%20with%20Weakly%20supervised%20Embedding%20Models.html">论文笔记1</a>和<a href="https://yan624.github.io/·论文笔记/dialogue/QA/KBQA/21、Question%20Answering%20with%20Subgraph%20Embeddings.html">论文笔记2</a>中具有提及，ctrl f 之后搜索 <em>Paraphrase-Driven Learning for Open Question Answering</em> 或者 <em>Fader</em> 即可找到对应位置）</del>，本论文进一步提出了一种<strong>将 NL 问题映射到 LFs 中</strong>的新的<strong>嵌入式</strong>方法，其利用<strong>词汇表达</strong>与 <strong>KB 中的属性</strong>在隐含空间中的语义关联来实现。实验表明，在两个公开的 QA 数据集上，该方法优于其他三种 KB-QA 的基线方法。 先前工作必须处理以下两种限制： 1. 由于逻辑谓语的含义通常具有不同的自然语言表达（natural language expression，NLE）形式，因此从谓语提取的词汇触发器可能有时会受到大小限制； 2. 由于命名体识别（named entity recognition，NER）组件检测到的实体将用于与逻辑谓语一起组成逻辑形式，因此它们的类型也应该与谓语一致。然而，现有的 KB-QA 系统使用的 NER 组件大都独立于 NLE 到谓语的映射步骤。 <a id="more"></a></p>
<h1 id="相关工作">相关工作</h1>
<p>一如既往地（我为什么要说一如既往？因为前两篇论文笔记都记录了）说明<strong>语义分析</strong>有多糟糕，需要使用大量的人力，继而只能被限制在特定的领域（以后关于这些劣势都不写了）。 一如既往地描述了 FreeBase。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Question Answering with Subgraph Embeddings</title>
    <url>/posts/976325f9.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://arxiv.org/pdf/1406.3676" target="_blank" rel="noopener">论文地址</a>，发表于 2014 年。 本文的作者在同年发表了另一篇论文，将上一篇论文称为 A，此论文称为 B，对于 A 论文我也做了<a href="https://yan624.github.io/·论文笔记/dilogue/QA/KBQA/20、Open%20Question%20Answering%20with%20Weakly%20supervised%20Embedding%20Models.html">论文笔记</a>，本论文是上一篇论文的改进版。A 只是对简单问题进行研究，B 研究如何改进模型并回答更复杂的问题。 开放域问答中的一流技术大致可以分为两大类：1)基于信息检索；2)基于语义解析。<strong>信息检索</strong>系统首先通过 KBs 的搜索 API（转换方式估计是手写模版，论文中未细说） <strong>将问题转换为有效的查询语句</strong>（比如 neo4j 数据库的 CQL）以此检索到大量的候选答案，然后再仔细地识别准确的答案（<a href="https://www.sciencedirect.com/science/article/pii/S0020025511003860" target="_blank" rel="noopener" title="A survey on question answering technology from an information retrieval perspective">Kolomiyets O 等 2011</a>，<a href="https://www2012.universite-lyon.fr/proceedings/proceedings/p639.pdf" target="_blank" rel="noopener" title="Template-based Question Answering over RDF Data">Unger C 等 2012</a>，<a href="https://www.aclweb.org/anthology/P14-1090" target="_blank" rel="noopener" title="Information Extraction over Structured Data: Question Answering with Freebase">Yao X 等 2014</a>）。<strong>语义解析</strong>旨在通过语义分析系统正确<strong>解释</strong>问题的含义，<strong>解释步骤</strong>的做法是把问题转换为数据库查询语句（这里的查询语句应该是逻辑形式，比如<strong>组合范畴法</strong>），以此查询到正确的答案。尽管这两种方法有能力去处理大规模知识库，但是需要专家手动的创建词汇、语法以及 KB 协议才能有所成效。且<strong>没有通用性</strong>，<strong>无法方便地扩展到</strong>具有其他模式、更广泛词汇或英语以外语言的<strong>新数据库</strong>。 相反，<a href="https://www.aclweb.org/anthology/P13-1158" target="_blank" rel="noopener">Paraphrase-Driven Learning for Open Question Answering</a> 提出了一个几乎不需要人工注释的开放域 QA 框架，虽然这是一种有趣的方法，但是它被其他方法超越了。即第二段提到的论文 A。 相比于论文 A，作者作出了以下几点<strong>改进</strong>：1）对于候选答案，考虑更多更长的路径（之前只考虑了 main entity 周围的节点）；2）对候选答案进行更有意义的表示：答案的表示包含问答路径以及周围的子图。</p>
<h1 id="任务定义">任务定义</h1>
<p>假设所有潜在的答案都是 KB 中的实体，当 KB 中不存在该实体时，可以使用一些方法解决（论文中具体没说，只是说了一种极简单的方式：<em>When this entity is not given, plain string matching is used to perform entity resolution</em>）。 <a id="more"></a> 此外 N 代表词典的大小，其中 <span class="math inline">\(N = N_W + N_S\)</span>，<span class="math inline">\(N_W\)</span> 代表词嵌入的大小，<span class="math inline">\(N_S\)</span> 代表实体和关系的数量。</p>
<h1 id="改进考虑多维度的信息">改进：考虑多维度的信息</h1>
<p>以下描述一个候选答案的特征表示，论文将以三个角度进行表示： 1. Single Entity：此表示方式与上一篇论文一样，没什么讲究。就是 Freebase 中的一个实体，<span class="math inline">\(\psi(a)\)</span> 代表答案的 1-of-<span class="math inline">\(N_S\)</span>（one hot）表示； 2. Path Representation：答案被认为是一条 path，该 path 从<strong>问题中被提及的实体</strong>到<strong>答案实体</strong>。此实验中，考虑 1-hop 或者 2-hops 级别的 path。比如，(barack obama, people.person.place of birth, honolulu) 是 1-hop path，(barack obama, people.person.place of birth, location. location.containedby, hawaii) 是 2-hop path。这导致了 <span class="math inline">\(\psi(a)\)</span> 代表 3-of-<span class="math inline">\(N_S\)</span> 或者 4-of-<span class="math inline">\(N_S\)</span> 的向量，至于为什么是 *-of-<span class="math inline">\(N_S\)</span>，显而易见。 3. Subgraph Representation：我们将 2 中的 <strong>Path</strong> 和连接候选答案的整个<strong>子图</strong>进行编码。<em>具体看论文，写的有点看不懂</em>。</p>
<p>我们的假想是将所有的信息都编码进表示以提高结果，但是这不大可能。所以还是采用将子图编码进表示的方法。下图即为实验的模型，右下角显示了编码方式。 <img src="https://img-blog.csdn.net/20171101002818501?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTEFXXzEzMDYyNQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" title="架构图" alt="架构图" /></p>
<h1 id="实验">实验</h1>
<p>与论文 A 差不多，多了一个多任务训练，其他的细枝末节没仔细看。</p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Open Question Answering with Weakly supervised Embedding Models</title>
    <url>/posts/2cdcf757.html</url>
    <content><![CDATA[<h1 id="论文概要">论文概要</h1>
<p><a href="https://arxiv.org/pdf/1404.4326" target="_blank" rel="noopener">论文地址</a>，论文发表于 2014 年。 建立一个能够回答任何问题的计算机是人工智能的一个长期目标。这一领域一个重要的发展时大规模知识库的建立，如 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.538.7139&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Freebase</a> 和 <a href="https://content.iospress.com/download/semantic-web/sw134?id=semantic-web%2Fsw134" target="_blank" rel="noopener">DBPedia</a>，它们存储了大量的通用信息。它们由三元组的形式构成一个数据库，通过各种关系和格式连接成实体对。那么回答问题被定义为<strong>给定一个用自然语言表达的查询语句</strong>（一个查询语句的例子：中国的首都在哪？）<strong>从知识库中检索正确的实体或实体集的任务</strong>。 最近，通过将问题映射为<strong>逻辑形式</strong>或者类似<strong>数据库查询</strong>的方法取得了富有希望的进展。虽然这种方法可能有效，但是缺点是要采用大量的人为标记的数据或者需要工作人员定义词汇表和语法。 本文采用一种激进的学习方式，将问题映射为向量（无法人为解释）的特征表示。并且将重点放在回答一些基于比较宽泛的主题的简单事实性问题。这项任务的难点来自词汇的多样性，而不是句法的复杂性。 该方法采用随机梯度下降，然后使用 fine-tuning 进行训练。经验表明该模型能够捕获一些有意义的信号，且这是唯一一种能够在弱标记数据上训练的方法。</p>
<h1 id="论文内容介绍">论文内容介绍</h1>
<ol type="1">
<li>Section 2：讨论了之前的工作；</li>
<li>Section 3：介绍了开放域问答的问题；</li>
<li>Section 4：给出了模型；</li>
<li>Section 5：实验结果。 <a id="more"></a></li>
</ol>
<h1 id="相关工作">相关工作</h1>
<ol type="1">
<li>大规模的问答历史悠久，主要由 TREC tracks（<a href="https://arxiv.org/pdf/cs/0110053.pdf" target="_blank" rel="noopener">Voorhees 2000</a>） 发起，这是第一个成功地<strong>将问题转换为查询</strong>的问答系统。将问题转换为查询之后，又<strong>将查询提供给 web 搜索引擎</strong>，然后<strong>从返回的页面或片段中取出答案</strong>（<a href="http://aiweb.cs.washington.edu/research/projects/ai3/mulder/mulder-www10.pdf" target="_blank" rel="noopener">Kwok 2001</a>, <a href="https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-06/SS02-06-002.pdf" target="_blank" rel="noopener">Banko 2002</a>）。这种方法需要大量的人工操作来处理查询，然后解析和搜索结果。</li>
<li>大型 KBs 的出现，如 FreeBase 和 DBPedia（论文地址已在第一章给出），改变了上述状况，但是也带来巨大的挑战。语言的多样性以及 KBs 规模的庞大，使得需要通过监督学习来处理大量的<strong>带标签</strong>的数据。最早的方法是基于手写模板的 KBs 开放问答，然而对于日新月异 KBs（增加/删除三元组和实体） 还不够成熟。之后开始尝试使用较少的监督情况下<strong>学习 KBs 和自然语言之间的联系</strong>，但是这项工作实际上在解决<strong>信息提取</strong>的问题（<a href="https://www.aclweb.org/anthology/P09-1113" target="_blank" rel="noopener" title="Distant supervision for relation extraction without labeled data">Mintz M 等 2009</a>，<a href="https://www.aclweb.org/anthology/P11-1055" target="_blank" rel="noopener" title="Knowledge-Based Weak Supervision for Information Extractionof Overlapping Relation">Hoffmann R 等 2011</a>，<a href="https://www.aclweb.org/anthology/D12-1093" target="_blank" rel="noopener" title="Reading The Web with Learned Syntactic-Semantic Inference Rules">Lao N 等 2012</a>，<a href="https://www.aclweb.org/anthology/N13-1008" target="_blank" rel="noopener" title="Relation Extraction with Matrix Factorization and Universal Schemas">Riedel S 等 2013</a>）。以上以及本文未提及到的这些通过直接或者间接的监督机器学习来获得更多表现力的解决办法实际上是为了避开标签数据过多的问题。</li>
<li>近年来，有一种基于语义解析器（<a href="https://www.aclweb.org/anthology/P13-1042" target="_blank" rel="noopener" title="Large-scale Semantic Parsing via Schema Matching and Lexicon Extension">Cai Q 等 2013</a>，<a href="https://www.aclweb.org/anthology/D13-1160" target="_blank" rel="noopener" title="Semantic Parsing on Freebase from Question-Answer Pairs">Berant J 等 2013</a>，<a href="https://www.aclweb.org/anthology/D13-1161" target="_blank" rel="noopener" title="Scaling Semantic Parsers with On-the-fly Ontology Matching">Kwiatkowski T 等 2013</a>）的新的问答系统被提出，它只具有少量标记数据。但仍需要耗费大量精力去仔细设计词汇，语法和知识库。</li>
<li>所以本文（2014 年）提出了基于嵌入式的问答模型。据我们所知，这是以前从未尝试过的。</li>
</ol>
<h1 id="开放域问答">开放域问答</h1>
<p>本文使用 <a href="https://www.aclweb.org/anthology/P13-1158" target="_blank" rel="noopener">Fader 2013</a> 的问答框架，并使用了相同的数据。</p>
<h2 id="任务定义">任务定义</h2>
<p>我们将回答问题的任务看作为：给定一个问题 q，对应的答案由 KB 中的三元组 t 给出。这意味着我们的问题由<strong>一组三元组 t</strong> 提供对问题及其答案的解释，例如： &gt; q: What environment does a dodo live in?（渡渡鸟生活在什么样的环境中？） &gt; t: (dodo.e, live-in.r, makassar.e) &gt; q: What are the symbols for Hannukah?（光明节的象征是什么？） &gt; t: (menorah.e, be-for.r, hannukah.e) &gt; q: What is a laser used for?（极光可以用来做什么？） &gt; t: (hologram.e,be-produce-with.r,laser.e)</p>
<p>这里每个问题我们只给出一个 t，但是实际上它可以有很多，所以上文说是一组三元组。本文其余部分，<strong>使用 <span class="math inline">\(\kappa\)</span>（读作 kappa） 代表 KB ，使用 <span class="math inline">\(\epsilon\)</span> 代表 KB 中的实体或者关系。问题的词表用 V 表示，<span class="math inline">\(n_V\)</span> <span class="math inline">\(n_{\epsilon}\)</span>分别表示 V 和 <span class="math inline">\(\epsilon\)</span> 的大小</strong>。 我们的模型在于<strong>函数 S(·)</strong>，它可以为 question-answer triple pairs (q,t) 打分。因此，找到问题 q 的 top-ranked 的答案 <span class="math inline">\(\hat{t}\)</span>(q) 直接由以下公式得出： <span class="math display">\[
\hat{t}(q) = arg \max_{t&#39; \in \kappa}S(q, t&#39;)
\]</span> 为了处理多个答案，我们将结果呈现为排完序的列表并对其评分，而不是直接采用最前面的预测结果。 使用评分函数可以直接查询 KB，而不需要在<strong>语义分析系统</strong>中一样为问题定义一个中间的结构化逻辑表示。我们的目标是学习 S(·)，余下将讲述用于训练的数据的创建步骤。</p>
<h2 id="用于训练的数据">用于训练的数据</h2>
<div class="note info"><p>待续</p>
</div>
<h1 id="embedding-based-model">Embedding-based model</h1>
<p>模型使用了词嵌入（2019 年了，应该谁都知道了，不做解释）。</p>
<h2 id="question-kb-triple-scoring">Question-KB Triple Scoring</h2>
<p>我们的框架关注的是函数 S(q,t) 的学习，该函数的目的是对一个<strong>问题 q</strong> 和 一个<strong>来自 <span class="math inline">\(\kappa\)</span> 的三元组 t</strong> 进行打分。该评分方法受到了先前工作 labeling images withwords 的启发（<a href="https://link.springer.com/content/pdf/10.1007/s10994-010-5198-3.pdf" target="_blank" rel="noopener">Weston 2013</a>），我们采用该方法将图片和标签替换成了问题和三元组。直观来讲就是： 有点难翻译，故给出原文： &gt; Intuitively, it consists of projecting questions, treated as a bag of words(and possibly n-grams as well), on the one hand, and triples on the other hand,into a shared embedding space and then computing a similarity measure (the dot product in this paper) between both projections. &gt; 大致意思，将问题和三元组使用词袋模型（也可以是 n-gram 模型）投射到共享的嵌入空间，然后计算二者的相似度（本文使用点积的方式）。</p>
<p>那么评分函数为: <span class="math display">\[
S(q,t) = f(q)^Tg(t)
\]</span> <strong>其中 f(·) 将问题中的单词映射到 <span class="math inline">\(\mathbb{R}^{\kappa}\)</span>，<span class="math inline">\(f(q) = V^T \Theta(q)\)</span>。V 是关于 <span class="math inline">\(\mathbb{R}^{n_v \times \kappa}\)</span> 包含所有词嵌入 v 的矩阵。<span class="math inline">\(\Theta(q)\)</span>是 q（<span class="math inline">\(\in \{0,1\}^{n_v}\)</span>） 的二进制（稀疏）表示。同样，g(·) 将 KB 三元组中的实体和关系映射到 <span class="math inline">\(\mathbb{R}^{\kappa}\)</span>，<span class="math inline">\(g(t) = W^T\Psi(t)\)</span>，W 是关于 <span class="math inline">\(\mathbb{R}^{n_e \times \kappa}\)</span> 包含所有实体和关系的嵌入 w 的矩阵，<span class="math inline">\(\Psi(t)\)</span> 是 t（<span class="math inline">\(\in \{0,1\}^{n_e}\)</span>） 的二进制（稀疏）表示。</strong> <div class="note info"><p>注：上一段太长了，解释一下。f(q) 就是词向量，g(t) 就是实体和关系的向量（下一段原文写到 g(t) 是将三元组中的嵌入全部相加）。</p>
</div></p>
<p>将单词表示为词袋模型似乎有一点局限性，但是由于我们特定的设置，语法都很简单，因此含有的信息十分有限，所以词袋模型应该也能带来不错的性能。当然也有反例，比如 <em>What are cats afraid of ?vs.What are afraid of cats ?</em> 这将会有不同的答案。不过这种情况十分罕见。未来考虑将 parse tree features 或者 semantic role labels 作为输入放入嵌入模型中。 与以前的工作（<a href="https://arxiv.org/pdf/1307.7973" target="_blank" rel="noopener">Weston 2013</a>）不同的是，在我们的模型中，实体出现三元组的不同侧面（左右侧）时，实体并非拥有相同的嵌入。KB 中的关系并不是对称的，所以会出现三元组中左侧和右侧的实体是不同的情况。<strong>由于 g(·) 是将三元组中的所有成分相加，所以每一个实体我们都需要两个嵌入</strong>。 这样就可以很容易地对任何三元组进行评分： <span class="math display">\[
\hat{t}(q) = arg \max_{t&#39; \in \kappa}S(q, t&#39;) = arg \max_{t&#39; \in \kappa}(f(q)^Tg(t&#39;))
\]</span> 接下来花了好几段讲怎么训练。</p>
<h2 id="fine-tuning-the-similarity-between-embeddings">Fine-tuning the Similarity between Embeddings</h2>
<p>由于受到数据大小的限制，需要使用微调来改进性能。</p>
<h1 id="论文总结">论文总结</h1>
<p>通读论文之后还是有点搞不清论文是怎么训练的，后来看了一下 CCF ADL100 刘康老师的 PPT ，感觉有点理解了，以下是训练步骤： 1. 输入自然语言表达的问题，比如：姚明的老婆的是哪里人？ 2. 使用 entity linking（论文中貌似没有这步，我在看 PPT 时也是一知半解，好在前几天我刚好在一篇论文中看到了这个 entity linking！<a href="https://yan624.github.io/·论文笔记/19、Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation：Question%20Answering%20with%20Knowledge%20Base.html#链接主题实体">博客地址</a>，entity linking 源于<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）找到 main entity，main entity 周围的 entity 均是候选 entity。如下图，姚明是 main entity，姚明周围的实体都算作候选 entity，比如叶莉、火箭队、上海等。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Open%20Question%20Answering%20with%20Weakly%20supervised%20Embedding%20Models/姚明的老婆是谁的知识图谱的子图.jpg" alt="姚明的老婆是谁的知识图谱的子图" /> 3. 计算问题和候选 entity 的相似度，其中问题由词向量表示，候选 entity 是一个三元组的形式，难以直接用词向量表示，方法是将三元组中的三个对象分别用词向量表示，然后将三个词向量相加。这样就得到了问题的词向量和 entity 的词向量，点乘获得相似度。 4. 由于候选 entity 不一定只有一个，所以可以获得多个相似度。进行排序即可获得最相似的候选 entity。</p>
<div class="note danger"><p>以上的训练步骤并不是论文中的训练步骤，只是我为了给自己加深映像写的，具体的训练步骤在原论文第 4 节，具体在 4.1。</p>
</div>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>向量建模KBQA</tag>
      </tags>
  </entry>
  <entry>
    <title>Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base</title>
    <url>/posts/5c4e57cd.html</url>
    <content><![CDATA[<h1 id="写在前面">写在前面</h1>
<p>此论文为 2015 年的论文。 本文会出现一个名为<strong>谓语序列（predicate sequence）</strong>的名词，论文中没有详细说明。但是估计就是：一个实体至另一个实体的有向路径上的所有谓语的连接形式。如下文第一张图 Family Guy-&gt;cvt1-&gt;Mila Kunis 的谓语序列就是 cast-actor。</p>
<h1 id="论文概要">论文概要</h1>
<p><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ACL15-STAGG.pdf" target="_blank" rel="noopener">论文地址</a> 节选自摘要部分： &gt; 论文提出了一个基于知识库问答的新的语义解析（semantic parsing）框架。首先定义一个类似于知识库的<strong>子图（subgraph）</strong>的查询图（query graph），可以直接映射到一个语义的逻辑形式（如<span class="math inline">\(\lambda\)</span>-calculus）。所以<strong>语义分析简化为查询图的生成</strong>，并将其表示为一个阶段性搜索问题。然后通过使用先进的实体链接系统（<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）以及深度卷积网络来实现问题与谓语序列之间的匹配。在 WEBQUESTIONS 的数据集上，F1 指标达到了 52.5% 的水平，高于以前的方法。</p>
<p>以下大型知识库已经成为支持开放领域问答的重要资源： - DBPedia - Freebase</p>
<p>最先进的 KB-QA 方法都是基于<strong>语义解析</strong>的，在语义解析中一个问题或者一种表达被映射到它具有一定意义的表示上（如逻辑形式，具体来说可以是 <span class="math inline">\(\lambda\)</span>-calculus），即将自然语言映射为表达式，然后被翻译为一个 <strong>KB 查询</strong>。最后，只需要执行查询就可以检索问题的答案。<strong>但是大多数<u>传统的</u>语义解析方法在很大程度上都<u>脱离</u>知识库</strong>。由于没有前人的贡献累积，因此 QA 问题面临着一系列的挑战。例如： - 当在逻辑形式中使用与知识库中的谓语不同的谓语时，可能需要用到本体匹配（ontology matching）的问题（Kwiatkowski et al., 2013）。 - 即使表示语言与知识库的模式接近，从知识库中的大量词汇表中寻找正确的谓语与语句的描述相关联仍然是一个难题（Berant and Liang, 2014）。 <a id="more"></a></p>
<p>由（Yao and Van Durme, 2014; Bao etal., 2014）的启发，该论文提出了一个语义解析框架，定义一个查询图可以直接地映射到由 <span class="math inline">\(\lambda\)</span>-calculus 表达的逻辑形式。从语义上来讲，与 <span class="math inline">\(\lambda\)</span>-DCS（Liang, 2013）十分接近。将解析行为分为 3 步： 1. 定位问题中的主题实体； 2. 找到回答与主题实体之间的主要关联； 3. （通过额外的约束扩大查询图，约束即回答需要附加的额外属性，如最早时间等）或者（答案与其他实体之间的关联）。</p>
<p>至此将一个语义解析问题划分成了一系列的子问题。例如 entity linking 和 relation matching。</p>
<h2 id="文章内容介绍">文章内容介绍</h2>
<ol type="1">
<li>Sec. 2: 介绍了图知识库（估计就是知识图谱）的概念和查询图的设计；</li>
<li>Sec. 3: 介绍了基于搜索方法的查询图生成；</li>
<li>Sec. 4: 实验结果；</li>
<li>Sec. 5: 论文中的方法和其他相关工作的比较；</li>
<li>Sec. 6: 总结。</li>
</ol>
<h1 id="knowledge-base">Knowledge Base</h1>
<p>论文中的知识库 K 是一个包含主语、谓语、宾语的三元组（e1, p, e2）的集合，其中 e1 和 e2<span class="math inline">\(\in\)</span>E，是一个实体。p<span class="math inline">\(\in\)</span>P，是一个谓语。这种形式的知识库通常称为知识图谱。每一个实体是一个节点，两个相关联的实体由谓语标记的有向边连接，边的方向是从主语实体到宾语实体。如下图就是一个 Freebase 的子图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/Freebase%20subgraph%20of%20Family%20Guy.jpg" alt="Freebase subgraph of Family Guy" /></p>
<div class="note info"><p>Freebase 中有一个叫 <a href="https://developers.google.com/freebase/guide/basic_concepts#cvts" target="_blank" rel="noopener">CVT</a>（此链接需要翻墙访问） 的特殊实体类型，它不是一个真正的实体，而是用于收集事件或特殊的关联的多个字段。</p>
</div>
<h1 id="query-graph">Query graph</h1>
<h2 id="概念">概念</h2>
<p>给定一个知识图谱。执行逻辑形式的查询等价于寻找一个子图，该子图的表现形式可以映射到查询动作。之后解析绑定的变量。 <div class="note warning"><p>接下来，以实体这个属性来表示真实世界的实体和 CVT 实体以及日期或高度等属性，这些实体之间的区别对于论文中的方法来说并不重要。</p>
</div> 就像知识图谱一样，查询图中的相关节点也是通过有向边连接，并用 K 中的谓语标记。查询图由四中类型的节点组成： 1. grounded entity：圆角矩形表示。grounded entity 是在知识库 K 中已存的实体。 2. existential variable：圆形表示。existential variable 是 un-grounded entity。 3. lambda variable：阴影圆形表示。lambda variable 是 un-grounded entity。尤其，该论文表示希望<strong>检索</strong>能够映射到 lambda variable 的所有实体<strong>作为</strong>最终答案。其也被称为<strong>answer 节点</strong>。 4. aggregation function：菱形表示。aggregation function 被用于操作特定的实体，该实体通常具有一些数值属性。</p>
<p>下图展示了一个查询图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/Query%20graph%20that%20represents%20the%20question%20“Who%20first%20voiced%20Meg%20on%20Family%20Guy？”.jpg" alt="Query graph that represents the question “Who first voiced Meg on Family Guy？”" /></p>
<p>上图是“谁第一次为 Family Guy 中的 Meg 配音？”的问题。MegGriffin 和 FamilyGuy 由圆角矩形表示，圆圈节点 y 表示应该存在一个实体来描述扮演关系，比如角色、演员和开始饰演此角色的时间。阴影圆圈节点也被称为 <strong>answer 节点</strong>。菱形节点 argmin 限制答案必须是扮演此角色的最早的演员。同样不含聚合函数的<span class="math inline">\(\lambda-calculus\)</span>逻辑形式查询为$x.y.cast(FamilyGuy,y) actor(y,x) character(y,MegGriffin) $。在使用聚合函数之前，对 K 运行此查询图会匹配 LaceyChabert 以及 MilaKunis，请看第一张图。但是只有 LaceyChabert 是正确答案，因为是她最早开始扮演这个角色。 <div class="note info"><p>查询图的设计灵感来源于（Reddyet al., 2014），但是他的查询图是从问题的 CCG 解析中映射出来的，在映射到子图前还需要进一步的转换。从语义上来说，该论文的查询图更像简单的 <span class="math inline">\(\lambda-DCS\)</span>。</p>
</div></p>
<h2 id="生成">生成</h2>
<p><strong>首先</strong>树图（tree graph）的根由一个实体节点组成，称为主题实体（topic entity）。<strong>其次</strong>，只有一个 lambda 变量 x 作为答案节点，从根到 x 有一个定向路径，其中含有 0 个或多个 existential variables。论文中将此路径称为图的核心推理链，因为它描述了答案和主题实体之间的主要关系。这个链除了根节点外只有变量节点。<strong>最后</strong>，可以将 0 个或多个实体或者聚合函数节点附加到每个变量节点，包括 answer 节点。例如，上图 Family Guy 是根，而 Family Guy-&gt;y-&gt;x 是核心推理链，分支 y-&gt;MegGriffin 阐述了角色，而 y-&gt;argmin 限制答案必须是该角色最早的参与者。 定义状态（state）集合<span class="math inline">\(S = \{\phi, S_e, S_p, S_c\}\)</span>，其中每个状态可以是一个空的图（<span class="math inline">\(\phi\)</span>），一个主题实体的单节点图（<span class="math inline">\(S_e\)</span>），一个核心推理链（<span class="math inline">\(S_p\)</span>）或者带有额外约束的更复杂的查询图（<span class="math inline">\(S_c\)</span>）。 定义动作（action）集合<span class="math inline">\(A = \{A_e, A_p, A_c, A_a\}\)</span>，其中<span class="math inline">\(A_e\)</span>选取实体节点，<span class="math inline">\(A_p\)</span>确定核心推理链，<span class="math inline">\(A_c\)</span>和<span class="math inline">\(A_a\)</span>分别约束和聚合节点。 给出一个示例<span class="math inline">\(q_{ex}\)</span> = &quot;Who first voiced Meg of Family Guy?&quot;。</p>
<h3 id="链接主题实体">链接主题实体</h3>
<p>从初始状态<span class="math inline">\(S_0\)</span>开始，正确的操作是创建一个与给定问题中的主题实体相对应单节点图。例如，<span class="math inline">\(q_{ex}\)</span>中可能的主题实体是 Family Guy 和 MegGriffin，如下图所示。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/Two%20possible%20topic%20entity%20linking%20actionsapplied%20to%20an%20empty%20graph,%20for%20question%20“Who%20firstvoiced%5BMeg%5Don%5BFamily%20Guy%5D？”.jpg" alt="Two possible topic entity linking actionsapplied to an empty graph, for question “Who firstvoiced[Meg]on[Family Guy]？”" /></p>
<p>使用的<strong>实体链接系统</strong>是专为短且有噪声的文本设计的，源于（<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）。具体不做赘述，详情可参考相关论文。</p>
<h3 id="确定核心推理链">确定核心推理链</h3>
<p>给定与主题实体 e 对应的单节点图的状态 s，扩展该图的正确操作是确定核心推理链，即主题实体和答案之间的关系。下图展示了扩展<span class="math inline">\(s_1\)</span>中的单节点图的三个可能的链。具体做法是，当中间的 existential variable 链接 CVT 时，探索长度为 2 的所有路径，如果没有链接，则探索长度为 1 的路径。 <div class="note primary"><p>本节主要描述了如何确定核心推理链，不过上文一段先描述了如何确定候选的核心推理链。具体做法上一段也已经给出，但是由于原论文讲的也有点不清楚，此处加以说明，以下只是推测。 1. 扩展主题节点 Family Guy 的三个可能的核心推理链，应该是从知识库 K 中入手。请看第一张图，它是知识库 K 中的一张子图。从 Family Guy 中开始可以看到有三条边，两条边上是 cast，一条边上是 writer。由于两条边相同，于是就融为了一条推理链。至于最后一条推理链的谓语是 genre，可能是第一张图的子图中没有标出造成的。总而言之，那三条推理链就是从知识库 K 中获取。 2. existential variable 即 y，lambda variable 即 x。可以把知识库 K 中的 CVT 节点看作是 y，答案看作是 x。</p>
</div> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/Candidate%20core%20inferential%20chains%20start%20from%20the%20entity%20FamilyGuy.jpg" alt="Candidate core inferential chains start from the entity FamilyGuy" /></p>
<p>这样做的目的是将自然表达映射到正确的谓语序列上。对于问题“Who first voiced Meg on [Family Guy]?”，需要衡量的是在{cast-actor, writer-start, genre}中每个序列（<em>注：这个元组就是上图的三个候选核心推理链上的谓语</em>）正确捕捉 Family Guy 和 Who 之间关系的可能性。因此将这个问题简化为使用神经网络测量语义相似度。</p>
<h4 id="deep-convolutional-neural-networks">Deep Convolutional Neural Networks</h4>
<p>虽然是陈述一个相同的问题，但是以语义等价的方式来重新表达该问题仍旧拥有巨大的多样性。并且还存在自然语言表达与知识库中的谓语不匹配的情况。<strong>为了处理上述两个问题</strong>，论文建议使用 Siamese neural networks（<a href="http://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf" target="_blank" rel="noopener">Bromley et al., 1993</a>）来识别核心推理链（暹（xiān）罗神经网络，也可以叫连体神经网络。看见这个中文就很好理解了。Siamese neural networks 可以进行语义相似度分析，QA 的匹配等操作。详情可以先看看<a href="https://www.jianshu.com/p/92d7f6eaacf5" target="_blank" rel="noopener">这篇</a>博客）。注：由于上图可以得知一个问题可以获得几个候选得到核心推理链，这就是因为语言的多样性造成的，所以需要一个方法来识别一条最核心的推理链。 例如，将一个问题映射到一种<strong>模式</strong>上，方法是将实体替换为通用符号 &lt;e&gt;，然后将其与<strong>候选链</strong>比较。比如问题“who first voiced meg on &lt;e&gt;”和 cast-actor。该模型由两个神经网络组成，一个处理<strong>模式</strong>，一个处理<strong>核心推理链</strong>（这个模型说白了就是 Siamese neural networks）。两个神经网络都映射到 k 维向量作为网络的输出，最后使用距离函数（如余弦相似度）计算语义相似度。 <div class="note info"><p>该论文处理<strong>匹配问题</strong>使用了 CNN 模型。你可能会有点疑惑<strong>匹配问题</strong>是什么问题，前面压根就没提到过。是的，论文里也没说过，我只能猜测，这里的 CNN 其实就是上述模型的两个神经网络的具体实现。处理模型和处理核心推理链可能都用了 CNN 模型。另外论文中也没有说如何将核心推理链送入 CNN 中。论文中倒是稍微提了一下如何将问题送入 CNN 中，使用 word hashing 技术（<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf" target="_blank" rel="noopener">Huang et al., 2013</a>）。</p>
</div> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/CNN架构.jpg" alt="CNN架构" /></p>
<h3 id="增加约束和聚合函数">增加约束和聚合函数</h3>
<h3 id="训练过程">训练过程</h3>
<p><strong>Topic Entity</strong>：由实体链接系统返回的分数直接作为特征。 <strong>Core Inferential Chain</strong>：使用不同的 CNN 模型的相似度分数来衡量核心推理链的质量，以下为 3 个模型。 - <strong>PatChain</strong>：比较模式和谓语序列。 - <strong>QuesEP</strong>：将主题实体的名称与谓语序列拼接完成之后，将其与原问题比较。 - <strong>ClueWeb</strong>：使用 ClueWeb 语料库的 Freebase 注释训练 ClueWeb 模型</p>
<p><strong>Constraints &amp; Aggregations</strong>：当查询图中有约束节点，使用一些简单的特征来检查问题中是否存在单词可以与约束实体或者属性相关联。相似地，也可以使用一些预定义的关键字，比如“first”、“current”或者“latest”作为 argmin 节点的特征。 <strong>Overall</strong>：回答节点的个数和总节点个数也都作为特征。 比如下图，（1）属于 Topic Entity，（2）（3）（4）属于 Core Inferential Chain，（5）（6）（7）属于 Constraints &amp; Aggregations，（8）（9）属于 Overall： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic%20Parsing%20via%20Staged%20Query%20Graph%20Generation%20Question%20Answering%20with%20Knowledge%20Base/特征举例.jpg" alt="特征举例" /></p>
<h1 id="实验">实验</h1>
<p>使用 WEBQUESTIONS 数据集，评价指标有：precision，recall 和 F1。其中 F1 的平均值作为主要的评价指标。</p>
<h1 id="其他参考资料">其他参考资料</h1>
<p>在浏览此篇论文时，发现还有其他人也看过这篇论文并且留下了笔记（中文）。 <a href="https://bigquant.com/community/t/topic/121147" target="_blank" rel="noopener">笔记1</a> <a href="https://blog.csdn.net/qq_32782771/article/details/82773048" target="_blank" rel="noopener">笔记2</a> <!-- more --></p>
]]></content>
      <categories>
        <category>paper</category>
      </categories>
      <tags>
        <tag>KBQA</tag>
        <tag>Query Graph</tag>
        <tag>semantic parsing</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（七）：K-NN</title>
    <url>/posts/be345b28.html</url>
    <content><![CDATA[<h1 id="概念">概念</h1>
<blockquote>
<p>K-NN 算法采用测量不同特征值之间的距离的方法进行分类。 工作原理： 存在一个<strong>样本数据集</strong>，也称作训练样本集，并且样本集中每个数据都存在标签。输入<strong>没有标签的新数据</strong>后，将<strong>新数据</strong>的每个特征与<strong>样本集</strong>中的数据对应特征进行比较，然后算法提取样本集中特征最相似的数据（最邻近）的分类<strong>标签</strong>。一般来说，只选择样本数据集中前 k 个最相似的数据，这就是 k-NN 算法中 k 的出处，通常 k 是不大于 20 的整数。 最后选择在 k 个最相似的数据中出现次数最多的分类，作为新数据的分类。</p>
</blockquote>
<div id="flowchart-0" class="flow-chart">

</div>
<p>简单来说，K-NN 算法使用了一种计算特征之间的距离的公式，然后选择距离前 k 近的数据，获取这些数据的标签。通过一个简单的统计，获取这 k 项数据中最多的类别。最后我们将新数据看作是这个类别。 <a id="more"></a></p>
<h1 id="代码">代码</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    group = np.array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(input, dataset, labels, k)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    K-NN 分类</span></span><br><span class="line"><span class="string">    :param input: 输入数据，即待分类的数据</span></span><br><span class="line"><span class="string">    :param dataset: 训练数据集</span></span><br><span class="line"><span class="string">    :param labels: dataset 对应的标签</span></span><br><span class="line"><span class="string">    :param k: 显而易见</span></span><br><span class="line"><span class="string">    :return: input 的类别</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 计算特征之间的距离，只是一个很简单的算法</span></span><br><span class="line">    <span class="comment"># 先算差，再平方，然后将一个项数据的所有特征累加，最后开方</span></span><br><span class="line">    all_distances = np.sqrt(np.sum(np.power((input - dataset), <span class="number">2</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 对距离进行逆序排序</span></span><br><span class="line">    sorted_distance_indices = all_distances.argsort()</span><br><span class="line">    <span class="comment"># 对类别进行计数</span></span><br><span class="line">    class_count = &#123;&#125;</span><br><span class="line">    <span class="comment"># 选取前 k 项数据</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 第 i 项数据的标签</span></span><br><span class="line">        label = labels[sorted_distance_indices[i]]</span><br><span class="line">        <span class="comment"># 标签存在则加 1，不存在就默认是 0 再加 1</span></span><br><span class="line">        class_count[label] = class_count.get(label, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据标签的数量排序</span></span><br><span class="line">    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sorted_class_count[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    X, Y = create_dataset()</span><br><span class="line">    res = classify([<span class="number">0</span>, <span class="number">0</span>], X, Y, <span class="number">3</span>)</span><br><span class="line">    print(res)</span><br></pre></td></tr></table></figure>
<h2 id="均值归一化">均值归一化</h2>
<p>由于有些数据范围波动较大，可以进行均值归一化处理。</p>
<h1 id="应用">应用</h1>
<p>引用《机器学习实战》中的应用。 1. 可以分类电影的类别，已知数据：打斗镜头、接吻镜头、<strong>电影的类别</strong>。如果给定一部新电影，则可以根据该电影的打斗镜头、接吻镜头来计算此部电影属于哪种类别。 2. 改进约会网站配对效果。已知数据：每年获得的飞行常客里程数、玩视频游戏所耗时间百分比、每周消费的冰淇淋公升数、<strong>用户交往对象的类别</strong>。其中<strong>用户交往对象的类别</strong>指： - 不喜欢的人 - 魅力一般的人 - 极具魅力的人 则可以输入一个新的约会对象的数据，从而判断此人属于哪种类别，如果属于不喜欢的人的类别，那么用户可以提前得知，并且决定不去约会。 3. 甚至可以识别手写数字。将图片转换成 0 1 表示，即数字部分用 1 表示，其他部分用 0 表示。组成一个 32 x 32 数字矩阵，然后将矩阵转换为 1 x 1024 的向量。其中的每一维度的值可以看作为一个特征。算法类似。</p>
<!-- more -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/raphael/2.2.7/raphael.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js"></script>
<textarea id="flowchart-0-code" style="display: none">st=>start: 新数据
op1=>operation: 计算新数据特征
与样本集特征之间的距离
op2=>operation: 提取前 k 个
最相似的数据的标签
count=>inputoutput: 统计标签
e1=>end: 返回出现次数最多的分类
e2=>end: 程序无法继续执行
c1=>condition: k 小于等于
样本集个数

st(right)->c1
c1(yes, right)->op1(right)->op2->count(right)->e1
c1(no)->e2(left)->st</textarea><textarea id="flowchart-0-options" style="display: none">{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12}</textarea><script>  var code = document.getElementById("flowchart-0-code").value;  var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value));  var diagram = flowchart.parse(code);  diagram.drawSVG("flowchart-0", options);</script>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>knn</tag>
      </tags>
  </entry>
  <entry>
    <title>2019 CCF会议总结</title>
    <url>/posts/ba399034.html</url>
    <content><![CDATA[<h1 id="问答系统">问答系统</h1>
<h2 id="知识图谱问答系统概述">知识图谱问答系统概述</h2>
<p>现在的<strong>搜索引擎</strong>工作流程是输入要搜索的内容，搜索引擎返回一大堆内容，供你自己选择。 <strong>问答系统</strong>是下一代的搜索引擎的基本形态。 &gt; 以直接而准确的方式回答用户自然语言提问的自动问答系统将构成下一代搜索引擎的基本形态。</p>
<p>下图展示问答系统在近几十年的发展历史。 1. 1960 年的问答系统属于专家系统（模版系统） 2. 1990 - 2000 年的问答系统属于基于信息检索的 QA 系统 3. 2000 - 2010 年的问答系统属于社区 QA 系统 4. 2011 年之后的问答系统属于基于知识图谱的 QA 系统</p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/问答系统的历史.jpg" alt="问答系统的历史" /> <a id="more"></a></p>
<h2 id="分类">分类</h2>
<p>问答系统的分类（或者说三个阶段）： 1. IR-based QA：基于<strong>关键词匹配 + 信息抽取</strong>，任然是基于<strong>浅层语义分析</strong> 2. Community QA：依赖于网民贡献，问答过程任然依赖于<strong>关键词检索技术</strong> 3. KB-based QA：Knowledge Base，例如：WolfframAlpha</p>
<p>根据问答形式分类： 1. 一问一答：字面意思，也是演讲的主题 2. 交互式问答：就是进行连续的复杂的问答 3. 阅读理解</p>
<div class="note warning"><p>KB-QA 现在只能解决事实性的问题，无法解决： 1. 怎么去天安门 2. 西红柿炒鸡蛋怎么做等提问</p>
<p>某公司（在会议上没听清，可能是一个公司）只有 5% 的问题能用 KB-QA 解决。</p>
</div>
<h2 id="什么是知识图谱">什么是知识图谱</h2>
<h3 id="一个简单的例子">一个简单的例子</h3>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/知识图谱示例.jpg" alt="知识图谱示例" /><figcaption>知识图谱示例</figcaption>
</figure>
<h3 id="知识图谱基本架构">知识图谱基本架构</h3>
<p>图中三元组中的 Ent1、Ent2 等指的是 entity。entity 可以在架构中选取，比如将 concept 作为 entity 或者将 instance 作为 entity。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/知识图谱基本架构.jpg" alt="知识图谱基本架构" /></p>
<h3 id="运用知识图谱问答">运用知识图谱问答</h3>
<p>语义如何表示是其中的一个问题： 1. 使用符号表示的形式（传统方法） 2. 使用分布式表示方法</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/运用知识图谱问答.jpg" alt="运用知识图谱问答" /><figcaption>运用知识图谱问答</figcaption>
</figure>
<h3 id="知识图谱问答的两类方法根据技术路线分">知识图谱问答的两类方法（根据技术路线分）</h3>
<ol type="1">
<li>语义解析(Semantic Parsing)：问句转换成形式化的查询语句，进行结构化查询得到答案</li>
<li>语义检索（Answer Retrieval &amp; Ranking）：简单的搜索得到候选答案，利用问句和候选答案的匹配程度(特征)抽取答案</li>
</ol>
<h2 id="公开的评测数据集">公开的评测数据集</h2>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/公开的评测数据集.jpg" alt="公开的评测数据集" /> 例如： <span class="math display">\[
    \text{图数据结构}
    \begin{cases}
        QALD \\
        WebQuestions \\
        Simple Question\\
    \end{cases}\\
    \text{表数据结构}
    \begin{cases}
        WikiSQL &amp; \text{一个表} \\
        Spider &amp; \text{多个表} \\
    \end{cases}
\]</span></p>
<h2 id="知识图谱问答基于的几种方法">知识图谱问答基于的几种方法</h2>
<ol type="1">
<li>基于符号语义解析的知识图谱问答
<ul>
<li>语义表示（lambda 验算，DCS Tree）</li>
<li>语义解析方法（CCG）
<ul>
<li>还有许多语义解析方法，略</li>
</ul></li>
</ul></li>
<li>基于语义检索的知识图谱问答
<ul>
<li>基于显示特征的知识检索</li>
<li>基于端到端的知识图谱问答</li>
</ul></li>
<li>基于神经符号计算的知识图谱问答
<ul>
<li>基于序列学习的解析方法</li>
<li>基于动作序列的解析方法</li>
<li>基于对战神经网络的端到端问答方法</li>
</ul></li>
</ol>
<h3 id="基于符号语义解析的知识图谱问答">基于符号语义解析的知识图谱问答</h3>
<p>两种技术的具体实现过程略过，对比如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/Lambda演算vs.DCSTree.jpg" alt="Lambda演算vs.DCSTree" /></p>
<h3 id="基于语义检索的知识图谱问答">基于语义检索的知识图谱问答</h3>
<ul>
<li>基于显示特征的知识检索
<ul>
<li>关键词检索</li>
<li>文本蕴含推理</li>
<li>逻辑表达式</li>
<li><div class="note primary"><p>给出了许多研究进展。</p>
</div></li>
</ul></li>
<li>基于端到端的知识图谱问答
<ul>
<li>LSTM</li>
<li>Attention Model</li>
<li>Memory Network</li>
<li><div class="note primary"><p>其中有部分问题： 1. 如何学习？ - RNN - CNN - Transformer 2. 问句如何表示？ - 取所有词向量的平均值 - 关注答案不同的部分，问句的表示应该问句的不同部分 - 等 3. <strong>考虑多维度的相似度</strong> - 从多个角度计算问句和知识的语义匹配（语义相似度） - 问句如何表示？ - 依据问答特点，考虑答案不同维度的信息</p>
<p>PPT 中给出了许多研究进展，包括最基本的做法。</p>
</div>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/基于语义检索的知识图谱问答.jpg" title="fig:" alt="基于语义检索的知识图谱问答" /></li>
</ul></li>
</ul>
<h3 id="基于神经符号计算的知识图谱问答">基于神经符号计算的知识图谱问答</h3>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/符号语义解析vs.深度学习.jpg" alt="符号语义解析vs.深度学习" /> - 基于序列学习的解析方法 + seq2seq * RNN-based * with Attention + 基于序列学习的神经符号计算 <div class="note primary"><p>就是运用<strong>基于符号语义解析的知识图谱问答</strong>的原理，让神经网络生成这些符号，而不是生成文字。</p>
</div> &gt; 基于序列学习的方法将问句和答案的逻辑表达式看作为两个序列 &gt; - 使用序列转换的神经网络模型（如 Seq2Seq）来建模 &gt; - 神经网络生成的逻辑表达式可能不合语法规范</p>
<pre><code>    * Seq2Tree</code></pre>
<ul>
<li>基于动作序列的解析方法
<ul>
<li>Seq2Action</li>
</ul></li>
<li>基于对战神经网络的端到端问答方法</li>
</ul>
<h2 id="总结">总结</h2>
<p>限定域的深度问答的准确度比较高，开放域的深度问答的准确度还是处于较低的水平。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/深度问答的性能.jpg" alt="深度问答的性能" /></p>
<h1 id="对话系统">对话系统</h1>
<p>对话系统也可以直白的称为聊天机器人。 目前 54% 的用户会使用闲聊（开放域对话）功能。26% 的用户会选择使用某些功能性功能，比如查出行路线、查天气等。其余小部分用户使用其他的功能。 目前大部分的聊天机器人都基于<strong>微软小冰</strong>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/各种聊天机器人.jpg" alt="各种聊天机器人" /></p>
<p>聊天机器人一共分为两种： 1. 检索式 2. 生成式</p>
<h2 id="response-selection-for-retrieval-based-chatbots">Response Selection for Retrieval-based Chatbots</h2>
<p>检索式又分为单轮和多轮。 单轮不考虑回复历史。下图展示了一个单轮回复的场景，用户提出一个问题，机器人需要在一堆回复中检索出一个最有可能的结果来对用户进行回复。多轮回复与单轮类似，只不过多轮需要考虑上下文的对话。最后也是选择一个最优可能的结果进行回复。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复.jpg" alt="检索式单轮回复" /></p>
<div class="note info"><p>对于单轮： 回复不只回复 Top1 的候选回复，而是要训练一个 classifier，从而随机地返回一个回复。因为如果回复总是为同一个，用户可能会感觉很无聊。 对于多轮： 有一些挑战： - A hierarchical data structure + Words -&gt; utterances -&gt; session - Information redundancy + Not all words and utterances are useful for response selection - Logics + Order of utterances matters in response selection + Long-term dependencies among words and utterances + Constraints to proper responses</p>
</div>
<p>下面是检索式单轮回复系统架构图和多轮回复系统架构图的对比。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复架构图.jpg" alt="检索式单轮回复架构图" /></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式多轮回复架构图.jpg" alt="检索式多轮回复架构图" /><figcaption>检索式多轮回复架构图</figcaption>
</figure>
<h3 id="单轮回复中使用的模型">单轮回复中使用的模型</h3>
<p>一共有两种框架，分别为：Framework I 和 Framework II。 <strong>Framework I 和 Framework II 的区别是</strong>： 1. Framework I 是将句子表示为向量，Framework II 将字表示为向量。</p>
<p><strong>Framework I 和 Framework II 的比较：</strong> - Efficacy（功效）： 1. 一般来讲，在外界公布出的数据集上，Framework II 模型比 Framework I 模型更好。因为在 Framework II 中的 interaction 充分保留了一个 message-response pair 中的匹配信息。 - Efficiency（效率）： 1. 由于过多的 interaction，Framework II 的模型普遍比 Framework I 的模型在计算上代价更大。 2. 由于可以预先计算 messages and responses 的表示并将它们以索引形式存储。所以当对线上响应时间有严格要求时， Framework I 的模型更可取。</p>
<p>下图是 Framework I 的架构，其中最下层的 sentence embedding layer 大概就是词向量，然后需要经过一个 Representation function（这个 function 下面会给出架构）。最后将已经经过 Representation function 转换后的 q 和 r 送入 Matching layer，该层有一个 Matching function（这个 function 下面也会给出架构）。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复的%20Framework%20I.jpg" alt="检索式单轮回复的 Framework I" /></p>
<p>下图是 Representation funtion 的结构： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复的%20Framework%20I%20的%20Representation%20funtion.jpg" alt="检索式单轮回复的 Framework I 的 Representation funtion" /></p>
<p>下图是 Matching funtion 的结构： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复的%20Framework%20I%20的%20Matching%20funtion.jpg" alt="检索式单轮回复的 Framework I 的 Matching funtion" /></p>
<p><strong><em>有一些特殊的模型：Arc-I，Attentive LSTM 等</em></strong></p>
<p>Framework II 的架构与 Framework I 类似，只是多了一个 Interaction Function。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复的%20Framework%20II.jpg" alt="检索式单轮回复的 Framework II" /></p>
<p>Interaction 由两种形式： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019%20CCF会议总结/检索式单轮回复的%20Framework%20II%20中%20Interaction%20的两种类型.jpg" alt="检索式单轮回复的 Framework II 中 Interaction 的两种类型" /></p>
<p><strong><em>有一些特殊的模型：Match Pyramid，Match LSTM 等</em></strong></p>
<p>PPT 中有数据集。以及很多 reference。</p>
<h3 id="多轮回复中使用的模型">多轮回复中使用的模型</h3>
<p>对于多轮回复也有两种框架，分别为：Framework I 和 Framework II。 具体的架构略。PPT 里都有。</p>
<h1 id="技术总结">技术总结</h1>
<h2 id="技术">技术</h2>
<h2 id="数据集">数据集</h2>
]]></content>
      <categories>
        <category>coding</category>
        <category>conference</category>
      </categories>
      <tags>
        <tag>北京</tag>
        <tag>QA</tag>
        <tag>对话系统</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n学习笔记</title>
    <url>/posts/d9a134a.html</url>
    <content><![CDATA[<div class="note info"><p>本笔记记录的内容来源于 <a href="https://www.bilibili.com/video/av41393758" target="_blank" rel="noopener">b站——CS224n 斯坦福深度自然语言处理课</a>。 之后我补充了18 章之后的内容，其来源为<a href="https://www.bilibili.com/video/av46216519" target="_blank" rel="noopener">b站——(2019)斯坦福CS224n深度学习自然语言处理课程 by Chris Manning</a></p>
</div>
<h1 id="开场白">开场白</h1>
<p>略</p>
<h1 id="词向量表示word2vec">词向量表示：word2vec</h1>
<p>课程计划如下： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/课程计划.jpg" alt="课程计划" /></p>
<p><strong>神经网络词嵌入学习的通用做法</strong>：定义一个模型，根据中心词 <span class="math inline">\(w_t\)</span> 去预测上下文单词。给定 <span class="math inline">\(w_t\)</span> 的条件下 context 的概率。 <span class="math display">\[
p(context|w_t) = \dots
\]</span> 然后用损失函数判断预测的准确性，例如： <span class="math display">\[
J = 1 - p(w_{-t}|w_t), \quad  \text{-t 代表 t 周围的单词}
\]</span> 如果可以精准地根据 t 预测到这些单词，那么概率就为 1，于是损失就没有了。但通常情况下，做不到这点。<strong>所以我们应该调整词汇表示，从而使损失最小化</strong>。 <a id="more"></a> 下图是以前的低维词向量表示方法，2003 年 Bengio 发表的这篇现在属于开创性的论文其实并没有太多人关注，因为那时候深度学习并没有很流行。但是当这篇论文开始流行的时候，就开始大行其道了。于是 2008 年 Collobert 和 Weston 开启了一个新方向，<strong>他们觉得如果我们只想要得到好的单词表示，我们甚至不需要构建一个具有预测功能的概率语言模型（probabilistic language model），我们只需要找到一种学习单词表示的方法即可</strong>。于是 2013 年有了 word2vec 模型。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/以前的低维词向量表示方法.jpg" alt="以前的低维词向量表示方法" /></p>
<p>word2vec 是一个软件，实际上，它里面包含很多东西。有两个用于生成词汇向量的算法（Hierarchical softamx，negative sampling），还有两套效率中等的训练方法（Skip-grams，CBOW）。<em>这里的软件应该指的不是那种可以运行 exe 文件</em>。本节只讲 skip-grams 算法，并且不会讲那两个高效的词向量生成算法，而是将一个效率极低的算法（因为比较简单且包含了基本概念）。 skip-grams 模型的概念是：在每一个估算步中，都取一个词为中心词汇，然后尝试预测它<strong>一定范围内</strong>的上下文的词汇。这个模型将定义一个概率分布：<strong>给定一个中心词汇预测某个单词在它上下文中出现的概率</strong>。如下图所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/skip-grams模型.jpg" alt="skip-grams模型" /></p>
<p>我们将会选取词汇的向量表示，以让概率分布值最大化。</p>
<h2 id="优化目标">优化目标</h2>
<p>我们需要做的是定义一个半径 m，然后从中心词汇开始到距离为 m 的位置来预测周围的词汇。这句话比较抽象，因为到这为止，你还是构建不出一个模型（优化目标）。下面先给出模型的公式，注意一撇不是求导： <span class="math display">\[
J&#39;(\theta) = \prod^T_{t=1} \prod_{-m \leq m, j \neq 0} p(w_{t+j}|w_t;\theta)
\]</span> 其中定义一句话有 T 个单词，word t = 1 <span class="math inline">\(\dots\)</span> T。上式中 m 为半径窗口，j 为整个窗口之中的索引。先不看第一个累乘符号，当 t = 1 时，也就是当中心词的索引为 1 时，以 m 为半径，预测该中心词汇的上下文单词出现的概率，并将所有的概率累乘。即公式： <span class="math inline">\(\prod_{-m \leq m, j \neq 0} p(w_{t+j}|w_t;\theta)\)</span>。而第一个累乘符号指的是，将句子中每一个字都当做一次中心词汇，然后将概率再累乘起来。当然当中心词的索引比较靠前时，可能窗口会超出句子的前部，比如 中心词汇所以为 1，而 m = 5，则需要预测 -4，-3... 的位置，这显然不可能，所以需要自己做一下处理。 公式中的 <span class="math inline">\(\theta\)</span> 是模型唯一的参数，让上下文所有词汇出现的概率都尽可能的高，其实 <span class="math inline">\(\theta\)</span> 就是词向量，而模型的输入就是 one-hot 表示。但是，处理概率问题是一件很不爽的事，我们要做最大化操作，实际上就是解决对数分布的问题。这样求积就会变成求和，如下所示： <span class="math display">\[
J(\theta) = -\frac{1}{T} \sum^T_{t=1} \sum_{-m \leq m, j \neq 0} log \, p(w_{t+j}|w_t;\theta)
\]</span> 这样我们就得到了<strong>负的对数似然</strong>，上述公式就是最终版。但是这里还有一小点就是 m 其实也算是模型的参数，但是确是<strong>超参数</strong>，需要自己手动改的。所以上面说“<em>公式中的 <span class="math inline">\(\theta\)</span> 是模型唯一的参数</em>”也没错。事实上这个模型还有很多其他的超参数，但是现在暂且视为常数。 公式前面有个负号，是因为我们要求最小化问题，而原式只能取最大值，所以取了个负号。</p>
<h3 id="确定相应的概率分布">确定相应的概率分布</h3>
<p>那么我们具体应该怎么通过中心词汇来预测周围单词出现的概率呢？也就是说公式中的函数 p 应该是什么。其实 p 就是 softmax 函数。具体来说就是用由词向量构成的中心词汇去预测周围词汇的概率分布。下图就是 softmax 函数。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/softmax.jpg" alt="softmax" /></p>
<h2 id="损失函数">损失函数</h2>
<p>最前面讲到需要有一个损失函数来判断预测的准确性。我们使用 cross-entropy loss。</p>
<h2 id="计算">计算</h2>
<p><span class="math display">\[
\begin{align}
     &amp; \frac{\partial}{\partial v_c} log \frac{exp(u^T_o v_c)}{\sum^v_{w=1} exp(u^T_w v_c))} \\
    = &amp; \frac{\partial}{\partial v_c} (\underbrace{log \, exp(u^T_o v_c)}_{1} - \underbrace{log \, \sum^v_{w=1} exp(u^T_w v_c)}_2) \\
     &amp; \frac{\partial}{\partial v_c} log \, exp(u^T_o v_c) &amp; \text{1} \\
    = &amp; \frac{\partial}{\partial v_c} u^T_o v_c = u_o  \\
     &amp; \frac{\partial}{\partial v_c} log \, \sum^v_{w=1} exp(u^T_w v_c) &amp; \text{2} \\
    = &amp; \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \frac{\partial}{\partial v_c} \sum^v_{x=1} exp(u^T_x v_c) \\
    = &amp; \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \sum^v_{x=1} \frac{\partial}{\partial v_c} exp(u^T_x v_c) \\
    = &amp; \frac{1}{\sum^v_{w=1} exp(u^T_w v_c)} \sum^v_{x=1} exp(u^T_x v_c) \, u_x \\
    = &amp; \sum^v_{x=1} \frac{exp(u^T_x v_c)}{\sum^v_{w=1} exp(u^T_w v_c)} \, u_x \\
    = &amp; \sum^v_{x=1} p(x|c) u_x \\
     &amp; u_o - \sum^v_{x=1} p(x|c) u_x &amp; \text{合并}\\
\end{align}
\]</span></p>
<h1 id="高级词向量表示">高级词向量表示</h1>
<p>略。说了一些 word2vec 算法以及 GloVe 等算法。</p>
<h1 id="word-window分类与神经网络">Word Window分类与神经网络</h1>
<p>略。讲 Word Window 分类和简单的神经网络。</p>
<h1 id="反向传播和项目建议">反向传播和项目建议</h1>
<p>讲反向传播，略。</p>
<h1 id="依存分析">※ 依存分析</h1>
<p>6分38秒开始进入正题，之前都在说学校里的事。</p>
<h2 id="语言结构的两种观点">语言结构的两种观点</h2>
<p>Constituency=phrase structure grammar=context-free grammars(CFGs)。上下文无关文法。 Dependency。依存句法分析。 传统上讲，语言学家和自然语言处理器想做的是描述人类语言结构。过去有两个工具可以做到这点，1. 上下文无关文法（计算机科学中）/短语结构文法（语言学家）；2. 依存句法结构。 依存句法分析做的是<strong>通过找到句子中每一个词所依赖的部分来描述句子的结构</strong>。如果一个词修饰另一个词或者是另一些词的论证，那么它就是那个词的依赖。例：“barking dog”，barking 是 dong 的依赖，因为 barking 修饰 dog。“dog by the door”，by the door 也是 dog 的依赖。我们可以<strong>在词之间添加依存关系，通常用箭头表示它们之间的依存关系</strong>，可以参考 <a href="http://hanlp.com/" target="_blank" rel="noopener">这里</a> 加以理解。 对于语义含糊的例子，都可以考虑使用依存分析，例如下图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/scientistis%20study%20whales%20from%20space的句法分析.jpg" alt="scientistis study whales from space的句法分析" /></p>
<p>一个重要的概念：<strong>人类的语言确实有歧义，我们希望可以通过这些依存关系来描述人类语言</strong>。可以发现我们分析出了两组关系。 另一个重要的概念是：<strong>完整的语言学以树库（treebanks）的形式标注数据</strong>。1990年开始，将网络上的句子的句法结构描述为依存关系图，如下图所示，这是来自雅虎问答上的句子，我们将这些称为树库。1990年，我们投入了大量资源来建立这种标注型树库。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/example%20of%20treebanks.jpg" alt="example of treebanks" /></p>
<p>此处没有讲上下文语法，在过去的 10 年间（视频中的时间是 2017 年），nlp 中，<strong>依存句法分析</strong>已经取代了<strong>上下文无关文法</strong>。人们发现<strong>依存分析文法</strong>是一种（依存句法分析应该是依存分析文法的一种实现）仅仅构建语义表征就能轻松得到语言理解的合适框架。</p>
<h2 id="dependency-grammar-and-dependency-structure">Dependency Grammar and Dependency Structure</h2>
<p>开始时间 22.19。 上面了解了什么是<strong>依存分析语法</strong>（从此节开始称之为语法，我感觉“文法”翻译得怪怪的），接下来讲解具体应该怎么做。 句法分析的思想是<strong>一个句法模型就是我们有一个词法项之间的关系或者词之间的关系</strong>。也就是说我们在词法项之间画箭头，这些箭头就是依存。通常我们做依存分析时，要做的工作要比这多。通常我们会根据一些语法关系来给这些依存关系分类并命名，比如主语、谓语、辅助修饰词等。</p>
<h2 id="dependency-parsing">Dependency parsing</h2>
<p>依存分析有多种方式，视频中采用 Greedy transition-based parsing。视频开始于 52.05。</p>
<h1 id="tensorflow-入门">Tensorflow 入门</h1>
<p>略，不学 tensorflow。</p>
<h1 id="rnn和语言模式">RNN和语言模式</h1>
<p>讲了传统语言模型，例如马尔科夫模型，n-gram 模型等。讲了 simple RNN ，bi-RNN and deep bi-RNN。提到了梯度消失，梯度爆炸，grad clipping 等。大部分都会，主要记录一些不会的内容。</p>
<h2 id="梯度消失">梯度消失</h2>
<p>19.50 - 49.05</p>
<h2 id="梯度爆炸">梯度爆炸</h2>
<p>49.06 - 62.38</p>
<h2 id="序列模型用于其他任务">序列模型用于其他任务</h2>
<p>66:00 - NER - Entity level sentiment in context - opinionated expressions</p>
<h1 id="机器翻译和高级循环神经网络">机器翻译和高级循环神经网络</h1>
<p>花了二三十分钟讲机器翻译，然后讲解各类 RNN，包括 GRU, LSTM, <strong>Pointer-Sentinel Model</strong>。</p>
<h1 id="神经机器翻译和注意力模型">神经机器翻译和注意力模型</h1>
<p>先将机器翻译，后讲 attention。</p>
<h2 id="神经机器翻译">神经机器翻译</h2>
<h2 id="attention">attention</h2>
<p>下图是 attention 的工作原理。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/attention机制.jpg" alt="attention机制" /> 0. 图中的 a 代表 score，<span class="math inline">\(\bar{h}_s\)</span> 代表 encoder 中每个 time step 生成的隐藏状态向量，<span class="math inline">\(c_t\)</span> 代表 attention 之后的向量； 1. 首先将开始标志输入到一个 decoder，代表开始进行翻译，输出一个单词后，将该 decoder 的<strong>隐藏状态</strong>（注意是隐藏状态而不是输出值，此节课视频中有明确指出）与 encoder 中的<strong>隐藏状态</strong>进行计算得到一个 score。打分的公式为 <span class="math inline">\(score(h_{t - 1}, \bar{h}_s)\)</span>，score 具体是什么公式可以自己定义，最简单就是向量内积，下面会细说； 2. 关于 score 函数，它有多种选择，<strong>注意一点</strong>下面的 score 函数只是对<strong>一个</strong>时间步上的隐藏状态打分，<span class="math inline">\(\bar{h}_s\)</span> 也可以是个矩阵，即一步计算所有时间步的 attention score（这做法是最好的）。以下罗列几种做法，被广泛采用（2017 年的说法，现不知）的是第二个表达式，第三个表达式的 <span class="math inline">\(v_a\)</span> 也是一个向量参数。另外对于第三个表达式 <span class="math inline">\(v_a tanh(W_a [h_t;\bar{h}_s])\)</span>，它不是 score function，而是 Bahdanau，不知道为什么把它放到 score function 这。 <span class="math display">\[
score(h_t, \bar{h}_s) = 
\begin{cases}
h^T_t \bar{h}_s \\
h^T_t W_a \bar{h}_s \\
v_a tanh(W_a [h_t;\bar{h}_s])
\end{cases}
\]</span> 3. 将 score 送入 softmax 得到概率； 4. 通过公式 <span class="math inline">\(c_t = \sum_s a_t(s)\bar{h}_s\)</span>，将所有的向量乘上注意力分数加起来； 5. 将此新向量当做下一个 decoder 的输入；</p>
<p>下图是加 attention 机制和不加的区别。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/加入attention机制后的性能.jpg" alt="加入attention机制后的性能" /></p>
<h2 id="coverage">coverage</h2>
<p>coverage = more attention，想法源于计算机视觉，请看下图。神经网络读入一张图片，要求输出一段话。但是我们知道一段话不仅要描写图中的鸟，还要描写鸟旁边的事物，所以就引出了多次注意，即神经网络需要注意图中更多的地方。将这一想法引入 NLP 中，其实就是多做几次 attention，<em>注：这一想法貌似就是后来 transformer 的 multi-head attention</em>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/more%20attention（coverage）.jpg" alt="more attention(coverage)" /></p>
<h2 id="search">※ search</h2>
<h1 id="gru及nmt的其他议题">※ GRU及NMT的其他议题</h1>
<h2 id="gruslstms">GRUs/LSTMs</h2>
<p>gated unit 是如何解决 BPTT 的。</p>
<h2 id="nmt-evaluation">NMT evaluation</h2>
<h1 id="语音处理的端对端模型">语音处理的端对端模型</h1>
<p>略，不做语音。</p>
<h1 id="卷积神经网络">卷积神经网络</h1>
<p>略，不学 CNN。</p>
<h1 id="树rnn和短语句分析">※ 树RNN和短语句分析</h1>
<p>人类语言具有嵌套结构（训练结构、树结构），如：[The man from [the company that you spoke with about [the project] yesterday]]。 那么如何使用向量来表示这些句子的语义呢？可以使用 tree RNN，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/Recursive%20vs.%20recurrent%20neural%20network.jpg" alt="Recursive vs. recurrent neural network" /> &gt; <strong>Tree recursive neural network 的问题在于你需要得到一个树形结构</strong>，这是一个比较大的问题。树形网络并没有火遍全球，在语言方面确实有原因喜欢这类的模型（原因后面会有讲到），但是如果你在 arxiv 里面找，人们在语言神经网络研究中所使用的的方法时，你会发现人们并不多使用树形结构模型。LSTMs 的比例几乎是其十倍之多。 &gt; 这里面比较大的原因是树形递归神经网络的使用者必须构建一个树形结构。<strong>在你构建完成后，使用反向传播学习模型会是一个问题</strong>。 &gt; <a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a> 25分开始。</p>
<h2 id="simple-tree-rnn">simple tree RNN</h2>
<h3 id="树rnn的计算">树RNN的计算</h3>
<p>那么具体如何使用树形递归神经网络计算呢？比如下图中使用向量 [3 3] 和 [8 5] 计算，输入进神经网络之后，就会输出一个向量 [8 3] 和一个分数 1.3，这个分数代表输出的向量 [8 3] 是否合理（即结构是否合理。如果不太理解什么是结构是否合理，请看下两张图以及博客内容即可理解）。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive%20neural%20network%20for%20training.jpg" alt="recursive neural network for training" /></p>
<p>具体的做法如下图所示。应该很好理解，就不详细说明了，其中对于计算 score 的 U，我猜测可能是一个 trainable 的参数，视频中并没有详细的说明。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/recursive%20neural%20network%20details.jpg" alt="recursive neural network details" /></p>
<p>那么到了真正的实战阶段应该怎么做呢？训练一个贪心的解析器，对于单词两两组合，然后发现最前的两个单词 &quot;The cat&quot; 组成的短语训练之后的分数最高，然后我们将 &quot;The cat&quot; 看作一个成分并且尤其对应的语义 [5 2]。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing%20a%20sentence%20with%20rnn%201.jpg" alt="parsing a sentence with rnn" /></p>
<p>接下来继续重复做，请注意现在的 &quot;The cat&quot; 是一个成分（可看作单词），而不是两个单词。又做一遍解析之后发现 &quot;the mat&quot; 的分数最高。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing%20a%20sentence%20with%20rnn%202.jpg" alt="parsing a sentence with rnn——2" /></p>
<p>再将 &quot;the mat&quot; 看作一个成分，并拥有对应的语义。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing%20a%20sentence%20with%20rnn%203.jpg" alt="parsing a sentence with rnn 3" /></p>
<p>以此类推，我们发现 &quot;on the mat&quot; 的分数最高，然后发现 &quot;sat on the mat&quot; 的分数最高，最后就得到 &quot;The cat sat on the mat&quot; 的分数最高。如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/parsing%20a%20sentence%20with%20rnn%204.jpg" alt="parsing a sentence with rnn 4" /></p>
<p>这是一棵解析树（parse tree），我们会得到这棵解析树的分数，它的分数由每个节点的分数加和得到。<strong>我们要做的就是找到由这堆节点所能组成的分数最高的解析树</strong>。 还需要一个优化目标，similar to max-margin parsing(Taskar et al. 2004), a supervised max-margin objective: <span class="math inline">\(J = \sum_i s(x_i, y_i) - \max_{y \in A(x_i)} (s(x_i, y) - \Delta(y, y_i))\)</span> 最后我们还需要反向传播算法进行计算，这一工作早在 20 世纪 90 年代就由几个德国人做过了。Goller 和 Kuchler 提出了这个算法，并命名为 <strong>back propagation through structure</strong>.</p>
<h2 id="syntactically-untied-rnn">Syntactically-Untied RNN</h2>
<p>语义解绑树形递归神经网络，这被证明是构建高质量解析器的一个成功的方法。 <a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a>，50 分开始。</p>
<h2 id="compositionality-through-recursive-matrix-vector-spaces">Compositionality Through Recursive Matrix-Vector Spaces</h2>
<p><a href="https://www.bilibili.com/video/av41393758/?p=14" target="_blank" rel="noopener">第十四讲 - 树 RNN 和短语句法分析</a>，65 分开始。</p>
<h2 id="related-work-for-parsing">related work for parsing</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/CS224n学习笔记/related%20work%20for%20parsing.jpg" alt="related work for parsing" /><figcaption>related work for parsing</figcaption>
</figure>
<h1 id="共指解析">※ 共指解析</h1>
<p><span class="math inline">\(B^3\)</span>(B-CUBED) 算法用于评估。其他的一些算法： - MUC Score (Vilain et al., 1995) - BEAF (Luo 2005); entity based - BLANC (Recasens and Hovy 2011) Cluster RAND-index</p>
<p>在于语言学中，人们常区分两种关系。其中之一是共指，即两个词指代同一个实体，这和文本结构无关；另一种关系是首语重复，它指的是文本中某一项，一个照应语（或一个指代，anaphor）指代的事物由另一项决定，即先行词。 一些共指消解的做法： - Mention Pair models - Mention Ranking models - Entity-Mention models</p>
<p>神经共指模型，人们通过深度学习和共指做的内容。 - Wisemean, Rush, Shieber, and Weston (ACL 2015) + Mention-pair model. Only partially neural network system over conventional, categorical coreference features - Wiseman, Rush and Shieber (NAACL 2016) + Use RNNs to learn global representations of entity clusters from mentions - Clark and Manning (ACL 2016) + An entity-mention model based around clustering using distributed representations of mentions and entity clusters - Clark and Manning (EMNLP 2016) + Expolores deep reinforcement learning to improve a metion-pair model</p>
<div class="note info"><p>此节视频讲了很多共指的理论，我没有记下来。实际内容比这里记的还要多一点。</p>
</div>
<h1 id="用于回答问题的动态神经网络">用于回答问题的动态神经网络</h1>
<p>略，这节听不懂。</p>
<h1 id="nlp的问题和可能性架构">※ NLP的问题和可能性架构</h1>
<p>tree-RNN、pointer model、sub-word and character-based model 等。</p>
<h1 id="应对深度-nlp-的局限性">※ 应对深度 NLP 的局限性</h1>
]]></content>
      <categories>
        <category>notes</category>
        <category>nlp</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习算法（一）：simple NN（前馈神经网络的正反向推导）</title>
    <url>/posts/44544db3.html</url>
    <content><![CDATA[<div class="note info"><p>本文的公式不存在次方的说法，所以看见上标，不要想成是次方。 对于权重的表示问题，请看<a href="https://yan624.github.io/·学习笔记/AI/dl/《神经网络与深度学习》学习笔记：反向传播算法中weight的表示问题.html">博客</a>，但是由于是以前的学习笔记，不保证完全正确。 如果想了解为什么梯度下降要对w和b求导，可以看<a href="https://yan624.github.io/·zcy/AI/ml/梯度下降算法的推导.html">这篇</a>。 <strong>建议边看边写，否则思维跟不上。</strong></p>
</div>
<h1 id="前言">前言</h1>
<p>参考<a href="https://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">文章</a> 以如下神经网络架构为例。参考<a href="https://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">文章</a>中使用了一个2 2 2的神经网络架构，但是现实中神经网络架构不会这么整整齐齐。所以还是使用了略复杂的架构，此外原文中未对bias（偏差）更新。另外原文也没有实现向量化后的计算。虽然在后面的代码写了，但是由于代码太长了，有一种代码我给出来了，你们自己去看的感觉。说实话没多少注释，都没看的欲望(╬￣皿￣)。然后她所使用的符号让我不太习惯，因为看吴恩达以及李宏毅老师使用的符号都是<span class="math inline">\(w^l_{ji}\ a^l_i\)</span>等等，所以自己重新推导一遍，并且使用了数学公式，而不是截图，更好看一点。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/带参数的前馈神经网络模版.svg" alt="带参数的前馈神经网络模版" /> 解释一下最下面的神经元，这个神经元初始化为1，也就是意味着1 * b = b。输入值为1，一个偏差乘1还是偏差本身。 <a id="more"></a></p>
<h2 id="关于函数选用">关于函数选用</h2>
<p>本文所有激活函数选择sigmoid函数，代价函数选择binary_crossentropy。</p>
<h2 id="一些约定">一些约定</h2>
<div class="note info"><p>本文所有的输入值，激活值，输出值都是<strong>列向量</strong>。</p>
</div>
<h1 id="初始化数据以及正向传播">初始化数据以及正向传播</h1>
<h2 id="初始化数据">初始化数据</h2>
<p>此处初始化各层的权重值，偏差。由于是演示，所以顺便把输入层也初始化了。 设 <span class="math display">\[
\begin{cases}
    x_1 = a^0_1 = 0.55, x_2 = a^0_2 = 0.72\\
    y_1 = 0.60, y_2 = 0.54\\
\end{cases}\\
\begin{cases}
    w^1_{11}=0.4236548, w^1_{12}=0.64589411\quad|\quad w^1_{21}=0.43758721, w^1_{22}=0.891773\quad|\quad w^1_{31}=0.96366276, w^1_{32}=0.38344152\\
    b^1_1=0.79172504, b^1_2=0.52889492, b^1_3=0.56804456\\
    w^2_{11}=0.92559664, w^2_{12}=0.07103606, w^2_{13}=0.0871293\quad|\quad w^2_{21}=0.0202184, w^2_{22}=0.83261985, w^2_{23}=0.77815675\\
    b^2_1=0.87001215, b^2_2=0.97861834\\
\end{cases}
\]</span> 不用多看，反正也用不到几次。。。</p>
<h2 id="正向传播">正向传播</h2>
<p>对于正向传播，应该是很熟悉了，所以我直接一次写完，不做过多解释。</p>
<h3 id="输入层到隐藏层">输入层到隐藏层</h3>
<p><span class="math display">\[
z^1_1 = w^1_{11} * a^0_1 + w^1_{12} * a^0_2 + 1 * b^1_1\\
z^1_2 = w^1_{21} * a^0_1 + w^1_{22} * a^0_2 + 1 * b^1_2\\
z^1_3 = w^1_{31} * a^0_1 + w^1_{32} * a^0_2 + 1 * b^1_3\\
\]</span> 带入sigmoid函数中，以下开始省略bias乘的1： <span class="math display">\[
a^1_1 = \sigma{(z^1_1)}\\
a^1_2 = \sigma{(z^1_2)}\\
a^1_3 = \sigma{(z^1_3)}\\
\]</span></p>
<h3 id="隐藏层到输出层">隐藏层到输出层</h3>
<p><span class="math display">\[
z^2_1 = w^2_{11} * a^1_1 + w^2_{12} * a^1_2 + w^2_{13} * a^1_3 + b^2_1\\
z^2_2 = w^2_{21} * a^1_1 + w^2_{22} * a^1_2 + w^2_{13} * a^1_3 + b^2_2\\
\]</span> 带入sigmoid函数中： <span class="math display">\[
a^2_1 = \sigma{(z^2_1)}\\
a^2_2 = \sigma{(z^2_2)}\\
\]</span></p>
<h3 id="计算代价">计算代价</h3>
<p>以字母J记为代价函数的名称，最后一个表达式为最简版： <span class="math display">\[
\begin{align}
    J &amp; = -[(y_1 * \log(a^2_1) + (1 - y_1) * \log(1 - a^2_1) + (y_2 * \log(a^2_2) + (1 - y_2) * \log(1 - a^2_2)]\\
    J &amp; = -\Sigma^2_{i = 1}{[(y_i * \log(a^2_i) + (1 - y_i) * \log(1 - a^2_i)]}\\
    J &amp; = -\Sigma{[(y * \log(a^2) + (1 - y) * \log(1 - a^2)]}\\
\end{align}
\]</span></p>
<h3 id="向量化">向量化</h3>
<p>上述的表达式全部是一个一个列出来的，如果使用向量来表示乘积那就方便很多。可以看到下面只用了五行就写完了上面<a href="https://yan624.github.io/前馈神经网络的正反向推导.html#正向传播">正向传播</a>的所有步骤。 <div class="note warning"><p>如果无法理解这一步那就是不会线性代数的问题，线性代数不在此文的介绍范围之内。</p>
</div> <span class="math display">\[
\begin{align}
    z^1 &amp; = w^1 * a^0 + b^1 &amp; \text{输入层到隐藏层}\\
    a^1 &amp; = \sigma{(z^1)} &amp; \text{带入隐藏层的激活函数}\\
    z^2 &amp; = w^2 * a^1 + b^2 &amp; \text{隐藏层到输出层}\\
    a^2 &amp; = \sigma{(z^2)} &amp; \text{带入输出层的激活函数}\\
    J &amp; = -\Sigma{[(y * \log(a^2) + (1 - y) * \log(1 - a^2)]} &amp; \text{计算代价}\\
\end{align}
\]</span></p>
<h2 id="上述表达式代码实现">上述表达式代码实现</h2>
<p>最后几节有神经网络numpy实现的全部代码，可以直接跳过本节看下一节，这里的代码只是给出一个直观的理解，可以自己运行看看。 受到keras以及万物皆对象的启发，首先建立一个神经元对象 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleNN</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units, activation=<span class="string">'sigmoid'</span>)</span>:</span></span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = activation</span><br><span class="line">        self.hyperparameters = dict()</span><br><span class="line">        <span class="comment"># W, b, A_prev的导数</span></span><br><span class="line">        self.grads = dict()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_hyperparameters</span><span class="params">(self, shape)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化超参数，在神经网络中权重值不能初始化为0，偏差可以</span></span><br><span class="line"><span class="string">        :param shape: 神经元的形状，(units, input_shape)</span></span><br><span class="line"><span class="string">        :return: hyperparameters，该神经元的超参数。可以通过hyperparameters['W']、hyperparameters['b']取值</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 由于是演示，所以使用了随机初始化</span></span><br><span class="line">        W = np.random.rand(*shape)</span><br><span class="line">        b = np.random.rand(shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> W, b</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        构造神经元，目前只执行初始化超参数的步骤</span></span><br><span class="line"><span class="string">        :param input_shape:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        W, b = self._init_hyperparameters(shape=(self.units, input_shape))</span><br><span class="line">        self.hyperparameters[<span class="string">'W'</span>] = W</span><br><span class="line">        self.hyperparameters[<span class="string">'b'</span>] = b</span><br></pre></td></tr></table></figure> 为方便起见，将大部分的函数都放入Model中，下面给出所有的代码 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> simple_neural_network.activation_function <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> simple_neural_network.cost_function <span class="keyword">import</span> *</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleNN</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, units, activation=<span class="string">'sigmoid'</span>)</span>:</span></span><br><span class="line">        self.units = units</span><br><span class="line">        self.activation = activation</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_init_hyperparameters</span><span class="params">(self, shape)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        初始化超参数，在神经网络中权重值不能初始化为0，偏差可以</span></span><br><span class="line"><span class="string">        :param shape: 神经元的形状，(units, input_shape)</span></span><br><span class="line"><span class="string">        :return: hyperparameters，该神经元的超参数。可以通过hyperparameters['W']、hyperparameters['b']取值</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 用于是演示，所以使用了随机初始化</span></span><br><span class="line">        hyperparameters = &#123;</span><br><span class="line">                <span class="string">'W'</span>: np.random.rand(*shape),</span><br><span class="line">                <span class="string">'b'</span>: np.random.rand(shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> hyperparameters</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span><span class="params">(self, input_shape)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        构造神经元，目前只执行初始化超参数的步骤</span></span><br><span class="line"><span class="string">        :param input_shape:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.hyperparameters = self._init_hyperparameters(shape=(self.units, input_shape))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Model</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># 全部的神经元，并且根据神经元数量计算神经网络架构的层数，在计算时需要减1因为输入层不算入神经网络层数</span></span><br><span class="line">        self.neurons = list()</span><br><span class="line">        <span class="comment"># 按顺序缓存A, (Z, W, b)，由于输入层不需要任何缓存，所以放入None填充此位置。方便根据索引取值</span></span><br><span class="line">        self.value_caches = [<span class="keyword">None</span>]</span><br><span class="line">        <span class="comment"># 代价函数</span></span><br><span class="line">        self.cost = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(self, neuron)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        在模型中添加神经元</span></span><br><span class="line"><span class="string">        :param neuron:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.neurons.append(neuron)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">linear_forward</span><span class="params">(self, A_prev, W, b)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        正向传播，线性运算：Z = W * A + b</span></span><br><span class="line"><span class="string">        :param A_prev: 前一层的激活值</span></span><br><span class="line"><span class="string">        :param W: 权重值</span></span><br><span class="line"><span class="string">        :param b: 偏差</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        Z: 运算结果</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        Z = np.dot(W, A_prev) + b</span><br><span class="line">        cache = A_prev, (Z, W, b)</span><br><span class="line">        self.value_caches.append(cache)</span><br><span class="line">        <span class="keyword">return</span> Z</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nonlinear_forward</span><span class="params">(self, A_prev, W, b, activation)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        进入激活函数进行非线性计算</span></span><br><span class="line"><span class="string">        :param A_prev:</span></span><br><span class="line"><span class="string">        :param W:</span></span><br><span class="line"><span class="string">        :param b:</span></span><br><span class="line"><span class="string">        :param activation:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        Z = self.linear_forward(A_prev, W, b)</span><br><span class="line">        <span class="keyword">if</span> activation == <span class="string">'sigmoid'</span>:</span><br><span class="line">            <span class="keyword">return</span> sigmoid(Z)</span><br><span class="line">        <span class="keyword">elif</span> activation == <span class="string">'relu'</span>:</span><br><span class="line">            <span class="keyword">return</span> relu(Z)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deep_forward</span><span class="params">(self, X)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param X: 输入值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        A: 最后一层的运算结果，也就是输出层的激活值</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 计算神经网络层数，减1是为了去掉输入层，众所周知输入层不需要进行计算</span></span><br><span class="line">        L = len(self.neurons) - <span class="number">1</span></span><br><span class="line">        A = X</span><br><span class="line">        <span class="comment"># 循环整个神经网络，进行正向传播，从1开始，因为索引0是输入层</span></span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">1</span>, L + <span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 根据索引获取神经元实例</span></span><br><span class="line">            neuron = self.neurons[l]</span><br><span class="line">            A_prev = A</span><br><span class="line">            W = neuron.hyperparameters[<span class="string">'W'</span>]</span><br><span class="line">            b = neuron.hyperparameters[<span class="string">'b'</span>]</span><br><span class="line">            A = self.nonlinear_forward(A_prev, W, b, neuron.activation)</span><br><span class="line">        <span class="keyword">return</span> A</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compile</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, X, Y, epochs=<span class="number">1</span>)</span>:</span></span><br><span class="line">        <span class="comment"># 将输入层的神经元添加进去</span></span><br><span class="line">        self.neurons.insert(<span class="number">0</span>, SimpleNN(len(X)))</span><br><span class="line">        <span class="comment"># 初始化神经元的超参数</span></span><br><span class="line">        <span class="keyword">for</span> i, n <span class="keyword">in</span> enumerate(self.neurons[<span class="number">1</span>:]):</span><br><span class="line">            input_shape = self.neurons[i].units</span><br><span class="line">            n.build(input_shape)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始反向传播</span></span><br><span class="line">        AL = self.deep_forward(X)</span><br></pre></td></tr></table></figure> 激活函数 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-z))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(z)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> z * (z &gt; <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu_backward</span><span class="params">(dA, Z)</span>:</span></span><br><span class="line">    dZ = np.array(dA, copy=<span class="keyword">True</span>)  <span class="comment"># just converting dz to a correct object.</span></span><br><span class="line"></span><br><span class="line">    dZ[Z &lt;= <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> dZ</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_backward</span><span class="params">(dA, Z)</span>:</span></span><br><span class="line">    s = sigmoid(Z)</span><br><span class="line">    <span class="keyword">return</span> dA * s * (<span class="number">1</span> - s)</span><br></pre></td></tr></table></figure> 测试一下 <figure class="highlight makefile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 输入值的大小</span></span><br><span class="line">input_size = 2</span><br><span class="line"><span class="comment"># 输出值的大小</span></span><br><span class="line">output_size = 2</span><br><span class="line"><span class="comment"># 方便书写，截断小数</span></span><br><span class="line">X0 = np.round(np.random.rand(input_size, 1), 2)</span><br><span class="line">Y0 = np.round(np.random.rand(output_size, 1),2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 该模型为2 3 2架构</span></span><br><span class="line">model = Model()</span><br><span class="line">model.add(SimpleNN(3))</span><br><span class="line">model.add(SimpleNN(output_size))</span><br><span class="line">model.compile()</span><br><span class="line">model.fit(X0, Y0)</span><br><span class="line">print(model.value_caches[0])</span><br></pre></td></tr></table></figure></p>
<h1 id="反向传播">反向传播</h1>
<div class="note primary"><p>说是说反向传播，实际上整个流程就是在<strong><a href="https://baike.baidu.com/item/链式法则/3314017?fr=aladdin" target="_blank" rel="noopener">链式求导</a></strong>。如果把这点想通了，整个神经网络的难点就只在向量化上了。一定要理解为什么整个流程只是在做链式求导的问题，在这里我并不是随便一提。</p>
</div>
<p>为了便于查找，把之前的图再放这。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/带参数的前馈神经网络模版.svg" alt="带参数的前馈神经网络模版" /></p>
<h2 id="首先更新输出层的权重值w以及偏差值b">首先更新输出层的权重值（W）以及偏差值（b）</h2>
<p>梯度下降公式大家应该都知道：<span class="math inline">\(W = W - \alpha * grad\)</span>。其中的grad实际上就是W的导数，<a href="https://yan624.github.io/·zcy/AI/ml/梯度下降算法的推导.html">参考</a>。 可以对照上图观察，<strong>输出层</strong>的权重值分别为: <span class="math display">\[
\begin{pmatrix}
    w^2_{11}&amp;w^2_{12}&amp;w^2_{13}\\
    w^2_{21}&amp;w^2_{22}&amp;w^2_{23}\\
\end{pmatrix}
\]</span> 所以我们需要分别求： <span class="math display">\[
\begin{pmatrix}
    \frac{\partial J}{\partial w^2_{11}} &amp; \frac{\partial J}{\partial w^2_{12}} &amp; \frac{\partial J}{\partial w^2_{13}}\\
    \frac{\partial J}{\partial w^2_{21}} &amp; \frac{\partial J}{\partial w^2_{22}} &amp; \frac{\partial J}{\partial w^2_{23}}\\
\end{pmatrix} \tag{3.1.1}\label{3.1.1}
\]</span></p>
<h3 id="求矩阵中第一个w的导数并更新w">求矩阵中第一个w的导数并更新w</h3>
<p>先求<span class="math inline">\(\frac{\partial J}{w^2_{11}}\)</span>，我们知道这个神经网络的代价的表达式是 <span class="math display">\[
J = -[(y_1 * \log(a^2_1) + (1 - y_1) * \log(1 - a^2_1) + (y_2 * \log(a^2_2) + (1 - y_2) * \log(1 - a^2_2)]
\]</span> <strong>为了方便对照我将隐藏层到输出层的正向传播的步骤</strong>也写在下面： <span class="math display">\[
\begin{align}
    z^2_1 &amp; = w^2_{11} * a^1_1 + w^2_{12} * a^1_2 + w^2_{13} * a^1_3 + b^2_1\\
    z^2_2 &amp; = w^2_{21} * a^1_1 + w^2_{22} * a^1_2 + w^2_{13} * a^1_3 + b^2_2\\
    a^2_1 &amp; = \sigma{(z^2_1)} = \frac{1}{1 - e^{-z^2_1}}\\
    a^2_2 &amp; = \sigma{(z^2_2)} = \frac{1}{1 - e^{-z^2_2}}\\
\end{align}
\]</span> 根据链式求导法则得： <span class="math display">\[
\frac{\partial J}{\partial w^2_{11}} = \frac{\partial J}{\partial a^2_1} * \frac{\partial a^2_1}{\partial z^2_1} * \frac{\partial z^2_1}{\partial w^2_{11}} 
\]</span> 我们将其拆解，一步一步地求： <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial a^2_1} &amp; = -[(\frac{y_1}{a^2_1} + \frac{1 - y_1}{a^2_1 - 1}) + 0] &amp; \text{首先对a求导，此步如果你不会微积分会有疑惑} \tag{3.1.2}\label{3.1.2}\\
    \frac{\partial a^2_1}{\partial z^2_1} &amp; = (a^2_1) * (1 - a^2_1) &amp; \text{这是对sigmoid函数的求导，百度一下求导过程}\\
    \frac{\partial J}{\partial z^2_1} &amp; = \frac{\partial J}{\partial a^2_1} * \frac{\partial a^2_1}{\partial z^2_1} &amp; \text{其次对z求导}\\
                                      &amp; = \frac{\partial J}{\partial a^2_1} * (a^2_1) * (1 - a^2_1) \tag{3.1.3}\label{3.1.3}\\
    \frac{\partial z^2_1}{\partial w^2_{11}} &amp; = a^1_1\\
    \frac{\partial J}{\partial w^2_{11}} &amp; = \frac{\partial J}{\partial z^2_1} * \frac{\partial z^2_1}{\partial w^2_{11}} &amp; \text{最后对w求导} \tag{3.1.4}\label{3.1.4}\\
                                         &amp; = \frac{\partial J}{\partial z^2_1} * a^1_1\\
    \frac{\partial J}{\partial w^2_{11}} &amp; = -[(\frac{y_1}{a^2_1} + \frac{1 - y_1}{a^2_1 - 1}) + 0] * (a^2_1) * (1 - a^2_1) * a^1_1 &amp; \text{整合在一起}\\
\end{align}
\]</span> 其中<span class="math inline">\([(\frac{y_1}{a^2_1} + \frac{1 - y_1}{a^2_1 - 1}) + 0] * (a^2_1) * (1 - a^2_1)\)</span>实际上是可以化简的，化简为<span class="math inline">\(a^2_1 - y_1\)</span>，同时去掉了负号，所以 <span class="math display">\[
\frac{\partial J}{\partial w^2_{11}} = (a^2_1 - y_1) * a^1_1
\]</span> 我们将数值带入其中，之前的正向传播已经得到了所有激活值。 <span class="math inline">\(\frac{\partial J}{\partial w^2_{11}} = (0.85220348 - 0.60) * 0.81604509 = 0.20580941153491322\)</span> 对<span class="math inline">\(w^2_{11}\)</span>更新， <span class="math display">\[
w^2_{11} = w^2_{11} - \alpha * \frac{\partial J}{\partial w^2_{11}}
\]</span> 学习速率<span class="math inline">\(\alpha\)</span>选1，经过简单的运算，<span class="math inline">\(w^2_{11} = 0.92559664 - 1 * 0.20580941153491322 = 0.7197872284650868\)</span> <div class="note info"><p>如果细心点就会发现，<span class="math inline">\(\frac{\partial J}{\partial w^2_{11}}\)</span>其实就等于这层的z的导数乘上前一层的激活值a。如果没发现也没关系，下面<a href="https://yan624.github.io/前馈神经网络的正反向推导.html#向量化-1">向量化</a>这节会做一个总结。</p>
</div></p>
<h3 id="求所有w的导数">求所有w的导数</h3>
<p>同理可以求出所有的导数 <span class="math display">\[
\begin{pmatrix}
    \frac{\partial J}{\partial w^2_{11}} &amp; \frac{\partial J}{\partial w^2_{12}} &amp; \frac{\partial J}{\partial w^2_{13}}\\
    \frac{\partial J}{\partial w^2_{21}} &amp; \frac{\partial J}{\partial w^2_{22}} &amp; \frac{\partial J}{\partial w^2_{23}}\\
\end{pmatrix} \tag{\ref{3.1.1}}
\]</span></p>
<h3 id="向量化-1">向量化</h3>
<div class="note danger"><p>上面只求了一个w的导数，虽然其他的w的求导都是类似操作，但是真要算起来，对于自己没去算过的人，可能花一天都没有办法将其用<strong>向量化表示</strong>。 求导是十分简单的，但是向量化可能会有点问题。问题的主要来源是<strong>想偷懒</strong>。对于这种问题，最好得到解决办法是暴力破解，即求出所有的w的导数，然后再将其向量化。</p>
</div>
<p>首先观察上述公式<span class="math inline">\(\ref{3.1.4}\)</span>： <span class="math display">\[
\frac{\partial J}{\partial w^2_{11}} = \frac{\partial J}{\partial z^2_1} * \frac{\partial z^2_1}{\partial w^2_{11}}
\]</span> 它由两部分组成，一个是<span class="math inline">\(\frac{\partial J}{\partial z^2_1}\)</span>，第二部分是<span class="math inline">\(\frac{\partial z^2_1}{\partial w^2_{11}}\)</span>，如果你自己求过导就会发现其实<span class="math inline">\(\frac{\partial z^2_1}{\partial w^2_{11}} = a^1_1\)</span>。为了方便你们观察，我列出所有式子： <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial w^2_{11}} = \frac{\partial J}{\partial z^2_1} * a^1_1 \quad \frac{\partial J}{\partial w^2_{12}} = \frac{\partial J}{\partial z^2_1} * a^1_2 \quad \frac{\partial J}{\partial w^2_{13}} = \frac{\partial J}{\partial z^2_1} * a^1_3\\
    \frac{\partial J}{\partial w^2_{21}} = \frac{\partial J}{\partial z^2_2} * a^1_1 \quad \frac{\partial J}{\partial w^2_{22}} = \frac{\partial J}{\partial z^2_2} * a^1_2 \quad \frac{\partial J}{\partial w^2_{23}} = \frac{\partial J}{\partial z^2_2} * a^1_3\\
\end{align}
\]</span> <strong>可能到这你有点烦躁了，因为表达式实在太多了。没关系，下方蓝色的note会给出总结，直接一步求解完毕。</strong> 有没有发现，里面有一半是重复的元素？我们可以将它们组成向量得到： <span class="math display">\[
\eqref{3.1.1}
\begin{pmatrix}
    \frac{\partial J}{\partial w^2_{11}} &amp; \frac{\partial J}{\partial w^2_{12}} &amp; \frac{\partial J}{\partial w^2_{13}}\\
    \frac{\partial J}{\partial w^2_{21}} &amp; \frac{\partial J}{\partial w^2_{22}} &amp; \frac{\partial J}{\partial w^2_{23}}\\
\end{pmatrix} = 
\begin{pmatrix}
\frac{\partial J}{\partial z^2_1}\\
\frac{\partial J}{\partial z^2_2}\\
\end{pmatrix} * 
\begin{pmatrix}
a^1_1 &amp; a^1_2 &amp; a^1_3
\end{pmatrix} \tag{3.1.5}
\]</span> 公式3.1.5和上面那六个表达式实际上计算的东西是一样的。进一步缩写为 <span class="math display">\[
\frac{\partial J}{\partial w^2} = \frac{\partial J}{\partial z^2} * (a^1)^T \tag{3.1.6}
\]</span> 这里加了一个T代表转置，实际上我们所有的输入值，激活值，输出值都是列向量。 <div class="note info"><p>总结一下，在这里<strong>求<span class="math inline">\(\frac{\partial J}{\partial w}\)</span>的步骤为：求权重值所在层的z的导数<span class="math inline">\(\frac{\partial J}{\partial z}\)</span>再乘上前一层的激活值</strong>。这是对一个w求导所做的运算，而对一整个W矩阵求导那就是公式3.1.6的那个向量化操作。但是观察公式3.1.6发现，其实求一个w和求一个W矩阵并无区别，无非是将数字相乘改为向量（矩阵）相乘。 另外，其实这对神经网络中每一层的操作都是一样。如果不信可以自己算一下。所以以后理解的时候，可以用这种方式理解，加快理解速度。</p>
</div></p>
<h3 id="更新偏差">更新偏差</h3>
<p>偏差比权重简单很多。 <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial a^2_1} &amp; = -[(\frac{y_1}{a^2_1} + \frac{1 - y_1}{a^2_1 - 1}) + 0] \tag{\ref{3.1.2}}\\
    \frac{\partial J}{\partial z^2_1} &amp; = \frac{\partial J}{\partial a^2_1} * \frac{\partial a^2_1}{\partial z^2_1}\\
                                      &amp; = \frac{\partial J}{\partial a^2_1} * (a^2_1) * (1 - a^2_1) \tag{\ref{3.1.3}}\\
    \frac{\partial J}{\partial b^2_1} &amp; = \frac{\partial J}{\partial z^2_1} * \frac{\partial z^2_1}{\partial b^2_1} \\
                                      &amp; = \frac{\partial J}{\partial z^2_1}\\
    \frac{\partial J}{\partial b^2_1} &amp; = -[(\frac{y_1}{a^2_1} + \frac{1 - y_1}{a^2_1 - 1}) + 0] * (a^2_1) * (1 - a^2_1)\\
\end{align}
\]</span> 可以看到 <span class="math display">\[
\frac{\partial J}{\partial b^2_1} = \frac{\partial J}{\partial z^2_1}
\]</span> 所以偏差的向量化比较简单： <span class="math display">\[
\begin{pmatrix}
    \frac{\partial J}{\partial b^2_1}\\
    \frac{\partial J}{\partial b^2_2}\\
\end{pmatrix} = 
\begin{pmatrix}
    \frac{\partial J}{\partial z^2_1}\\
    \frac{\partial J}{\partial z^2_2}\\
\end{pmatrix}
\]</span> ### 整理 整理一下上一波的求导过程。目标是求得<span class="math inline">\(\frac{\partial J}{w^2_{11}}\)</span>，但是上面我并没有一步求导到底，相反我将每一步都写出来了，这是有原因的。因为<span class="math inline">\(\frac{\partial J}{\partial z^2_1}\)</span>会在前一层对w求导时使用，所以在代码上当然需要保存副本。而<span class="math inline">\(\frac{\partial J}{w^2_{11}}\)</span>已经在这次的反向传播中使用过了，它的价值也算是用完了。 在<a href="https://yan624.github.io/前馈神经网络的正反向推导.html#首先更新输出层的权重值（W）以及偏差值（b）">首先更新输出层的权重值（W）以及偏差值（b）</a>中<strong>略有瑕疵</strong>的步骤（也就是上述所有步骤）是：</p>
<ol type="1">
<li>求出<span class="math inline">\(\frac{\partial J}{\partial a^2}\)</span></li>
<li>进一步求出<span class="math inline">\(\frac{\partial J}{\partial z^2}\)</span></li>
<li>分别求出<span class="math inline">\(\frac{\partial J}{\partial w^2}\ \frac{\partial J}{\partial b^2}\)</span></li>
</ol>
<div class="note info"><p>根据上面三步，我们可以观察出，如果需要求出一层的<span class="math inline">\(\frac{\partial J}{\partial w^2}\ \frac{\partial J}{\partial b^2}\)</span>（<strong>步骤3</strong>），需要<strong>先</strong>求出<strong>同一层</strong>的<span class="math inline">\(\frac{\partial J}{\partial a^2}\ \frac{\partial J}{\partial z^2}\)</span>（<strong>步骤1和2</strong>）。<strong><em>所以</em></strong>如果我们需要求出<strong>前一层</strong>的<span class="math inline">\(\frac{\partial J}{\partial w^1}\ \frac{\partial J}{\partial b^1}\)</span>，必须先求出<strong>前一层</strong>的a的导数<span class="math inline">\(\frac{\partial J}{\partial a^1}\ \frac{\partial J}{\partial z^1}\)</span>，而由于公式<span class="math inline">\(z^2_1 = w^2_{11} * a^1_1 + w^2_{12} * a^1_2 + w^2_{13} * a^1_3 + b^2_1\)</span>，可以观察到上述<strong>步骤2</strong>对z求导之后其实拥有三个选项： 1. 求w的导数（<strong>步骤3</strong>） 2. 求b的导数（<strong>步骤3</strong>） 3. 求上一层a的导数</p>
</div>
<p>所以正确的步骤是： 1. 求出<span class="math inline">\(\frac{\partial J}{\partial a^2}\)</span>（<strong>不变</strong>） 2. 进一步求出<span class="math inline">\(\frac{\partial J}{\partial z^2}\)</span>（<strong>不变</strong>） 3. 分别求出<span class="math inline">\(\frac{\partial J}{\partial w^2}\ \frac{\partial J}{\partial b^2}\)</span>（<strong>不变</strong>） 4. 最后求出前一层的<span class="math inline">\(\frac{\partial J}{\partial a^1}\)</span>，准备下一步的计算。</p>
<p><strong>也就是说，我们在一层中进行求导，需要分别求4个参数的导数，即当前层的a，w，b以及前一层的a的导数。</strong></p>
<h2 id="更新隐藏层的权重值以及偏差值">更新隐藏层的权重值以及偏差值</h2>
<p>由于上述步骤太多，来回滑动网页略繁琐，我再次把图放出来，以供参考。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/带参数的前馈神经网络模版.svg" alt="带参数的前馈神经网络模版" /> 隐藏层的更新与输出层略微不同，由于看公式不太形象，可以看上面的图。观察发现，隐藏层的某一个神经元链接着输出层的<strong>所有</strong>神经元。所以隐藏层的神经元的误差其实来源于与它相连接的输出层的神经元。 根据链式求导法则，我们知道：一个函数对一个变量求导，如果有多条路径可以到达该变量，那么就需要对每条路径都求导，最后将结果相加。转换成数学公式就跟下面公式3.2.1的求导过程一样。</p>
<h3 id="对第一个w求导">对第一个w求导</h3>
<p>我们按照上一节<a href="https://yan624.github.io/前馈神经网络的正反向推导.html#整理">《整理》</a>的四个步骤来做，先求出a的导数： <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial a^1_1} &amp; = \frac{\partial J}{\partial a^2_1} * \frac{\partial a^2_1}{\partial a^1_1} + \frac{\partial J}{\partial a^2_2} * \frac{\partial a^2_2}{\partial a^1_1} &amp; \text{输出层两个神经元均要求导再相加}\\
                                      &amp; = \frac{\partial J}{\partial z^2_1} * \frac{\partial z^2_1}{\partial a^1_1} + \frac{\partial J}{\partial z^2_2} * \frac{\partial z^2_1}{\partial a^1_1} &amp; \text{之前求过z的导数，为了方便书写用它替换}\\
                                      &amp; = \frac{\partial J}{\partial z^2_1} * w^2_{11} + \frac{\partial J}{\partial z^2_2} * w^2_{21} \tag{3.2.1}\label{3.2.1}\\
\end{align}
\]</span> <div class="note info"><p>我们可以观察到隐藏层的a的导数<span class="math inline">\(\frac{\partial J}{\partial a^1_1}\)</span>实际上就是<strong>输出层</strong>的z的导数<span class="math inline">\(\frac{\partial J}{\partial z^2_1}\)</span>乘上与之相连的<strong>输出层</strong>的神经元的w。 一般化之后就是：<strong>除了输出层</strong>，其他所有层的<strong>a的导数</strong>都是<strong>后一层</strong>的<strong>z的导数</strong>乘上<strong>后一层</strong>的w。因为输出层的<strong>a的导数</strong>是通过代价函数求的。</p>
</div> 所以下一步就是求z的导数： <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial z^1_1} &amp; = \frac{\partial J}{\partial z^2_1} * \frac{\partial z^2_1}{\partial a^1_1} * \frac{\partial a^1_1}{\partial z^1_1} + \frac{\partial J}{\partial z^2_2} * \frac{\partial z^2_1}{\partial a^1_1} * \frac{\partial a^1_1}{\partial z^1_1}\\
                                      &amp; = \frac{\partial J}{\partial z^2_1} * w^2_{11} * \frac{\partial a^1_1}{\partial z^1_1}  + \frac{\partial J}{\partial z^2_2} * w^2_{21} * \frac{\partial a^1_1}{\partial z^1_1}\\
                                      &amp; = \frac{\partial J}{\partial a^1_1} * \frac{\partial a^1_1}{\partial z^1_1} &amp; \text{这里a的导数参考}\ref{3.2.1}\\
    \frac{\partial a^1_1}{\partial z^1_1} &amp; = a^1_1 * (1 - a^1_1) &amp; \text{对sigmoid函数求导，前面已经说过了}\\
\end{align}
\]</span> 最后求出w的导数 <span class="math display">\[
\begin{align}
    \frac{\partial J}{\partial w^1_{11}} &amp; = \frac{\partial J}{\partial a^1_1} * \frac{\partial a^1_1}{\partial z^1_1} * \frac{\partial z^1_1}{\partial w^1_{11}}\\
                                         &amp; = \frac{\partial J}{\partial z^1_1} * \frac{\partial z^1_1}{\partial w^1_{11}}\\
                                         &amp; = \frac{\partial J}{\partial z^1_1} * a^0_1
\end{align}
\]</span></p>
<h3 id="向量化-2">向量化</h3>
<p>你肯定已经想把它向量化了。先列出所有的表达式。 <span class="math display">\[
\frac{\partial J}{\partial w^1_{11}} = \frac{\partial J}{\partial z^1_1} * a^0_1\\
\frac{\partial J}{\partial w^1_{12}} = \frac{\partial J}{\partial z^1_1} * a^0_2\\
\frac{\partial J}{\partial w^1_{21}} = \frac{\partial J}{\partial z^1_2} * a^0_1\\
\frac{\partial J}{\partial w^1_{22}} = \frac{\partial J}{\partial z^1_2} * a^0_2\\
\frac{\partial J}{\partial w^1_{31}} = \frac{\partial J}{\partial z^1_3} * a^0_1\\
\frac{\partial J}{\partial w^1_{32}} = \frac{\partial J}{\partial z^1_3} * a^0_2\\
\]</span> 可以发现这其实跟上面的向量化步骤一模一样： <span class="math display">\[
\begin{align}
    \begin{pmatrix}
        \frac{\partial J}{\partial w^1_{11}} &amp; \frac{\partial J}{\partial w^1_{12}}\\
        \frac{\partial J}{\partial w^1_{21}} &amp; \frac{\partial J}{\partial w^1_{22}}\\
        \frac{\partial J}{\partial w^1_{31}} &amp; \frac{\partial J}{\partial w^1_{32}}\\
    \end{pmatrix} &amp; = 
    \begin{pmatrix}
        \frac{\partial J}{\partial z^1_1}\\
        \frac{\partial J}{\partial z^1_2}\\
        \frac{\partial J}{\partial z^1_3}\\
    \end{pmatrix} * 
    \begin{pmatrix}
        a^0_1 &amp; a^0_2
    \end{pmatrix} \\
    \frac{\partial J}{\partial w^1} &amp; = \frac{\partial J}{\partial z^1} * (a^0)^T
\end{align}
\]</span></p>
<h3 id="对偏差求导">对偏差求导</h3>
<p>这一步更是简单，直接给结果了。 <span class="math display">\[
\begin{align}
    \begin{pmatrix}
        \frac{\partial J}{\partial b^1_1}\\
        \frac{\partial J}{\partial b^1_2}\\
        \frac{\partial J}{\partial b^1_3}\\
    \end{pmatrix} &amp; = 
    \begin{pmatrix}
        \frac{\partial J}{\partial z^1_1}\\
        \frac{\partial J}{\partial z^1_2}\\
        \frac{\partial J}{\partial z^1_3}\\
    \end{pmatrix}\\
    \frac{\partial J}{\partial b^1} &amp; = \frac{\partial J}{\partial z^1}
\end{align}
\]</span></p>
<h3 id="注意点">注意点</h3>
<p>上述步骤看起来没什么问题，但是在实际编程中会有很大问题。在向量化的时候，我直接使用了<span class="math inline">\(\frac{\partial J}{\partial z^1}\)</span>，但是问题就是<span class="math inline">\(\frac{\partial J}{\partial z^1}\)</span>的向量化我直接跳过了。要向量化<span class="math inline">\(\frac{\partial J}{\partial z^1}\)</span>，实际上得先向量化<span class="math inline">\(\frac{\partial J}{\partial a^1}\)</span>。观察表达式<span class="math inline">\(\ref{3.2.1}\)</span>，先给出所有的式子： <span class="math display">\[
\frac{\partial J}{\partial a^1_1} = \frac{\partial J}{\partial z^2_1} * w^2_{11} + \frac{\partial J}{\partial z^2_2} * w^2_{21}\\
\frac{\partial J}{\partial a^1_2} = \frac{\partial J}{\partial z^2_1} * w^2_{12} + \frac{\partial J}{\partial z^2_2} * w^2_{22}\\
\frac{\partial J}{\partial a^1_3} = \frac{\partial J}{\partial z^2_1} * w^2_{13} + \frac{\partial J}{\partial z^2_2} * w^2_{23}\\
\]</span></p>
<h4 id="向量化-3">向量化</h4>
<p><span class="math display">\[
\begin{pmatrix}
    \frac{\partial J}{\partial a^1_1}\\
    \frac{\partial J}{\partial a^1_2}\\
    \frac{\partial J}{\partial a^1_3}\\
\end{pmatrix} = 
\begin{pmatrix}
w^2_{11} &amp; w^2_{12} &amp; w^2_{13}\\
w^2_{21} &amp; w^2_{22} &amp; w^2_{23}\\
\end{pmatrix}^T * 
\begin{pmatrix}
\frac{\partial J}{\partial z^2_1} &amp; \frac{\partial J}{\partial z^2_2}
\end{pmatrix}
\]</span></p>
<h1 id="总结">总结</h1>
<p>在反向传播中，每一层都只需要重复如下几步：</p>
<ol type="1">
<li>求出<span class="math inline">\(\frac{\partial J}{\partial a^2}\)</span></li>
<li>进一步求出<span class="math inline">\(\frac{\partial J}{\partial z^2}\)</span></li>
<li>分别求出<span class="math inline">\(\frac{\partial J}{\partial w^2}\ \frac{\partial J}{\partial b^2}\)</span></li>
<li>最后求出前一层的<span class="math inline">\(\frac{\partial J}{\partial a^1}\)</span>，准备下一步的计算。此步骤的向量化操作在<a href="https://yan624.github.io/前馈神经网络的正反向推导.html#注意点">注意点</a>。</li>
</ol>
<h1 id="代码">代码</h1>
<p><a href="https://github.com/yan624/machine_learning_algorithms/tree/master/simple_neural_network" target="_blank" rel="noopener">使用numpy实现一个简单的神经网络</a></p>
<h1 id="注意事项">注意事项</h1>
<p>在做反向传播代码时，验算了很多遍，发现公式推导没有问题，但是梯度却一直在上升，心态都炸了。 最后发现，用了大半年的crossentropy在最前面居然要加上一个“-”号。以前由于是偷懒，在求导的时候一般不加负号，在求完导之后再补上。然后由于写习惯了，导致我忘记crossentropy居然是有负号的。</p>
<h1 id="撒花">撒花</h1>
<p>在第二节有一步是初始化数据，但是全篇都没用几个地方用到。是因为数据测试起来太麻烦了，我需要在代码里一步一步分析神经网络的计算过程，从而获得数据。以后再补充吧。</p>
<!-- more -->
]]></content>
      <categories>
        <category>AI</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>系列</tag>
        <tag>simple NN</tag>
        <tag>深度学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>linux非root用户配置环境变量</title>
    <url>/posts/f2ef4f4c.html</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/gstblog/p/10160976.html" target="_blank" rel="noopener">参考文章</a> 本文以配置anaconda的环境变量为例。</p>
<p>切换到用户目录 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br></pre></td></tr></table></figure> 输入，发现有一个名为<code>.bashrc</code>的文件 <figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">ll</span></span><br></pre></td></tr></table></figure> 编辑它 <figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">vim ~<span class="string">/.bashrc</span></span><br></pre></td></tr></table></figure> 在最后一行加上如下代码，保存并退出。 <figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=~/anaconda3/bin:$PATH</span><br></pre></td></tr></table></figure> <div class="note warning"><p>PATH和=之间不能有空格。由于写java代码习惯了，加上了空格，导致报错。</p>
</div> 更新配置 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure> <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>梯度下降算法的推导</title>
    <url>/posts/c8ddbafb.html</url>
    <content><![CDATA[<div class="note info"><p>2020.09.07更新：<a href="https://www.bilibili.com/video/BV13x411v7US?p=6" target="_blank" rel="noopener">42:50</a>，突然发现这个视频又讲梯度下降的底层理论，可以去看看。</p>
</div>
<p>梯度下降算法大家都知道，公式是<span class="math inline">\(\theta = \theta - \alpha * J&#39;(\theta)\)</span>，其中J是代价函数。但是这个算法具体是怎么来的，可能不太清楚。 本文参考 <a href="https://mp.weixin.qq.com/s/k26Fm0GL3fdVA9VbQIVAuQ" target="_blank" rel="noopener">微信公众号</a> <a href="https://baike.baidu.com/item/梯度/13014729" target="_blank" rel="noopener">梯度-百度百科</a> 由于没有专业的制图工具，所以只能手画了。。。</p>
<h1 id="梯度下降问题">梯度下降问题</h1>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/梯度下降算法的推导/梯度下降草图.jpg" alt="梯度下降草图" /><figcaption>梯度下降草图</figcaption>
</figure>
<p>由图中可以观察到，我们将参数初始化到A点，我们的目标是将点移动到最小值点（或者极小值点）。那么问题就是如何移动了。 先给出梯度下降公式：<span class="math inline">\(\theta = \theta - \alpha * J&#39;(\theta)\)</span>，J是代价函数，这个公式应该不陌生。</p>
<h1 id="一阶泰勒展开式">一阶泰勒展开式</h1>
<p>如果学过高数，应该知道<strong>一阶泰勒展开式</strong>的公式是：<span class="math inline">\(f(x) = f(x_0) + (x - x_0) * f&#39;(x_0) + R_n(x)\)</span>，其中<span class="math inline">\(R_n(x)\)</span>是泰勒公式的余项，可以理解为一个无穷小量。既然是无穷小量那么便可以省略不写，但是即使是无穷小，其实等式的左右边还是有点差距的，所以将等式修改为<strong>约等于号</strong>。 <a id="more"></a> <span class="math display">\[
f(x) \approx f(x_0) + (x - x_0) * f&#39;(x_0)
\]</span> 但是由于我们最小化的代价函数的参数是<span class="math inline">\(\theta\)</span>，所以我们可以将x替换为<span class="math inline">\(\theta\)</span>，即 <span class="math display">\[
f(\theta) \approx f(\theta_0) + (\theta - \theta_0) * f&#39;(\theta_0)
\]</span> 如果不知道泰勒公式，可以看下图 <embed src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/梯度下降算法的推导/泰勒公式线性近似.webp" /></p>
<p>在点<span class="math inline">\(\theta_0\)</span>处，找一条极短的直线来表示曲线，则直线的斜率为<span class="math inline">\(f&#39;(\theta_0)\)</span>，并且已知<span class="math inline">\(\theta_0\)</span>，那么根据初中数学，可以获得直线公式<span class="math inline">\(f(\theta) = f(\theta_0) + (\theta - \theta_0) * f&#39;(\theta_0)\)</span>（还不懂看这个：<span class="math inline">\(y-y_0=k(x-x_0)\)</span>===&gt;<span class="math inline">\(y = y_0 + k(x-x_0)\)</span>）。 <div class="note warning"><p>如果仔细看到了上一行的推导，你也许要问：为什么直线斜率是<span class="math inline">\(f&#39;(\theta_0)\)</span>。百度。</p>
</div></p>
<div class="note warning"><p>如果对上式没有问题，可能要问为什么这个红线的箭头要向下，不能向上？我有强迫症，我就要让它向上，并且我还要让<span class="math inline">\(\theta\)</span>在<span class="math inline">\(\theta_0\)</span>右边。这个下面会讲，但是现在假定以下的步骤均围绕上图展开。</p>
</div>
<p>至此准备工作完成。</p>
<h1 id="数学原理">数学原理</h1>
<p>我们将 <span class="math inline">\(f(\theta) \approx f(\theta_0) + (\theta - \theta_0) * f&#39;(\theta_0)\)</span> 的 <span class="math inline">\(\theta - \theta_0\)</span> 是一个微小矢量，用字母 <span class="math inline">\(\alpha v\)</span> 代替。其中标量 <span class="math inline">\(\alpha\)</span> 代表步长，<span class="math inline">\(\theta - \theta_0\)</span> 的<strong>单位向量</strong>用 v 表示。其实 <span class="math inline">\(\alpha v\)</span> 可以合并成 <span class="math inline">\(\alpha\)</span> 的，但是为了下面的推导更容易说明梯度下降到底在做什么，还是拆开来表示。 <span class="math display">\[
\theta - \theta_0 = \alpha v
\]</span> 所以公式被简化为如下形式，并且将导数的表示做一下改变，用<strong>倒三角</strong>表示 <span class="math display">\[
f(\theta) \approx f(\theta_0) + \alpha v * \nabla f(\theta_0)
\]</span> 由于我们的目标是使得<span class="math inline">\(f(\theta)\)</span>比<span class="math inline">\(f(\theta_0)\)</span>小，也就是使得<span class="math inline">\(f(\theta) - f(\theta_0) &lt; 0\)</span>。那么将公式转变为 <span class="math display">\[
f(\theta) -  f(\theta_0) \approx \alpha v * \nabla f(\theta_0) &lt; 0
\]</span> 省略一部分 <span class="math display">\[
\alpha v * \nabla f(\theta_0) &lt; 0
\]</span> 由于<span class="math inline">\(\alpha\)</span>一般为正值，所以 <span class="math display">\[
v * \nabla f(\theta_0) &lt; 0
\]</span> 由于<span class="math inline">\(v\)</span>和<span class="math inline">\(\nabla f(\theta_0)\)</span>实际上都是向量。所以上式就转换为<strong>两个向量相乘在什么时候是小于0的</strong>，并且我们希望<span class="math inline">\(f(\theta) - f(\theta_0)\)</span>越小越好（注意这里的<strong>小</strong>指的是小于 0 的尺度上，并非在 0~1 的尺度上），也就是<span class="math inline">\(v * \nabla f(\theta_0)\)</span>越小越好。那么问题又转化为<strong>两个向量相乘在什么时候是最小的</strong>。 <div class="note warning"><p>问题1：为什么<span class="math inline">\(v\)</span>和<span class="math inline">\(\nabla f(\theta_0)\)</span>是向量。 以上都是使用二维的图来描述，但是实际上 <span class="math inline">\(\theta\)</span> 不只有一个，所以是向量而不是一个数。 问题2：为什么希望<span class="math inline">\(f(\theta) - f(\theta_0)\)</span>越小越好。 因为希望<span class="math inline">\(f(\theta)\)</span>这一步迈远一点。</p>
</div></p>
<p>以下为向量乘积的三种形式，由初中的知识可以得知，当向量相反时<span class="math inline">\(cos(\alpha)\)</span>为-1，即cos函数的最小值。 <embed src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/梯度下降算法的推导/向量的乘积.webp" /></p>
<p>由于公式可以转为如下，其中<span class="math inline">\(\beta\)</span>是向量夹角 <span class="math display">\[
|v| * |\nabla f(\theta_0)| * cos(\beta) &lt; 0
\]</span> 所以当 <span class="math inline">\(v\)</span> 和 <span class="math inline">\(\nabla f(\theta_0)\)</span> 正好相反时，<span class="math inline">\(cos(\beta) = -1\)</span>。也就是说当 <span class="math inline">\(v\)</span> 和 <span class="math inline">\(\nabla f(\theta_0)\)</span> 反向，<span class="math inline">\(v * \nabla f(\theta_0)\)</span>最小。 所以现在的问题就是 v 怎么样才能是梯度方向的反方向？众所周知，<span class="math inline">\(\nabla f(\theta_0)\)</span> 就是梯度，也就是梯度方向。那么在 <span class="math inline">\(\nabla f(\theta_0)\)</span> 加个负号不就是相反方向了？所以 <span class="math display">\[
v  = -\frac{\nabla f(\theta_0)}{|\nabla f(\theta_0)|}\\
\]</span> 之所以要除以 <span class="math inline">\(\nabla f(\theta_0)\)</span> 的模，是因为 <span class="math inline">\(v\)</span> 是单位向量。 将 <span class="math inline">\(v\)</span> 带入到 <span class="math inline">\(\theta - \theta_0 = \alpha * v\)</span> 中 <span class="math display">\[
\theta = \theta_0 - \alpha * \frac{\nabla f(\theta_0)}{|\nabla f(\theta_0)|}
\]</span> 一般地，因为<span class="math inline">\(|\nabla f(\theta_0)|\)</span>是标量，可以并入到中，即简化为： <span class="math display">\[
\theta = \theta_0 - \alpha *\nabla f(\theta_0)
\]</span> <div class="note primary"><p>有点需要说明，我认为 <span class="math inline">\(\frac{1}{|\nabla f(\theta_0)|}\)</span> 不能并入 <span class="math inline">\(\alpha\)</span> 因为 <span class="math inline">\(\frac{1}{|\nabla f(\theta_0)|}\)</span> 是一个变量。它是梯度的模长，但是在执行梯度下降时，每一个 epoch 的梯度都是不一样的。故 <span class="math inline">\(\frac{1}{|\nabla f(\theta_0)|}\)</span> 也在每个 epoch 不中不同，但是学习率 <span class="math inline">\(\alpha\)</span> 却是一个定值，比如 0.01, 0.03, 0.1 等。</p>
</div></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>梯度下降</tag>
        <tag>bp</tag>
      </tags>
  </entry>
  <entry>
    <title>练习Keras RNN的代码</title>
    <url>/posts/ba091254.html</url>
    <content><![CDATA[<h1 id="python深度学习第6章预测imdb的影评">《Python深度学习》第6章预测imdb的影评</h1>
<p><a href="https://github.com/yan624/deep-learning-notes/tree/master/RNN_learning/imdb_predication" target="_blank" rel="noopener">imdb影评代码</a></p>
<h1 id="第五课第二周作业emojify">第五课第二周作业：Emojify</h1>
<p>本文实现吴恩达深度学习第五课第二周的Emojify作业。目的是了解一个小型nlp系统的构建流程。 首先需要导入以下模块。由于在Jupyter中打开的ipynb文件全是英文，所以本文的大部分标题也用英文，方便ctrl F。 Emojifier-V1略。</p>
<h2 id="代码">代码</h2>
<p>加了很多注释，但是代码的顺序我做了很大的改动。下面博客里面的代码，是作业里面的代码，基本没改几个字。 <a href="https://github.com/yan624/deep-learning-notes/tree/master/RNN_learning/emojify" target="_blank" rel="noopener">emojify_V2代码</a> <a id="more"></a></p>
<h2 id="emojifier-v2-using-lstms-in-keras">Emojifier-V2: Using LSTMs in Keras</h2>
<h3 id="初始化">初始化</h3>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">np<span class="selector-class">.random</span><span class="selector-class">.seed</span>(<span class="number">0</span>)</span><br><span class="line">from keras<span class="selector-class">.models</span> import Model</span><br><span class="line">from keras<span class="selector-class">.layers</span> import Dense, Input, Dropout, LSTM, Activation</span><br><span class="line">from keras<span class="selector-class">.layers</span><span class="selector-class">.embeddings</span> import Embedding</span><br><span class="line">from keras<span class="selector-class">.preprocessing</span> import sequence</span><br><span class="line">np<span class="selector-class">.random</span><span class="selector-class">.seed</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.initializers <span class="keyword">import</span> glorot_uniform</span><br></pre></td></tr></table></figure>
<h3 id="overview-of-the-model">Overview of the model</h3>
<h3 id="keras-and-mini-batching">Keras and mini-batching</h3>
<p>本练习中，我们使用mini-batch算法训练Kears。大部分深度学习框架要求在相同的mini-batch中所有序列都要等长。这使得可以执行向量化，如果你有一个3个单词的句子和一个4个单词的句子，它们之间的计算会不同（一个需要3个timestep，一个需要4个timestep，也就是说需要的LSTM个数不同），所有同时计算它们是不可能的，即无法向量化。 通用的解决办法是使用padding。具体来说，设置一个序列的最大长度，然后使其他的序列都与该长度等长。比如序列的最大长度是20，那么将其他的序列在后面补充0，知道长度等于20。所以句子“I love you”会在“you”后面被补充17个0。即<span class="math inline">\(\begin{pmatrix}e_i &amp; e_{love} &amp; e_{you} &amp; \overrightarrow{0} &amp; \overrightarrow{0} &amp; \cdots &amp; \overrightarrow{0}\end{pmatrix}\)</span>，e代表词向量。如果长度大于20的话会被裁剪。 以下代码实现将句子转换为句子中的每个单词转为索引，这个索引是GloVe词嵌入的，每一个单词对应一个id。id就是索引。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: sentences_to_indices</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将句子转为索引形式，短于max_len的句子后面补充0，长于max_len的句子直接截断</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sentences_to_indices</span><span class="params">(X, word_to_index, max_len)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.</span></span><br><span class="line"><span class="string">    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    X -- array of sentences (strings), of shape (m, 1)</span></span><br><span class="line"><span class="string">    word_to_index -- a dictionary containing the each word mapped to its index</span></span><br><span class="line"><span class="string">    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. </span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    m = X.shape[<span class="number">0</span>]                                   <span class="comment"># number of training examples</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Initialize X_indices as a numpy matrix of zeros and the correct shape</span></span><br><span class="line">    X_indices = np.zeros((m, max_len))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):                               <span class="comment"># loop over training examples</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Convert the ith training sentence in lower case and split is into words. You should get a list of words.</span></span><br><span class="line">        sentence_words = X[i].lower().split()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Initialize j to 0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Loop over the words of sentence_words</span></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> sentence_words:</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Set the (i,j)th entry of X_indices to the index of the correct word.</span></span><br><span class="line">            X_indices[i, j] =word_to_index[w]</span><br><span class="line">            <span class="comment"># Increment j to j + 1</span></span><br><span class="line">            j = j + <span class="number">1</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> X_indices</span><br></pre></td></tr></table></figure> 以下设计Embedding层，使用keras的Embedding类。 <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: pretrained_embedding_layer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 此方法创建了一个Embedding层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretrained_embedding_layer</span><span class="params">(word_to_vec_map, word_to_index)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.</span></span><br><span class="line"><span class="string">    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    embedding_layer -- pretrained layer Keras instance</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># GloVe的总单词数量</span></span><br><span class="line">    vocab_len = len(word_to_index) + <span class="number">1</span>                  <span class="comment"># adding 1 to fit Keras embedding (requirement)</span></span><br><span class="line">    emb_dim = word_to_vec_map[<span class="string">"cucumber"</span>].shape[<span class="number">0</span>]      <span class="comment"># define dimensionality of your GloVe word vectors (= 50)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="comment"># Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)</span></span><br><span class="line">    <span class="comment"># 词嵌入矩阵，之前V1压根没用词嵌入矩阵，将这个矩阵放入Embedding层中供keras使用</span></span><br><span class="line">    emb_matrix = np.zeros((vocab_len, emb_dim))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set each row "index" of the embedding matrix to be the word vector representation of the "index"th word of the vocabulary</span></span><br><span class="line">    <span class="keyword">for</span> word, index <span class="keyword">in</span> word_to_index.items():</span><br><span class="line">        emb_matrix[index, :] = word_to_vec_map[word]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define Keras embedding layer with the correct output/input sizes, make it trainable.</span></span><br><span class="line">    <span class="comment"># Use Embedding(...). Make sure to set trainable=False.</span></span><br><span class="line">    embedding_layer = Embedding(vocab_len, emb_dim, trainable=<span class="keyword">False</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the "None".</span></span><br><span class="line">    embedding_layer.build((<span class="keyword">None</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.</span></span><br><span class="line">    embedding_layer.set_weights([emb_matrix])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> embedding_layer</span><br></pre></td></tr></table></figure></p>
<h3 id="building-the-emojifier-v2">Building the Emojifier-V2</h3>
<p>以下代码完成Emojify。主要是keras代码。 <figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: Emojify_V2</span></span><br><span class="line"></span><br><span class="line"><span class="attr">def</span> <span class="string">Emojify_V2(input_shape, word_to_vec_map, word_to_index):</span></span><br><span class="line">    <span class="attr">"""</span></span><br><span class="line">    <span class="attr">Function</span> <span class="string">creating the Emojify-v2 model's graph.</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">Arguments</span>:<span class="string"></span></span><br><span class="line">    <span class="attr">input_shape</span> <span class="string">-- shape of the input, usually (max_len,)</span></span><br><span class="line">    <span class="attr">word_to_vec_map</span> <span class="string">-- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation</span></span><br><span class="line">    <span class="attr">word_to_index</span> <span class="string">-- dictionary mapping from words to their indices in the vocabulary (400,001 words)</span></span><br><span class="line"></span><br><span class="line">    <span class="attr">Returns</span>:<span class="string"></span></span><br><span class="line">    <span class="attr">model</span> <span class="string">-- a model instance in Keras</span></span><br><span class="line">    <span class="attr">"""</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    ### START CODE HERE ###</span></span><br><span class="line"><span class="comment">    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).</span></span><br><span class="line">    <span class="attr">sentence_indices</span> = <span class="string">Input(input_shape, dtype='int32')</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    # Create the embedding layer pretrained with GloVe Vectors (≈1 line)</span></span><br><span class="line">    <span class="attr">embedding_layer</span> = <span class="string">pretrained_embedding_layer(word_to_vec_map, word_to_index)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    # Propagate sentence_indices through your embedding layer, you get back the embeddings</span></span><br><span class="line">    <span class="attr">embeddings</span> = <span class="string">embedding_layer(sentence_indices)   </span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state</span></span><br><span class="line"><span class="comment">    # Be careful, the returned output should be a batch of sequences.</span></span><br><span class="line"><span class="comment">    # 这个128是神经元的个数</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">LSTM(128, return_sequences=True)(embeddings)</span></span><br><span class="line"><span class="comment">    # Add dropout with a probability of 0.5</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">Dropout(0.5)(X)</span></span><br><span class="line"><span class="comment">    # Propagate X trough another LSTM layer with 128-dimensional hidden state</span></span><br><span class="line"><span class="comment">    # Be careful, the returned output should be a single hidden state, not a batch of sequences.</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">LSTM(128, return_sequences=False)(X)</span></span><br><span class="line"><span class="comment">    # Add dropout with a probability of 0.5</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">Dropout(0.5)(X)</span></span><br><span class="line"><span class="comment">    # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">Dense(5)(X)</span></span><br><span class="line"><span class="comment">    # Add a softmax activation</span></span><br><span class="line">    <span class="attr">X</span> = <span class="string">Activation('softmax')(X)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    # Create Model instance which converts sentence_indices into X.</span></span><br><span class="line">    <span class="attr">model</span> = <span class="string">Model(inputs=sentence_indices, outputs=X)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">    ### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">return</span> <span class="string">model</span></span><br></pre></td></tr></table></figure></p>
<h2 id="系统整体流程">系统整体流程</h2>
<p>RNN 1. 读取GloVe文件和训练数据 2. 将训练数据的label转为one hot表示 3. 求出所有训练数据中最长句子的长度，该长度就是LSTM的个数。由于向量化的要求，LSTM的个数需要相同，以最长长度作为LSTM的个数，当然并不需要每个项目都这么设置，完全可以自己选，随便举几个例子比如20,50，100等。 4. 设计Embedding层 5. 建立神经网络模型 6. 将每句话转换为索引表示，如果长度不够就填0，够了就截断。《Python深度学习》中使用了pad_sequences类 7. 使用模型预测，第6条就是输入的训练数据，第2条就是输入的标签</p>
<p>Embedding层需要输入一个词嵌入矩阵，就是一个二维数组。每行代表一个单词的特征向量，行数就是单词的索引。而输入的训练数据被处理成单词的索引形式。如一组训练样本，每个单词被替换成唯一的索引。 Embedding层太过复杂，故不作详解。第一章的代码中全部有注释。</p>
<!-- more -->
]]></content>
      <categories>
        <category>notes</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>keras</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter出现gbk codec cant decode byte 0x93 in position 3136：illegal multibyte sequence</title>
    <url>/posts/99a5ad8a.html</url>
    <content><![CDATA[<p>一般来说是open()方法没有加encoding='utf-8'，但是没用，试了其他办法没一个能用。</p>
<p>解决办法：重启Jupyter。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title>吴恩达深度学习学习笔记：自然语言处理与词嵌入</title>
    <url>/posts/8de7f8fd.html</url>
    <content><![CDATA[<h1 id="字母表示">字母表示</h1>
<p>我们一直使用<a href="https://yan624.github.io/·学习笔记/吴恩达深度学习与李宏毅深度学习学习笔记：RNN序列模型.html#one%20hot编码">one hot编码</a>，这在之前已经记过笔记。这种表示方法的最大缺点是将每个词孤立起来，并且泛化能力不强。由于每个向量的内积都是0，所以它们之间的距离都是一样的。比如 1. I want a glass of orange juice. 2. I want a glass of apple ___. 这两个句子是很常见的句子，所以自然而然的想到划线处应该是juice。但是由于one hot编码，程序并不知道orange和apple之间的关系，也就猜不出来。</p>
<h2 id="featurized-representation-word-embedding">Featurized representation： word embedding</h2>
<p>既然one hot有问题，那么自然就有人发明了新的算法。 使用特征来表示每个词。如果适应特征化来表示，那么最后发现orange和apple的特征差不多，就可以推测出划线处应该填写什么。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达深度学习学习笔记：自然语言处理与词嵌入/Featurized%20representation：%20word%20embedding.jpg" alt="Featurized representation： word embedding" /> <a id="more"></a></p>
<h2 id="visualizing-word-embedding">Visualizing word embedding</h2>
<p>可以使用t-SNE算法将数据可视化为二维的图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达深度学习学习笔记：自然语言处理与词嵌入/Visualizing%20word%20embedding.jpg" alt="Visualizing word embedding" /></p>
<h1 id="词嵌入的特性">词嵌入的特性</h1>
<h2 id="类比">类比</h2>
<p>看下图中的表格，现在已知对应关系man-&gt;woman，能否推出king对应于queen？也就是说king-&gt;___，填空题。 解法是： 求出man和woman之间的差 <span class="math display">\[
\begin{pmatrix}
-1\\
0.01\\
0.03\\
0.09\\
\end{pmatrix} - 
\begin{pmatrix}
1\\
0.02\\
0.02\\
0.01\\
\end{pmatrix} \approx
\begin{pmatrix}
-2\\
0\\
0\\
0\\
\end{pmatrix}
\]</span> 假设计算king和queen的差 <span class="math display">\[
\begin{pmatrix}
-0.95\\
0.93\\
0.70\\
0.02\\
\end{pmatrix} - 
\begin{pmatrix}
0.97\\
0.95\\
0.69\\
0.01\\
\end{pmatrix} \approx
\begin{pmatrix}
-2\\
0\\
0\\
0\\
\end{pmatrix}
\]</span> 算法的原理就是找到一个词使得man和woman的差与king和新词的差接近。翻译为代码就是<span class="math inline">\(find\ word\ w: argmax\ sim(e_w, e_{king} - e_{man} + e _{woman})\)</span>。但是算法的准确度只有30%-75%。</p>
<h3 id="余弦相似度">余弦相似度</h3>
<p>余弦相似度也可以计算相似度。公式为<span class="math inline">\(sim(u,v) = \frac{u^Tv}{\parallel u\parallel_2\parallel v\parallel_2}\)</span></p>
<h1 id="嵌入矩阵">嵌入矩阵</h1>
<p>略。大致意思是一个嵌入矩阵E乘上one hot编码可以得到一个单词的特征向量。E就是全部单词的特征矩阵。</p>
<h1 id="如何train一个词嵌入矩阵">如何train一个词嵌入矩阵</h1>
<p>在早期深度学习的研究人员都是使用比较复杂的算法，但是随着时间的推移，这些复杂的算法被慢慢的简化。以至于现在的新手看到这些简化版的算法时，会疑惑这样简单的算法时怎么工作的。所以现在先介绍一个比较复杂的算法，再慢慢介绍简化版的。 <div class="note info"><p>这节好像是用来讲如何建立神经语言模型的，以后再看。之前讲了嵌入矩阵E，但是E中全部的特征向量是已经假定存在的，那么这些特征从何而来呢？就是这节讲的，去训练得来的。但是其实有已经训练好的，我们可以直接拿来用，网上有很多。</p>
</div></p>
<h1 id="word2vec">Word2Vec</h1>
<h1 id="负采样">负采样</h1>
<h1 id="词嵌入除偏">词嵌入除偏</h1>
<p>就是词嵌入中可能带有一些偏见，比如男女偏见、种族偏见等。现在的目的就是除去这种偏见。 暂且不看，其他的算法都还没学。</p>
]]></content>
      <categories>
        <category>notes</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>nlp</tag>
      </tags>
  </entry>
  <entry>
    <title>吴恩达李宏毅综合学习笔记：RNN入门</title>
    <url>/posts/5e27260b.html</url>
    <content><![CDATA[<h1 id="大纲">大纲</h1>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>序号</th>
<th>课程</th>
<th>内容</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2~8</td>
<td>吴恩达深度学习</td>
<td>one hot编码、RNN包括双向和深层、GRU、LSTM</td>
</tr>
<tr class="even">
<td>9~14</td>
<td>李宏毅机器学习</td>
<td>RNN包括双向和深层、LSTM、RNN反向传播、seq2seq</td>
</tr>
<tr class="odd">
<td>15~20</td>
<td>李宏毅深度学习</td>
<td>计算图、语言模型中的深度学习、几个有用的网络架构。到原视频的 p12 结束，由于后续部分涉及到了 GAN 等其他模型，所以不在此处做笔记，详见<a href="https://yan624.github.io/posts/b803ed7e.html">对神经网络整体的理解</a>博文中靠后的几节</td>
</tr>
<tr class="even">
<td>21</td>
<td>李宏毅机器学习/深度学习剩余的一些知识点</td>
<td>这些知识点记录在其他的博客中，此处只提供链接</td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h1 id="字母表示">字母表示</h1>
<p>假设：</p>
<p>x: Harry Potter and Hermione Granger invented a new spell.</p>
<p>y: 1 1 0 1 1 0 0 0 0</p>
<p>其中1代表人名地名之类的单词。这句话一共有九个单词，则x可以表示为：<span class="math inline">\(x^{&lt;1&gt;} x^{&lt;2&gt;} \cdots x^{&lt;t&gt;} \cdots x^{&lt;9&gt;}\)</span>。</p>
<p>则y可以表示为：<span class="math inline">\(y^{&lt;1&gt;} y^{&lt;2&gt;} \cdots y^{&lt;t&gt;} \cdots y^{&lt;9&gt;}\)</span></p>
<p>输入的长度表示为<span class="math inline">\(T_x\)</span>，则<span class="math inline">\(T_x = 9\)</span>。</p>
<p>输出的长度表示为<span class="math inline">\(T_y\)</span>，则<span class="math inline">\(T_y = 9\)</span>。</p>
<p>之前在神经网络中<span class="math inline">\(X^i\)</span>或<span class="math inline">\(X^(i)\)</span>代表第i个训练样本。现在在序列模型中，<span class="math inline">\(X^{(i)&lt;t&gt;}\)</span>代表代表第i个训练样本的第t个元素。对应地，<span class="math inline">\(T^i_x\)</span>就代表第i个样本的输入长度。</p>
<h1 id="one-hot编码">one hot编码</h1>
<p>在我们做自然语言处理时，一件需要事先决定的是，怎么表示一个序列里的单词。</p>
<p>第一件事就是做一张词表（Vocabulary）有时也叫字典（Dictionary），然后将表示方法中要使用的单词列出一列。最后将一个单词用一个稀疏向量表示，如Harry表示为<span class="math inline">\(\begin{pmatrix}0&amp;0&amp;0&amp;\cdots&amp;1&amp;0&amp;\cdots&amp;0\end{pmatrix}\)</span>。1所在位置就是Harry这个单词在词表中的所在位置。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/ont%20hot%E4%BE%8B%E5%AD%90.jpg" alt="ont hot例子" /></p>
<h1 id="循环神经网络rnn">循环神经网络——RNN</h1>
<p>与Simple Neural Network不同的是，循环神经网络的每一层都要有输入x和输出y。</p>
<p>第一步与Simple Neural Network类似，<span class="math inline">\(a_1 = w_{ax} * x^{&lt;1&gt;} + b_a\)</span>，这样就获得了激活值a，但是这时需要使用sigmoid函数或者其他函数直接算出y，另外与Simple Neural Network不同的是，它在计算激活值时需要附带加上前一层的激活值乘上一个权重，此权重与其他的权重类似，也是NN自己训练的。所以第二个序列的计算公式是<span class="math inline">\(a_2 = w_{aa} * a_1 + w_{ax} * x^{&lt;2&gt;} + b_a\)</span>。后面的序列就跟第二个序列一样。<strong>注意一点，RNN中平行方向是时间序列，并不是隐藏层，并且此例中为了方便起见，垂直方向只有一个隐藏层。那几个圆圈是神经元</strong>。看下图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E5%90%B4%E6%81%A9%E8%BE%BE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84RNN%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt="吴恩达深度学习中的RNN示意图" /> 1. 由于为了一般化，第一层需要修改成跟后面的计算类似，所以引入一个零向量<span class="math inline">\(a_0\)</span>来计算<span class="math inline">\(a_1\)</span>。 所以RNN的计算公式为： <span class="math display">\[
\left\{ 
    \begin{array}{c}
        a^{&lt;1&gt;} = g_1(w_{aa} * a^{&lt;0&gt;} + w_{ax} * x^{&lt;1&gt;} + b_a)\\
        \hat{y}^{&lt;1&gt;} = g_2(w_{ya} * a^{&lt;1&gt;} + b_y)\\
        a^{&lt;2&gt;} = g_1(w_{aa} * a^{&lt;1&gt;} + w_{ax} * x^{&lt;2&gt;} + b_a)\\
        \hat{y}^{&lt;2&gt;} = g_2(w_{ya} * a^{&lt;2&gt;} + b_y)\\
        \vdots\\
        a^{&lt;t&gt;} = g_1(w_{aa} * a^{&lt;t-1&gt;} + w_{ax} * x^{&lt;t&gt;} + b_a)\\
        \hat{y}^{&lt;t&gt;} = g_2(w_{ya} * a^{&lt;t&gt;} + b_y)\\
    \end{array}
\right. 
\]</span> 注意上式中的<span class="math inline">\(w_{aa}\)</span>、<span class="math inline">\(w_{ax}\)</span>、<span class="math inline">\(w_{ya}\)</span>、<span class="math inline">\(b_{a}\)</span>和<span class="math inline">\(b_{y}\)</span>并没有上标或者下标，所以意味着每一层同一个符号的权重值和偏差值都是一样的。另外对于激活函数也是用户自行选择，在<a href="https://yan624.github.io/posts/b803ed7e.html">对神经网络整体的理解</a>一文中已经解释的很清楚了，为了区分输入与输出的激活函数不同，我特意使用了不同的下标，这个下标仅代表这个意思。</p>
<ol start="2" type="1">
<li>为了进一步地一般化，我们将<span class="math inline">\(w_{aa}\)</span>、<span class="math inline">\(w_{ax}\)</span>合并成为<span class="math inline">\(w_{a}\)</span>，如果表示为矩阵形式就是<span class="math inline">\(w_{a} = \begin{pmatrix}w_{aa} | w_{ax}\end{pmatrix}\)</span>，然后将1中的最后两行表达式一般化为： <span class="math display">\[
a^{&lt;t&gt;} = g_1(w_{a} * [a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_a)\\
\hat{y}^{&lt;t&gt;} = g_2(w_{y} * a^{&lt;t&gt;} + b_y)\\
\]</span> 表达式<span class="math inline">\([a^{&lt;t-1&gt;}, x^{&lt;t&gt;}]\)</span>的意思是将两个向量堆起来，如果表示为矩阵形式就是<span class="math inline">\(\begin{pmatrix} a^{&lt;t-1&gt;}\\ x^{&lt;t&gt;}\\ \end{pmatrix}\)</span>，上式为了排版问题就不写成矩阵形式了。</li>
</ol>
<h2 id="rnn的反向传播">RNN的反向传播</h2>
<p>跟Simple Neural Network类似，也要先定义一个cost function，可以选择crossentropy。由于RNN每一层都有输出值y，所以需要对每一层都求出代价，最后将这些代价值加起来</p>
<div class="note primary">
<pre><code>&lt;p&gt;吴恩达老师在讲反向传播的实现时并没有讲计算过程，所以有点糊里糊涂的。从代价函数到激活值反向传播还可以理解，但是从后一层到前一层的反向传播理解不了。另外由于权重值一样，那么权重值到底该怎么更新？&lt;/p&gt;</code></pre>
</div>
<h2 id="不同类型的rnn">不同类型的RNN</h2>
<p>上面讲到的都是<span class="math inline">\(T_x = T_y\)</span>，但是有时候输入和输出的长度并不相同。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84RNN%E5%AE%9E%E4%BE%8B.jpg" alt="不同类型的RNN实例" /></p>
<p>多对多（many to many）、多对一（many to one）、一对一（one to one）、一对多（one to many）架构 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.jpg" alt="不同类型的RNN结构" /></p>
<h2 id="语言模型和序列生成">语言模型和序列生成</h2>
<h2 id="对新序列采样">对新序列采样</h2>
<h2 id="长期依赖梯度消失">长期依赖，梯度消失</h2>
<p>观察两个句子：</p>
<ul>
<li>The cat, which already ate..., was full.</li>
<li>The cats, which already ate..., were full.</li>
</ul>
<p>这两个句子只有复数形式上的不同，但是开头的名词影响到了最后面的be动词。但是我们目前见到的最基本的RNN不擅长捕获这种长期依赖效应。</p>
<p>用梯度消失解释一下为什么，其实原理相同的，这里引用之前的文章 <a href="https://yan624.github.io//%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3.html#%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E5%92%8C%E6%A2%AF%E5%BA%A6%E7%88%86%E7%82%B8">梯度消失和梯度爆炸</a></p>
<h1 id="gru单元gate-recurrent-unit">GRU单元——Gate Recurrent Unit</h1>
<p>中文名为门控循环单元。它也解决了梯度消失的问题。</p>
<h2 id="符号表示">符号表示</h2>
<p>c = memonry cell，使用<span class="math inline">\(c^{&lt;t&gt;}\)</span>符号表示输出，其中<span class="math inline">\(c^{&lt;t&gt;} = a^{&lt;t&gt;}\)</span>，由于后面的LSTM的c和a代表意思不同，所以这里直接使用c来表示输出值。所以本小章下的c你都看作是a即可。</p>
<h2 id="gru工作流程">GRU工作流程</h2>
<p>由于通过<span class="math inline">\(c^{&lt;t-1&gt;}\)</span>来更新<span class="math inline">\(c^{&lt;t&gt;}\)</span>的值，但是现在我们使用GRU，GRU就是来控制是否更新<span class="math inline">\(c^{&lt;t&gt;}\)</span>的值的，这里使用“更新”的名词可能有点怪，因为<span class="math inline">\(c^{&lt;t&gt;}\)</span>实际上是通过<span class="math inline">\(c^{&lt;t-1&gt;}\)</span><strong>计算</strong>出来的。那么公式<span class="math inline">\(a^{&lt;t&gt;} = g_1(w_{a} * [a^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_a)\)</span>变为<span class="math inline">\(\tilde{c}^{&lt;t&gt;} = tanh(w_{c} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c)\)</span>，这里的<span class="math inline">\(\tilde{c}^{&lt;t&gt;}\)</span>是一个候选值——candidate value，类似于中间变量，而激活函数我们选择tanh。</p>
<p>GRU的核心是有一个Gate，就是上面说的是否更新值的功能，它的公式为<span class="math inline">\(\Gamma_u = \sigma(w_{u} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u)\)</span>，<span class="math inline">\(\Gamma_u\)</span>的u的意思是update，sigmoid函数的输出范围在0-1之间，所以就完成了类似更新的功能。如果是0就代表不让你更新，如果是1就代表让你更新，这里听起来还有点绕，没关系看下面的表达式。</p>
<p>这时开始执行更新步骤：<span class="math inline">\(c^{&lt;t&gt;} = \Gamma_u * \tilde{c}^{&lt;t&gt;} + (1 - \Gamma_u) * c^{&lt;t-1&gt;}\)</span>，这一步可以看出如果<span class="math inline">\(\Gamma_u\)</span>等于1就将<span class="math inline">\(c^{&lt;t&gt;}\)</span>更新为<span class="math inline">\(\tilde{c}^{&lt;t&gt;}\)</span>，如果等于0就相当于不让你更新，结果还是上一个的c，即<span class="math inline">\(c^{&lt;t-1&gt;}\)</span>。</p>
<p>将公式写在一起，GRU的工作流程就是： <span class="math display">\[
\begin{cases}
    \tilde{c}^{&lt;t&gt;} = tanh(w_{c} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c)\\
    \Gamma_u = \sigma(w_{u} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u)\\
    c^{&lt;t&gt;} = \Gamma_u * \tilde{c}^{&lt;t&gt;} + (1 - \Gamma_u) * c^{&lt;t-1&gt;}\\
\end{cases}
\]</span></p>
<h2 id="gru完整版">GRU完整版</h2>
<p>可以看到下式中就多了一个<span class="math inline">\(\Gamma_r\)</span>，但是为什么不用上面的简化版呢？那是因为经研究者多年的尝试，发现下面的版本是很实用的，也算是一个标准版，你可以自己开发不同的版本。 <span class="math display">\[
\begin{cases}
    \tilde{c}^{&lt;t&gt;} = tanh(w_{c} * [\Gamma_r * c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_c)\\
    \Gamma_u = \sigma(w_{u} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_u)\\
    \Gamma_r = \sigma(w_{r} * [c^{&lt;t-1&gt;}, x^{&lt;t&gt;}] + b_r)\\
    c^{&lt;t&gt;} = \Gamma_u * \tilde{c}^{&lt;t&gt;} + (1 - \Gamma_u) * c^{&lt;t-1&gt;}\\
\end{cases}
\]</span></p>
<h1 id="lstm">LSTM</h1>
<p>吴恩达老师讲得感觉理解起来有点费劲，因为他觉得图片比文字更难理解，所以写了一大堆公式，只是再后面补充了图片。所以我建议看李宏毅老师的深度学习视频来理解LSTM。李宏毅老师的视频用了一张图片很好的解释了LSTM，并且他还举了一个例子，更加生动形象。</p>
<p>可能是东西方的差异，我感觉是图片好理解点，所以我选择看李宏毅老师的视频。这里就不写了，因为我在<strong>下面写了</strong>李宏毅老师课程的<strong>笔记</strong>。</p>
<h1 id="双向神经网络">双向神经网络</h1>
<h1 id="深层神经网络">深层神经网络</h1>
<hr />
<p>李宏毅机器学习 **********************************</p>
<h1 id="字母表示-1">字母表示</h1>
<p>跟吴恩达老师讲的类似，李宏毅老师也讲了文字如何表示，与吴恩达老师不同的是，李宏毅老师多讲了几个。</p>
<p>最简单的方法利用向量来表示文字，就是上面说过的one-hot：</p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/1%20of%20N%20encoding.jpg" alt="1 of N encoding" /> 因为会出现某些单词没见到过，所以需要使用other这一维来表示。并且在右边的图中还可以使用字母来表示。然后理想上只要将词向量放入神经网络就会出现结果。但是Feedforward Network其实没办法解决这问题。</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/beyond%201-of-N%20encoding.jpg" alt="beyond 1-of-N encoding" /><figcaption>beyond 1-of-N encoding</figcaption>
</figure>
<p>可以看到下图，由于Feedforward Network没有记忆，所以两个句子对它来说是一个意思，但是对人来说可以很明显判断出第一句话台北是目的地，第二句话台北是出发地。Feedforward Network它只能训练当前的词，前一个词是什么它并不知道。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Feedforward%20Network%E6%97%A0%E6%B3%95%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98.jpg" alt="Feedforward Network无法解决的问题" /></p>
<h1 id="rnn">RNN</h1>
<p>上面讲到Feedforward Network由于没有记忆，无法记住前一个或者前几个词，所以就诞生了RNN。RNN其实也没那么神秘，就是每次输入并交给激活函数计算完毕后，将计算结果存入缓存中，并且在下一次计算时，将缓存取出来一起计算（这里一起计算的意思是将 memory 也当做 input，也就是说<strong>下图的 RNN 有 4 个输入</strong>）。就是下图的蓝色方框，由于是第一次计算，其中初始化为0。下图第一遍已经在计算了，实际上已经准备更新蓝色方框中的值了。RNN在上面的章节中其实已经写过了，都是类似的。</p>
<p><strong>注意一点，下图代表一个 RNN，那几个圆圈是一个神经细胞，而不代表一个 RNN</strong>。一个神经细胞中有一个权重向量，对比 simple NN 就能理解了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E4%B8%80%E4%B8%AARNN%E7%9A%84%E5%B0%8F%E5%9E%8B%E4%BE%8B%E5%AD%90.jpg" alt="一个RNN的小型例子" /></p>
<p>经过上面的例子发现，当前的输入已经在依赖前一个的缓存了，所以当顺序有所变化，或者前一个数据有所变化时，RNN可以察觉到，输出的结果也自然不同。</p>
<h2 id="deep-rnn">deep RNN</h2>
<p>我一共写了两个RNN的笔记，无论是吴恩达老师的还是李宏毅老师的到目前为止，RNN其实都不是deep的，之前也在疑惑，RNN横轴有很多层，但是实际上那些层只是不同时间的输入，根本不算deep。今天继续看下去，发现这个问题终于有解了，RNN也可以是deep的。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/deep%20RNN.jpg" alt="deep RNN" /></p>
<h2 id="elman-network-jordan-network">Elman Network &amp; Jordan Network</h2>
<p>上面讲的RNN都被称为Elman Network。还有另一种辩题叫做Jordan Network，它将输出值缓存起来。传说之中Jordan Network可以有更好的性能。</p>
<div class="note primary"><p>为什么有更好的性能</p>
</div>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Elman%20Network%E5%92%8Cordan%20Network.jpg" alt="Elman Network和ordan Network" /><figcaption>Elman Network和ordan Network</figcaption>
</figure>
<h2 id="双向rnnbidirectional-rnn">双向RNN——Bidirectional RNN</h2>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Bidirectional%20RNN.jpg" alt="RNN——Bidirectional RNN" /><figcaption>RNN——Bidirectional RNN</figcaption>
</figure>
<h1 id="长短期记忆long-short-term-memorylstm">长短期记忆——Long Short-term Memory(LSTM)</h1>
<div class="note primary"><p>LSTM的神经元个数不同有什么区别？其他的NN架构也有同样的疑问</p>
</div>
<p>上面讲的memory实际上是最简单的，LSTM才是现在最常用的Memory。Menory在RNN中实际只是一个神经元而已，它负责输入和输出。它们之间的关联是：RNN依旧是RNN，只不过把RNN中的神经元换成了LSTM。我们知道神经元的逻辑其实很简单，只有输入——计算——输入到激活函数——输出激活值，而LSTM只不过麻烦一点罢了。</p>
<p>下图就是一个LSTM。Input Gate中如果f(z)是1就代表Gate打开，也就是f(z)*g(z) = 1 * g(z) = g(z)，就相当于可以让外界输入。如果f(z)=0，Gate被关闭，那么 f(z)*g(z)=0，是不是就像不允许外界输入一样？因为你输入多少都被置为0。而Forget Gate也类似，当f(z)=1时，即Forget Gate被打开，这里与直觉有点相反，因为Gate打开，有点感觉像遗忘。但是其实c*f(z) = 1，所以Forget Gate为1其实是记住原本的c的意思。</p>
<p>另外图中也写到了，Gate的激活函数一般选sigmoid，里面的值就代表Gate的打开程度。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E7%A4%BA%E4%BE%8B.jpg" alt="LSTM示例" /></p>
<h2 id="lstm的例子">LSTM的例子</h2>
<p>例子介绍：只有一个LSTM，输入有3维，输出有1维。<span class="math inline">\(x_2 = 1\)</span>则<span class="math inline">\(x_1\)</span>的值就会被存到Memory中，<span class="math inline">\(x_2 = -1\)</span>则重置Memory，<span class="math inline">\(x_3 = 1\)</span>则输出。</p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E4%BE%8B%E5%AD%90%E4%BB%8B%E7%BB%8D.jpg" alt="LSTM例子介绍" /> 注：下图中的蓝色数字和灰色数字是权重值。</p>
<div class="note primary"><p>Q：权重值是初始化的？还是固定的？还是初始化后自己可以训练的？其实就是LSTM的反向传播算法要弄懂。</p>
<p>A：是初始化后自己可以训练的。<em>2019 年 11 月 11 日回答</em>。</p>
</div>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E4%BE%8B%E5%AD%90%E8%AE%A1%E7%AE%97.jpg" alt="LSTM例子计算" /><figcaption>LSTM例子计算</figcaption>
</figure>
<ol type="1">
<li>Input Gate： 将偏差设为-10是因为我们通过x2来对Input Gate控制。平常x2=0，计算x*w+b=-10，那么通过sigmoid function就会得到一个接近于0的值，所以就实现了将Input Gate关闭的功能。而如果x2=1，那么x2*100=100，通过sigmoid function就会得到一个接近于1的值，Input Gate就实现了打开的功能。</li>
<li>Forget Gate: 这里的功能跟Input Gate类似。</li>
<li>Output Gate: 如果Output Gate被关闭，那么输出0.</li>
</ol>
<h2 id="多个lstm工作场景">多个LSTM工作场景</h2>
<p>里面的<span class="math inline">\(x^t\)</span>就是对应于NN中的一个向量，它分别乘上4个参数矩阵得到4个不同的向量，以此操控LSTM，而LSTM实际上就等于神经元，说白了就是一个类似激活函数的功能。</p>
<div class="group-picture"><div class="group-picture-row"><div class="group-picture-column" style="width: 50%;"><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E5%AE%9E%E9%99%85%E5%B7%A5%E4%BD%9C%E5%9C%BA%E6%99%AF.jpg" alt="LSTM实际工作场景" /></div><div class="group-picture-column" style="width: 50%;"><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E5%AE%9E%E9%99%85%E5%B7%A5%E4%BD%9C%E5%9C%BA%E6%99%AF2.jpg" alt="LSTM实际工作场景2" /></div></div></div>
<p>多个LSTM连起来工作就是像下面一样，红线和红线旁边的那个黑色曲线链接的值之前没有讲过，但是下图的这样才是LSTM实际的长相，所以之前讲的那么复杂实际上还是LSTM的简化版。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/LSTM%E5%AE%9E%E9%99%85%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.jpg" alt="LSTM实际工作流程" /></p>
<h1 id="rnn反向传播">RNN反向传播</h1>
<div class="note info"><p>此处的笔记来源于 <a href="https://www.bilibili.com/video/av10590361?p=37" target="_blank" rel="noopener">26: Recurrent Neural Network (Part II)</a> 从 0 分开始。</p>
</div>
<p>BPTT——backpropagation through time，与 NN 的 backpropagation 类似，李宏毅老师也没讲原理直接跳过了。</p>
<p>然而不幸的是，RNN 的 training 是很困难的。下面蓝色的线是希望的结果，但是实际上是绿色的线，会出现剧烈地抖动，最后在某个点出现NAN。这就是类似梯度消失问题。可以使用一些办法解决，但是现在用得最多的方法是LSTM。</p>
<p><strong>视频中花了很长的时间去讲解梯度爆炸和梯度消失的问题，但是我没有将它记录在这，详情可访问下面两个链接。</strong> <div class="note primary"><p>Q：如何防止出现如下剧烈抖动的 loss 曲线？</p>
<p>A：处理梯度爆炸的问题。</p>
</div> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/RNN%20training%E7%A2%B0%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98.jpg" alt="RNN trWaining碰到的问题" /></p>
<h1 id="其他解决梯度消失的办法">其他解决梯度消失的办法</h1>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E5%85%B6%E4%BB%96%E8%A7%A3%E5%86%B3%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E7%9A%84%E5%8A%9E%E6%B3%95.jpg" alt="其他解决梯度消失的办法" /><figcaption>其他解决梯度消失的办法</figcaption>
</figure>
<h1 id="seq2seq">seq2seq</h1>
<h2 id="many-to-one">Many to one</h2>
<p>输入一个向量sequence，只输出一个向量。</p>
<ol type="1">
<li>语义分析。比如分析电影评论是好是坏。</li>
<li>key term extraction。对文档提取关键词。</li>
</ol>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Many%20to%20One.jpg" alt="Many to One" /><figcaption>Many to One</figcaption>
</figure>
<h2 id="many-to-manyoutput-is-shorter">Many to many(Output is shorter)</h2>
<p>输入和输出都是向量sequence，但是输出要短。</p>
<ol type="1">
<li>Speech Recognition 。语音辨识。</li>
</ol>
<h2 id="many-to-manyno-limitation">Many to many(No limitation)</h2>
<p>输入和输出都是序列且长短不一。被称为 <strong>Sequence to sequence learning</strong> 。</p>
<ol type="1">
<li>Machine Translation. 机器翻译。</li>
</ol>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Many%20to%20Many（No%20Limitation）.jpg" alt="Many to Many(No Limitation)" /><figcaption>Many to Many(No Limitation)</figcaption>
</figure>
<h2 id="beyond-sequence">Beyond Sequence</h2>
<ol type="1">
<li>Syntactic parsing</li>
</ol>
<h2 id="autoencoder">autoencoder</h2>
<p><a href="https://www.bilibili.com/video/BV13x411v7US?p=37" target="_blank" rel="noopener">26: Recurrent Neural Network (Part II)</a>，45.43 开始。</p>
<hr />
<p>李宏毅深度学习</p>
<hr />
<h1 id="注意事项">注意事项</h1>
<p>此系列视频还有两个Review视频，分别为第一个视频：Basic Structures for Deep Learning Models(Part 1)， 第二个视频：Basic Structures for Deep Learning Models(Part 2)。</p>
<p>个人认为Review视频不需要看，而且这两个视频时间贼长，加起来得有两个多小时。没必要浪费时间，即使你根本没学过Review中的知识点也不用去看。他的Review里不会讲很深，基本上就过过场，就算有很深的东西也完全不影响继续往下学。1P时长80分钟，说实话如果自己属于小白阶段，去看那么长的视频是挺打击人的兴趣的，如果是大佬或者已经入门的人当然看得津津有味了。 <a href="https://yan624.github.io/posts/5e27260b.html#字母表示-1">此文</a>记录了李宏毅机器学习视频中讲解的RNN的笔记。</p>
<h1 id="computational-graph-backpropagation">Computational Graph &amp; Backpropagation</h1>
<div class="note danger"><p>2019年6月7号更新：关于计算图这章，现在才发现原来很重要，因为这是完成<strong>自动求导</strong>的关键。学了 pytorch 之后才发现的。</p>
</div>
<h2 id="什么是computational-graph">什么是Computational Graph</h2>
<p>这实际上跟要学的深度学习没什么关系，只是名字好听点，无视就好，如下图就是一个Computational Graph。主要用来在计算神经网络一些输出时，便于理解。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Computational%20Graph%E4%BE%8B%E5%AD%90.jpg" alt="Computational Graph例子" /></p>
<p>在看一个比较贴近实际的例子，顺便复习一下链式求导法则。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Computational%20Graph%E9%93%BE%E5%BC%8F%E6%B1%82%E5%AF%BC%E6%B3%95%E5%88%99%E7%A4%BA%E4%BE%8B.jpg" alt="Computational Graph链式求导法则示例" /></p>
<h2 id="通过链式求导的例子理解反向传播backpropagation算法">通过链式求导的例子理解反向传播（Backpropagation）算法</h2>
<p>首先进行正向链式求导，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E6%AD%A3%E5%90%91%E9%93%BE%E5%BC%8F%E6%B1%82%E5%AF%BC.jpg" alt="正向链式求导" /></p>
<p>图中要求计算e对a求偏导，首先给出a=3, b=2。其中c=a+b, d=b+1。</p>
<p>按照李宏毅老师使用链式求导法则，先要计算c对a求导得到1。e再对c求导得到b+1，带入b=2，得到3。所以3对a求偏导等于1*3=3。</p>
<p>上面这种链式求导法则有点乱，如果没仔细学过<em>微积分</em>可能难以理解。其实对于方程e = (a+b) * (b+1)，e对a求偏导，直接看出来都可以。利用考研时的口诀“左导右不导，左不导右导”（也就是<a href="https://baike.baidu.com/item/%E8%8E%B1%E5%B8%83%E5%B0%BC%E8%8C%A8%E5%85%AC%E5%BC%8F/8779293?fr=aladdin" target="_blank" rel="noopener">莱布尼茨公式</a>），直接得到结果<span class="math inline">\(\frac{\partial e}{\partial a} = b+1\)</span>。</p>
<p>然后将b=2带入b+1得到结果还是3。</p>
<p>接着进行反向模式，如下图: <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E5%8F%8D%E5%90%91%E9%93%BE%E5%BC%8F%E6%B1%82%E5%AF%BC.jpg" alt="反向链式求导" /></p>
<p>现在图中要求计算<span class="math inline">\(\frac{\partial e}{\partial a}\)</span>以及<span class="math inline">\(\frac{\partial e}{\partial b}\)</span>，当然你可以分别进行两次链式求导，得到结果。但是如果从e出发，也就是反向，那么就可以同时得到<span class="math inline">\(\frac{\partial e}{\partial a}\)</span>以及<span class="math inline">\(\frac{\partial e}{\partial b}\)</span>的结果。</p>
<p>不要在意e为什么等于1，只不过一个输入而已。 此外，如果阅读过《deep learning and neural network》一书，看过吴恩达机器学习视频或者其它资料的应该已经能反应出来。连接线上的求偏导实际上就跟神经网络上的权重一个意思，然后也是一层一层地反向传播。</p>
<p>这个输入e实际上就是神经网络中的反向传播算法中的输入。就是最后一层神经元的误差<span class="math inline">\(\delta^l = h-y\)</span>。这里吴恩达老师和《deep learning and neural network》作者的最后一层误差公式不一样，<strong>目前不明</strong>，暂时不做解释，这里的公式是吴恩达老师的。</p>
<p>然后就是误差*权重+偏差得到前一层的误差，具体不展开。</p>
<h2 id="反向传播的好处">反向传播的好处</h2>
<p>如果你的root只有一个，那么这个Computational Graph中的所有偏微分就都可以一次性算出。对应于神经网络，我们就是要这样的效果。</p>
<h2 id="参数共享parameter-sharing">参数共享（Parameter sharing）</h2>
<p>略，看了一眼貌似挺简单。16:20</p>
<h2 id="computational-graph-for-feedforword-net">Computational Graph for Feedforword Net</h2>
<p>李宏毅深度学习p3从21:16到52:48讲解梯度下降算法、前馈神经网络以及反向传播算法的具体数学原理 一直没看懂原理，以后再看。</p>
<h2 id="computational-graph-for-recurrent-network">Computational Graph for Recurrent Network</h2>
<h1 id="deep-learning-for-language-modeling">※ Deep Learning for Language Modeling</h1>
<p>语言模型就是预测一个word sequence出现的几率有多大。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Language%20Modeling.jpg" alt="Language Modeling" /></p>
<h2 id="n-gram">N-gram</h2>
<p>N-gram是自然语言处理中的算法。2-gram读作bi-gram。</p>
<h3 id="传统做法">传统做法</h3>
<ul>
<li>怎么预测一句话出现的几率</li>
<li>收集大量文本作为训练数据
<ul>
<li>然后计算<span class="math inline">\(w_1\cdots w_n\)</span>这句话在训练数据中出现的概率</li>
</ul></li>
<li>N-gram语言模型：
<ul>
<li>如何计算一小部分的概率？例如下图的p(beach|nice)出现的概率。就是将nice beach出现的次数除以nice出现的次数。</li>
</ul></li>
</ul>
<p>前两条是理想的处理办法，但是麻烦的是要预测的句子在语料库——corpus中八成一次都没出现过。于是就需要使用N-gram模型。它的处理办法就是将句子拆成比较小的部分——component，再把每个小部分的概率乘起来就是句子出现的几率。像下图这种只考虑前一个单词的模型叫做2-gram model。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/N-gram.jpg" alt="N-gram" /></p>
<h3 id="nn-based-lm">NN-based LM</h3>
<p>怎么做基于NN的N-gram？做法如下：</p>
<ol type="1">
<li>搜集training数据</li>
<li>learn一个Neural Network，通过两个词predict下一个词，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/NN-based%20LM.jpg" alt="NN-based LM" /></li>
<li>使用cross entropy minimize</li>
<li>有了Neural Network后算一个句子的几率，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/%E8%AE%A1%E7%AE%97%E5%8F%A5%E5%AD%90%E7%9A%84%E5%87%A0%E7%8E%87.jpg" alt="计算句子的几率" /> 其中STRAT是一个token，代表句子的起始。</li>
</ol>
<h3 id="rnn-based-lm">RNN-based LM</h3>
<p>往上翻<strong>循环神经网络——RNN</strong>，原理就是这个。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/RNN-based%20LM.jpg" alt="RNN-based LM" /></p>
<h3 id="challenge-of-n-gram">Challenge of N-gram</h3>
<h4 id="nn-based-model">NN-based model</h4>
<p>为什么要使用NN-based model。相较于传统方法有什么好处。就是概率估不准，因为永远没有足够的数据。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Challenge%20of%20N-gram.jpg" alt="Challenge of N-gram" /> <div class="note info"><p>视频13:20~27:01仔细讲解了为什么要使用NN，而且把我困惑了快一个月的问题解决了，就是将文字转为数字之后进行训练的意义。</p>
</div></p>
<h4 id="rnn-based-model">RNN-based model</h4>
<p>为什么要使用RNN-based model。相较于传统方法有什么好处。</p>
<h1 id="几个有用的network架构">几个有用的network架构</h1>
<h2 id="spatial-transformer-layer">Spatial Transformer Layer</h2>
<p><a href="http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf" target="_blank" rel="noopener">论文地址</a>，中文可以叫<strong>空间变换层</strong>。 此神经网络架构的出现的原因：CNN 对图片的缩放以及旋转无所谓（CNN is invariant to scaling androtation）。比如说在图片的局部地区中，一个人移动一点点距离，对 CNN 来说其实没什么多大区别。不过距离有点远的话，还是有点影响的。</p>
<h2 id="highway-network">Highway Network</h2>
<p>先对前馈神经网络和 RNN 进行一下对比。</p>
<ol type="1">
<li>Feedforward NN 不是每一步都有输入。</li>
<li>Feedforward NN 每一层都有不同的参数。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Feedforward%20NN和RNN的对比.jpg" alt="Feedforward NN和RNN的对比" /></li>
</ol>
<p><a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank" rel="noopener">Highway Network 论文地址</a>；<a href="https://arxiv.org/pdf/1507.06228.pdf" target="_blank" rel="noopener">Highway Network 实战论文地址</a> Highway Network 的想法就是把 RNN <strong>立</strong>起来，把它当做前馈神经网络来用。 <a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">Highway Network 的改进版论文地址</a>，这个就是<strong>残差神经网络</strong>。</p>
<h2 id="grid-lstm">Grid LSTM</h2>
<p><a href="https://arxiv.org/pdf/1507.01526.pdf" target="_blank" rel="noopener">论文地址</a> 太复杂了，估计以后也很难用到。。。</p>
<h2 id="recusive-network">Recusive Network</h2>
<p>Recursive Network 是 Recurrent Network 更 Generalize 的版本。Recurrent Network 是 Recursive Network 的一个特殊的例子，如果翻译成中文的话，实际上名字都一样。所以可以称之为递归式网络。以下是 RNN 和 Recursive Network 的对比图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Recursive%20Network示意图.jpg" alt="Recursive Network示意图" /></p>
<p>在做 Recursive Network 之前，需要考虑输入的序列的结构。图中将 <span class="math inline">\(x_1\)</span> 和 <span class="math inline">\(x_2\)</span> 一同输入进一个 function，但是其实可以不这么做，具体要怎么输入，取决于输入数据的结构。<strong>而由于 f 与 f 前后相接，所以在写代码时需要预先做好设计</strong>。</p>
<p>举个具体的例子，要判断“not very good”包含什么情绪，可以先使用语法解析，将句子结构化，然后根据句子的语法结构来使用 Recursive Network 进行训练，如下图：</p>
<p>“very”的词向量和“good”的词向量一同放入 f 中训练，我们可以将得到的向量看做是“very good”的意思。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/根据句子语法结构训练1.jpg" title="根据句子语法结构训练1" alt="根据句子语法结构训练1" /></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/根据句子语法结构训练2.jpg" title="根据句子语法结构训练2" alt="根据句子语法结构训练2" /><figcaption>根据句子语法结构训练2</figcaption>
</figure>
<p>当然两个词向量不能是简单的相加，具体做法可以自行选择。最简单的做法可以参考下图的上半部分，而下图的下半部分被称为 <strong>Recursive Neural Tensor Network</strong>，总而言之就是一个很复杂的做法来解决两个词向量不仅仅是进行简单的拼接或者相加。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Recursive%20Neural%20Tensor%20Network.jpg" alt="Recursive Neural Tensor Network" /></p>
<p>对于 f 还有其他的做法，如 Matrix-Vector Recursive Network，<a href="https://arxiv.org/pdf/1503.00075.pdf" target="_blank" rel="noopener">Tree LSTM 2015</a> 等。具体就不记了，以后可以查 Recursive Network 相关论文。</p>
<h1 id="conditional-generation-by-rnn-attention">Conditional Generation by RNN &amp; Attention</h1>
<p>注意本文讲的是 RNN <strong>入门</strong>，而下面的部分也只是讲普通的 RNN Generation，甚至连 decoder 部分都没用。下图是生成文字，其实也可以生成图片、音频等，我就不一一截图了，第二张图将这些<strong>想法</strong>及其<strong>论文</strong>都汇总了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/一个简单的Generation.jpg" alt="一个简单的Generation" /></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Generation汇总.jpg" alt="Generation汇总" /><figcaption>Generation汇总</figcaption>
</figure>
<h2 id="conditional-generation">Conditional Generation</h2>
<p>但是在真实的场景中，我们不仅仅是希望只生成随机的句子，我们更偏向于生成一些基于某些条件的句子，比如：当看见一张一个人正在跳舞的图片，我们希望电脑生成“A young girl is dancing”；当给予一个条件“Hello”时，我们希望电脑生成“Hello, nice to see you.”。</p>
<p>一个实际的例子，我们可以将一张图片输入进 CNN，从而产生一个向量，再把该向量输入进 decoder 部分，最后生成句子。如下图所示，其他类型的<strong>条件生成</strong>也类似。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Image%20Caption%20Generation.jpg" title="Image Caption Generation" alt="Image Caption Generation" /></p>
<h2 id="attention">Attention</h2>
<p>将 <span class="math inline">\(z_0\)</span> 与 <span class="math inline">\(h_1 h_2 h_3 h_4\)</span> 分别做一次 match，至于 match 怎么计算可以看下图右边。</p>
<p>计算步骤可以参考下列公式： <span class="math display">\[
\begin{align}
    h &amp; = [h^1, h^2, h^3, h^4] \\
    s &amp; = h^T z \\
    c^0 &amp; = h^t s \\
\end{align}
\]</span></p>
<p>attention score 的计算公式可以由自己设计，下图使用的是 <span class="math inline">\(h^T W z\)</span>，有兴趣的话，<a href="https://yan624.github.io/·学习笔记/AI/nlp/CS224n学习笔记.html#attention">这里</a>介绍了三个。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Attention机制.jpg" alt="Attention机制" /></p>
<p>然后获得 <span class="math inline">\(a^1_0 a^2_0 a^3_0 a^4_0\)</span>，之后将它们输入 softmax 层（有实验发现其实不经过 softmax 层也可以，甚至效果更好），最后将所有 a 分别乘上它们对应的向量并且相加，得到一个向量 <span class="math inline">\(c^0\)</span>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Attention机制计算score.jpg" alt="Attention机制计算score" /></p>
<p>使用 Attention 机制计算完毕后，将向量 <span class="math inline">\(c^0\)</span> 输入进 decoder 即可，接下来的计算都是以此类推。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Attention机制计算完毕后输入到decoder.jpg" alt="Attention机制计算完毕后输入到decoder" /></p>
<h3 id="attention应用到speach-recognition">Attention应用到Speach Recognition</h3>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Attention%20for%20Speach%20Recognition.jpg" alt="Attention for Speach Recognition" /><figcaption>Attention for Speach Recognition</figcaption>
</figure>
<h2 id="memory-network">Memory Network</h2>
<p><a href="https://papers.nips.cc/paper/5846-end-to-end-memory-networks.pdf" target="_blank" rel="noopener">论文地址</a>，<a href="https://www.bilibili.com/video/av9770302/?p=8" target="_blank" rel="noopener">视频地址</a>43:00开始。 Memory Network 最先被用在 Reading Comprehension，说白了就是一个 Attention 机制。下图就是一个简易的 <strong>Memory Network</strong>。</p>
<ol type="1">
<li>首先将 document 由多个句子组成，句子由 vector x 表示。具体如何表示的问题，可以由自定义解决，如 bag of word 或者由词向量表示；</li>
<li>query 就是问题，也由 vector q 表示；</li>
<li>使用 q 对每个句子做 attention 得到 match score <span class="math inline">\(\alpha\)</span>，然后使用 <span class="math inline">\(\alpha\)</span> 和 x 做 weighted sum；</li>
<li>最后将 weighted sum 后的 vector 和 vector q 都丢到 DNN 中，得到答案。</li>
</ol>
<p>注：这是在做阅读理解。document -&gt; vector 等于 input(I) 和 generalization(G)，attention 等于 output(O)，生成答案等于 response(R)。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/一个简易的Memory%20Network.jpg" title="一个简易的Memory Network" alt="一个简易的Memory Network" /></p>
<p>Memory Network 还有更复杂的版本，即 attention 的 vector 和抽取信息的 vector 并不需要是同一个，如下图所示。</p>
<ol type="1">
<li>将 document 表示为句子时，使用两组向量。一组用于计算 match score，一组用于 weighted sum。</li>
<li>其他的步骤都差不多，但是有一个地方不一样。在 weighted sum 得到一个 vector 之后，可以和 q 加在一起，得到一个新的 q，再重复 步骤 1。而且这个步骤可以做很多次，做完之后再输入进 DNN 获取答案。这个步骤被称之为 Hopping，注意从 document 抽取的两组 vector 在 hopping 的时候，可以是不一样的。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/更复杂的memory%20network.jpg" alt="更复杂的memory network" /></li>
</ol>
<h2 id="neural-turing-machine">Neural Turing Machine</h2>
<h2 id="tips-for-generation">Tips for Generation</h2>
<p>这里听不太懂，跳过了。有 Beam Search 之类的。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/对Generation的建议1.jpg" alt="对Generation的建议1" /></p>
<h1 id="pointer-network">Pointer Network</h1>
<p><a href="https://pdfs.semanticscholar.org/eb5c/1ce6818333560d0d3247c0c74985ef295d9d.pdf" target="_blank" rel="noopener">论文地址</a></p>
<p>举一个简单的例子助于理解 Pointer Network。在二维坐标系中任意给出 4 个点，我们的目标是找到几个点，将它们连起来形成一个封闭圈，剩下的那几个点要正好在这个封闭圈之中，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/助于理解Pointer%20Network的一个例子.jpg" alt="助于理解Pointer Network的一个例子" /></p>
<p>当然，这肯定已经有一些算法可以解了，比如在坐标系中计算距离。但是今天我们使用硬 train 一发的方法，即不管三七二十一将它输入到神经网络里面训练。首先制造一些训练数据，然后给 encoder-deocder 训练。<strong>具体的训练步骤为</strong>：输入点的坐标，输出 one-hot 表示 <code>{1,2,3,4,END}</code> 的五维向量，碰到 END 则代表解码完毕。</p>
<p>但结果是网络训练不起来，因为在上述的例子中我们只输入了 4 个点，我们的目的是得到 1-4 个点。但是如果我们的测试数据是输入 400 个点呢？那么我们也只会得到 1-4 个点，因为 <code>{1,2,3,4,END}</code> 是预先定义好的。你可能会想那就多定义一点啊，但是下次我要是输入 4000 个点呢？要是 40000 个点呢？总有你无法预先定义的时候。</p>
<p>所以我们需要 <strong>Pointer Network</strong> 来<strong>动态的改变类别</strong>（具体做法详见下一小节），注意我这里直接说成类别了，我们可以把 decoder 部分看作是多元分类的工作，如输出 4000 个点，就是 4000 元分类。</p>
<p><strong>上面的例子其实是 Pointer Netwoek 论文中的一个例子，但是对于这个例子来说，使用 Pointer Network 其实没多大意义，因为问题本身有更简单的解法，下面说一下有意义的用途。</strong></p>
<p>Pointer Network 应用于 <strong>Summarization</strong>，<a href="https://www.aclweb.org/anthology/P17-1099" target="_blank" rel="noopener">论文地址</a>。给定一篇文档，让机器做出总结。对于此类问题，我们会碰到很多<strong>生僻的地名、人名</strong>等等字词。我们可以使用 Pointer Network 来解决这个问题。</p>
<p>下图就是做法，整张图的意思就是在做文本摘要的工作，输入一个句子，输出摘要。先不看中间的黄色圆圈 <span class="math inline">\(p_{gen}\)</span>，看看其他部分（红黄两部分）就是很普通的 encoder-decoder。但是对于这个 encoder-decoder 来说，词表中并没有 <em>Aregentina</em> 这个单词。那么我们就可以使用 Pointer Network，这个 <span class="math inline">\(p_{gen}\)</span> 就是概率（具体描述见下一节）。最后结果就是我们将注意力关注到 <em>Aregentina</em> 这个单词。当然对于 encoder-decoder 这部分的工作也是要做的，我们可以将两个结果加起来，从而判断出最终要产生哪个单词，做法详见原论文。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Pointer%20Network%20for%20Summarization.jpg" alt="Pointer Network for Summarization" /></p>
<p>还可用于 <strong>machine learning</strong>、<strong>chatbot</strong> 等。</p>
<h2 id="具体做法">具体做法</h2>
<p>具体的实现就是像下图一样，首先在输入的序列之前加入一个 END 序列，然后将 decoder 删掉。我们还是使用 Attention 机制计算每个序列的 attention score，但是这次的 score 不再乘上它对应的向量，而是直接当做向量输出，意思就是把所以的 score 做一次 max，最大的就输出 1。而<strong>停止条件就是 END 这个序列的 score 是最大的，即为 1 就停止训练。</strong></p>
<p>这样的做法乍一看好像无法理解，我解释一下。由于 encoder 是对序列的长度不敏感的，也就是说如果预先定义的类别是 40 维，而我输入 400 个点，那么对于 encoder 来说，它可以增加神经元的数量从而使得 400 个点<strong>正好</strong>全部输入进 encoder。但是对于 decoder 来说，它输出只能是 40 维。<strong>那么 Pointer Network 的做法是将 decoder 删除，把输出的工作也交给 encoder 去做。所以我输入 400 个点，自然也就可以输出 400 维的类别</strong>（这里应该是 401 维，因为还有一个 END 序列）。看下图的 encoder，<span class="math inline">\(h^4\)</span> 的分数是 0.7，所以我们的输出就是 4，当然对于向量来说就是 <span class="math inline">\((0, 0, 0, 0, 1)\)</span>。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达李宏毅综合学习笔记：RNN入门/Pointer%20Network的做法.jpg" alt="Pointer Network的做法" /></p>
<h1 id="剩余的一些与nlp关系不大的视频">剩余的一些与NLP关系不大的视频</h1>
<ol type="1">
<li>调参的技巧</li>
<li>训练的时候的 loss 曲线一般如下所示，过去人们常常以为这是卡在了 local minima（右上图），但是后来发现可能是卡在了 saddle point（右下）。有一个对为什么卡在 saddle point 而不是 local minima 的直观解释：local minima 要求你的所有 dimension 都必须往下凹的，可以看右上的图，二维的图展示了要想处于 local minima，必须两个维度在一个区间都是向下的才行。假设你有 1000 个维度，那么其实出现这种几率是很低的。 假设多数点的微分值是零的情况，通常这些点都是有些维度趋于向上，有些维度趋于向下，类似右下图。现在多数人比较相信我们训练数据时，其实是卡在了鞍点上。 但是 Ian GoodFellow（花书作者）曾经说过，可能这种说法也是不准确的。因为即使是鞍点，该位置的梯度也应该很低才对，但是他给出了一张图，证明训练至 loss 卡住之后，该处的梯度很大。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/zcy/神经网络训练技巧（tricks）/训练卡住了是因为？.jpg" alt="训练卡住了是因为？" /></li>
<li>Brute-force Memorization：<a href="https://arxiv.org/pdf/1706.05394" target="_blank" rel="noopener">神经网络其实可能只是在暴力记忆？</a></li>
<li>知识蒸馏</li>
</ol>
<script>
window.onload = function () {
    $('colgroup').remove()
    }
</script>
]]></content>
      <categories>
        <category>notes</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>rnn</tag>
      </tags>
  </entry>
  <entry>
    <title>git学习记录</title>
    <url>/posts/a72e4bb6.html</url>
    <content><![CDATA[<p>本文是在学习<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000" target="_blank" rel="noopener">该教程</a>时/后做的笔记。 我现在用git基本都是用<a href="https://desktop.github.com/" target="_blank" rel="noopener">Github Desktop</a>，前面的是下载地址。用起来方便又快捷。事实上我也不会用git的命令o(<em>￣︶￣</em>)o所以今天稍微学一下。</p>
<h1 id="git-init">git init</h1>
<p>切换到想要创建仓库的文件夹，执行命令<code>git init</code>就会在该文件夹下创建一个.git的文件夹，这个文件夹是隐藏的。</p>
<h1 id="git-addgit-commit">git add/git commit</h1>
<p>使用命令<code>git add whatever.txt</code>将文件添加到仓库。使用命令<code>git commit -m &quot;wrote a file&quot;</code>将文件提交到仓库，-m后面的是描述这份文件你改了什么。其实就是相当于desktop的一个按钮，按一下就把全部有改动文件都提交了。 这样就完成了提交一份文件。这里就会有疑问了，为什么设计成先add再commit？直接commit不就行了？因为commit可以提交多份文件，你可以使用add命令一份一份地添加文件，再使用commit一次性提交到仓库。 该命令指示推送到本地仓库，并非远程仓库。 <a id="more"></a></p>
<h1 id="git-status">git status</h1>
<p>查看仓库当前的修改状态</p>
<h1 id="git-diff">git diff</h1>
<p>发现某份文件被修改了，但是忘记改了什么怎么办？使用命令<code>git diff modified_file.txt</code>查看，它会显示文件哪里被修改了。diff就是difference的意思。</p>
<h1 id="git-log">git log</h1>
<p>git可以记住你的历史提交版本，如果有一天电脑损坏，自己干了什么完全忘记，可以使用<code>git log</code>命令。它会显示以前所有的历史记录。这条命令会显示很详细的信息，但是就是因为信息太详细了，人可能看不过来，可以加上<code>--pretty=oneline</code>来限制。类似<code>c3fca95239a4bbe21ee2991e0a914fb522060e74</code>这种是版本号（commit id）。</p>
<h1 id="git-rest">git rest</h1>
<p>该命令可以回退版本。<code>git reset --hard HEAD^</code>，命令里的HEAD代表当前版本，^代表上一个版本，如果想要回退至前100个版本，可以使用HEAD~100。 也可以直接指定commit id，如<code>git reset --hard c3fca95239a4bbe21ee2991e0a914fb522060e74</code>，commit id可以不写全，写个开头就行了<code>git reset --hard c3fca</code> 注意回退版本后，如果关闭git bash那么就无法查询到该版本之后的所有版本。</p>
<h1 id="git-reflog">git reflog</h1>
<p>该命令记住了你每一步操作，如果回退版本后后悔了，可以使用该命令查询以前的commit id。</p>
<h1 id="git-checkout---filename">git checkout --filename</h1>
<p>把文件夹在工作区的修改全部撤销。总之，就是让这个文件回到最近一次git commit或git add时的状态。 参考<a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001374831943254ee90db11b13d4ba9a73b9047f4fb968d000" target="_blank" rel="noopener">文章</a></p>
<h1 id="git-rm">git rm</h1>
<p>删除文件，与linux命令类似。</p>
<h1 id="git-remote">git remote</h1>
<p>将本地的仓库和远程的仓库关联，使用命令<code>git remote add origin git@github.com:github_account_name/repository_name.git</code> 注意将github_account_name和repository_name分别替换成github账号名和仓库名。添加关联后，远程库的名字就是origin，这是Git默认的叫法，也可以改成别的。下一步，就可以把本地库的所有内容推送到远程库上。</p>
<h1 id="git-push">git push</h1>
<p><code>git push -u origin master</code> &gt;把本地库的内容推送到远程，用git push命令，实际上是把当前分支master推送到远程。 由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。 从现在起，只要本地作了提交，就可以通过命令： <code>git push origin master</code> 把本地master分支的最新修改推送至GitHub，现在，你就拥有了真正的分布式版本库！</p>
<h1 id="git-clone">git clone</h1>
<p>上面说了将本地仓库和远程仓库关联，并将本地仓库的文件推送到远程仓库，那么自然也可以从远程仓库clone文件到本地仓库。 使用命令：<code>git clone git@github.com:github_account_name/repository_name.git</code> 还可以从https://github.com/yan624/yan624.github.io.git这样的地址克隆</p>
<h1 id="对分支的管理">对分支的管理</h1>
<p>字太多，不想打了。看下面教程。 <a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375840038939c291467cc7c747b1810aab2fb8863508000" target="_blank" rel="noopener">教程</a></p>
<h2 id="git-checkout--b-branch_name">git checkout -b branch_name</h2>
<p>创建名为branch_name的分支并切换到该分支，-b参数代表切换。</p>
<h2 id="git-branch">git branch</h2>
<p>查看当前分支，如果分支之前有*就代表这个分支是主分支。</p>
<h2 id="git-merge-branch_name">git merge branch_name</h2>
<p>合并分支</p>
<h2 id="git-branch--d-branch_name">git branch -d branch_name</h2>
<p>删除名为branch_name分支</p>
<h2 id="合并分支发生冲突">合并分支发生冲突</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/001375840202368c74be33fbd884e71b570f2cc3c0d1dcf000" target="_blank" rel="noopener">解决办法</a></p>
<h2 id="强大的分支功能">强大的分支功能</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013758410364457b9e3d821f4244beb0fd69c61a185ae0000" target="_blank" rel="noopener">创建分支的策略</a></p>
<h2 id="bug分支将当前工作暂存先修改出现的bug">bug分支。将当前工作暂存，先修改出现的bug</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137602359178794d966923e5c4134bc8bf98dfb03aea3000" target="_blank" rel="noopener">暂存命令</a></p>
<h2 id="feature分支">feature分支</h2>
<p>与上面类似，无非概念不同</p>
<h2 id="多人协作">多人协作</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013760174128707b935b0be6fc4fc6ace66c4f15618f8d000" target="_blank" rel="noopener">教程</a></p>
<h2 id="git-rebase">git rebase</h2>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0015266568413773c73cdc8b4ab4f9aa9be10ef3078be3f000" target="_blank" rel="noopener">教程</a></p>
<h1 id="标签">标签</h1>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0015266568413773c73cdc8b4ab4f9aa9be10ef3078be3f000" target="_blank" rel="noopener">教程</a></p>
<h1 id="使用github">使用github</h1>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0015266568413773c73cdc8b4ab4f9aa9be10ef3078be3f000" target="_blank" rel="noopener">教程</a></p>
<h1 id="使用码云">使用码云</h1>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00150154460073692d151e784de4d718c67ce836f72c7c4000" target="_blank" rel="noopener">教程</a></p>
<h1 id="配置文件的更多配置">配置文件的更多配置</h1>
<p><a href="https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00150154460073692d151e784de4d718c67ce836f72c7c4000" target="_blank" rel="noopener">教程</a></p>
]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>4me</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>ViewPager无法刷新数据</title>
    <url>/posts/e6412665.html</url>
    <content><![CDATA[<p>实现ViewPager刷新数据功能，在网上找了很多资料都已经过时了。 由于本人并不是android开发出身，完全是做app玩的。所以很多术语都不知道，如果看不懂就算了。。。 实现PagerAdapter类，我命名为HomePagerAdapter <a id="more"></a> <figure class="highlight aspectj"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HomePagerAdapter</span> <span class="keyword">extends</span> <span class="title">PagerAdapter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> ArrayList&lt;View&gt; pageView;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HomePagerAdapter</span><span class="params">(ArrayList&lt;View&gt; pageView)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.pageView = pageView;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> mChildCount = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">notifyDataSetChanged</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        mChildCount = getCount();</span><br><span class="line">        <span class="keyword">super</span>.notifyDataSetChanged();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">int</span> <span class="title">getItemPosition</span><span class="params">(Object object)</span>   </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> ( mChildCount &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            mChildCount --;</span><br><span class="line">            <span class="keyword">return</span> POSITION_NONE;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">return</span> <span class="keyword">super</span>.<span class="title">getItemPosition</span><span class="params">(object)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//获取当前窗体界面数</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">int</span> <span class="title">getCount</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">        <span class="function"><span class="keyword">return</span> pageView.<span class="title">size</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//判断是否由对象生成界面</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">boolean</span> <span class="title">isViewFromObject</span><span class="params">(View arg0, Object arg1)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">        <span class="keyword">return</span> arg0==arg1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">destroyItem</span><span class="params">(ViewGroup container, <span class="keyword">int</span> position, Object object)</span> </span>&#123;</span><br><span class="line">        container.removeView(pageView.get(position));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function">Object <span class="title">instantiateItem</span><span class="params">(ViewGroup container, <span class="keyword">int</span> position)</span> </span>&#123;</span><br><span class="line">        View view = pageView.get(position);</span><br><span class="line">        container.addView(view);</span><br><span class="line">        <span class="keyword">return</span> view;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">finishUpdate</span><span class="params">(ViewGroup container)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(container.getChildCount() == <span class="number">0</span>)&#123;</span><br><span class="line">            pageView.clear();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 注意destroyItem、instantiateItem方法，PagerAdapter中还有两个同名的方法，但是已被废弃，注意参数不同。 实现刷新数据主要在destroyItem、instantiateItem、finishUpdate三个方法。其他的方法其实别人的教程也写了，但是我这三个方法是我自己研究的，我没见别人写过。</p>
<p>解释流程。 第一步，改变数据，我是将数据保存在了<code>private ArrayList&lt;View&gt; pageView;</code>中。 第二步，调用<code>adapter.notifyDataSetChanged();</code>方法，它首先会销毁item，即调用<code>destroyItem(ViewGroup container, int position, Object object)</code>方法。随即调用<code>instantiateItem(ViewGroup container, int position)</code>方法。 一般来说大家都是这么干的，因为将数据改变后，调用<code>adapter.notifyDataSetChanged();</code>方法。直觉认为这么做合乎常理。 但是这里注意一点，假设<code>private ArrayList&lt;View&gt; pageView;</code>中原先保存两个View，改变数据将这个View删除，从新添加三个新的View，那么在<code>destroyItem(ViewGroup container, int position, Object object)</code>方法中，它无法删除，仔细看里面的代码<code>container.removeView(pageView.get(position));</code>，发现它是通过position这个索引获取对象，再在container容器中通过对象查找删除。那么问题来了，你之前已经将两份View删除了，它还怎么通过position获取到呢？所以在这一步出了问题。 当然这一步出了问题后，后面的创建页面步骤更是稀巴烂。</p>
<p>正确步骤如下： <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 将页面刷新，渲染新的数据集</span></span><br><span class="line">homePagerAdapter.notify<span class="constructor">DataSetChanged()</span>;</span><br><span class="line">change<span class="constructor">Data(<span class="params">inflater</span>, <span class="params">data</span>)</span>;</span><br><span class="line">homePagerAdapter.notify<span class="constructor">DataSetChanged()</span>;</span><br></pre></td></tr></table></figure> 第一步，不要更改数据，直接调用<code>homePagerAdapter.notifyDataSetChanged();</code>，目的是让其删除原先的view。 第二步，更改数据。 第三步，再次调用<code>homePagerAdapter.notifyDataSetChanged();</code>，完成页面的创建。由于container中已经没有view了，所以删除那个步骤做了也等于没做，但是由于数据已经更新页面还是会被创建出来。</p>
<p>最后强调用一点。在HomePagerAdapter类中一个<code>finishUpdate(ViewGroup container)</code>方法，注意看里面的代码。<strong>以上的所有步骤，全部依赖于这几句代码。</strong> 上面第一步说到直接调用notifyDataSetChanged()方法目的是删除原先的view，但是view删除后，你必须将<code>private ArrayList&lt;View&gt; pageView;</code>中的数据也删除。<strong>这里补充一点，pageView内是我创建的View，而container中是android自己维护的界面</strong>，我也不知道怎么称呼，就将其称为界面吧。 在finishUpdate()方法中判断，如果container中已经没有界面了，那就直接移除pageView中所有的数据，也就是算更新数据了。值得注意的是，这里面逻辑及其复杂，这行清空数据的代码，只有放在<code>finishUpdate(ViewGroup container)</code>中执行，并且必须加上那个if条件判断，app才能正常运行。 <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>android</category>
      </categories>
  </entry>
  <entry>
    <title>在写了大量内容以及大量数学表达式后，mathJax无法渲染数学表达式</title>
    <url>/posts/b6508bb7.html</url>
    <content><![CDATA[<p>之前写的数学表达式明明可以渲染，但是接下去隔了n行的数学表达式无法渲染。推测是因为单行数学表达式在文字前面换行。 比如说： &gt;文字文字文字文字：·￥￥· 该表达式渲染正常。</p>
<p>如果， &gt;文字文字文字文字： ·￥￥· 那么下面的数学表达式将全部无法渲染。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Android开发，使用腾讯云的API请求对象存储中的资源始终失败</title>
    <url>/posts/f076a4cb.html</url>
    <content><![CDATA[<ol type="1">
<li>腾讯云api内部在调用时，把url转义了。我的链接是http://###.cos.ap-shanghai.myqcloud.com/11111/app_list.txt?abcdefg，它内部给我转义成http://###.cos.ap-shanghai.myqcloud.com/11111/app_list.txt%3Fabcdefg，就是把&quot;?&quot;转义成了&quot;%3F&quot;。总而言之，我使用api一直获取不到资源，然后我在浏览器上试验了一下。发现把%3F改回?就可以访问了，实际上应该不是这样，反正就给我产生了误导。我想尽办法都不能将其转义回来，最后只好放弃。腾讯云api内部肯定自己转义了一下，真的坑爹。</li>
<li>尝试自己写代码请求资源，结果发现如果url的协议是https就可以访问到资源了。这可能是android的问题，于是我又使用腾讯的api，配置更改如下： <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">CosXmlServiceConfig serviceConfig = <span class="keyword">new</span> <span class="constructor">Builder()</span></span><br><span class="line">				.is<span class="constructor">Https(<span class="params">true</span>)</span></span><br><span class="line">                .set<span class="constructor">Region(<span class="params">region</span>)</span></span><br><span class="line">                .set<span class="constructor">Debuggable(<span class="params">true</span>)</span></span><br><span class="line">                .builder<span class="literal">()</span>;</span><br></pre></td></tr></table></figure> 将isHttps设为ture，协议就改为了https。可是又报了另一个错：The specified key does not exist.它说我密钥不存在。</li>
<li>如果使用http协议访问就会说无法解析域名，总之用腾讯云的api无法访问到资源就对了。</li>
<li>放弃腾讯云的api，自己手写代码去请求资源！</li>
</ol>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>android</category>
      </categories>
      <tags>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title>对神经网络整体的理解</title>
    <url>/posts/b803ed7e.html</url>
    <content><![CDATA[<div class="note info"><p>本文虽然理了一遍神经网络的知识点，但还是有些地方不明白，文中对此进行了提问。</p>
</div>
<h1 id="大纲">大纲</h1>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">序号</th>
<th>描述的内容</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2~4</td>
<td>神经网络和深度学习的发展史。</td>
</tr>
<tr class="even">
<td style="text-align: center;">5</td>
<td>从二元分类开始。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">6~10</td>
<td>浅层神经网络的介绍。如神经网络中一些参数代表的意思、激活函数、梯度下降、随机初始化。</td>
</tr>
<tr class="even">
<td style="text-align: center;">11~15</td>
<td>深层神经网络的介绍。正向传播和反向传播中向量化后的计算、参数和超参数、神经网络和大脑的关系。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">16</td>
<td>一个Simple NN的例子。</td>
</tr>
<tr class="even">
<td style="text-align: center;">17~22</td>
<td>深度学习的实用性层面。数据切分、偏差与方差、正则化、dropout、其他正则化方法、均值归一化、梯度消失和梯度爆炸、梯度检验。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">23~25</td>
<td>一些优化算法。Mini-batch、指数加权平均、Momentum、RMSprop、Adam、Adagrad。</td>
</tr>
<tr class="even">
<td style="text-align: center;">26~29</td>
<td>超参数调试、Batch正则化、激活函数以及一些深度学习框架。</td>
</tr>
<tr class="odd">
<td style="text-align: center;">30~end</td>
<td>本文略长，后序的文章请看对应章节的链接。</td>
</tr>
</tbody>
</table>
<a id="more"></a>
<h1 id="神经网络和深度学习的发展">神经网络和深度学习的发展</h1>
<p>TODO</p>
<h1 id="神经网络和深度学习的关系">神经网络和深度学习的关系</h1>
<p>TODO</p>
<h1 id="为什么要深度学习">为什么要深度学习</h1>
<p>TODO</p>
<h1 id="从二元分类开始">从二元分类开始</h1>
<p>暂时省略，因为这里已经会了。</p>
<h1 id="神经网络的表示">神经网络的表示</h1>
<p>规定如下，l：第几层；w：权重值；b：偏差；z：输出值；a：激活值；i，j：都代表第几个神经元，如<span class="math inline">\(w^l_i\)</span>代表第l层的第i个权重值；W：向量化后的权重值；Z：向量化后的输出值；A：向量化后的激活值；<span class="math inline">\(\alpha\)</span>：学习速率；<span class="math inline">\(\lambda\)</span>：正则化项；</p>
<p>如果输出值z和激活值a无法理解或者区分，没关系，继续往下看就知道了。 如下图所示，一般规定input layer为第0层，不算入神经网络的层数中，所以下图是一个三层神经网络架构。 1. input layer的输入值被称为x，下图一共有三个输入所以分别被称为<span class="math inline">\(x_1\ x_2\ x_3\)</span>。为了方便起见，可以将input layer的值x以<span class="math inline">\(a^0\)</span>来代替，下面解释a代表什么。 2. hidden layer中的值被称为a——<strong>激活值</strong>（activations），图中有四个神经元，所以分别被称为<span class="math inline">\(a^1_1\ a^1_2\ a^1_3\)</span>，上标代表着所在神经网络中的第几层，下标代表着所在层中的第几个神经元。如果表示成向量形式就是 <span class="math display">\[
\begin{pmatrix}
    x_1\\
    x_2\\
    x_3\\
\end{pmatrix} = 
\begin{pmatrix}
    a^0_1\\
    a^0_2\\
    a^0_3\\
\end{pmatrix} 和
\begin{pmatrix}
    a^1_1\\
    a^1_2\\
    a^1_3\\
    a^1_4\\
\end{pmatrix} 和
\begin{pmatrix}
    a^2_1\\
    a^2_2\\
    a^2_3\\
    a^2_4\\
\end{pmatrix} 和
\begin{pmatrix}
    a^3_1\\
\end{pmatrix}
\]</span></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%8E%9F%E5%9B%BE.jpg" alt="神经网络架构原图" /><figcaption>神经网络架构原图</figcaption>
</figure>
<h2 id="神经网络中神经元的一些参数的含义特别解释w的含义">神经网络中神经元的一些参数的含义，特别解释w的含义</h2>
<p>hidden layer和output layer的每个神经元都有几个参数。分别为<span class="math inline">\(w^l\ b^l\)</span>，对照上图，这里的<span class="math inline">\(w^l\)</span>是一个(4,3)的矩阵，<span class="math inline">\(b^l\)</span>是一个(4,1)的向量。解释如下： <span class="math display">\[
\begin{cases}
    z^1_1 = a^0_1 * w^1_{11} + a^0_2 * w^1_{12} + a^0_3 * w^1_{13} + b^1_1\\
    z^1_2 = a^0_1 * w^1_{21} + a^0_2 * w^1_{22} + a^0_3 * w^1_{23} + b^1_2\\
    z^1_3 = a^0_1 * w^1_{31} + a^0_2 * w^1_{32} + a^0_3 * w^1_{33} + b^1_3\\
    z^1_4 = a^0_1 * w^1_{41} + a^0_2 * w^1_{42} + a^0_3 * w^1_{43} + b^1_4\\
\end{cases}
\]</span> 可以看到一个公式中有三个w和一个b，一共有四个公式。<span class="math inline">\(w^l_{ij}\)</span>代表第l-1层的第j个神经元到第l层的第i个神经元上的w。如<span class="math inline">\(w^1_{12}\)</span>代表第0层的第2个神经元到第1层的第1个神经元上的w。注意这里的i和j实际上是与直觉相反的，也就是说按直觉来看应该是<span class="math inline">\(w^l_{ji}\)</span>才正常。如果对w的表示有疑惑的，可以看<a href="https://yan624.github.io/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%E4%B8%ADweight%E7%9A%84%E8%A1%A8%E7%A4%BA%E9%97%AE%E9%A2%98.html">这篇</a>。 注意下这里的z是<strong>输出值</strong>，之前一直在说hidden layer中的值是a——激活值，其实a就是将z放到一个<strong>激活函数</strong>（activation function）中得到的一个值，这个激活函数是随用户挑选的，如果不能理解激活函数是什么，就暂时理解为激活函数自己想设成什么就设成什么。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg" alt="神经网络架构图" /></p>
<h1 id="神经网络中的输出是怎么计算的">神经网络中的输出是怎么计算的</h1>
<h2 id="以一个样本为例">以一个样本为例</h2>
<p>第0层是输入层，所以是不需要计算的，x我本来就有，我还计算什么？对吧。从hidden layer1开始到output layer每一层都需要计算一连串的值，下面给出第一层的计算公式： <span class="math display">\[
\begin{cases}
    z^1_1 = a^0_1 * w^1_{11} + a^0_2 * w^1_{12} + a^0_3 * w^1_{13} + b^1_1，a^1_1 = \sigma(z^1_1)\\
    z^1_2 = a^0_1 * w^1_{21} + a^0_2 * w^1_{22} + a^0_3 * w^1_{23} + b^1_2，a^1_2 = \sigma(z^1_2)\\
    z^1_3 = a^0_1 * w^1_{31} + a^0_2 * w^1_{32} + a^0_3 * w^1_{33} + b^1_3，a^1_3 = \sigma(z^1_3)\\
    z^1_4 = a^0_1 * w^1_{41} + a^0_2 * w^1_{42} + a^0_3 * w^1_{43} + b^1_4，a^1_3 = \sigma(z^1_4)\\
\end{cases}
\]</span> 这里的<span class="math inline">\(\sigma(z)\)</span>函数其实就是上面说的<strong>激活函数</strong>，一般来讲<span class="math inline">\(\sigma\)</span>这个符号特指sigmoid function: <span class="math inline">\(\frac{1}{1+e^{-z}}\)</span>。 这4行公式其实在上面已经给出部分，每一行包含两个公式，也就是说一个神经元中实际上先得到了z，然后再通过激活函数将z转为a。这里可能会有疑惑，已经得到z了为什么还要用一个函数将z转为a呢？这样不是毫无意义？下面有一部分会具体解释，也可以看下面几篇的解释： <a href="https://www.zhihu.com/question/22334626" target="_blank" rel="noopener">神经网络激励函数的作用是什么？有没有形象的解释？</a> <a href="https://blog.csdn.net/program_developer/article/details/78704224" target="_blank" rel="noopener">神经网络激活函数的作用是什么？</a> 现在回到本文，正如我上面所说，我一共写了四个公式（激活函数现在暂时不看），所以我要分别计算四个公式，也就是说要计算四次。那么有没有办法只计算一次就得到所有结果呢？答案是<strong>向量化</strong>（vectorization），现在开始用向量化来解决这个问题。 <span class="math display">\[
\begin{pmatrix}
    z^1_1\\
    z^1_2\\
    z^1_3\\
    z^1_4\\
\end{pmatrix} = 
\begin{pmatrix}
    w^1_{11}&amp;w^1_{12}&amp;w^1_{13}\\
    w^1_{21}&amp;w^1_{22}&amp;w^1_{23}\\
    w^1_{31}&amp;w^1_{32}&amp;w^1_{33}\\
    w^1_{41}&amp;w^1_{42}&amp;w^1_{43}\\
\end{pmatrix} *
\begin{pmatrix}
    a^0_1\\
    a^0_2\\
    a^0_3\\
\end{pmatrix} + 
\begin{pmatrix}
    b^1_1\\
    b^1_2\\
    b^1_3\\
    b^1_4\\
\end{pmatrix} 
\]</span> <span class="math inline">\(===&gt;\ z^1 = w^1 * a^0 + b^1\)</span> 以下是整个神经网络的计算过程，也就是说只需要下面6行就可以代替上文占据几个屏幕的内容。 <span class="math display">\[
\begin{array}{c|}
    z^1 = w^1 * a^0 + b^1\\
    a^1 = \sigma(z^1)\\
    z^2 = w^2 * a^1 + b^2\\ 
    a^2 = \sigma(z^2)\\
    z^3 = w^3 * a^2 + b^3\\
    a^3 = \sigma(z^3)\\ 
\end{array} =&gt;记为P
\]</span> 最后一个a就是整个神经网络的输出值，也就是预测值（prediction），也可以用<span class="math inline">\(\hat{y}\)</span>表示，自然<span class="math inline">\(\hat{y} = a^3\)</span>。</p>
<h2 id="向量化计算多个样本">向量化计算多个样本</h2>
<p>上面我没有特意地说明其实我们只使用了一个样本，我们一直在使用<span class="math inline">\(a^0_1\ a^0_2\ a^0_3\)</span>，但是<span class="math inline">\(a^0_1\ a^0_2\ a^0_3\)</span>实际上只是<strong>一个</strong>样本。<span class="math inline">\(a^0\)</span>代表的是一个样本，<span class="math inline">\(a^0_1\)</span>代表的是样本中的第一个特征，如果不明白我可以举个例子：<span class="math inline">\(a^0_1\)</span>代表天气样本中的第一个特征——温度，<span class="math inline">\(a^0_2\)</span>代表湿度，<span class="math inline">\(a^0_3\)</span>代表PM2.5，<span class="math inline">\(a^0\)</span>代表整一个天气样本。 那么如果有成千上万个样本，总不能使用P计算成千上万次吧。这里再次使用向量化进行计算。 <span class="math display">\[
\begin{pmatrix}
    z^{11}_1&amp;z^{12}_1&amp;\cdots\\
    z^{11}_2&amp;z^{12}_2&amp;\cdots\\
    z^{11}_3&amp;z^{12}_3&amp;\cdots\\
    z^{11}_4&amp;z^{12}_4&amp;\cdots\\
\end{pmatrix} = 
\begin{pmatrix}
    w^1_{11}&amp;w^1_{12}&amp;w^1_{13}\\
    w^1_{21}&amp;w^1_{22}&amp;w^1_{23}\\
    w^1_{31}&amp;w^1_{32}&amp;w^1_{33}\\
    w^1_{41}&amp;w^1_{42}&amp;w^1_{43}\\
\end{pmatrix} *
\begin{pmatrix}
    a^{01}_1&amp;a^{01}_1&amp;\cdots\\
    a^{01}_2&amp;a^{02}_1&amp;\cdots\\
    a^{01}_3&amp;a^{03}_1&amp;\cdots\\
\end{pmatrix} + 
\begin{pmatrix}
    b^1_1\\
    b^1_2\\
    b^1_3\\
    b^1_4\\
\end{pmatrix}
\]</span> <span class="math inline">\(===&gt;\ z^1 = w^1 * a^0 + b^1\)</span> <span class="math display">\[
\begin{pmatrix}
    z^{21}_1&amp;z^{22}_1&amp;\cdots\\
    z^{21}_2&amp;z^{22}_2&amp;\cdots\\
    z^{21}_3&amp;z^{22}_3&amp;\cdots\\
    z^{21}_4&amp;z^{22}_4&amp;\cdots\\
\end{pmatrix} = 
\begin{pmatrix}
    w^2_{11}&amp;w^2_{12}&amp;w^2_{13}&amp;w^2_{14}\\
    w^2_{21}&amp;w^2_{22}&amp;w^2_{23}&amp;w^2_{24}\\
    w^2_{31}&amp;w^2_{32}&amp;w^2_{33}&amp;w^2_{34}\\
    w^2_{41}&amp;w^2_{42}&amp;w^2_{43}&amp;w^2_{44}\\
\end{pmatrix} *
\begin{pmatrix}
    a^{11}_1&amp;a^{11}_1&amp;\cdots\\
    a^{11}_2&amp;a^{12}_1&amp;\cdots\\
    a^{11}_3&amp;a^{13}_1&amp;\cdots\\
    a^{11}_3&amp;a^{14}_1&amp;\cdots\\
\end{pmatrix} + 
\begin{pmatrix}
    b^2_1\\
    b^2_2\\
    b^2_3\\
    b^2_4\\
\end{pmatrix}
\]</span> <span class="math inline">\(===&gt;\ z^2 = w^2 * a^1 + b^2\)</span> 省略号代表后面有无数个样本，同理矩阵相乘也可以只用一个字母表示。上标的第二个数字代表是第几个样本，第一个数字依旧是代表所属第几层。</p>
<h1 id="激活函数">※ 激活函数</h1>
<p><a href="https://blog.csdn.net/program_developer/article/details/78704224" target="_blank" rel="noopener">神经网络激活函数的作用是什么？</a></p>
<table>
<colgroup>
<col style="width: 57%" />
<col style="width: 42%" />
</colgroup>
<thead>
<tr class="header">
<th>激活函数名称</th>
<th>如何选择</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sigmoid</td>
<td><strong>输出层</strong>为<strong>二元分类</strong>时选用。对于隐藏层来说，基本不会用 sigmoid 函数，因为现在已经有更好的激活函数<br /> <strong>缺点</strong>：1）会产生梯度消失/弥散（<strong>注：sigmoid 不会导致梯度爆炸</strong>），详见下面的 Sigmoid 章节；2）不是原点对称；3）计算 exp 较耗时。</td>
</tr>
<tr class="even">
<td>tanh</td>
<td><strong>优点</strong>：1）原点对称；2）比 sigmoid 快。<br /> <strong>缺点</strong>：1）还是有梯度消失</td>
</tr>
<tr class="odd">
<td><strong>ReLU</strong></td>
<td>首选 ReLU，如果 ReLU 不行，再换其他形式的 ReLU。<a href="https://github.com/llSourcell/Which-Activation-Function-Should-I-Use" target="_blank" rel="noopener">观点来源</a><br /> <strong>优点</strong>：1）解决了部分梯度消失问题；2）收敛速度更快。<br /> <strong>缺点</strong>：1）梯度消失的问题没有完全解决，在激活函数（-）部分相当于让神经元死亡，且无法复活。</td>
</tr>
<tr class="even">
<td>Leaky ReLU</td>
<td></td>
</tr>
<tr class="odd">
<td>Parametric ReLU</td>
<td></td>
</tr>
<tr class="even">
<td>Randomized ReLU</td>
<td></td>
</tr>
<tr class="odd">
<td>ELU</td>
<td></td>
</tr>
<tr class="even">
<td>SELU</td>
<td></td>
</tr>
<tr class="odd">
<td>GELU</td>
<td></td>
</tr>
<tr class="even">
<td>Swish</td>
<td></td>
</tr>
<tr class="odd">
<td>softmax</td>
<td><strong>输出层</strong>为<strong>多元分类</strong>时选用。只适合于输出层</td>
</tr>
<tr class="even">
<td>log_softmax</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="sigmoid">Sigmoid</h2>
<p>上文中我们一直假设使用 sigmoid function 作为激活函数。但是事实上还有很多其他选择，甚至其他的激活函数比sigmoid funtion效果要更好。 上面讲过<span class="math inline">\(\sigma(z)\)</span>特指 sigmoid function，现在我们将表达式改为：<span class="math inline">\(a = g(z)\)</span>，用g来表示激活函数，它可以是线性的，也可以是非线性的。 引用吴恩达在深度学习视频中的话： &gt; 有一个函数总是比 sigmoid function 表现得更好，就是tanh函数或者叫双曲正切函数，公式为：<span class="math inline">\(\frac{e^z-e^{-z}}{e^z+e^{-z}}, \, x\in(-1,1)\)</span>，在数学上实际是<span class="math inline">\(\sigma\)</span>函数平移后的版本。 &gt; <strong>事实证明，如果将<span class="math inline">\(g(z)\)</span>选为 tanh 函数，效果几乎总比 <span class="math inline">\(\sigma(z)\)</span> 函数要好。</strong></p>
<p>有一个例外是 output layer，它还是使用 sigmoid funtion，因为 output layer 跟普通的分类问题没什么区别，它要得到0~1之间的一个概率。 sigmoid function 的值总是位于 0~1 之间，tanh function 的值总是位于 -1~1 之间。 <div class="note warning"><p>在 CNN 中 ReLu 激活函数可能是首选，但是对于 RNN 来说，首选是 tanh，而不是 relu。</p>
</div></p>
<h3 id="缺陷">缺陷</h3>
<p>Sigmoid 函数将导致梯度消失。梯度的问题，在下面的章节（21 章左右）中会有讲到，但是此部分只讲 sigmoid 函数的梯度消失问题。 首先我们脑中大概有个 sigmoid 函数的图像，这应该很简单。注意函数的两边，我们发现函数曲线在 <span class="math inline">\(-\infty\)</span> 方向越来越接近 0，在 <span class="math inline">\(\infty\)</span> 方向越来越接近 1。以正方向为例，我们可以得知输入 sigmoid 的值越大，sigmoid 的输出值越接近 1。 做一个小小的测试，当输入值为 3 时，输出值为 0.9526，当输入值为 9 时，输出值为 0.9999。可以观察发现，输入值相差巨大的情况下，输出值居然相差无几。当然如果举一个更极端的例子，比如输入 20 和 2000，就会发现输出值都非常接近 1，详见下图。也就是说，输入值相差巨大，但是经过 sigmoid 之后，输出值居然相差无几。<strong>换句话说就是一个值在经过 sigmoid 之后被衰减了</strong>。通俗来讲，我管你是 2000 还是 20000000，只要经过我 sigmoid，你输出就只能是一个接近 1 的数。这样就是被衰减了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/对神经网络整体的理解/sigmoid梯度消失.jpg" alt="sigmoid梯度消失" /></p>
<p>其次我们又知道对于一个神经网络而言，它一般会叠的很深，四五层都很常见。有了以上两个基础，下面举个具体的例子。 我们知道梯度下降算法的公式是 <span class="math inline">\(W = W - \alpha \Delta W\)</span>，在进行一次梯度下降后，对于 W 来说，<strong>变化</strong>就是 <span class="math inline">\(\alpha \Delta W\)</span>，不严格的说其实只有 <span class="math inline">\(\Delta W\)</span>。然后将新的 W 传入 sigmoid 函数，我们就会发现 <span class="math inline">\(\Delta W\)</span> 被衰减了（为什么会衰减上面已经说过了）。而 <span class="math inline">\(\Delta W\)</span> 其实是<strong>梯度</strong>，也就是说梯度被衰减了，然后再经过多层神经网络之后，梯度被一减再减。 综上所述，梯度在第一层可能很大，在经过几层 sigmoid 函数之后，可能就<strong>减</strong>没了。 <strong>不过，由于 sigmoid 导数的取值范围是 (0, 0.25)，所以梯度也不会很大，但是这仍然架不住多层的神经网络</strong>。</p>
<h2 id="relu">ReLU</h2>
<p>但是不管是<span class="math inline">\(\sigma\)</span>或者tanh函数都一个缺点，那就是当z非常大或者非常小时，函数的斜率（导数的梯度）很小。这样会拖慢梯度下降。在机器学习中还有一个函数，即ReLU函数——Rectified Linear Unit，表达式为<span class="math inline">\(max(0, z)\)</span>。 所以在选择激活函数时有一些经验法则： 1. 如果你的输出值是0或1，那么<span class="math inline">\(\sigma\)</span>函数很适合做output layer的激活函数，非二元分类的情况下使用tanh函数几乎都比<span class="math inline">\(\sigma\)</span>优越。藏层单元全用ReLU函数，现在ReLU函数已经是隐藏层的默认激活函数了，大多数人都这么做。 2. 还有个叫Leaky ReLU的函数比ReLU稍微好点，但是目前暂时不是很多人用。</p>
<h2 id="softmax回归">Softmax回归</h2>
<p>Sogmoid函数<span class="math inline">\(\sigma = \frac{1}{1 + e^{-z}}\)</span>适用于二元分类，那么碰到多元分类怎么么办呢？Softmax函数就可以解决这个问题。 Softmax函数计算步骤如下，假设是n元分类： <span class="math display">\[
Z^L = W^L * A^{L-1} + b^L\\
t = e^{Z^L}\\
A^L = \frac{e^{Z^L}}{\sum^n_{i=1}t_i},\quad A^L_i = \frac{t_i}{\sum^n_{i=1}t_i}\\
\]</span> 多元分类中每一个神经元代表对应标签的概率是多少，并且将概率相加等于1。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/softmax%E4%BE%8B%E5%AD%90.jpg" alt="softmax例子" /></p>
<h2 id="为什么需要非线性激活函数">为什么需要非线性激活函数</h2>
<div class="note info"><p>为什么<span class="math inline">\(w*x+b=z\)</span>之后，需要使用一个激活函数<span class="math inline">\(a = \sigma(z)\)</span>？不能不加这个激活函数吗？权重值乘上输入值加上偏差之后直接输出就行了，何必再带入激活函数中？</p>
</div>
<p>由于y=bx+c是线性函数，只不过将输入值乘了一个常量并进行位移而已，所以使用非y=bx+c型的激活函数就算是使用了非线性函数。而在神经元中不加激活函数，实际上就是把激活函数设置成y=x这个函数。 那么现在从头再做一次神经网络计算，与上面的区别是这次不加激活函数。 <span class="math display">\[
\left \{ 
    \begin{array}{ll}
        a^1 = w^1 * a^0 + b^1 \qquad这是计算第一层的激活值，现在没有使用激活函数。\\
        a^2 = w^2 * a^1 + b^2 \qquad这是计算第二次的激活值，也没有使用激活函数。\\
        a^2 = w^2 * (w^1 * a^0 + b^1) + b^2 \qquad消掉a^1，两式合并之后\\
        a^2 = w^2 * w^1 * a^0 + w^2 * b^1 + b^2 \qquad合并同类项后\\
        a^2 = w&#39; * a^0 + b&#39; \qquad由于w和b只是一堆常数，所以将w&#39;代替w^2 * w^1，b&#39;同理
    \end{array}
\right. 
\]</span> 通过上面几个式子发现，我们计算了第一层和第二层之后，结果居然还是一个线性的式子，和最初的输入没有什么差别，也就是说你无论叠了几层hidden layer最后输出还是类似<span class="math inline">\(a^2 = w&#39; * a^0 + b&#39;\)</span>的式子，那么深度学习的意义在哪呢？还不如直接把hidden layer去掉。所以重点就是线性的hidden layer没有任何用处，因为两个线性方程的组合结果还是线性方程。 只有在一个地方可以使用线性方程，那就是回归问题——线性回归。</p>
<h1 id="梯度下降反向传播算法backpropagation解析">梯度下降，反向传播算法——backpropagation解析</h1>
<div class="note primary"><p>Q：首先虽然全部的过程已经理清，但是还有几个问题：为什么要对w求导？梯度下降的意义是什么？为什么使用梯度下降就可以解决误差问题？ A：（2020.2.21） 1. <a href="https://yan624.github.io/·zcy/AI/ml/梯度下降算法的推导.html">梯度下降算法的推导</a> 2. <a href="https://yan624.github.io/·zcy/AI/深度学习500问笔记.html#词向量乘上权重以及做梯度下降有什么意义">深度学习500问笔记#词向量乘上权重以及做梯度下降有什么意义</a></p>
</div>
<p>本节的示例均建立在一个样本的情况下，如果是多个样本经过神经网络，可能略微不同。我看了吴恩达老师的深度学习课程，发现多个样本与一个样本的区别，可能只在偏差b那里会有点不同。 下图以一个三层神经网络为例，说明正向与反向传播过程。由于神经元之间的链接太多会导致混乱，所以下图只链接了第一个神经元。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E4%BD%BF%E7%94%A8%E5%AF%BC%E6%95%B0%E8%A7%A3%E9%87%8A%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95.jpg" alt="使用导数解释反向传播算法" /> 下图略微简化一下反向传播算法中的导数项，并且完成了最后的权重值优化。值得注意的是：如果cost function不同，下面求导结果会略微不同，本文统一使用<span class="math inline">\(cost = \frac{1}{m} * \sum{(\hat{y} - y)^2}\)</span>，但是神经网络一般是使用<strong>交叉熵</strong>——crossentropy，其公式为：<span class="math inline">\(cost = -\frac{1}{m} * (y * log(\hat{y}) + (1 - y) * log(1 - \hat{y}))\)</span>。使用前者，<span class="math inline">\(\frac{\partial{J}}{\partial{z^{(3)}}} = (a^{(3)} - y) * g&#39;(z^{(3)})\)</span>；如果使用后者，<span class="math inline">\(\frac{\partial{J}}{\partial{z^{(3)}}} = a^{(3)} - y\)</span>。可以看到使用两个不同的代价函数，会有不同的结果，这是因为两个函数求导的结果不一样。而两者对表达式<span class="math inline">\(\frac{\partial{J}}{\partial{z^{(3)}}}\)</span>的结果只差了一个<span class="math inline">\(g&#39;(z^{(3)})\)</span>，这完全是巧合罢了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E7%AE%80%E5%8C%96%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95.jpg" alt="简化反向传播算法" /> <strong>另外再提醒一下自己，这里全是以一个样本为例。但是仅仅这样权重已经是一个二维矩阵了，要是如果传入多个样本，权重岂不是是一个三维矩阵？然而不管传入几个样本权重实际上对于不同的样本是没有变化的，所以还是二维矩阵。</strong></p>
<h1 id="随机初始化">※ 随机初始化</h1>
<p>对于逻辑回归可以将<strong>权重</strong>（weight）全部初始化为0，但是对于神经网络来说，将个权重初始化为0，再使用梯度下降会完全无效。实际上将偏差b初始化为0是可以的，但是权重不行。 解释起来太麻烦，详情看吴恩达深度学习——01神经网络和深度学习第三周浅层神经网络，3.11随机初始化。吴恩达老师解释地还是很清楚的。 可以像以下这样设置weight：<span class="math inline">\(w^l = np.random.randn((2, 2)) * 0.01\)</span>//这可以产生参数为(2, 2)的高斯分布随机变量，后面再成一个很小的数，比如0.01。而对于b，之前说了初始化为0也可以。 对于上式的0.01可能会感到很疑惑，为什么要乘这么一个值。因为我们一般将weight初始化为很小的值，如果weight值很大，最终导致z也很大，那么会落在sigmoid function或者tanh function的平缓部分，会使梯度的写了很小，意味着梯度下降算法会非常慢，所以学习得很慢。</p>
<h2 id="初始化补充">初始化补充</h2>
<p>经在作业中做的测试得出如下结论：</p>
<table>
<thead>
<tr class="header">
<th><strong>Model</strong></th>
<th><strong>Train accuracy</strong></th>
<th><strong>Problem/Comment</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>3-layer NN with <strong>zeros initialization</strong></td>
<td>50%</td>
<td>fails to break symmetry</td>
</tr>
<tr class="even">
<td>3-layer NN with large <strong>random initialization</strong></td>
<td>83%</td>
<td>too large weights</td>
</tr>
<tr class="odd">
<td>3-layer NN with <strong>He initialization</strong></td>
<td>99%</td>
<td><strong>recommended method</strong></td>
</tr>
</tbody>
</table>
<p>其中&quot;He initialization&quot;最近（论文是2015年的）新搞出来得初始化算法，现在推荐使用此算法进行初始化。</p>
<h1 id="核对矩阵维数">核对矩阵维数</h1>
<p>w的维数应该与dw的维数相同。b和db的维数相同</p>
<h1 id="为什么使用深度表示why-deep-representations">为什么使用深度表示——Why deep representations</h1>
<p>引用在2017course深度学习课程上吴恩达老师的话 &gt;深度神经网络能解决很多问题，其实并不需要很大的神经网络，但是得有深度。得有比较多的隐藏层。</p>
<p>为什么深度神经网络会很好用？ 1. 深度神经网络到底在计算什么？假设现在在做一个人脸识别系统。那么神经网络的第一层会去找照片里的边缘部分；第二层会去识别人类的特征，比如耳朵，鼻子，嘴巴；第三层会去识别不同的人脸。如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E6%B7%B1%E5%BA%A6%E8%A1%A8%E7%A4%BA%E7%9A%84%E7%9B%B4%E8%A7%82%E6%98%A0%E5%83%8F.jpg" alt="深度表示的直观映像" /> 这种识别模式可能难以理解，但是会在卷积神经网络——Convolutional Neural Network中详细解释。 这视频的这一章节有点难以总结，可以看看<a href="https://mooc.study.163.com/learn/2001281002?tid=2001392029&amp;_trace_c_p_k2_=03442699ea78498a873a1dbe2fcfee40#/learn/content?type=detail&amp;id=2001701022" target="_blank" rel="noopener">该视频</a>，总共也就10分钟。</p>
<h1 id="深层神经网络块">深层神经网络块</h1>
<p>此视频中画出了深度神经网络的<a href="https://mooc.study.163.com/learn/2001281002?tid=2001392029&amp;_trace_c_p_k2_=03442699ea78498a873a1dbe2fcfee40#/learn/content?type=detail&amp;id=2001701023" target="_blank" rel="noopener">代码流程</a>。</p>
<h1 id="参数vs超参数">参数VS超参数</h1>
<p>有如下超参数（hyperparameters）：W, b, lerning rate <span class="math inline">\(\alpha\)</span>, iterations, hidden layer L, hidden units, choice of activatation function.这些超参数都需要自己设置。 上面这些都是基础的，实际上还有其他的超参数，稍后会涉及到。</p>
<h1 id="神经网络和大脑有什么关系">神经网络和大脑有什么关系？</h1>
<p>计算机视觉、其他深度学习领域或者其他学科在早期可能都受过人类大脑的启发，但是近年来人类将神经网络类比为大脑的次数越来越少，也就是说近年来大家都不怎么认为这二者有关联。</p>
<h1 id="一个simple-nn的例子">一个Simple NN的例子</h1>
<p><a href="https://github.com/yan624/machine_learning_algorithms/tree/master/simple_neural_network" target="_blank" rel="noopener">Simple Neural Network</a>例子</p>
<hr />
<p>本节以下开始利用算法改善深层神经网络 *********************************************************************************************************************************************</p>
<h1 id="训练开发测试集">训练/开发/测试集</h1>
<p>训练集——training set 开发集/交叉验证集/验证集——dev set/cross validation set/validation set 测试集——test set</p>
<p>以前数据量小的时候，比如100个样本、10000个样本。一般将数据按三七分，七份训练集，三份测试集。验证集（以下均称验证集）在训练集中再细分，比如二八分，八份训练集。 但是现在进入大数据时代，验证集和测试集已经没有必要占大量比例了。比如现在有100万的样本，那么验证集和测试集只需要各抽取大约10000的样本即可。也就是98/1/1的比例，甚至验证集和测试集可以再降低占比。</p>
<h2 id="训练集和验证集测试集分布不匹配">训练集和验证集/测试集分布不匹配</h2>
<p>如下图，吴恩达老师建议最好让<strong>验证集</strong>和<strong>测试集</strong>匹配，即来自同一源，要都来自网络高清图，要么都来自手机低像素拍摄。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E5%BC%80%E5%8F%91%E9%9B%86%E6%B5%8B%E8%AF%95%E9%9B%86%E5%88%86%E5%B8%83%E4%B8%8D%E5%8C%B9%E9%85%8D.jpg" alt="训练集和验证集测试集分布不匹配" /> 如果直接不设置测试集也是可以的。</p>
<h1 id="偏差方差">※ 偏差/方差</h1>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E6%AC%A0%E6%8B%9F%E5%90%88%E5%92%8C%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E5%86%B3%E7%AD%96%E7%95%8C%E9%99%90.jpg" alt="欠拟合和过拟合的决策界限" /><figcaption>欠拟合和过拟合的决策界限</figcaption>
</figure>
<p>下图讲述了什么是<strong>过拟合</strong>，什么是<strong>欠拟合</strong>，如图所示，该神经网络用于判断一张图片是猫还是狗。 左边。训练样本中的误差为1%，这个值已经很小了，但是在验证集上的误差有11%。这就代表了过拟合，试想一下，在训练集上误差很小是因为你的决策界限划分的很好，在上图中的最后一个例子，整条决策界限画的十分完美，但是我们要知道在验证集中，这样一条完美的线肯定不能再拟合的很好。因为训练集和验证集即使来源于同一份数据，他们之间的分布也是不一样的，你训练出一条完美的曲线，在另一份数据集上肯定是过于完美了。所以导致了下图中验证集上的误差有11%。我们称这种情况为<strong>高方差</strong>——high variance。 中间。训练样本中的误差为15%，这已经不需要再看验证集上的误差了。因为训练集上的误差那么大，肯定是没有拟合好，所以这就是欠拟合，我们称为<strong>高偏差</strong>——high bais。 右边。如果训练集中的误差很高，验证集上的误差更高，那么可以判断为同时具有高方差和高偏差。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/对神经网络整体的理解/欠拟合和过拟合.jpg" alt="欠拟合和过拟合" /></p>
<p>如果训练集上的误差为0.5%，验证集上的误差为1%。那这就是低方差和低偏差，这是很好结果。 最后一点，以上均建立在人眼判断的误差为0%上以及训练集和验证集来自相同分布。如果人眼判断的误差也高达15%，那么中间的例子也算是可以的结果一般来说<strong>最优误差</strong>也被称为<strong>贝叶斯误差</strong>。（不知道语义解析领域如何定义最优误差？） 关于上图同时高方差和高方差，就如同下图紫色线条的决策界限一般。过渡拟合了数据，但是拟合的数据其实狗屁不通。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E5%90%8C%E6%97%B6%E9%AB%98%E6%96%B9%E5%B7%AE%E5%92%8C%E9%AB%98%E5%81%8F%E5%B7%AE%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84.jpg" alt="同时高方差和高偏差是怎么样的" /></p>
<h2 id="非理想状态下的偏差方差">非理想状态下的偏差/方差</h2>
<p>那么当上图的理想状态被打破时（比如一张图片很模糊，连人眼也无法分辨），该如何分辨偏差/方差呢？ 可以通过对比训练集的 error 和 验证集的 error 来确定是否高方差。比如训练集的 error 为 1%，验证集的为 15%，那就是高方差。实际上跟上面的判断方法一样。</p>
<h2 id="机器学习遇到偏差或方差的解决办法">机器学习遇到偏差或方差的解决办法</h2>
<div class="note info">
<pre><code>&lt;p&gt;笔记中都记了，懒得再写一遍了。补充一点，遇到偏差或方差都可以更换神经网络架构，比如换成CNN或者RNN，如果是高偏差还可以使用更大的神经网络。&lt;/p&gt;</code></pre>
</div>
<p>可以看这个6分半中的小视频，<a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=9c4c25c37dd148a5b85b2edc8dca540e&amp;from=study#/learn/content?type=detail&amp;id=2001702115" target="_blank" rel="noopener">机器学习基础</a>。</p>
<h1 id="正则化">正则化</h1>
<p>如果出现了过拟合，即高方差的情况，第一件想到的事是<strong>正则化</strong>——regularization。当然也可以增加数据，不过有时候数据不是那么容易获取的。可以对W使用<a href="https://www.baidu.com/s?wd=L2%E8%8C%83%E6%95%B0" target="_blank" rel="noopener">L2范数</a>进行正则化，当然对b也可以进行L2范数正则化，不过一般不加。L2范数的公式为<span class="math inline">\(||w||^2_2 = \sum_{j=1}^n w^2_j = W^T * W\)</span> 因此代价函数修改为<span class="math inline">\(cost = \frac{1}{m} \sum^m_{i=1} g(\hat{y}^i, y^i) + \frac{\lambda}{2m}||w||^2_2\)</span>，<span class="math inline">\(\lambda\)</span>是正则化的超参数。这里的w实际上是一个二维矩阵，所以L2范数需要把里面的每一个值的平方都加起来。 如果加入了正则化项，那么在计算dW时有点变化。将会变为：<span class="math inline">\(dW = dZ * A\_prev + \frac{\lambda}{m} w ^ l\)</span></p>
<h2 id="为什么正则化可以防止过拟合">为什么正则化可以防止过拟合</h2>
<p>略。<a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=9c4c25c37dd148a5b85b2edc8dca540e&amp;from=study#/learn/content?type=detail&amp;id=2001702116" target="_blank" rel="noopener">1.5 为什么正则化可以减少过拟合？</a></p>
<h2 id="dropout">dropout</h2>
{% note primary %}
Q：那么问题又来了，dropout背后的原理是什么？
A：[深度学习500问笔记#Dropout-系列问题](https://yan624.github.io/·zcy/AI/深度学习500问笔记.html#Dropout-系列问题)（2020.2.21）
{% endnote %}
<p>dropout，中文翻译为<strong>随机失活</strong>。 先将神经网络复制一遍，然后dropout会遍历神经网络的每一层，并设置消除神经网络中结点的概率，比如设置0.5。下图的带X的结点就是准备消除的。另外每一层的概率都可以是不同的，如果在某一层不担心会过拟合可以将概率设为1.0，比如输出层。如果觉得某些层比其他层更容易过拟合，可以把那些层的keep-prob设置的更低。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/dropout%E5%BE%85%E5%88%A0%E9%99%A4%E7%BB%93%E7%82%B9.jpg" alt="dropout待删除结点" /> 下图则是消除后的神经网络。将结点的进出的链接全部删除。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E4%BD%BF%E7%94%A8dropout%E5%90%8E%E7%9A%84%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.jpg" alt="使用dropout后的神经网络" /> dropout使用之后，就让一个样本进入神经网络进行训练。而对于其他样本也如法炮制，需要再进行复制一遍神经网络，并进行dropout。 以上均是逻辑上的做法，接下来讲实际编码该怎么做。</p>
<ol type="1">
<li>设置一个结点保留的概率——keep-prob，假设为0.8。<span class="math inline">\(d^3 = np.random.randn(a^3.shape[0], a^3.shape[1]) &lt; keep-prob\)</span>，这样会得到一个True和False的数组，但是python中Ture等于1，False等于0。</li>
<li>让<span class="math inline">\(a^3\)</span>乘上这个向量。<span class="math inline">\(a^3 = np.multiply(a^3, d^3)\)</span>。由于False等于0，所以变相地将<span class="math inline">\(a^3\)</span>中的值失活了。</li>
<li>最后一步看起来有点奇怪，<span class="math inline">\(a^3 /= keep-prob\)</span>。 完整代码如下： <span class="math display">\[
\begin{cases}
 d^3 = np.random.randn(a^3.shape[0], a^3.shape[1]) &lt; keep-prob\\
 a^3 = np.multiply(a^3, d^3)\\
 a^3 /= keep-prob\\
\end{cases}
\]</span></li>
</ol>
<p>对于最后一步，由于<span class="math inline">\(Z^4 = W^4 * A^3 + b^4\)</span>，由于<span class="math inline">\(A^3\)</span>被dropout减少0.2，为了使得<span class="math inline">\(Z^4\)</span>不受影响，所以对<span class="math inline">\(A^3\)</span>除0.8，来保证<span class="math inline">\(A^3\)</span>的值不变。由于早期的版本没有除于keep-prob，使得测试阶段，平均值越来越复杂。 最后，从技术上来讲，输入值也可以使用dropout，但是基本不这么做，直接把keep-prob设为1.0即可，当然0.9也可以。不过太低的值一般不会去设置。 以上的步骤被称为<strong>Inverted dropout</strong>——<strong>反向随机失活</strong>。 dropout在计算机视觉中用的非常多，甚至成了标配。但要记住一点，dropout是一种正则化方法，为了预防过拟合。所以除非算法过拟合，不然不会使用dropout。由于计算机视觉的特殊性，他们才经常用dropout。 dropout的缺点是使我们失去了代价函数这一调试功能。我们经常使用代价函数得到误差，从而画出曲线图。但是使用dropout之后，这样的曲线图就不再准确了。</p>
<h3 id="测试">测试</h3>
<p>在测试阶段不再使用dropout，因为我们不希望输出结果是随机的，如果使用dropout预测会受到干扰。</p>
<h3 id="理解dropout">理解dropout</h3>
{% note info %}
略。有点晦涩。
{% endnote %}
<p>看<a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=1f1aedd0dd9f431da0ce64963f010916#/learn/content?type=detail&amp;id=2001701044" target="_blank" rel="noopener">视频</a>。。</p>
<h2 id="其他正则化方法">其他正则化方法</h2>
<ol type="1">
<li>Data augment——数据增强。如果拟合猫咪图片分类器，可以对原图片做一些处理，来增加数据，比如翻转、旋转、随机裁剪等。</li>
<li>Early stopping。在训练时画出代价的曲线图，x轴为迭代次数，再绘制验证时的误差。然后选择验证误差曲线图中最低点的迭代次数，下次训练时就改用这个迭代次数，或者也可以在程序中写一个条件判断。如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/early%20stopping.jpg" alt="early stopping" /></li>
</ol>
<h1 id="均值归一化输入">均值归一化输入</h1>
<div class="note info">
<pre><code>略。其实很简单。</code></pre>
</div>
<h1 id="梯度消失和梯度爆炸">梯度消失和梯度爆炸</h1>
<p><a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=1f1aedd0dd9f431da0ce64963f010916#/learn/content?type=detail&amp;id=2001702118&amp;cid=2001699114" target="_blank" rel="noopener">视频</a> <a href="https://www.bilibili.com/video/av10590361/?p=18" target="_blank" rel="noopener">另外一个参考视频</a>，08:37开始。 <a href="https://www.bilibili.com/video/av10590361/?p=37" target="_blank" rel="noopener">另一个</a>13:50~18左右</p>
<h2 id="解决办法">解决办法</h2>
<p><a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=1f1aedd0dd9f431da0ce64963f010916#/learn/content?type=detail&amp;id=2001701047" target="_blank" rel="noopener">视频</a></p>
<h1 id="梯度检验">梯度检验</h1>
<p>Gradient checking(Grad check). <a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=1f1aedd0dd9f431da0ce64963f010916#/learn/content?type=detail&amp;id=2001701048" target="_blank" rel="noopener">原理视频</a> <a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=1f1aedd0dd9f431da0ce64963f010916#/learn/content?type=detail&amp;id=2001702119" target="_blank" rel="noopener">实战视频</a> 梯度检验可以帮助我们发现神经网络中的一些bug。具体原理是，通过数学上导数的定义来确认反向传播算法是否正确。如果学过高数就会知道，使用导数的定义求解和直接使用公式求解，两者结果十分接近或者一模一样。如果二者不一样说明肯定是求错了。 对应于神经网络，那就肯定是代码写错了。具体操作可在视频中看见，每个视频都不超过10分钟。</p>
<h2 id="注意事项">注意事项</h2>
<ol type="1">
<li>不要在训练中使用梯度检验，它只用于调试。</li>
<li>如果梯度检验确实发现问题，要检查每一项，看看是哪个i的w和b有问题。</li>
<li>记得正则化项，它也被包含在w的梯度中。</li>
<li>梯度检验不能和dropout一起用。</li>
<li><del>在随机初始化时就运行一遍梯度检验；或许在训练一会后可以再运行一遍梯度检验。当W和b接近于0时，梯度下降正确执行在现实中几乎不太可能。</del>吴恩达老师说这条他在现实中几乎不会这么做，并且第五条的翻译，个人感觉翻得有问题，然后看了英文原文后，感觉原文表达得也不是很好，我看不太懂，所以这条就不算进注意事项了。</li>
</ol>
<h1 id="mini-batch梯度下降">Mini-batch梯度下降</h1>
<p>移至《<a href="https://yan624.github.io/·zcy/AI/dl/机器学习中的各种优化算法.html">机器学习中的各种优化算法</a>》。</p>
<h1 id="指数加权平均">指数加权平均</h1>
<p>移至《<a href="https://yan624.github.io/·zcy/AI/dl/机器学习中的各种优化算法.html">机器学习中的各种优化算法</a>》。</p>
<h1 id="learning-rate-decay">※ Learning rate decay</h1>
<p>移至《<a href="https://yan624.github.io/·zcy/AI/dl/机器学习中的各种优化算法.html">机器学习中的各种优化算法</a>》。</p>
<h1 id="如何为超参数选择范围">如何为超参数选择范围</h1>
<p>上面说了那么多算法，其中包括了许多超参数，那么应该怎么为超参数选择值呢？</p>
<h2 id="超参数的重要程度">超参数的重要程度</h2>
<p>按照吴恩达老师的排序，超参数的重要程度如下： 1. learning rate<span class="math inline">\(\alpha\)</span> 2. Momentum的<span class="math inline">\(\beta\)</span>, hidden layer units, mini-batch size 3. layer的数量，learning rate decay 4. Adam中的<span class="math inline">\(\beta_1\quad \beta_2\quad \epsilon\)</span>不是很重要，一般按<span class="math inline">\(0.9\quad 0.99\quad 10^{-8}\)</span>设置</p>
<h2 id="超参数的取值">超参数的取值</h2>
<ol type="1">
<li>随机取值</li>
<li>从粗糙到精细的策略。首先进行随机取值，发现某个点的效果很好，并且附近的点也很好，然后放大这块区域，进行更密集地取值。下图被圈出来的蓝点就是效果不错的，然后被方框画出一大块区域进行密集地取值或者也可以在这块区域随机取值。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E4%BB%8E%E7%B2%97%E7%B3%99%E5%88%B0%E7%B2%BE%E7%BB%86%E7%9A%84%E5%8F%96%E5%80%BC%E7%AD%96%E7%95%A5.jpg" alt="从粗糙到精细的取值策略" /></li>
</ol>
<h2 id="选择合适的范围">选择合适的范围</h2>
<p><a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=48e14d97b8284ad0b4e8d32be2605c3d&amp;from=study#/learn/content?type=detail&amp;id=2001701053" target="_blank" rel="noopener">视频1</a> <a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036&amp;_trace_c_p_k2_=48e14d97b8284ad0b4e8d32be2605c3d&amp;from=study#/learn/content?type=detail&amp;id=2001701054" target="_blank" rel="noopener">视频2</a></p>
<h2 id="补充用神经网络训练另一个神经网络的超参数">补充——用神经网络训练另一个神经网络的超参数</h2>
<p>看完李宏毅深度学习后的补充，他在教学视频中也讲述了如何调整超参数，有个说的挺有创意的，就是<strong>用神经网络来训练超参数如何取值</strong>。典型的例子就是 <strong>Swish</strong>，它可以用神经网络训练出最好的几个激活函数。</p>
<h1 id="batch-normalization对激活值均值归一化">batch normalization——对激活值均值归一化</h1>
<p><a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank" rel="noopener">论文地址</a> 这个原来不是一个算法，它就是让我们对神经网络的每一层都做一次normalization，从而提供性能，而算法是在batch中做的，所以叫这名。 <a href="https://mooc.study.163.com/learn/2001281003?tid=2001391036#/learn/content?type=detail&amp;id=2001701055&amp;cid=2001693088" target="_blank" rel="noopener">视频地址</a>，第25章写了均值归一化，它对输入值进行了均值归一，更易于算法优化。而batch normalization对激活值进行了均值归一化，说白了是一个东西。</p>
<h2 id="代价函数">代价函数</h2>
<p>代价函数为<span class="math inline">\(cost(\hat{y}, y) = - \sum^n_{j=1} y_j * log(\hat{y_j})\)</span>。</p>
<div class="note primary"><p>但是这里可能会有点奇怪。因为二元分类的代价函数是<span class="math inline">\(cost(\hat{y}, y) = - \sum^n_{j=1} (y_j * log(\hat{y_j}) + (1 - y_j) * log(\hat{1-y_j}))\)</span>。怎么多元分类的表达式那么短？</p>
<p>2020.8.18 更新：不管是二元还是多元，其实公式都是一样的，最后都会缩减到只有一项，因为 y 是一个 one hot 向量。</p>
</div>
<h1 id="选择深度学习框架">选择深度学习框架</h1>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%AF%B9%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%95%B4%E4%BD%93%E7%9A%84%E7%90%86%E8%A7%A3/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E9%80%89%E6%8B%A9.jpg" alt="深度学习框架选择" /><figcaption>深度学习框架选择</figcaption>
</figure>
<h1 id="序列模型rnn">序列模型——RNN</h1>
<p><a href="https://yan624.github.io/posts/5e27260b.html">传送门</a></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>back propagation</tag>
        <tag>gradient descent</tag>
        <tag>simple NN</tag>
        <tag>bias</tag>
        <tag>variance</tag>
        <tag>regularization</tag>
        <tag>dropout</tag>
        <tag>early stopping</tag>
        <tag>激活函数</tag>
      </tags>
  </entry>
  <entry>
    <title>《神经网络与深度学习》学习笔记：反向传播算法中weight的表示问题</title>
    <url>/posts/fe37c4.html</url>
    <content><![CDATA[<p><a href="https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/chapter2.html" target="_blank" rel="noopener">本文中文章节地址</a> <a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="noopener">本文英文章节地址</a></p>
<h3 id="神经网络中一些符号的定义">神经网络中一些符号的定义</h3>
<p>引用自<a href="https://tigerneil.gitbooks.io/neural-networks-and-deep-learning-zh/content/chapter2.html#%E7%83%AD%E8%BA%AB%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E8%AE%A1%E7%AE%97%E8%BE%93%E5%87%BA%E7%9A%84%E8%A7%82%E7%82%B9" target="_blank" rel="noopener">原文中文翻译</a> &gt;我们首先给出网络中权重的清晰定义。我们使用<span class="math inline">\(w^l_{jk}\)</span>表示从 <span class="math inline">\((l−1)^{th}\)</span> 层的 <span class="math inline">\(k^{th}\)</span> 个神经元到 <span class="math inline">\((l)^{th}\)</span> 层的 <span class="math inline">\(j^{th}\)</span> （<font style="color:red">注意：这个地方中文文章中写错了</font>，他写成了<span class="math inline">\(l^{th}\)</span>）个神经元的链接上的权重。例如，下图给出了第二隐藏层的第四个神经元到第三隐藏层的第二个神经元的链接上的权重： &gt; <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E9%93%BE%E6%8E%A5%E4%B8%8A%E7%9A%84%E6%9D%83%E9%87%8D%E8%A1%A8%E7%A4%BA%E5%9B%BE%E8%A7%A3.png" alt="神经网络中的神经元链接上的权重表示图解" /> &gt; 我们对网络偏差和激活值也会使用类似的表示。显式地，我们使用 <span class="math inline">\(b^l_J\)</span> 表示在 <span class="math inline">\(l^{th}\)</span> 层 <span class="math inline">\(j^{th}\)</span> 个神经元的偏差，使用 <span class="math inline">\(a^l_j\)</span> 表示 <span class="math inline">\(l^{th}\)</span> 层 <span class="math inline">\(j^{th}\)</span> 个神经元的激活值。下面的图清楚地解释了这样表示的含义： &gt; <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%81%8F%E5%B7%AE%E5%92%8C%E6%BF%80%E6%B4%BB%E5%80%BC%E5%9B%BE%E8%A7%A3.png" alt="神经网络中的偏差和激活值图解" /></p>
<a id="more"></a>
<p>说白了就是<strong>前一层的</strong>的神经元到后一层的神经元上的链接的权重。 这里解释一下，我在<a href="https://www.bilibili.com/video/av9770302" target="_blank" rel="noopener">李宏毅深度学习的视频</a>中，也听到他讲过。<span class="math inline">\(w^l_{jk}\)</span>中的j和k在这个公式中是写反的，可以想想：上文说到<span class="math inline">\(w^l_{jk}\)</span>是代表第k个神经元到第j个神经元链接上的权重，按逻辑来说，似乎写成<span class="math inline">\(w^l_{kj}\)</span>更合理。因为我们说话写字都是按顺序的，没有说是反着来的。 之所以这么反着写，是因为后面在对权重（weight）、激活值（activations）进行向量化时，不需要加一个转置。接下来解释一下为什么不用加： 以上图为例，有如下权重：<span class="math inline">\(w^3_{21}\)</span> <span class="math inline">\(w^3_{22}\)</span> <span class="math inline">\(w^3_{23}\)</span> <span class="math inline">\(w^3_{24}\)</span> 现在将上标3移除组成一个向量——<span class="math inline">\(\begin{pmatrix}w_{21}&amp;w_{22}&amp;w_{23}&amp;w_{24}\end{pmatrix}\)</span>，大家已经发现了吧，我将这个向量横着写的。众所周知，矩阵的下标第一个数字代表矩阵的行，第二个数字代表矩阵的列。所以如果将w这个矩阵补全就是下面这样。 <span class="math display">\[\begin{pmatrix}
w_{11}&amp;w_{12}&amp;w_{13}&amp;w_{14}\\
w_{21}&amp;w_{22}&amp;w_{23}&amp;w_{24}\\
\end{pmatrix}\]</span> 这是一个2行4列的矩阵，因为第三层layer只有两个神经元，自然只有两个权重向量。先给出公式：<span class="math inline">\(z^3_2\)</span> = <span class="math inline">\(w^3_2\)</span> * <span class="math inline">\(a^2\)</span>，这里原本应该还要加上偏差b，但是由于改起来太麻烦以下都不加上b了，该公式就是<span class="math inline">\(\begin{pmatrix}w_{21}&amp;w_{22}&amp;w_{23}&amp;w_{24}\end{pmatrix}\)</span>乘<span class="math inline">\(a^2\)</span>，<span class="math inline">\(a^2\)</span>就是第二层的激活值的<strong>列</strong>向量表现形式，这很好理解就不解释了。运用考研线性代数的知识可以知道，行向量乘以列向量结果是一个<strong>数值</strong>，这样就得到了<span class="math inline">\(z^3_2\)</span>的值。 我们再将第二层到第三层的其他向量补上就是如下的矩阵运算公式，为了方便查看，我将上标又加上了。 <span class="math display">\[
\begin{pmatrix}
z^3_1\\
z^3_2\\
\end{pmatrix} = 
\begin{pmatrix}
w^3_{11}&amp;w^3_{12}&amp;w^3_{13}&amp;w^3_{14}\\
w^3_{21}&amp;w^3_{22}&amp;w^3_{23}&amp;w^3_{24}\\
\end{pmatrix} * 
\begin{pmatrix}
a^2_1\\
a^2_2\\
a^2_3\\
a^2_4\\
\end{pmatrix}
\]</span> 上式可以简化为<span class="math inline">\(a^l = \sigma(z^l)\)</span>，其中<span class="math inline">\(z^l\)</span> = <span class="math inline">\(w * a^{l-1}\)</span>。合并之后写为<span class="math inline">\(a^l = \sigma(w * a^{l-1})\)</span>，<span class="math inline">\(\sigma\)</span>只是代表某个函数而已。</p>
<h4 id="如果不交换jk的位置">如果不交换jk的位置</h4>
<p>绕了这么一大圈，终于说完了为什么jk交换位置要好，因为w被向量化后被表示成行向量了。行乘列直接就可以乘，不需要再对w转置。如果我们不交换jk的位置，那么w表示成如下形式： <span class="math display">\[
\begin{pmatrix}
w^3_{11}&amp;w^3_{12}\\
w^3_{21}&amp;w^3_{22}\\
w^3_{31}&amp;w^3_{32}\\
w^3_{41}&amp;w^3_{42}\\
\end{pmatrix}
\]</span> 下面这样是乘不了的。 <span class="math display">\[
\begin{pmatrix}
w^3_{11}&amp;w^3_{12}\\
w^3_{21}&amp;w^3_{22}\\
w^3_{31}&amp;w^3_{32}\\
w^3_{41}&amp;w^3_{42}\\
\end{pmatrix} * 
\begin{pmatrix}
a^2_1\\
a^2_2\\
a^2_3\\
a^2_4\\
\end{pmatrix} = 
个屁
\]</span> 如果下面这样就可以。T代表将矩阵转置。 <span class="math display">\[
\begin{pmatrix}
w^3_{11}&amp;w^3_{12}\\
w^3_{21}&amp;w^3_{22}\\
w^3_{31}&amp;w^3_{32}\\
w^3_{41}&amp;w^3_{42}\\
\end{pmatrix}^T * 
\begin{pmatrix}
a^2_1\\
a^2_2\\
a^2_3\\
a^2_4\\
\end{pmatrix} = 
\begin{pmatrix}
z^3_1\\
z^3_2\\
\end{pmatrix}
\]</span> 简化之后就是<span class="math inline">\(\sigma(w^T\)</span> * <span class="math inline">\(a^{l-1})\)</span> = <span class="math inline">\(a^l\)</span>。所以绕了那么大一圈，其实只是为了少加一个T。。。</p>
<h4 id="w的下标总结">w的下标总结</h4>
<p>说实话我还是希望加上T的，因为上面说了那么一大堆，说实话是很绕的，还不如直接不交换jk的位置。从各个方面来说都是极为通顺的，不妥的仅仅是多加了T。 最后还是无法理解别人为什么将jk交换位置的，可以试着不去想神经网络，完全去思考数学中的矩阵。我给点提示，对于元素<span class="math inline">\(w^3_{24}\)</span>首先3和2是定死的，同理得到<span class="math inline">\(w^3_{21}\)</span> <span class="math inline">\(w^3_{22}\)</span> <span class="math inline">\(w^3_{23}\)</span>，现在开始不要想关于神经网络的事，想想向量<span class="math inline">\(\begin{pmatrix}w^3_{21}&amp;w^3_{22}&amp;w^3_{23}&amp;w^3_{24}\end{pmatrix}\)</span>是不是行向量？ 再想想下面的向量是不是列向量 <span class="math display">\[
\begin{pmatrix}
w^3_{12}\\
w^3_{22}\\
w^3_{32}\\
w^3_{42}\\
\end{pmatrix}
\]</span> 我仅仅是交换了jk的位置对吧，虽然说数值没有任何变化，但是从数学角度讲，从行向量转为了列向量。</p>
<p>然而我觉得这样徒增了学习成本。我佛他们。</p>
<h3 id="计算输出的公式">计算输出的公式</h3>
<p>公式比较简单，就是<span class="math inline">\(a^l = \sigma(z^l)\)</span>，<span class="math inline">\(z^l\)</span> = <span class="math inline">\(w^T\)</span> * <span class="math inline">\(a^{l-1}\)</span> + <span class="math inline">\(b^l\)</span></p>
<!-- more -->
]]></content>
      <categories>
        <category>notes</category>
        <category>dl</category>
      </categories>
      <tags>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.</title>
    <url>/posts/fd574181.html</url>
    <content><![CDATA[<p>网上很多人说要修改h5py的版本，但是我压根没装这个库。 <a href="https://blog.csdn.net/u013092293/article/details/80447201" target="_blank" rel="noopener">参考文章</a> 将numpy版本降低即可，我原先好像是1.16，记不清了，我没留意到。 <figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">conda install numpy==<span class="number">1.13</span><span class="number">.0</span></span><br></pre></td></tr></table></figure> <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>error</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（六）：SVM</title>
    <url>/posts/5e193242.html</url>
    <content><![CDATA[<p>看《机器学习实战》这本书的 SVM 部分，感觉始终无法理解，因为书里把数学公式的推导直接省略了。所以在b站找了视频学习 SVM。 本文<a href="https://zhuanlan.zhihu.com/p/24638007" target="_blank" rel="noopener">参考文章</a> 本文<a href="https://www.bilibili.com/video/av37947862/?p=75" target="_blank" rel="noopener">参考视频</a></p>
<p>首先分割超平面（separating hyperplane）的函数表达式是<span class="math inline">\(w^T * x + b = 0\)</span>，而它上下两条间隔最远的超平面的表达式分别为 <span class="math display">\[
\begin{align}
    w^T * x + b = &amp; 1 \\
    w^T * x + b = &amp; -1 \\
\end{align}
\]</span> 至于为什么正好等于 1 和 -1，其实是为了方便计算。实际上可以等于任何值。看以下推导，先让其等于连个随机的值，比如 2 和 -3： <a id="more"></a> <span class="math display">\[
\begin{align}
    w^T * x + b = &amp; 2 \\
    w^T * x + b = &amp; -3 \\
\end{align}
\]</span> 解一个不等式 <span class="math display">\[
\begin{align}
    2u + v = &amp; 1 \\
    -3u + v = &amp; -1 \\
\end{align}
\]</span> 解得 u = <span class="math inline">\(\frac{2}{5}\)</span>， v = <span class="math inline">\(\frac{1}{5}\)</span> 于是使 <span class="math display">\[
\begin{align}
    w^T * x + b = &amp; 2 \\
    w^T * x + b = &amp; -3 \\
\end{align}
\]</span> 左右分别乘上<span class="math inline">\(\frac{2}{5}\)</span>再加上<span class="math inline">\(\frac{1}{5}\)</span>，即可得到 <span class="math display">\[
\begin{align}
    w^T * x + b = &amp; 1 \\
    w^T * x + b = &amp; -1 \\
\end{align}
\]</span> 而 W 和 b 只不过是一个表示的符号而已，虽然经过运算，两个 W 和两个 b 已经不是同一个了，但是这么表示没太大问题。 将连个表达式更进一步表示为 <span class="math display">\[
\begin{align}
    w^T * x_1 + b = &amp; 1 \\
    w^T * x_2 + b = &amp; -1 \\
\end{align}
\]</span> 两者相减得 <span class="math display">\[
\begin{align}
    w^T * (x_1 - x_2) = 2 \\
\end{align}
\]</span> 也即 <span class="math display">\[
\begin{align}
    ||w^T|| * ||(x_1 - x_2)|| cos\theta = 2 \\
\end{align}
\]</span> 两条竖线代表，向量的模长，<span class="math inline">\(\theta\)</span>代表 <span class="math inline">\(W^T\)</span>和<span class="math inline">\(x_1 - x_2\)</span>之间的夹角。 由于初中知识，我们知道：<span class="math inline">\(cos\alpha\)</span>=邻边比斜边，即邻边=斜边*<span class="math inline">\(cos\alpha\)</span>。所以 <span class="math display">\[
\begin{align}
    ||w^T|| * d = &amp; 2 \\
    d = \frac{2}{||w^T||}
\end{align}
\]</span></p>
<!-- more -->
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（五）：PCA</title>
    <url>/posts/d68d7c63.html</url>
    <content><![CDATA[<a id="more"></a>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（四）：K均值（K-means）</title>
    <url>/posts/77f173b6.html</url>
    <content><![CDATA[<h3 id="todo">TODO</h3>
<p>K-均值(K-means)算法是无监督算法，也是聚类(clustering)算法。</p>
<h3 id="算法步骤">算法步骤</h3>
<ol type="1">
<li>随机初始化几个点作为簇的质心，初始化方式有多种，可以自行选择。已知两种：</li>
</ol>
<ul>
<li>随机选择K个样本作为簇的质心。来源于吴恩达机器学习视频</li>
<li>min + (max - min) * (0到1之间的小数)，其中最大值最小值均代表。来源于《机器学习实战》</li>
</ul>
<ol start="2" type="1">
<li>计算某个样本到每个簇的质心之间的代价（距离），代价函数有多种可自行选择。比如：</li>
</ol>
<ul>
<li>均方误差(mse) 选出其中最小的代价，并求出簇的索引，然后将该样本划分给该质心所属的簇。每个样本都执行这步直到样本遍历完毕。</li>
</ul>
<ol start="3" type="1">
<li>经过步骤2，每个样本都归属于一个簇。然后遍历每一个簇，将簇中的数据求均值，将该均值作为簇的新质心。 <a id="more"></a></li>
<li>重复以上步骤，直到发现每个样本都归属于某个簇，并且样本归属不会再发生变化。 简化如下： <figure class="highlight kotlin"><table><tr><td class="code"><pre><span class="line">随机初始化质心</span><br><span class="line">	<span class="keyword">while</span> <span class="literal">true</span></span><br><span class="line">		<span class="keyword">for</span> 每个样本</span><br><span class="line">			<span class="keyword">for</span> 每个质心</span><br><span class="line">				计算每个样本到质心的代价</span><br><span class="line">			选出最小的代价</span><br><span class="line">			将样本分配给这个簇</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">for</span> 每个质心</span><br><span class="line">			求出该簇所属的样本的均值</span><br><span class="line">			将该均值设置为簇的新质点</span><br><span class="line">			</span><br><span class="line">		<span class="keyword">if</span> 样本归属不再发生变化</span><br><span class="line">			<span class="keyword">break</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="举一个简单的例子">举一个简单的例子</h3>
<p><a href="https://github.com/yan624/machine_learning_algorithms/tree/master/kmeans/simple_demo" target="_blank" rel="noopener">这里有一个简单例子</a> <!-- more --></p>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>kmeans</tag>
      </tags>
  </entry>
  <entry>
    <title>selenium下打开Chrome闪退</title>
    <url>/posts/a6ca92a5.html</url>
    <content><![CDATA[<p>网上的其他解决办法都不对，后来发现了是因为一个很逗的错。 以下代码闪退 <figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">webdriver.Chrome()</span><br></pre></td></tr></table></figure> 以下代码正常运行 <figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line">chrome = webdriver.Chrome()</span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>selenium</tag>
      </tags>
  </entry>
  <entry>
    <title>使用WikiExtractor处理维基百科上的数据步骤-2019年3月</title>
    <url>/posts/564a3518.html</url>
    <content><![CDATA[<p>网上有很多博客介绍如何使用开源工具wiki extractor解压提取维基百科上的数据，但是我试了一下他们的命令发现没一个能用的，而且他们对于该命令基本都是一笔带过，没有做深入的解释，对于我这种小白在第一步就卡死了。另外他们大部分人都是用linux系统，还有些使用Mac系统，用Windows的只有少数，而且他们提供的命令还不好用。所以我在此提供<strong>Windows系统</strong>的使用办法。 0. 数据来源：<a href="https://dumps.wikimedia.org/zhwiki/20190320/" target="_blank" rel="noopener">维基百科数据</a> 1. 首先进入<a href="https://github.com/attardi/wikiextractor" target="_blank" rel="noopener">wiki extractor的官网</a>。发现里面有很多py文件，与其他人写的博客上的教程完全不一样。别人的教程只有一个<em>WikiExtractor.py</em>文件。 2. 将该项目clone下来，放在你的项目中。如下图： <a id="more"></a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/wiki%20extractor%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E8%B7%AF%E5%BE%84.png" alt="wiki extractor文件存放路径" /> 我下的是压缩包，解压开后就存放在wikiextractor-master文件夹。至于test.py只是用来测试gensim的word2vec算法好不好用的，无视就好。 3. 进入wikiextractor-master文件夹执行<code>python setup.py install</code>，该步骤用于安装wiki extractor。其实<a href="https://github.com/attardi/wikiextractor" target="_blank" rel="noopener">wiki extractor的官网</a>也写了这一步。但是不知道为什么其他人的博客没人介绍。 4. 退出该文件夹到nlp_learning文件夹，执行<code>python wikiextractor-master/WikiExtractor.py -b 1200M -o extracted zhwiki-20190320-pages-articles-multistream1.xml-p1p162886.bz2</code>，这个命令应该很好理解，说一下里面的extracted，它是目标文件夹，就是提取出来的文本存放的那个文件夹。可以看到上面的图片里有这个文件夹。-b代表每多大字节输出一份文件，参数的具体使用方法可以到<a href="https://github.com/attardi/wikiextractor#usage" target="_blank" rel="noopener">这里</a>查询。 5. 接下慢慢等就行了，我的文件157MB，大概洗脸刷牙后就提取完了。</p>
<p>参考了<a href="https://blog.csdn.net/grafx/article/details/78575850" target="_blank" rel="noopener">博客</a>，但是他这篇博客提供命令我也执行不了。如果你也成功不了，可以试试我的步骤。</p>
]]></content>
      <categories>
        <category>notes</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>WikiExtractor</tag>
      </tags>
  </entry>
  <entry>
    <title>运用文本相似度实现（证券）智能客服的记录</title>
    <url>/posts/e8e501ee.html</url>
    <content><![CDATA[<p>数据来源于维基百科。 数据来源：<a href="https://dumps.wikimedia.org/zhwiki/20190320/" target="_blank" rel="noopener">维基百科数据</a> ### 从维基百科提取数据 不会操作的，具体参考我这篇<a href="https://yan624.github.io/%E4%BD%BF%E7%94%A8WikiExtractor%E5%A4%84%E7%90%86%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E4%B8%8A%E7%9A%84%E6%95%B0%E6%8D%AE%E6%AD%A5%E9%AA%A4-2019%E5%B9%B43%E6%9C%88.html">博客:使用WikiExtractor处理维基百科上的数据步骤-2019年3月</a> <a id="more"></a></p>
<h3 id="将数据从繁体字转为简体字">将数据从繁体字转为简体字</h3>
<p>具体参考该博客：<a href="https://blog.csdn.net/sinat_29957455/article/details/81290356" target="_blank" rel="noopener">windows使用opencc中文简体和繁体互转</a>，我试过里面的教程，没有任何问题。直接将博客往下拉，看<em>3、OpenCC的使用</em>即可。执行命令后，命令行会没有任何反应，这时只是在跑代码而已，我的文件157兆，大概只用了15秒。我把我的命令贴下来： <figure class="highlight taggerscript"><table><tr><td class="code"><pre><span class="line">E:<span class="symbol">\p</span>ython_workspace<span class="symbol">\n</span>lp_learning<span class="symbol">\o</span>pencc-1.0.4<span class="symbol">\b</span>in<span class="symbol">\o</span>pencc -i E:<span class="symbol">\p</span>ython_workspace<span class="symbol">\n</span>lp_learning<span class="symbol">\z</span>hwiki-20190320-pages-articles<span class="symbol">\A</span>A<span class="symbol">\w</span>iki_00 -o E:<span class="symbol">\p</span>ython_workspace<span class="symbol">\n</span>lp_learning<span class="symbol">\z</span>hwiki-20190320-pages-articles<span class="symbol">\o</span>pencc<span class="symbol">\w</span>iki_00 -c E:<span class="symbol">\p</span>ython_workspace<span class="symbol">\n</span>lp_learning<span class="symbol">\o</span>pencc-1.0.4<span class="symbol">\s</span>hare<span class="symbol">\o</span>pencc<span class="symbol">\t</span>2s.json</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>notes</category>
        <category>ml</category>
      </categories>
  </entry>
  <entry>
    <title>linux Ubuntu安装NVIDIA驱动</title>
    <url>/posts/5f1f16e2.html</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/ghw15221836342/article/details/79571559" target="_blank" rel="noopener">参考文章</a> 以下步骤基于ubuntu16，下载的文件在Downloads文件夹。 1. 使用命令<code>lspci |grep -i nvidia</code>，查看显卡型号 2. 然后去<a href="http://www.nvidia.com/Download/index.aspx?lang=en-us" target="_blank" rel="noopener">官网</a>查找对应显卡版本。 3. 下载NVIDIA驱动文件，名称类似为NVIDIA-Linux-x86_64-375.20.run。 4. 卸载已有的驱动。由于我的是新机器，所以卸载步骤未执行。 <a id="more"></a> 5. 然后使用命令禁用nouveau，使用以下命令编辑配置文件。 <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">sudo <span class="keyword">vim</span> /etc/modprobe.d/blacklist.<span class="keyword">conf</span></span><br></pre></td></tr></table></figure> 在最后一行添加： <code>blacklist nouveau</code> 6. 之后执行<code>sudo update-initramfs -u</code>，完成之后需要重启电脑，重启电脑命令：<code>reboot</code>。电脑重启之后执行<code>lsmod |grep nouveau  #没有输出，即说明安装成功</code>. 7. 接下来开始安装驱动。。。 8. 使用<code>ctrl+alt+f3</code>命令进入命令行界面。 9. 给驱动run文件赋予执行权限（若出现[sudo] 计算机名 ◆ ◆ ◆ ◆，这是因为安装了中文的ubuntu，输入登录密码即可）。使用如下命令： <figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">cd</span> <span class="selector-tag">Downloads</span></span><br><span class="line"><span class="selector-tag">sudo</span> <span class="selector-tag">chmod</span> <span class="selector-tag">a</span>+<span class="selector-tag">x</span> <span class="selector-tag">NVIDIA-Linux-x86_64-375</span><span class="selector-class">.20</span><span class="selector-class">.run</span></span><br></pre></td></tr></table></figure> 10. 安装：<code>sudo ./NVIDIA-Linux-x86_64-375.20.run –no-opengl-files</code> 11. 一直选择OK、yes、continue按回车键 12. 可能会出现没有gcc的错误，如果出现此问题，安装gcc即可。使用<code>sudo apt-get install gcc</code>安装。 13. 可能出现没有make工具的错误。使用<code>sudo apt-get install make</code>安装 14. <code>nvidia-smi</code>查看是否安装成功。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title>机器学习算法（三）：决策树</title>
    <url>/posts/f20f80c0.html</url>
    <content><![CDATA[<h3 id="todo">TODO</h3>
<h3 id="定义">定义</h3>
<p>由于新手不太懂术语，规定行为一条数据，列为一组特征。 <strong>特征</strong>代表一列数据。如性别、年龄、身高等。 <strong>分类</strong>代表一个特征中不同的分类。如性别中分类为男女，天气中分类为晴、阴、雨、雪等，收入中分类为贫困、低收入、小康、中高收入者、富人等。</p>
<h3 id="信息增益">信息增益</h3>
<p>引用自《机器学习实战》 &gt;划分数据集的大原则：将无需的数据变得更加有序。我们可以使用多种方法划分数据集，但是每种方法都有各自的优缺点。组织杂乱无章数据的一种办法就是使用信息论度量信息，信息论是量化处理信息的分支学科。我们可以在划分数据之前或之后使用信息论量化度量信息的内容。 &gt;在划分数据集之前之后信息发生的变化称为信息增益，知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。</p>
<p>节选 &gt;集合信息的度量方式称为香农熵或者简称为熵，这个名字来源于信息论之父克劳德·香农。</p>
<a id="more"></a>
<p><strong>下面这一段待修改，在进一步学习后发现有问题</strong></p>
<p>如果不懂什么是信息增益（information）和熵（entropy）也无所谓，只需要知道熵越大则不确定性越大即可。因为我们需要的是不确定性小的<strong>特征</strong>，所以熵越小越好。试想决策树就是将信息一分为二，是不是最好某一个特征只有两种<strong>分类</strong>，如男、女。这样不确定性是极小的，因为它只能分为男和女。如果某一个特征有多个分类，如鸟类下有多种详细的分类，那么该特征的熵值就会很大，不确定性也很大。想想决策树就是将信息一分为二，我该选哪条线将鸟类一分为二？这是很难想的事情，所以这个特征并不好。以上只是举例，在具体项目中不一定对，并且决策树也不一定是二叉树（此处存疑？）。 熵的计算公式如下，其中pi是选择该分类的概率，即有20条数据，其中13条是男性，7条是女性。则男性的pi=13/20，女性的pi=7/20。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E4%BF%A1%E6%81%AF%E7%86%B5%E7%9A%84%E5%85%AC%E5%BC%8F.jpg" alt="信息熵的公式" /></p>
<h3 id="决策树构建步骤">决策树构建步骤</h3>
<p>决策树构建首先需要一个根节点，这是毋庸置疑的，但是根节点也不是一拍脑门就突然有了的。需要使用一些算法，现在一些常用的算法如：ID3(信息增益)、C4.5(信息增益率，解决ID3的问题，考虑自身熵)、CART(使用GINI系数来当做衡量标准，GINI系数和熵的衡量标准类似，但是计算方式不同)等。 以下使用<a href="https://baike.baidu.com/item/ID3%E7%AE%97%E6%B3%95/5522381" target="_blank" rel="noopener">ID3算法</a>，<strong>给出如下训练数据</strong>，来源于唐宇迪机器学习视频中的截图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E6%AD%A5%E9%AA%A4%E2%80%94%E2%80%94%E4%B8%BE%E7%9A%84%E4%BE%8B%E5%AD%90%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE.jpg" alt="例子中的数据" /> 1. 首先计算全部数据的熵值，其实就是计算一下给出的数据中的最后一列（最后一列可以当做y）的熵值。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E6%AD%A5%E9%AA%A4%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E7%86%B5%E5%80%BC.jpg" alt="计算原始数据的熵值" /> 2. 计算其他特征的熵值。解释一下什么叫其他特征的熵值：比如 outlook 这个特征值，如果要计算它，首先需要知道 outlook 这个特征值分为 3 类，sunny、overcast 和 rainy，然后计算依次计算这三种类别的熵值。具体步骤是，比如计算 sunny 的熵值，那就将原数据中 outlook 不是 sunny 类别的数据全部删除，然后使用信息熵的公式计算剩余数据的熵值。其他的类别计算方式以此类推。计算完毕之后就得到了三个熵值，然后按照类别在特征中的比例相加即可。 如下图右侧，当天气为 sunny 时去打球的概率为<span class="math inline">\(\frac{2}{5}\)</span>，不去打球的概率为<span class="math inline">\(\frac{3}{5}\)</span>，利用上面的熵值公式计算结果为 0.971。再分别计算 outlook 其他<strong>分类</strong>：overcast 和 rainy 的熵值，此时得到了三个不同分类的熵值，即 sunny为<span class="math inline">\(\frac{5}{14}\)</span>， overcast为<span class="math inline">\(\frac{4}{14}\)</span>。最终 outlook 的熵值即为<span class="math inline">\(\frac{5}{14} * 0.971 + \frac{4}{14} * 0 + \frac{5}{14} * 0.971 = 0.693\)</span>。最后其他特征值也需要分别计算它们的分类的熵值。 <strong>这里可能会出现困惑</strong>，如果每个特征值都有多个分类，那计算量不是特别大？而且这里的分类是文字，计算量较小，如果分类是数字那么分类几乎不会重复，计算量不是突破天际？我在学决策树时出现了这种疑惑，后来发现算法确实是这样的，并没有错。 分类为文字称为<strong>离散值</strong>，分类为数值称为<strong>连续值</strong>。上面说到决策树碰到连续值计算量会非常大，解决办法：<a href="https://www.baidu.com/s?wd=%E5%86%B3%E7%AD%96%E6%A0%91%E8%BF%9E%E7%BB%AD%E5%80%BC%E5%A4%84%E7%90%86" target="_blank" rel="noopener">决策树连续值处理</a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E6%AD%A5%E9%AA%A4%E2%80%94%E2%80%94%E8%AE%A1%E7%AE%97%E5%85%B6%E4%BB%96%E7%89%B9%E5%BE%81%E7%9A%84%E7%86%B5%E5%80%BC.jpg" alt="计算其他特征的熵值" /> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%86%B3%E7%AD%96%E6%A0%91%E6%9E%84%E5%BB%BA%E6%AD%A5%E9%AA%A4%E2%80%94%E2%80%94%E5%85%B6%E4%BB%96%E7%89%B9%E5%BE%81%E4%BB%A5%E5%8F%8A%E5%85%B6%E5%88%86%E7%B1%BB.jpg" alt="其他特征以及其分类" /> 3. 通过1和2对比，选择出熵值最低的特征，并且熵值需要小于原始数据的基本熵值。 上述123步，均可以直接在choose_best_feature_index(dataset)函数中计算获得，顶多加几个封装过的函数，比如calculate_entropy(dataset)，split_dataset(dataset, axis, value)等。 4. 删除已作出决策的数据，并将数据再次执行123步操作。 比如经过一轮筛选发现 outlook 为熵值最低的特征，则按照 outlook 的 3 个类别，决策树将会有 3 条分支，节点与节点连接的边上的值分别是 sunny、overcast 和 rainy。 首先按类别 sunny 继续往下决策，比如所有数据中，类别为 sunny 的数据全部为 yes，即想要出去打球，那么决策树递归结束。因为这个算法的目的就是要判断在这些特征下，这一天去打球是否合适，如果 sunny 下的每条数据都是 yes，就代表我们的目的已经达到了，也就没必要继续决策了。接下来假设类别 overcast 与 sunny 相反，那么就将类别是 overcast 的所有数据从原数据集中删去，再重复 123 步。 5. 构造决策树，决策树可以使用递归算法构建。 新手入门系列，完全可以仅使用python的dict来存储决策树。如：{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'no': {'age': {'young': 'soft', 'pre': 'soft', 'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}}}}, 'yes': {'prescript': {'hyper': {'age': {'young': 'hard', 'pre': 'no lenses', 'presbyopic': 'no lenses'}}, 'myope': 'hard'}}}}}}</p>
<h3 id="举一个简单的例子">举一个简单的例子</h3>
<p><a href="https://github.com/yan624/machine_learning_algorithms/tree/master/decision_tree/simple_demo" target="_blank" rel="noopener">这里有一个简单例子</a> 运行结果： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%80%E5%8D%95%E4%B8%BE%E4%BE%8B%E6%9C%80%E7%BB%88%E7%BB%93%E6%9E%9C%E5%9B%BE.png" alt="决策树简单举例最终结果图" /></p>
<h3 id="其他还未解决的问题">其他还未解决的问题</h3>
<ul>
<li>决策树处理缺失值</li>
<li>决策树处理连续值</li>
<li>剪枝的问题 <!-- more --></li>
</ul>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（二）：逻辑回归</title>
    <url>/posts/cf91ea54.html</url>
    <content><![CDATA[<a id="more"></a>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>逻辑回归</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习算法（一）：线性回归</title>
    <url>/posts/5cbfe6f6.html</url>
    <content><![CDATA[<h1 id="线性回归">线性回归</h1>
<ul>
<li>优点：结果易于理解，计算上不复杂。</li>
<li>缺点：对非线性的数据拟合不好。</li>
<li>适用数据类型：数值型和标称型数据。</li>
</ul>
<p>比如预测汽车的功率，可能会这么计算：<code>horse_power = 0.0015 * annual_salary - 0.99 * hours_listening_to_public_radio</code>。</p>
<p>这就是所谓的<strong>回归方程（regression equation）</strong>，其中 0.0015 和 -0.99 称作<strong>回归系数（regression weights）</strong>，求这些回归系数的过程就是回归。</p>
<blockquote>
<p>回归一词的由来：是由达尔文（Charles Darwin）的表兄弟 Francis Galton 发明的。</p>
</blockquote>
<p>线性回归的代价函数是： <a id="more"></a> <span class="math display">\[
cost = \sum^m_{i = 1}(y_i - x^T_i W)^2
\]</span></p>
<p>用矩阵可以表示为 <span class="math inline">\((y - XW)^T(y - XW)\)</span>，如果对 W 求导就可以得到 <span class="math inline">\(X^T(Y - XW)\)</span>。令其等于 0，解得 W: <span class="math display">\[
\hat{W} = (X^TX)^{-1} X^Ty
\]</span> 这公式也可以被称为<strong>正规方程</strong>。需要注意的点是 <span class="math inline">\((X^TX)^{-1}\)</span> 是一个求逆的过程，但是矩阵求逆在有些情况下是无解的，所以 <span class="math inline">\((X^TX)^{-1}\)</span> 必须有解才可以使用正规方程，如果无解就不能直接使用正规方程。</p>
<p>上述求解过程被称为最小二乘法（ordinary least squares），简称 OLS。</p>
<h1 id="局部加权线性回归">局部加权线性回归</h1>
<p>线性回归的一个问题是有可能出现欠拟合现象。所以有些方法允许在估计中引入一些偏差，从而降低预测的均方差。其中一个方法是局部加权线性回归（Locally Weighted Linear Regression, LWLR），<strong>该算法给待预测点附近的每个点赋予一定的权重</strong>。所以正规方程的公式变为：</p>
<p><span class="math display">\[
\theta = (X^TWX)^{-1}X^TWy
\]</span></p>
<p>需要说明一点省得搞混了，刚才我自己都乱了，<em>这里引入的偏差并不是线性方程 y = WX + b 中的偏差</em>。公式中的 W 是一个矩阵，用来给每个数据点赋予权重。LWLR 使用“核”（与支持向量机中的核类似）来<u>对附近的点赋予更高的权重</u>。核的类型可以自由选择，最常用的核就是高斯核，对应权重如下（<strong>那两竖不是求绝对值，而是求模长</strong>）：</p>
<p><span class="math display">\[
w(i, i) = exp(\frac{|x^{(i)} - x|}{-2k^2})
\]</span></p>
<p>这样就构建了一个只含对角的权重矩阵 W，并且点 x 与 <span class="math inline">\(x^{(i)}\)</span> 越近，w(i, i)将会越大。上述公式<strong>只</strong>包含一个需要用户指定的参数 k，它决定了对附近的点赋予多大的权重。对高斯核公式的解释：</p>
<ol type="1">
<li>W 是一个对角矩阵，因为高斯核每次赋值都是在 (i, i)点上赋值。主要说明 <span class="math inline">\(|x^{(i)} - x|\)</span> 部分，其他部分都很好理解。首先说明 x 代表待预测的点，其次开始遍历每一项数据，数据记为t，计算每一个 |t - x| ，这样就得到了一个对角矩阵。意思就是通过待预测点经过一系列运算，为所有数据加上了一个权重。当然这里肯定也计算自己本身，不过自己减自己就是等于 0，e 的 0 次方等于1，所以就等于没有给自己加权重。最后使用公式 <span class="math inline">\((X^TWX)^{-1}X^TWy\)</span> 求出了解，也就是回归方程的回归系数 W。这里面有两个一模一样的 W，但是意思完全不同，应该可以理解，我就不改了。有了回归系数就可以做预测了，prediction = XW。结束。</li>
<li>这样一来就计算好了第一个数据，注意：假设我们有 200 条数据，上述的步骤仅仅才计算了第一条数据，接着取出第二条数据 x（待预测点），再经过上述的步骤，又得到了回归系数 W，做预测，结束。</li>
<li>如此反复，直到取出第 200 条数据 x（待预测点），再经过上述的步骤，又得到了回归系数 W，做预测，结束。</li>
<li>这部分理解起来比较麻烦，故下面放出代码。<strong>从for 循环开始到 return 前都是上述123步的代码版本</strong>。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LWLR</span><span class="params">(X, Y, k=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    局部加权线性回归，Locally Weighted Linear Regression</span></span><br><span class="line"><span class="string">    :param X: input</span></span><br><span class="line"><span class="string">    :param Y: label</span></span><br><span class="line"><span class="string">    :param k: 超参数</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        prediction: 预测值</span></span><br><span class="line"><span class="string">        W: 回归系数，占个位置，可能以后会有用，现在没卵用</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    X, Y = np.matrix(X), np.matrix(Y)</span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(np.dot(X.T, X)) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"矩阵不可逆"</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    m = X.shape[<span class="number">0</span>]</span><br><span class="line">    weights = np.matrix(np.eye(m))</span><br><span class="line">    prediction = np.empty((m, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">	<span class="comment"># 使用第 i 个数据点对包括自己在内的每个数据点赋予权重，对自己就是赋予 1 的权重值，也就是说等于没赋予。</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        predict_dot = X[i, :]</span><br><span class="line">        <span class="comment"># 计算权重</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(m):</span><br><span class="line">            <span class="comment"># 这是高斯核的公式</span></span><br><span class="line">            difference = X[j, :] - predict_dot</span><br><span class="line">            weights[j, j] = np.exp((difference * difference.T) / (<span class="number">-2</span> * (k ** <span class="number">2</span>)))</span><br><span class="line">        W = (X.T * weights * X).I * (X.T * weights * Y)</span><br><span class="line">        prediction[i] = predict_dot * W</span><br><span class="line">    <span class="keyword">return</span> prediction, np.empty((m, m, m))</span><br></pre></td></tr></table></figure>
<h1 id="岭回归l2">岭回归（L2）</h1>
<p>岭回归中的岭是什么？</p>
<blockquote>
<p>岭回归使用了单位矩阵乘以常量 <span class="math inline">\(\lambda\)</span>，观察单位矩阵 I，发现值 1 贯穿这个对角线，其余元素全是 0。形象地，在 0 构成的平面上有一条由 1 组成的“岭”，这就是岭的由来。</p>
</blockquote>
<p>简单来说，岭回归就是在矩阵 <span class="math inline">\(X^TX\)</span> 上加上一个 <span class="math inline">\(\lambda I\)</span>从而使得矩阵非奇异。进而能对 <span class="math inline">\(X^X + \lambda I\)</span>求逆，其中 I 是一个单位矩阵，而 <span class="math inline">\(\lambda\)</span> 是用户定义的数值。正规方程变为：</p>
<p><span class="math display">\[
\theta = (X^TX + \lambda I)^{-1}X^Ty
\]</span></p>
<p>这里发现这个公式与加入 L2 正则化一样。（经百度之后，发现还真一样，所以这部分就不细写了）</p>
<p>加入 L2 正则化的代价函数为：</p>
<p><span class="math display">\[
\begin{aligned}
    cost &amp; = \sum^m_{i = 1}(y_i - x^T_i W)^2 + \lambda ||W||_2\\
    &amp; = \sum^m_{i = 1}(y_i - x^T_i W)^2 + \lambda \sum^m_{j = 1}w^2_j
\end{aligned}
\]</span></p>
<p><a href="https://www.zhihu.com/question/28221429" target="_blank" rel="noopener">知乎问题</a></p>
<h1 id="lassol1">lasso(L1)</h1>
<p>略。</p>
<p>补充，参考<a href="https://www.cnblogs.com/mantch/p/10242077.html" target="_blank" rel="noopener">文章</a>，发现岭回归其实就是在<strong>代价函数</strong>（<u>注意是代价函数，不是正规方程</u>）中加入了 L2 正则化，lasso 其实就是在<strong>代价函数</strong>中加入了 L1 正则化。</p>
<h1 id="前向逐步回归">前向逐步回归</h1>
]]></content>
      <categories>
        <category>AI</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>机器学习算法</tag>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop学习记录（一）：Hadoop集群搭建</title>
    <url>/posts/d766aa.html</url>
    <content><![CDATA[<h3 id="使用jps发现没有namenode">使用jps，发现没有namenode</h3>
<p>使用命令<code>/opt/hadoop/sbin/start-all.sh</code>启动hadoop，之后使用jsp，一般来讲会出现如下6个线程 <figure class="highlight basic"><table><tr><td class="code"><pre><span class="line"><span class="symbol">55598 </span>Jps</span><br><span class="line"><span class="symbol">54490 </span>NameNode</span><br><span class="line"><span class="symbol">54684 </span>DataNode</span><br><span class="line"><span class="symbol">54931 </span>SecondaryNameNode</span><br><span class="line"><span class="symbol">55332 </span>NodeManager</span><br><span class="line"><span class="symbol">38251 </span>ResourceManager</span><br></pre></td></tr></table></figure> 但是我发现我运行后没有出现namenode。仔细观察中断启动时的日志发现，namenode的日志记录在<strong>/opt/hadoop/logs/hadoop-zhangyu-namenode-a2d8c523dd0b.log</strong>中，打开它，发现在最后居然报了异常。由于Hadoop是java写的，异常很好认（我就是学java出身的）。 <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">java<span class="selector-class">.io</span><span class="selector-class">.IOException</span>: There appears to be <span class="selector-tag">a</span> gap <span class="keyword">in</span> the edit log.  We expected txid <span class="number">1</span>, but got txid <span class="number">16</span>.</span><br></pre></td></tr></table></figure> 百度之后发现namenode的元数据破坏，需要恢复，具体参考<a href="https://blog.csdn.net/u011478909/article/details/51864071" target="_blank" rel="noopener">某csdn博客</a>。 使用<code>hadoop namenode -recover</code>即可恢复。 <a id="more"></a></p>
<h3 id="使用jps发现没有datanode">使用jps，发现没有datanode</h3>
<p>总结写在前： 由于意外hadoop没有创建data文件夹，执行<code>cp -r /data/tmp/hadoop/tmp/dfs/data /data/tmp/hadoop/hdfs</code>，并修改clusterId，clusterId在<strong>/data/tmp/hadoop/hdfs/data/current/VERSION</strong>中。</p>
<p>在执行上面的操作修复namenode之后，发现原来在的datanode居然不见了。还是使用老办法发现日志文件（日志文件名字太长就不写了），异常：<code>All specified directories are failed to load。</code>。经过百度之后发现是datanode和namenode配置文件的VERSION文件中的clusterId不一致。所以只需要将clusterId更改成一致即可。 但是我的出现的问题重点不是这个，我在修改clusterId时发现：我的namenode配置在/data/tmp/hadoop/hdfs/name中。但是检查我的datanode配置是否在/data/tmp/hadoop/hdfs/data中时，发现hadoop根本没有创建这个文件夹。于是又进行排查，发现在/data/tmp/hadoop/tmp/dfs中存在data文件夹。于是使用命令<code>cp /data/tmp/hadoop/tmp/dfs/data /data/tmp/hadoop/hdfs</code>，将这份data文件夹拷贝到/data/tmp/hadoop/hdfs，并更改clusterId。<strong>VERSION文件在/data/tmp/hadoop/hdfs/data/current</strong></p>
]]></content>
      <categories>
        <category>notes</category>
        <category>big-data</category>
      </categories>
      <tags>
        <tag>系列</tag>
        <tag>学习笔记</tag>
        <tag>hadoop</tag>
        <tag>big data</tag>
      </tags>
  </entry>
  <entry>
    <title>anaconda的锅：使用pyquery出现urlopen-error-unknown-url-type-https</title>
    <url>/posts/6c7af6a.html</url>
    <content><![CDATA[<p>使用pyquery出现urlopen-error-unknown-url-type-https的异常，上网查发现是openssl的问题。话不多说直接说结果。 参考文章如下： <a href="https://blog.csdn.net/gw85047034/article/details/88039705" target="_blank" rel="noopener">anaconda新建环境在PyCharm执行import ssl失败</a></p>
<p>由于anaconda的python版本是3.7.0，而我在创建虚拟环境时，使用命令<code>conda create -n spider python=3</code>，最后的python=3会选择python最新的版本安装，所以anaconda选择了python3.7.3。于是anaconda的python版本和虚拟环境的python版本冲突了，而我把虚拟环境给PyCharm用了，所以就是anaconda和PyCharm冲突了。只要把虚拟环境的python版本换成和anaconda的python版本一致就可以了。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>Python爬虫学习记录（一）：正则表达式</title>
    <url>/posts/6b628223.html</url>
    <content><![CDATA[<h3 id="正则表达式的使用">正则表达式的使用</h3>
<p>正则表达式的匹配规则网上都有，这里不放出来了，毕竟只是记录学习的博文。 以下讲几个一直没搞明白的点。</p>
<h4 id="贪婪与非贪婪">贪婪与非贪婪</h4>
<p>实现介绍通用匹配，以<code>.*</code>表示。<code>.</code>代表匹配任意字符，<code>*</code>代表匹配0个或多个表达式所以两个连用就代表匹配任意字符。比如字符串<code>'Hello Python and Anaconda'</code>，表达式为<code>'^Hello.*Anaconda$'</code>。代码如下： <figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">txt = <span class="string">'Hello Python and Anaconda'</span></span><br><span class="line">result = re.match(<span class="string">"^Hello.*Anaconda$"</span>, txt)</span><br><span class="line"><span class="keyword">print</span>(result.<span class="keyword">group</span>())</span><br></pre></td></tr></table></figure> 可以得出我们想要的结果，因为<code>.*</code>代表匹配任意个字符，所以该正则表达式会在<strong><em>Hello</em></strong>之后一直匹配成功，直到遇到<strong><em>Anaconda</em></strong>停止。其中<code>.*</code>其实就是贪婪匹配。但是有时候贪婪匹配会出很大的问题。比如字符串<code>'My tel number is 15012345678'</code>，正则表达式为<code>'^My.*(\d+)$'</code>。具体代码如下： <a id="more"></a> <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">txt = <span class="string">'My tel number is 15012345678'</span></span><br><span class="line">result = re.match(<span class="string">"^My.*(\d+)$"</span>, txt)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group()</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group(<span class="number">1</span>)</span></span>)</span><br></pre></td></tr></table></figure> 首先这段代码意思是获取字符串中的手机号码，<code>(\d+)</code>代表一个组，这个组里面匹配的东西就是我们需要的结果，而我们的代码也看起来很正常<code>\d+</code>就意味着匹配多个数字。可以看到这段代码<code>print(result.group(1))</code>就是输出手机号。但是结果却只匹配到了8，因为<code>.*</code>代表了贪婪匹配，它会尽可能的匹配到多的字符。因为<code>.*</code>代表匹配任意多的字符串，所以它看到1501234567会一直往下匹配，知道看到8，发现8已经是最后一个数字了，如果这个8不与<code>\d+</code>匹配岂不是出现系统漏洞了，因为<code>\d+</code>就是让你匹配数字，你不匹配不是违反了规则？所以匹配成功。最后将8加入组中，通过result.group(1)获取到这一组。所以贪婪匹配在这种情况是有问题，这就引出了非贪婪匹配：<code>.*?</code>。代码如下： <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">txt = <span class="string">'My tel number is 15012345678'</span></span><br><span class="line">result = re.match(<span class="string">"^My.*?(\d+)$"</span>, txt)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group()</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group(<span class="number">1</span>)</span></span>)</span><br></pre></td></tr></table></figure> 如果运行这段代码，就会发现匹配成功了。所以以后尽量使用非贪婪模式<code>.*?</code>，而不是贪婪模式<code>.*</code>。</p>
<h4 id="修饰符">修饰符</h4>
<p>代码 <figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">import re</span><br><span class="line"></span><br><span class="line">txt = <span class="string">'My tel number is 15012345678'</span></span><br><span class="line">result = re.match(<span class="string">"^My.*?(\d+)$"</span>, txt, re.S)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group()</span></span>)</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(result.group(<span class="number">1</span>)</span></span>)</span><br></pre></td></tr></table></figure> 这里引用了上面的代码，注意多了个re.S，它代表使.匹配包括换行在内的所有字符。也就是说不加re.S，.其实是匹配不到换行符的。应用场景：网页代码中嵌套标签会经常出现这些换行符，要加入re.S。其他的方法re.search(),re.findall()用法类似。 待补充。。。</p>
<h4 id="re模块中的方法">re模块中的方法</h4>
<ol type="1">
<li>match() 这方法从头开始匹配，如果一开始即第一个字符就不匹配，直接就算匹配失败。可以用于校验用户输入的信息是否合乎规范。</li>
<li>search() 从头开始匹配，扫描整个字符串，如果碰到一段字符串匹配成功了就立即返回，它只会返回一个结果。</li>
<li>findall() 跟它名字一样，扫描整个字符串，获得所有匹配成功的结果。</li>
<li>待补充。。。</li>
</ol>
<h3 id="举一个栗子">举一个栗子</h3>
<p>爬取牛客网的技术栈。</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>anaconda安装问题以及之前安装的Python环境取舍问题</title>
    <url>/posts/4838395d.html</url>
    <content><![CDATA[<p>今天安装anaconda时发现了一些问题。</p>
<h3 id="背景介绍">背景介绍</h3>
<p>我在安装anaconda之前，已经安装了Python3.6，这个Python环境是很久以前还在学Java时安装的。然后现在安装完anaconda之后，发现anaconda不会自动将原有的Python环境收为己用。所以就出现了原有的Python怎么处理的问题。</p>
<h3 id="解决">解决</h3>
<p>如果原先的Python环境不是很重要，可以直接删了，改用anaconda提供的虚拟环境。当然同时也要删除电脑环境变量中的Python路径。为了保险可以先删除电脑环境变量中的Python路径，然后打开命令行，输入python，发现已经移除后再删除Python。最后还需要将anaconda添加到环境变量中，不过anaconda在安装时有个选项可以直接将其添加进环境变量，如果之前选择了这个选项。可以不用再添加环境变量了。anaconda环境变量总共需要输入三个变量，如下： <figure class="highlight taggerscript"><table><tr><td class="code"><pre><span class="line">D:<span class="symbol">\a</span>naconda</span><br><span class="line">D:<span class="symbol">\a</span>naconda<span class="symbol">\S</span>cripts</span><br><span class="line">D:<span class="symbol">\a</span>naconda<span class="symbol">\L</span>ibrary<span class="symbol">\b</span>in</span><br></pre></td></tr></table></figure> 注：我所有的编程软件、工具等等都放在D盘。 最后参考以下两篇，其中有anaconda安装教程： <a id="more"></a> - <a href="https://www.jianshu.com/p/eaee1fadc1e9" target="_blank" rel="noopener">Anaconda完全入门指南</a> - <a href="https://blog.csdn.net/qq_37025885/article/details/79158153" target="_blank" rel="noopener">如何在已安装Python条件下，安装Anaconda，并将原有Python添加到Anaconda中</a></p>
<p>其中，他们还创建了其他的虚拟环境，但是我觉得base环境用用算了，因为我刚学python，还不太懂。 至于anaconda可以创建多个虚拟环境，虽然我没用过anaconda，但是我估计理念跟github差不多。想要一个环境直接从别人那拷过来，就不需要自己安装了。 注意记得将Pycharm中的python环境改为anaconda的虚拟环境。其他的虚拟环境路径在D:。base环境在：D:.exe 如下图，进入设置界面，左上角File进入。点OK就行了。图中有个叫Virtualenv Environment的选项，这个看起来是虚拟环境的意思，其实是python本身自带的。它跟anaconda功能一样也是创建一个虚拟环境，但是这是python提供的。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/f095a0ecb23b43dfa99e2a82b720c6ff.jpg" title="创建Python环境" alt="创建Python环境" /></p>
<p>最后，在随便一个音乐平台、网站、软件搜索anaconda，歌手Nicki Minaj。不用谢我(ฅωฅ*)。</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>anaconda</tag>
      </tags>
  </entry>
  <entry>
    <title>spring boot中使用@ConfigurationProperties注解</title>
    <url>/posts/c940f4fc.html</url>
    <content><![CDATA[<p>在使用@ConfigurationProperties注解前必须引入这个依赖 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 为了使用@ConfigurationProperties注解，必须加入这个--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-configuration-processor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">optional</span>&gt;</span>true<span class="tag">&lt;/<span class="name">optional</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>使用方法： <a id="more"></a> <figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="variable">@Component</span></span><br><span class="line"><span class="variable">@ConfigurationProperties</span>(prefix = <span class="string">"io.github.yan624.file"</span>)</span><br><span class="line"><span class="variable">@Data</span></span><br><span class="line">public class PropertiesConfig &#123;</span><br><span class="line">    <span class="selector-tag">private</span> <span class="selector-tag">String</span> <span class="selector-tag">root</span>;</span><br><span class="line">    <span class="selector-tag">private</span> <span class="selector-tag">String</span> <span class="selector-tag">qrPath</span>;</span><br><span class="line">    <span class="selector-tag">private</span> <span class="selector-tag">String</span> <span class="selector-tag">imgPath</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>yml文件： <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">io:</span></span><br><span class="line"><span class="attr">  github:</span></span><br><span class="line"><span class="attr">    yan624:</span></span><br><span class="line"><span class="attr">      file:</span></span><br><span class="line"><span class="attr">        root:</span> <span class="attr">E:/itchat4j/</span></span><br><span class="line"><span class="attr">        qr-path:</span> <span class="string">$&#123;io.github.yan624.file.root&#125;/login</span></span><br><span class="line"><span class="attr">        img-path:</span> <span class="string">$&#123;io.github.yan624.file.root&#125;/img</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<p>其中@Data是lombok插件的注解，用于生成get/set方法</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>spring注解</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅机器学习2017春学习记录及作业：octave实现</title>
    <url>/posts/a2094cb3.html</url>
    <content><![CDATA[<p>所有代码在<a href="https://github.com/yan624/lihongyi-machine-learning-2017-homework" target="_blank" rel="noopener">lihongyi-machine-learning-2017-homework</a>上 ### 学习情况和做题背景 #### 学习情况 先看了<strong>《深度学习》（花书）</strong>这本书，由于我是零基础学习该方向，感觉这本书除了前几章数学方面略看得懂，其他的一脸懵逼。由于本人在学习某一知识之前会预先搜集资料。于是我打开了在知乎收藏的文章，点进了<strong>吴恩达机器学习</strong>网易云课堂。我看了几个算法：线性回归，逻辑回归，神经网络。并且做了线性回归和逻辑回归的练习题。个人感觉吴恩达的视频很适合入门，但是想要仔细理解太难了。我根据吴恩达老师提供的题目，照葫芦画瓢做了一下，做还是做出来了，但是这都是很简单的例子。大都是只有三四个参数，所以感觉只是入门了。 这时候我再去看<strong>《深度学习》</strong>这本书，发现有些内容我看得懂了。但是有只是有些而已，往后看还是无法理解。至此，在寒假中我彻底放弃继续看<strong>《深度学习》</strong>。这个时候我又继续搜集资料，我发现了另一个教学视频就是<strong>李宏毅机器学习</strong>，经过自己的查询，最终决定看这个。李宏毅老师讲的略微会难一点，因为他面向的是研究生，这个从他的课程介绍上可以看得出。可以对比一下， - <strong>吴恩达机器学习</strong>不会涉及任何数学部分，高数、线代、概率论在吴恩达老师的课堂上只会出现名词和推导过程，他不会解释为什么，他假设看这视频的人都不懂数学。因为他的课程面向的是所有人。而且他的课程当中很多知识都是讲解基础知识，深入的东西他会只介绍名词，甚至不会介绍。所以<strong><em>很</em></strong>适合做入门视频，<strong>最重要的是</strong>他的视频都很短，最长的也只有十几分钟。 - <strong>李宏毅机器学习</strong>讲的比吴恩达的深入许多，他会讲解原理，而且讲的也很清楚，并且数学部分他也不会跳过，而且他都是假设你会这部分的数学知识。另外他讲课是讲例子的，主要的例子是预测神奇宝贝进化后的cp值（大概就是战斗力的意思），还会出现一些游戏如帝国时代、我的世界等。这些都会使得课堂很有意思。在b站有他的视频，不过都很长，一个视频打都有60来分钟，有少数极短。最后他的作业数据量大做起来很有意思。 所以我建议先看吴恩达老师的机器学习视频看到神经网络，先入个门要不然看其他人的教学视频可能跟不上节奏，然后看李宏毅老师视频，注意完成他的作业，会很好的帮助自己理解。 <a id="more"></a></p>
<h4 id="做题背景">做题背景</h4>
<p>做完吴恩达老师布置的作业还以为已经懂了什么是线性回归，没想到做李宏毅老师的作业时发现连开个头都困难。在自己瞎做之后，经过五六天完成了作业，但是期间出现了大量问题，所以写这个博文用来纪录。</p>
<h3 id="hw1pm2.5预测">hw1:PM2.5预测</h3>
<h4 id="遇到的问题">遇到的问题</h4>
<ol type="1">
<li>李宏毅老师给的数据，没看懂是什么意思。可能是吴恩达老师和李宏毅老师的概念有一些处理，看了很久没理解这个作业的意思。这个没办法，我自己琢磨了一会才搞懂。</li>
<li>开头第一步，完全不知道干什么。<strong>解决</strong>：选函数。吴恩达称之为hypothesis函数，李宏毅称之为模型(Model)，都一个意思，以下称为hypothesis。</li>
<li>hypothesis函数需要一些特征值，即X。当然还有一个theta。但是特征那么多总不能全选吧，而且是几次方的式子也确定不了。<strong>解决</strong>：将每一个特征和需要预测的y，使用画图函数画出来，特征x作为横坐标，待预测y作为纵坐标。然后观察哪些图像关系比较正常，就用哪个特征（比如呈线性关系的就比较正常）。这也是看到其他人的博客才发现特征是这么选的，之前做了几天都是凭感觉选的。。。</li>
<li>做了半天才发现代码写错了。<strong>解决</strong>：做的时候不要太急，把代码好好检查一下。倒不是程序错误，也不是数据分割错误，我是数据划分的时候少划分一大半导致样本量一直很小。</li>
<li>学习速率(alpha)选择多少正常，第一次做心理没底，选了稍微大一点的如0.1，误差大得直接超出浮点型最大值。<strong>解决</strong>：使用adagrad，可以根据迭代次数的增加，自动减少alpha。</li>
<li>梯度下降的迭代次数选择多少正常，第一次做心理没底。<strong>解决</strong>：经过我反复尝试，虽然我还是没有得到肯定的答案，但是我一般将迭代次数设置为4000.</li>
<li>theta初始值设置为多少正常，第一次做心理没底。<strong>解决</strong>：全部为0，包括bais也设置为0。另外吴恩达老师讲过在神经网络中不能这么设置。</li>
<li>怎么选择hypothesis函数的表达式，到底是二次项，三次项，四次项还是五次项等等。<strong>解决</strong>：暂时没百度过，我看吴恩达老师的视频，个人理解应该是最后在1-10次中选择。</li>
<li>除了一个特征的几次方项，那么多个特征的乘积怎么选择，如有特征值x1,x2,x3，x1*x2*x3还是选x1*x3还是选x2*x3，甚至这些乘积里面的特征也可以加上次方。那项的可能就多了去了，到底该怎么选。<strong>解决</strong>：我刚开始是不加这些项的，也就是表达式的一个项中只会有一个特征。后面加也会自己慢慢尝试，基本上就是碰运气。</li>
<li>标准化的lambda怎么设置。<strong>解决</strong>：吴恩达老师有讲怎么调整lambda值以及lambda值调整会出现问题的情况也讲了，所以我都是感觉误差稳定了或者误差太大了才去调的。一般都设为0。</li>
<li>其他必要的变量怎么设置。<strong>解决</strong>：我真的是完全自己调，然后碰运气。。。</li>
<li>怎么看我训练出来的结果如何。<strong>解决</strong>：梯度下降本质是最后得到一组theta。你需要预测数据，首先肯定有X，然后X * theta，就会得到预测结果。接下来是使用代价函数看误差就行了。吴恩达称之为代价函数(Cost function)，李宏毅称之为损失函数(Loss function)，而且算法也有略微不同，不过问题不大。值得注意的是，之前训练的样本被称为train_data，现在预测的被称为cross_validation_data，是完全不同的数据，不要再用train_data去做预测，具体为什么，吴恩达老师讲的很明白了。</li>
<li>误差到多少才算可以。<strong>解决</strong>：吴恩达老师给出了几幅图，但是个人认为这几幅图有几个瑕疵的地方，那就是他没标刻度，可能是故意没标的，因为根本没刻度。所以压根不知道误差到什么程度才算可以。后来经过不断测试和百度，发现网上一个人认为40多的误差他说可以接受。我个人认为，训练误差0-20差不多，交叉验证误差0-40差不多，预测误差感觉40以下差不多。预测误差就是最终做出的预测产生的误差，所以我感觉要再低点，但是我的作业中训练的一直降不下去，最低都是20多。</li>
</ol>
<h3 id="步骤">步骤</h3>
<ol type="1">
<li>通过分别画出特征值和待输出值的二维图，观察图像来选择特征。</li>
<li>尽可能地把数据处理部分的代码写的完全正确。</li>
<li>选择hypothesis函数，可以从1次方开始尝试。</li>
<li>初始化值。alpha=0.001,iters_num=4000,lambda=0.</li>
<li>开始梯度下降。</li>
<li>出现误差，通过吴恩达老师给出的建议以及李宏毅老师给的补充，可以自行调整。对于我的话，误差太巨大，我一般先调整学习速率alpha(learning rate)和迭代次数iters_num.误差大概到100以内左右才会动特征数量，hypothesis表达式等等这些变量。误差到很小了（这个很小还真不确定，大概0-40左右吧）才会调整lambda。</li>
<li>待补充。</li>
</ol>
]]></content>
      <categories>
        <category>notes</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>ml</tag>
      </tags>
  </entry>
  <entry>
    <title>octave添加io包读取一些特定的文件，如csv,xls等</title>
    <url>/posts/bda4d8e3.html</url>
    <content><![CDATA[<p>输入<code>pkg install -forge io</code>，octave会自动下载，资源在国外会有点卡，需要等一会。 过一会会显示 &gt;For information about changes from previous versions of the io package, run 'news io'.</p>
<p>这不是说明安装失败了，而是安装成功了。意思是让你仔细了解一下io包个版本的区别。输入news io查询。 最后输入<code>pkg load io</code>加载io包。（这句代码不是输入一次永久有效，只要关闭了cli界面，就要重新输入一次，就像java中导包一样） 当读取csv文件时，我使用了csv2cell(&quot;文件名&quot;)函数，但是这个函数有问题，它返回的值不是矩阵貌似是字符串。建议使用csvread(&quot;文件名&quot;)函数</p>
]]></content>
      <categories>
        <category>notes</category>
        <category>ml</category>
      </categories>
      <tags>
        <tag>octave</tag>
      </tags>
  </entry>
  <entry>
    <title>栈和队列</title>
    <url>/posts/8d66b5f2.html</url>
    <content><![CDATA[<h1 id="线性表">线性表</h1>
<p>此章节为基础。线性表分为顺序表和单链表。 <a id="more"></a></p>
<h1 id="栈">栈</h1>
<p>只允许在表的一端就行插入和删除的线性表。栈分为顺序栈和链式栈，以下是它们各个操作的性能对比。</p>
<div class="group-picture"><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/顺序栈各操作性能比较.jpeg" alt="顺序栈各操作性能比较" /></div></div><div class="group-picture-row"><div class="group-picture-column" style="width: 100%;"><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/链式栈个操作性能的比较.jpeg" alt="链式栈个操作性能的比较" /></div></div></div>
<h2 id="顺序栈">顺序栈</h2>
<p>顺序栈指利用一块连续的存储单元作为栈元素的存储空间，只不过借用了数组来实现。设 n 为栈的最大容量，则栈可分为两种形式。</p>
<ol type="1">
<li>静态存储结构：预先申请或定义栈的存储空间，也就是说栈空间的容量有限。若栈满，会上溢。<strong>主要定义存储的数组以及当前top的索引位置</strong>。其他无关变量可自行定义，下同。</li>
<li>动态存储结构：如果栈满可自行扩充栈的大小，其中，原栈A中的内容会全部移植到新栈B。<strong>主要定义存储的数组、top的索引位置以及栈空间最大容量（maxCapacity）</strong>。其中，top 和 maxCapacity 可用来判断栈满栈空等。</li>
</ol>
<h2 id="链式栈">链式栈</h2>
<p>栈的链接存储表示。<strong>主要定义存储数据的变量以及链接下一个节点的变量</strong>。理论上链式栈没有栈满问题，但是它有栈空问题。如下图所示： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/链式栈.jpeg" alt="链式栈" /></p>
<h2 id="双栈">双栈</h2>
<p>双栈共享同一个存储空间：栈0从头部存储，栈1从尾部开始存储，通过标志flag设置0,1等方法判断从头部开始存储还是尾部。两个栈共用一个栈空间，互相调剂，灵活性强。</p>
<h2 id="栈的混洗">栈的混洗</h2>
<p>通过控制进栈和推栈的时机，可以得到不同的退栈序列。如进栈顺序为1，2，3，退栈序列有5种：{1,2,3}，{1,3,2}，{2,1,3}，{2,3,1}，{3,2,1}。注意{3,1,2}是不可能的退栈序列。其他数据元素于此类似。</p>
<h2 id="栈的应用">栈的应用</h2>
<ul>
<li>数制转换</li>
<li>括号匹配</li>
<li>表达式的计算与优先级处理（一般使用后缀表达式计算表达式）</li>
<li>递归</li>
</ul>
<h1 id="队列">队列</h1>
<p>只允许在表的一端插入，在另一端删去。允许插入的一端叫队尾（rear），允许删除的一端叫做对头（front）。</p>
<h2 id="顺序队列">顺序队列</h2>
<p>就是队列的定义。<strong>主要定义存储数据的数组、rear 以及 front</strong>。它也会有溢出的情况：如图所示，数据A从上部进入，A被放在数组的0索引的位置。由于顺序队列是数组实现，所以当A出队列时，A后面的数据不会往前移动，因为如果移动那就要整体的往前移，太浪费时间了。所以当队列进满时，不管第一个数据前面还有没有空位置，都算溢出了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/顺序队列的初始化、插入和删除.jpeg" alt="顺序队列的初始化、插入和删除" /></p>
<h2 id="循环队列">循环队列</h2>
<p>解决了顺序队列的溢出问题。主要定义存储数据的数组、rear以及front。循环队列的首位相接，初始状态下，front和rear都指向0，但是当队列撑满时，rear指向的是front的前一格，这样用于区分是队空还是队满。可用取余（%）的计算方式前进1一格。 对头指针进 1：front = (front + 1) % maxSize; 对尾指针进 1：rear = (rear + 1) % maxSize; <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/循环队列各个操作的性能比较.jpeg" alt="循环队列各个操作的性能比较" /></p>
<h2 id="链式队列">链式队列</h2>
<p>基于单链表的队列。主要定义与单链表不同的是，插入和删除仅限于链表的两端。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/链式队列各个操作的性能比较.jpeg" alt="链式队列各个操作的性能比较" /></p>
<h2 id="单循环队列">单循环队列</h2>
<p>毫无意义，单链表本身所在的空间就不受限制。</p>
<h2 id="队列的应用">队列的应用</h2>
<p>打印杨辉三角与逐行处理</p>
<h2 id="双端队列">双端队列</h2>
<h1 id="杨辉三角队列实现">杨辉三角：队列实现</h1>
<p>下图为打印杨辉三角的文字说明。图片下面将对该文字进行进一步地解释： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/杨辉三角解释.jpeg" alt="杨辉三角解释" /></p>
<ol type="1">
<li>首先队列是从右往左看的（←），杨辉三角第一个数是1。int s,t。将1放入队尾</li>
<li>在生成第二行时，首先放入一个0.(放入0的步骤下面细讲)</li>
<li>令s=0，将1取出，令t=1.s+t=1放入0后面。</li>
<li>令s=t，将0取出令t=0. s+t=1放入1后面。</li>
<li>第二行生成完成。</li>
<li>在生成第三行时。也首先放入一个0.(放入的步骤下面细讲)</li>
<li>令s=0,将1取出，令t=1.s+t=1放入0后面</li>
<li>令s=t，将1取出令t=1. s+t=2放入1后面。</li>
<li>以此类推。</li>
</ol>
<p>注：每生成一行之前都需要将s置为0；并且在队列尾部放入一个0，但是这里放一个0只是口头上表示的，实际写代码的时候，由于程序时线性执行的，电脑无法判断什么时候放0.所以需要写条件：当从队列中拿出一个0那么就代表一行生成完毕，所以当一个数与从队列中拿出的0相加时，就可以在队尾加一个0。下图是一个小型的演示。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/algorithm/data-structure/栈和队列/杨辉三角画图解释.jpeg" alt="杨辉三角画图解释" /></p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Description:</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* @Auther: zhuchongyan</span></span><br><span class="line"><span class="comment">* @Date: 2018/10/4 22:34</span></span><br><span class="line"><span class="comment">* @Version: 1.0</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="built_in">public</span> <span class="keyword">class</span> YangHuiSanJiao &#123;</span><br><span class="line"></span><br><span class="line">    private <span class="type">int</span> initialValue = <span class="number">1</span>;</span><br><span class="line">    LinkedList&lt;<span class="type">Integer</span>&gt; queue = <span class="built_in">new</span> LinkedList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 初始化</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    &#123;</span><br><span class="line">        queue.<span class="keyword">add</span>(initialValue);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 生成新的一行</span></span><br><span class="line"><span class="comment">    * @param index</span></span><br><span class="line"><span class="comment">    * @return</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="built_in">public</span> <span class="type">int</span> generateNewLine(<span class="type">int</span> <span class="keyword">index</span>)&#123;</span><br><span class="line">        //每次生成新的一行都要在队尾加一个<span class="number">0</span></span><br><span class="line">        queue.<span class="keyword">add</span>(<span class="number">0</span>);</span><br><span class="line">        <span class="type">int</span> s = <span class="number">0</span>, t = <span class="number">0</span>;</span><br><span class="line">        //用<span class="keyword">while</span>循环实现不了，写一年半代码第一次用<span class="keyword">do</span> <span class="keyword">while</span>循环</span><br><span class="line">        <span class="keyword">do</span>&#123;</span><br><span class="line">            t = queue.<span class="keyword">get</span>(<span class="keyword">index</span>);</span><br><span class="line">            queue.<span class="keyword">add</span>(s + t);</span><br><span class="line">            s = t;</span><br><span class="line">            <span class="keyword">index</span>++;</span><br><span class="line">        &#125;<span class="keyword">while</span>(!isZero(<span class="keyword">index</span> - <span class="number">1</span>));//如果是<span class="number">0</span>就要退出循环，因为新的一行已经生成完毕</span><br><span class="line">        //<span class="keyword">return</span>可有可无</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">index</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 这运行</span></span><br><span class="line"><span class="comment">    * @param args</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="built_in">public</span> static <span class="type">void</span> main(String[] args) &#123;</span><br><span class="line">        YangHuiSanJiao yangHuiSanJiao = <span class="built_in">new</span> YangHuiSanJiao();</span><br><span class="line">        Scanner scanner = <span class="built_in">new</span> Scanner(<span class="keyword">System</span>.<span class="keyword">in</span>);</span><br><span class="line">        <span class="keyword">System</span>.<span class="keyword">out</span>.println("请输入杨辉三角行数");</span><br><span class="line">        <span class="type">int</span> <span class="type">line</span> = scanner.nextInt();</span><br><span class="line">        <span class="keyword">if</span>(<span class="type">line</span> &gt;= <span class="number">2</span>)&#123;</span><br><span class="line">            <span class="type">int</span> <span class="keyword">index</span> = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="type">line</span>; i++) &#123;</span><br><span class="line">                <span class="keyword">index</span> = yangHuiSanJiao.generateNewLine(<span class="keyword">index</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        yangHuiSanJiao.print();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //判断该位置的数据是不是<span class="number">0</span></span><br><span class="line">    <span class="built_in">public</span> <span class="type">boolean</span> isZero(<span class="type">int</span> <span class="keyword">index</span>)&#123;</span><br><span class="line">        returnqueue.<span class="keyword">get</span>(<span class="keyword">index</span>) == <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">public</span> <span class="type">void</span> print()&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; queue.size(); i++) &#123;</span><br><span class="line">            <span class="type">Integer</span> data = queue.<span class="keyword">get</span>(i);</span><br><span class="line">            <span class="keyword">if</span>(data == <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">System</span>.<span class="keyword">out</span>.println();</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">System</span>.<span class="keyword">out</span>.print(data + "\t");</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>algorithm</category>
        <category>data-structure</category>
      </categories>
      <tags>
        <tag>4me</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello Hexo</title>
    <url>/posts/4a17b156.html</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>. <a id="more"></a></p>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>hexo</category>
      </categories>
  </entry>
  <entry>
    <title>用idea创建gradle构建的项目</title>
    <url>/posts/d5a8dffe.html</url>
    <content><![CDATA[<p>在网上找了找发现没几个人用maven创建kotlin项目，而我以前一直都用maven，没用过gradle，所以只能当学习gradle了。 第一步：选择gradle <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/f9fdef1607a94d4788848429af5af5a6.png" title="选择gradle" alt="选择gradle" /> 第二步填写GroupId和ArrtifactId，这个很简单。略。 第三步，默认是这样的窗口，但是我选择了User auto-import（自动导包功能），其他都是默认值。 <a id="more"></a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/70cb9fa0d58142f094e14a8c8a9f0a79.png" title="一些配置" alt="一些配置" /> 第四步，看看项目的所在文件夹没问题就可以finish了。 第五步，发现项目的文件夹有问题，只有个.idea。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/fa8abf0e9fa54d658512abb05b9436ae.png" title="项目目录只有.idea文件夹" alt="项目目录只有.idea文件夹" /> 第六步，我是第一次用gradle，只要等gradle下完就行了。如果下完还是没有，那么重启一下idea就行了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/6acb9a4b777f4c08b60fcce2a8f425eb.png" title="成功构建" alt="成功构建" /> <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>android</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title>（十）搭建springcloud：记录项目运行的日志</title>
    <url>/posts/3d97729c.html</url>
    <content><![CDATA[<p>项目运行避免不了出现错误，这是日志就帮了大忙。 springboot提供了一个便捷的方法配置日志。在application.yml中加入以下配置，其中com.yan624代表包名，即这个包下的所有类输出的日志都是error以上级别。 <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">logging:</span></span><br><span class="line"><span class="attr">  file:</span> <span class="string">upms.log</span></span><br><span class="line"><span class="attr">  level:</span></span><br><span class="line">    <span class="string">com.yan624:</span> <span class="string">error</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<p>如果如下配置，就代表项目的所有类输出的日志都是error以上级别 <a id="more"></a> <figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">logging:</span></span><br><span class="line"><span class="attr">  file:</span> <span class="string">upms.log</span></span><br><span class="line"><span class="attr">  level:</span></span><br><span class="line"><span class="attr">    root:</span> <span class="string">error</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<p>但是这样配置无法做出更灵活的操作，比如将info的日志输出到info.log；将warn的日志输出到warn.log；将error的日志输出到error.log。 所以可以删除上面的配置，在classpath路径中新建logback.xml文件，里面填入： <figure class="highlight dust"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 修改一下自己想配置的路径，就一个点代表项目根路径--&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"LOG_PATH"</span> <span class="attr">value</span>=<span class="string">"."</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- start springboot default configuration of console log pattern --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 彩色日志 --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 彩色日志依赖的渲染类 --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"clr"</span> <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.ColorConverter"</span>/&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"wex"</span> <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"</span>/&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">conversionRule</span> <span class="attr">conversionWord</span>=<span class="string">"wEx"</span> <span class="attr">converterClass</span>=<span class="string">"org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"</span>/&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 彩色日志格式 --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"CONSOLE_LOG_PATTERN"</span></span></span></span><br><span class="line"><span class="xml">              value="$</span><span class="template-variable">&#123;CONSOLE_LOG_PATTERN:-%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;</span><span class="xml">)</span><span class="template-variable">&#123;faint&#125;</span><span class="xml"> %clr($</span><span class="template-variable">&#123;LOG_LEVEL_PATTERN:-%5p&#125;</span><span class="xml">) %clr($</span><span class="template-variable">&#123;PID:- &#125;</span><span class="xml">)</span><span class="template-variable">&#123;magenta&#125;</span><span class="xml"> %clr(---)</span><span class="template-variable">&#123;faint&#125;</span><span class="xml"> %clr([%15.15t])</span><span class="template-variable">&#123;faint&#125;</span><span class="xml"> %clr(%-40.40logger</span><span class="template-variable">&#123;39&#125;</span><span class="xml">)</span><span class="template-variable">&#123;cyan&#125;</span><span class="xml"> %clr(:)</span><span class="template-variable">&#123;faint&#125;</span><span class="xml"> %m%n$</span><span class="template-variable">&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;</span><span class="xml">&#125;"/&gt;</span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"FILE_LOG_PATTERN"</span> <span class="attr">value</span>=<span class="string">"%date %-5level [$</span></span></span><span class="template-variable">&#123;HOSTNAME&#125;</span><span class="xml"><span class="tag"><span class="string"> %thread] %caller</span></span></span><span class="template-variable">&#123;1&#125;</span><span class="xml"><span class="tag"><span class="string">%msg%n"</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 控制台输出 --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"CONSOLE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.ConsoleAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">Pattern</span>&gt;</span>$</span><span class="template-variable">&#123;CONSOLE_LOG_PATTERN&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">Pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span> <span class="comment">&lt;!-- 此处设置字符集 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--此日志appender是为开发使用，只配置最底级别，控制台输出的日志级别是大于或等于此级别的日志信息--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.ThresholdFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>info<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- end springboot default configuration of console log pattern --&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 输出自己项目的日志，我比较喜欢将第三方的日志和自己的日志区分开存放，如果没我这样的强迫症可以不配置 --&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"MY_PROJECT_LOG_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$</span><span class="template-variable">&#123;LOG_PATH&#125;</span><span class="xml">/my-project.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--日志文件输出格式--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$</span><span class="template-variable">&#123;FILE_LOG_PATTERN&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span> <span class="comment">&lt;!-- 此处设置字符集 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>my-project/my-project-%d</span><span class="template-variable">&#123;yyyy-MM-dd&#125;</span><span class="xml">.%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="xml">                除按日志记录之外，还配置了日志文件不能超过20M，若超过20M，日志文件会以索引0开始，</span></span><br><span class="line"><span class="xml">                命名日志文件，例如info/info-2019-01-03.0.log</span></span><br><span class="line"><span class="xml">            --&gt;</span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>20MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--日志文件保留天数--&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 此日志文件只记录info级别的 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>info<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"INFO_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$</span><span class="template-variable">&#123;LOG_PATH&#125;</span><span class="xml">/info.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--日志文件输出格式--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$</span><span class="template-variable">&#123;FILE_LOG_PATTERN&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span> <span class="comment">&lt;!-- 此处设置字符集 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>info/info-%d</span><span class="template-variable">&#123;yyyy-MM-dd&#125;</span><span class="xml">.%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="xml">                除按日志记录之外，还配置了日志文件不能超过20M，若超过20M，日志文件会以索引0开始，</span></span><br><span class="line"><span class="xml">                命名日志文件，例如info/info-2019-01-03.0.log</span></span><br><span class="line"><span class="xml">            --&gt;</span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>20MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--日志文件保留天数--&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 此日志文件只记录info级别的 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>info<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="xml">                以下两个配置代表匹配到日志等级为info则输出，否则拒绝输出。</span></span><br><span class="line"><span class="xml">                如果删除这两行配置，那么这两个配置的默认值为NEUTRAL，意味着从日志等级info开始一层一层向上打印，即info-&gt;warn-&gt;error-&gt;fatal-&gt;off</span></span><br><span class="line"><span class="xml">                再比如上面<span class="tag">&lt;<span class="name">level</span>&gt;</span>配置的是error,那么输出error-&gt;fatal-&gt;off</span></span><br><span class="line"><span class="xml">                如果上面<span class="tag">&lt;<span class="name">level</span>&gt;</span>配置的是off，那么就只输出off等级的日志。</span></span><br><span class="line"><span class="xml">             --&gt;</span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"WARN_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$</span><span class="template-variable">&#123;LOG_PATH&#125;</span><span class="xml">/warn.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--日志文件输出格式--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$</span><span class="template-variable">&#123;FILE_LOG_PATTERN&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span> <span class="comment">&lt;!-- 此处设置字符集 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>warn/warn-%d</span><span class="template-variable">&#123;yyyy-MM-dd&#125;</span><span class="xml">.%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="xml">                除按日志记录之外，还配置了日志文件不能超过20M，若超过20M，日志文件会以索引0开始，</span></span><br><span class="line"><span class="xml">                命名日志文件，例如warn/warn-2019-01-03.0.log</span></span><br><span class="line"><span class="xml">            --&gt;</span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>20MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--日志文件保留天数--&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 此日志文件只记录warn级别的 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>warn<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">"ERROR_FILE"</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.RollingFileAppender"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">file</span>&gt;</span>$</span><span class="template-variable">&#123;LOG_PATH&#125;</span><span class="xml">/error.log<span class="tag">&lt;/<span class="name">file</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--日志文件输出格式--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>$</span><span class="template-variable">&#123;FILE_LOG_PATTERN&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">charset</span>&gt;</span>UTF-8<span class="tag">&lt;/<span class="name">charset</span>&gt;</span> <span class="comment">&lt;!-- 此处设置字符集 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">rollingPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.TimeBasedRollingPolicy"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">fileNamePattern</span>&gt;</span>error/error-%d</span><span class="template-variable">&#123;yyyy-MM-dd&#125;</span><span class="xml">.%i.log<span class="tag">&lt;/<span class="name">fileNamePattern</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--</span></span></span><br><span class="line"><span class="xml">                除按日志记录之外，还配置了日志文件不能超过20M，若超过20M，日志文件会以索引0开始，</span></span><br><span class="line"><span class="xml">                命名日志文件，例如error/error-2019-01-03.0.log</span></span><br><span class="line"><span class="xml">            --&gt;</span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">timeBasedFileNamingAndTriggeringPolicy</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"</span>&gt;</span></span></span><br><span class="line"><span class="xml">                <span class="tag">&lt;<span class="name">maxFileSize</span>&gt;</span>20MB<span class="tag">&lt;/<span class="name">maxFileSize</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;/<span class="name">timeBasedFileNamingAndTriggeringPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--日志文件保留天数--&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="comment">&lt;!--&lt;maxHistory&gt;30&lt;/maxHistory&gt;--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">rollingPolicy</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 此日志文件只记录error级别的 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">filter</span> <span class="attr">class</span>=<span class="string">"ch.qos.logback.classic.filter.LevelFilter"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">level</span>&gt;</span>error<span class="tag">&lt;/<span class="name">level</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMatch</span>&gt;</span>ACCEPT<span class="tag">&lt;/<span class="name">onMatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">onMismatch</span>&gt;</span>DENY<span class="tag">&lt;/<span class="name">onMismatch</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">filter</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">"test"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 控制台输出info级别以上的日志 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"CONSOLE"</span> /&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">springProfile</span> <span class="attr">name</span>=<span class="string">"prod"</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!--这里的name属性代表所属包的名称是以io.github.yan624.messageporter开头的类，会按照这个logger的配置打印日志--&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">logger</span> <span class="attr">name</span>=<span class="string">"io.github.yan624.messageporter"</span> <span class="attr">additivity</span>=<span class="string">"false"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"MY_PROJECT_LOG_FILE"</span> /&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">logger</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 打印warn，error级别的日志 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"warn"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"WARN_FILE"</span> /&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"ERROR_FILE"</span> /&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 控制台输出info级别以上的日志 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">"info"</span>&gt;</span></span></span><br><span class="line"><span class="xml">            <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">"CONSOLE"</span> /&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">springProfile</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure></p>
<p>并且在application.yml文件中自己配置 <figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">spring:</span></span><br><span class="line"><span class="symbol">  profiles:</span></span><br><span class="line"><span class="symbol">    active:</span> prod</span><br></pre></td></tr></table></figure> 这样代表了激活了prod的日志配置。对应于logback.xml文件中的<code>&lt;springProfile name=&quot;prod&quot;&gt;。。。&lt;/springProfile&gt;</code>。 如果希望把自己某个包中的类的日志输出，在appender-&gt;filter标签下不能写onMacth和onMisMatch具体原因不知，反正我是去掉了就可以输出了。参考springProfile-&gt;logger的name=&quot;com.yan624&quot;。其中MY_PROJECT_FILE的appender我并没有配置onMacth和onMisMatch。 名为CONSOLE的appender是springboot的默认输出格式，我在该xml中已经写明注释。 其他的应该都很好理解。 最后效果就是：在warn.log和error.log文件中分别输出warn和error级别的日志。在控制台输出info<strong>以上</strong>级别的日志。在my-project.log文件中输出我自己项目的info级别<strong>以上</strong>的日志。 上面我写了info级别的配置，但是我并没有使用，另外debug级别的配置我没有写，因为我用不上。</p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（九）搭建springcloud：在linux上运行springboot项目</title>
    <url>/posts/fce5c969.html</url>
    <content><![CDATA[<p>具将本地的jar文件拖到服务器上时发现，jar文件只有3kb。果然使用“java -jar 项目名.jar”命令后，显示<strong>no main manifest attribute, in springboot项目名.jar</strong>。 解决办法：在项目中（不是聚合父工程中）添加如下代码</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- 指定该Main Class为全局的唯一入口 --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.yan624.eureka.Eureka_Server7001<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">layout</span>&gt;</span>JAR<span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>repackage<span class="tag">&lt;/<span class="name">goal</span>&gt;</span><span class="comment">&lt;!--可以把依赖的包都打包到生成的Jar包中--&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>由于如果直接使用java -jar 项目名.jar启动springboot项目，会造成你启动了这个项目就不用想输入其他命令了，所以使用 “<strong>nohup java -jar springboot项目名.jar &gt;记录日志的文件名.log 2&gt;&amp;1 &amp;</strong>”命令，来让spirngboot项目后台运行，并且记录日志。 如果不想输出日志，可以使用“<strong>nohup java -jar springboot项目名.jar &gt;/dev/null 2&gt;&amp;1 &amp;</strong>”</p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>springboot启动出现Unable to start EmbeddedWebApplicationContext due to missing EmbeddedServlet</title>
    <url>/posts/c032153f.html</url>
    <content><![CDATA[<p>网上的解决办法打都相同，但是我这个问题纯属操作失误。</p>
<p>因为我想要启动我的微服务，但是在idea里配置的时候配置错了。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/abaa4d89631040ac90ccc023a34ac1d3.png" title="idea配置" alt="idea配置" /></p>
<p>我把主启动类配错了。可以看到下图主启动类是CMS_BLOG8082，但是手滑选择了CmsBlogApiApplication。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/a61afd34f52f46299eca32ab412f668b.png" title="主启动类" alt="主启动类" /> <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>印象笔记上的博文</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title>idea启动的项目，打开网页出现部分文字乱码</title>
    <url>/posts/e26db4b5.html</url>
    <content><![CDATA[<p>起因： 在文件中右键点击file encoding，打算更改编码，但是出现一个窗口显示Reloead,Convert,Cancel。由于不懂这几个按键按后的效果是什么所以瞎按，导致文件完全乱码，恢复不回去。 之后在打开网页时，发现有部分中文乱码，而且乱码还是出现在前端部分，而且我的文件格式全是utf-8，所以按理说应该没有任何问题。最终也没有解决问题。 解决办法： 重新配置idea。重置方法详见：https://jingyan.baidu.com/article/fa4125ac1c613f28ac7092c1.html <em>更新：这个方法治标不治本，导致了部分页面恢复正常了，但是其他页面还是有问题。</em> <strong>终极解决办法：</strong>找到错误的根源，可能是html，也可能是js。大部分都是js的错误，由于js动态地将中文添加到页面，导致乱码。所以需要将这份js文件，复制出来，用windows的文本文档打开，另存为的时候修改编码为urf-8。再复制回项目即可。</p>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>印象笔记上的博文</tag>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title>（零）搭建springcloud：创建项目</title>
    <url>/posts/af54e3b1.html</url>
    <content><![CDATA[<h3 id="创建springboot项目">创建springboot项目</h3>
<p>右键父工程选择new-&gt;module，创建一个子项目（packaging为jar）。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/33cb351041724b248d26b86121954e93.png" title="创建module" alt="创建module" /></p>
<p>点击Module之后会出现如下界面，选择spring Initializr(你如果要创建maven项目的话也选这个)，什么都不要干，点击Next。</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/41f65d0615394aefa53946aa6300d5d2.png" title="创建springboot项目" alt="创建springboot项目" /><figcaption>创建springboot项目</figcaption>
</figure>
<p>之后会出现这个界面，填写好信息，注意Packaging是jar，因为springboot是用netty启动的，不需要打成war包，点击Next。 <a id="more"></a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/4ad4d8919f1341098719e99ceaee285b.png" title="配置" alt="配置" /></p>
<h3 id="创建聚合工程">创建聚合工程</h3>
<p>右键父工程选择new-&gt;module，创建一个子项目（jpackaging为pom）。 选择maven即可。</p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a> <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>ip地址引起的无法单点登录</title>
    <url>/posts/5bb81bde.html</url>
    <content><![CDATA[<p>今天碰到一个很奇怪的问题，单点登录明明自认为代码没有任何问题，但是始终登录不进去。</p>
<p>最后发现，测试配置的cas-service地址是手动输入的localhost，所以当使用单点登录时在sso系统进行验证完毕时会回调这个地址回到原系统。这一切都符合预期运行。但是当原系统调用backUrl时出问题了。因为我点的是eureka的Application表格的Status列中链接，而这个链接我正好配置显示更详细的ip地址，所以由本来的localhost替换成了我的局域网中的ip地址。</p>
<p>综上：我需要登录的地址是localhost，而我需要回调的ip地址是我局域网的地址，显然两个ip不同那么shiro的subject也会不同，自然造成了每次使用isAuthenticated方法都会出问题。当然这只是特例，因为我的上述的两个地址虽然说不同但是实际上都是我一个人的，而上线之后应该不会遇到这种情况了。</p>
<p>可以尝试将这几个ip地址映射为一个地址，或者在当用户多次跳转回登录页面时，让它的地址栏强制去除backUrl参数，并给出相应提示。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title>（八）搭建springcloud：修改静态文件，如html，js后立即生效</title>
    <url>/posts/cd648d8e.html</url>
    <content><![CDATA[<ol type="1">
<li>setting--&gt;Build,Execution,Deployment--&gt;Compiler 找到 build project automatically <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/0e3e14335ea94258adf2616de29ed82d.PNG" title="idea配置自动构建" alt="idea配置自动构建" /></li>
<li>按ctrl+shift+alt+/，选择 Registry <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/1ed4835b01e54c82b6d0023db60873ac.jpg" title="更改注册" alt="更改注册" /></li>
<li>重启 如果还是不行，就用麻烦点的办法，每次修改在idea按ctrl+shift+f9即可 <a id="more"></a></li>
</ol>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</title>
    <url>/posts/4142c9a4.html</url>
    <content><![CDATA[<figure class="highlight dart"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableEurekaClient</span></span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Upms8081</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	public <span class="keyword">static</span> <span class="keyword">void</span> main(<span class="built_in">String</span>[] args) &#123;</span><br><span class="line">		<span class="built_in">Object</span>[] objects = <span class="keyword">new</span> <span class="built_in">Object</span>[<span class="number">3</span>];</span><br><span class="line">		objects[<span class="number">0</span>] = Upms8081.<span class="keyword">class</span>;</span><br><span class="line">		objects[<span class="number">1</span>] = UpmsApiAppliction.<span class="keyword">class</span>;</span><br><span class="line">		objects[<span class="number">2</span>] = CommonServiceStarter.<span class="keyword">class</span>;</span><br><span class="line">		SpringApplication.run(objects, args);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其他的class对象分别是所需要初始化类jar包中的springboot启动类 <a id="more"></a></p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>shiro的filter配置问题，自定义的filter交给spring容器管理会有问题</title>
    <url>/posts/22fa2838.html</url>
    <content><![CDATA[<p>此项目基于springboot，放在springmvc中，filter由spring管理不知道为什么就没问题。</p>
<p>我配置了/api/v1/<strong>----&gt;roles[]，/</strong>------&gt;authc</p>
<p>/api/v1/<strong>一直无法访问，一直调转到authc这个过滤器去验证，我就怀疑是不是/</strong>也匹配到了/api/v1/**，但是以前做的时候一直没问题，所以绕了一大圈。</p>
<p>最后发现！！！！！</p>
<p>重要的事说三遍，不要将自定义的filter交给spring容器管理！不要将自定义的filter交给spring容器管理！不要将自定义的filter交给spring容器管理！ <a id="more"></a> 因为在一个链接的所有配置好的filter执行完毕后，它会接着执行另外一个过滤链，该过滤链由servlet容器提供。也就是说shiro一共会执行两个过滤链，一个是你自己配置好的，第二个是servlet提供的（由于本人没有阅读过spring源码，故不清楚spring注册的bean是怎么进入servlet容器的）。</p>
<p>所以当你把自定义的过滤器交给spring管理时，这个过滤器无论如何都会至少执行一次。</p>
<p>具体的代码在org.apache.shiro.web.servlet.doFilter(ServletRequest request, ServletResponse response)，第一行就是判断自定义的过滤链是否执行完毕，如果执行完毕就执行servlet提供的过滤链。（注shiro版本为1.4.0）</p>
<p>如果出现这个问题只需要将filter的创建由自己完成即可。</p>
<p>tips:由于可能在filter中需要注入某些对象。这时只能用springContext获取bean了。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title>（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</title>
    <url>/posts/e9ea3cd8.html</url>
    <content><![CDATA[<p>由于是从eclipse迁移过来，之前的不同ide开发的问题搞了好久终于搞完了，以为终于成功了，然而又出了一大堆问题。 项目无法启动，报了一个奇葩的错： &gt;Could not initialize class org.hibernate.validator.internal.engine.Configuration</p>
<p>大致意思貌似就是javax.validation和hibernate-validator版本冲突了（详见<a href="https://stackoverflow.com/questions/14730329/jpa-2-0-exception-to-use-javax-validation-package-in-jpa-2-0）" target="_blank" rel="noopener">stackoverflow JPA 2.0 : Exception to use javax.validation.* package in JPA 2.0</a> 在无数次更换版本中，终于找到了一个没有问题的版本。hibernate-validator（5.2.4.Final版），我试过很多版本都有问题，包括4.1.3，5.1.6，5.3.6，5.4.1，6.0.1都是没有用的而其中个别版本居然还不会传递依赖，就是hibernate-validator本身是依赖javax.validation（1.1.0.Final版）的，所幸的是5.2.4.Fianl依赖了javax.validation，也省的我再去试javax.validation的版本。 所以最后应该将hibernate-validator添加到你需要的工程的pom文件中.spring-boot-starter-web这个jar包它本身是依赖hibernate-validator的，所以我把它直接排除了（exclusions标签）。而springboot默认依赖的版本是5.3.6是有问题的，不知道是不是我电脑的原因，反正我是运行不起来。 <a id="more"></a></p>
<p>总结：以后使用hibernate-validator要用5.2.4.Final版本。其次，我在eclipse里运行我的程序一点问题都没，移植到idea就各种问题，也不知道是不是idea太严格了。 <strong><em>补充：由于我的是聚合工程，我搞了两三个小时，<font color="red">发现我在pom文件中改动jar包的版本，虽然idea旁边的maven dependencies中相应的改变了jar包的版本，但是在实际运行过程中，它还是使用的之前版本的jar包，跟没改一样。</font>由于我是聚合工程，我将几乎所有的jar包版本都统一放在parent工程，所以后来发现只需要clean install一下parent工程即可。</em></strong></p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（五）搭建springcloud：在idea启动springboot项目</title>
    <url>/posts/9bfd1ba7.html</url>
    <content><![CDATA[<p>点击idea右上角 edit configuration <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/4803d077b7534b4fbf2f6f5a915db876.png" title="idea配置启动类" alt="idea配置启动类" /> 点击左上角的<font color="green">绿色“+”</font>然后点击maven就会出现右边窗口，注意要起一个name，然后下面的参数这么配置点击ok <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/e3a99aa12a0b4ad7a5544eaf1510cf4d.png" title="idea配置maven命令" alt="idea配置maven命令" /> 然后再到相同位置就会多了一个你起的名称的一个运行配置。点击即可。 最后还有最<strong>重要</strong>的一点，需要在你启动的项目的pom.xml文件中加上配置如下（主要是spring-boot-maven-plugin）： <a id="more"></a> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">skip</span>&gt;</span>true<span class="tag">&lt;/<span class="name">skip</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>更新：此方式启动，无法进行调试，貌似可以通过配置解决。后来我都不用这个方式启动项目，在图二中不选择maven，选择Spring Boot即可运行正常。</strong></p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（三）搭建springcloud：整合mybatis-plus</title>
    <url>/posts/9b163bbc.html</url>
    <content><![CDATA[<p>由于一直使用mybatis的example，无法忍受着过长的代码，所以转向了mybatis-plus，配置过于简单，就不演示了。 参考官网http://mp.baomidou.com/#/install 如果看不懂，可以看mybatis-plus提供的整合springboot例子 网址：https://gitee.com/baomidou/mybatisplus-spring-boot <a id="more"></a> 如果还看不懂，尼玛别整合了。（手动狗头） 提示： Service可以继承mybatis-plus提供的ServiceImpl类 mapper层可以继承BaseMapper，这样如果有些mapper比较简单完全可以省去mapper.xml IService可以继承IService</p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</title>
    <url>/posts/85f1a013.html</url>
    <content><![CDATA[<p>在使用maven的install命令时出现java.lang.ArrayIndexOutOfBoundsException: 10640 试了三个小时，一直以为idea有问题，最后没想到是maven版本的问题，我的是3.5.0，只要改成3.5.2以上就可以了（我改成3.5.4） 真的奇怪之前在eclipse上用一直好好地 <a id="more"></a></p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（一）搭建springcloud：springboot整合thymeleaf</title>
    <url>/posts/bfb2ab9c.html</url>
    <content><![CDATA[<p>thymeleaf的配置类如下，要注意的是它的prefix不是以前的&quot;/WEB-INF/&quot;，而是&quot;classpath:/templates/&quot;。templates文件夹位于resources源文件夹下，该文件夹的名称不是我随便写的，是springboot规定的，用于放置动态文件。类似的还有static用于放置静态文件。 其中我分别写了linux（即生产环境）及windows（即开发环境）下的配置，可以根据需要自己删留。（由于一般开发环境为windows，所以我自己偷懒写的加载bean条件，如果开发环境也是linux那么可以直接删掉）其中还可能包含我自己写的工具类，可以直接删去。 注：差点忘了，我的thymeleaf是3.0以上的版本，3.0以上的版本变动有些大，如果不是该版本以上，可能无法使用该配置类。springboot默认依赖的版本是2.1.6（貌似），所以需要手动更改，不会的看<a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a id="more"></a> <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">@ComponentScan</span><br><span class="line">public <span class="keyword">class</span> ThymeleafConfig &#123;</span><br><span class="line">    <span class="keyword">private</span> static final Logger LOGGER = <span class="module-access"><span class="module"><span class="identifier">LoggerFactory</span>.</span></span>get<span class="constructor">Logger(ThymeleafConfig.<span class="params">class</span>)</span>;</span><br><span class="line">    </span><br><span class="line">    @Bean</span><br><span class="line">    public ThymeleafViewResolver view<span class="constructor">Resolver(SpringTemplateEngine <span class="params">templateEngine</span>)</span>&#123;</span><br><span class="line">        ThymeleafViewResolver viewResolver = <span class="keyword">new</span> <span class="constructor">ThymeleafViewResolver()</span>;</span><br><span class="line">        viewResolver.set<span class="constructor">TemplateEngine(<span class="params">templateEngine</span>)</span>;</span><br><span class="line">        viewResolver.set<span class="constructor">Order(1)</span>;</span><br><span class="line">        viewResolver.set<span class="constructor">CharacterEncoding(<span class="string">"utf-8"</span>)</span>;</span><br><span class="line">        <span class="comment">//不知道这个缓存和下面的模板解析器的缓存是什么关系，但是应该不是同一个意思</span></span><br><span class="line">        <span class="comment">//我在模板解析器设置false，在这行代码之上打印了一下还是true</span></span><br><span class="line">        viewResolver.set<span class="constructor">Cache(<span class="params">false</span>)</span>;</span><br><span class="line">        viewResolver.set<span class="constructor">ViewNames(<span class="params">new</span> String[] &#123;<span class="string">"thymeleaf/*"</span>, <span class="string">".html"</span>, <span class="string">".xhtml"</span>&#125;)</span>;</span><br><span class="line">        return viewResolver;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模板解析器</span></span><br><span class="line"><span class="comment">     * @return</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    @<span class="constructor">Conditional(WindowsCondition.<span class="params">class</span>)</span></span><br><span class="line">    @Primary<span class="comment">//springboot貌似内置一个模板解析器，所以将这个bean定义为首选</span></span><br><span class="line">    @Bean</span><br><span class="line">    public SpringResourceTemplateResolver windows<span class="constructor">TemplateResolver()</span>&#123;</span><br><span class="line">        SpringResourceTemplateResolver templateResolver = <span class="keyword">new</span> <span class="constructor">SpringResourceTemplateResolver()</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Prefix(<span class="string">"classpath:/templates/"</span>)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Suffix(<span class="string">".html"</span>)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Order(1)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">TemplateMode(TemplateMode.HTML)</span>;</span><br><span class="line">        <span class="comment">//不缓存页面，即服务器开启时修改thymeleaf页面会有变化。</span></span><br><span class="line">        templateResolver.set<span class="constructor">Cacheable(<span class="params">false</span>)</span>;</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">LOGGER</span>.</span></span>info(<span class="keyword">new</span> <span class="constructor">LogPrintingTemplate()</span></span><br><span class="line">                .<span class="keyword">type</span>(<span class="string">"thymeleaf页面缓存禁用(￣▽￣)~*"</span>)</span><br><span class="line">                .print<span class="literal">()</span>);</span><br><span class="line">        templateResolver.set<span class="constructor">CharacterEncoding(<span class="string">"utf-8"</span>)</span>;</span><br><span class="line">        return templateResolver;</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">    @<span class="constructor">Conditional(LinuxCondition.<span class="params">class</span>)</span></span><br><span class="line">    @Primary<span class="comment">//springboot貌似内置一个模板解析器，所以将这个bean定义为首选</span></span><br><span class="line">    @Bean</span><br><span class="line">    public SpringResourceTemplateResolver linux<span class="constructor">TemplateResolver()</span>&#123;</span><br><span class="line">        SpringResourceTemplateResolver templateResolver = <span class="keyword">new</span> <span class="constructor">SpringResourceTemplateResolver()</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Prefix(<span class="string">"classpath:/WEB-INF/"</span>)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Suffix(<span class="string">".html"</span>)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">Order(1)</span>;</span><br><span class="line">        templateResolver.set<span class="constructor">TemplateMode(TemplateMode.HTML)</span>;</span><br><span class="line">        <span class="comment">//缓存页面</span></span><br><span class="line">        templateResolver.set<span class="constructor">Cacheable(<span class="params">true</span>)</span>;</span><br><span class="line">        <span class="module-access"><span class="module"><span class="identifier">LOGGER</span>.</span></span>info(<span class="keyword">new</span> <span class="constructor">LogPrintingTemplate()</span></span><br><span class="line">                .<span class="keyword">type</span>(<span class="string">"thymeleaf页面缓存开启(￣▽￣)~*"</span>)</span><br><span class="line">                .print<span class="literal">()</span>);</span><br><span class="line">        templateResolver.set<span class="constructor">CharacterEncoding(<span class="string">"utf-8"</span>)</span>;</span><br><span class="line">        return templateResolver;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 模版引擎</span></span><br><span class="line"><span class="comment">     * @return</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    @Bean</span><br><span class="line">    public SpringTemplateEngine template<span class="constructor">Engine(ITemplateResolver <span class="params">templateResolver</span>)</span>&#123;</span><br><span class="line">        SpringTemplateEngine templateEngine = <span class="keyword">new</span> <span class="constructor">SpringTemplateEngine()</span>;</span><br><span class="line">        templateEngine.set<span class="constructor">TemplateResolver(<span class="params">templateResolver</span>)</span>;</span><br><span class="line">        templateEngine.set<span class="constructor">EnableSpringELCompiler(<span class="params">true</span>)</span>;</span><br><span class="line">        return templateEngine;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Conditional里的类如下，linux的类似</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WindowsCondition</span> <span class="keyword">implements</span> <span class="title">Condition</span></span>&#123;</span><br><span class="line">       </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">matches</span><span class="params">(ConditionContext context, AnnotatedTypeMetadata metadata)</span> </span>&#123;</span><br><span class="line">        Environment environment = context.getEnvironment();</span><br><span class="line">        String osName = environment.getProperty(<span class="string">"os.name"</span>);</span><br><span class="line">        <span class="keyword">boolean</span> isWindows = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(osName.toLowerCase().contains(<span class="string">"windows"</span>))   isWindows = <span class="keyword">true</span>;</span><br><span class="line">         </span><br><span class="line">        <span class="keyword">return</span> isWindows;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>总结： 1. resources源文件夹下，templates文件夹放置动态文件，static文件夹下放置静态文件，其下的子文件夹可以随意创建。 2. thymeleaf的html文件建议放置在templates/thymeleaf文件夹下（我的习惯） 3. static文件夹下的资源是可以通过浏览器直接访问的，类似于传统web工程的webapp下的文件；而templates文件夹下的文件必须写上映射，即创建controller层，然后跟以前一样写mapping，这样就可以通过浏览器访问，然后springmvc视图解析，将视图返回给浏览器。类似于以前的WEB-INF文件夹。 4.* 更新：由于今天在配置thymeleaf时给我产生了疑惑，所以在此特地重申：templates和static文件夹的名字不是我起的，是springboot的规定。*</p>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a></p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>（二）搭建springcloud：修改thymeleaf版本</title>
    <url>/posts/f1d815e2.html</url>
    <content><![CDATA[<p>起因：springboot整合thymeleaf默认依赖的版本是3.0以下的版本，而我一直是用的3.0以上的版本，而且貌似3.0以上的版本性能更好，所以果断自己做了版本的更改。但是在更改是有一点问题。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- thymeleaf --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-thymeleaf<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>由于我想排除依赖，所以我在其中排除了thymeleaf-spring4的依赖，但是我发现thymeleaf核心包的版本还是3.0以下，具体解决过程不写了，解决如下： 上面的依赖不要删，在下面再添加依赖，父工程中添加版本，可以选择3.0以上的版本（我的是3.0.9） <a id="more"></a> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.thymeleaf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>thymeleaf<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这样就可以了，但是最好再多做一步，将第一个依赖改为这样：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- thymeleaf --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-thymeleaf<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>nz.net.ultraq.thymeleaf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>thymeleaf-layout-dialect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>nz.net.ultraq.thymeleaf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>thymeleaf-layout-dialect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>由于thymeleaf版本变迁，所以上面的这个dialect版本必须也要跟着改变（我使用2.0.0，建议使用2.0.0以上版本）。 最后附上父工程配置</p>
<figure class="highlight dust"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="comment">&lt;!-- 视图层，在springboot工程中二者缺一不可，因为springboot默认依赖thymeleaf2.0 --&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">thymeleaf.version</span>&gt;</span>3.0.9.RELEASE<span class="tag">&lt;/<span class="name">thymeleaf.version</span>&gt;</span><span class="comment">&lt;!-- thymeleaf版本 --&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">thymeleaf-layout-dialect.version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="name">thymeleaf-layout-dialect.version</span>&gt;</span></span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.thymeleaf/thymeleaf-spring4 --&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.thymeleaf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>thymeleaf-spring4<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;thymeleaf.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>nz.net.ultraq.thymeleaf<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>thymeleaf-layout-dialect<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span></span><br><span class="line"><span class="xml">       <span class="tag">&lt;<span class="name">version</span>&gt;</span>$</span><span class="template-variable">&#123;thymeleaf-layout-dialect.version&#125;</span><span class="xml"><span class="tag">&lt;/<span class="name">version</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span></span><br></pre></td></tr></table></figure>
<h3 id="目录">目录</h3>
<p><a href="https://yan624.github.io/（零）搭建springcloud：创建项目.html">（零）搭建springcloud：创建项目</a> <a href="https://yan624.github.io/（一）搭建springcloud：springboot整合thymeleaf.html">（一）搭建springcloud：springboot整合thymeleaf</a> <a href="https://yan624.github.io/（二）搭建springcloud：修改thymeleaf版本.html">（二）搭建springcloud：修改thymeleaf版本</a> <a href="https://yan624.github.io/（三）搭建springcloud：整合mybatis-plus.html">（三）搭建springcloud：整合mybatis-plus</a> <a href="https://yan624.github.io/（四）搭建springcloud：eclipse迁移到idea的问题（maven%20install命令出错）.html">（四）搭建springcloud：eclipse迁移到idea的问题（maven install命令出错）</a> <a href="https://yan624.github.io/（五）搭建springcloud：在idea启动springboot项目.html">（五）搭建springcloud：在idea启动springboot项目</a> <a href="https://yan624.github.io/（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）.html">（六）搭建springcloud：在idea启动项目出现的问题（hibernate-validator与javax.validation的兼容性问题）</a> <a href="https://yan624.github.io/（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器.html">（七）搭建springcloud：springboot如何将所依赖的jar包的类放入spring容器</a> <a href="https://yan624.github.io/（八）搭建springcloud：修改静态文件，如html，js后立即生效.html">（八）搭建springcloud：修改静态文件，如html，js后立即生效</a> <a href="https://yan624.github.io/（九）搭建springcloud：在linux上运行springboot项目.html">（九）搭建springcloud：在linux上运行springboot项目</a> <a href="https://yan624.github.io/（十）搭建springcloud：记录项目运行的日志.html">（十）搭建springcloud：记录项目运行的日志</a> <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>系列</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>腾讯云安装mysql</title>
    <url>/posts/c089763.html</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/itor/p/6339505.html" target="_blank" rel="noopener">linux下mysql-5.6忘记root密码，重置root密码详细过程</a> <a href="https://www.cnblogs.com/BenWong/p/4322085.html" target="_blank" rel="noopener">Linux 下MySql 重置密码</a> 这两篇结合着看就大致装完了，但是会有一个问题，就是外网连不上mysql，这是由于mysql默认不允许外网连接，所以需要做一点小变动。</p>
<p>当执行第三行时可能会出现：Duplicate entry '%-root' for key 'PRIMARY'的错误提示信息，但是不需要管它</p>
<figure class="highlight n1ql"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br><span class="line">mysql&gt;use mysql;</span><br><span class="line">mysql&gt;<span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> host = <span class="string">'%'</span> <span class="keyword">where</span> <span class="keyword">user</span> = <span class="string">'root'</span>;</span><br><span class="line">mysql&gt;<span class="keyword">select</span> host, <span class="keyword">user</span> <span class="keyword">from</span> <span class="keyword">user</span>;</span><br></pre></td></tr></table></figure>
<p>最后再执行<code>flush privileges;</code>即可 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>linux下安装redis</title>
    <url>/posts/14e0ad8b.html</url>
    <content><![CDATA[<h3 id="下载redis">下载redis</h3>
<p>首先下载redis，由于是linux下安装，所以下载tar.gz压缩包，官网地址https://redis.io/ 然后使用工具把下载下来的压缩包上传到服务器上（我用的是腾讯云），我放在了/usr/local/redis下</p>
<h3 id="解压">解压</h3>
<p><code>tar zxvf  redis-4.0.10.tar.gz</code> ### 进入解压后的文件夹 <code>cd redis-4.0.10</code></p>
<h3 id="安装">安装</h3>
<figure class="highlight gauss"><table><tr><td class="code"><pre><span class="line"><span class="built_in">make</span></span><br><span class="line">cd src(下一步需要有gcc编译redis源文件，如果没有，运行yum install gcc-c++)</span><br><span class="line"><span class="built_in">make</span> install PREFIX=/usr/<span class="keyword">local</span>/redis</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="移动配置文件到安装目录">移动配置文件到安装目录</h3>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cd</span> ..</span><br><span class="line"><span class="keyword">mkdir</span> /usr/<span class="keyword">local</span>/redis/etc </span><br><span class="line">mv redis.<span class="keyword">conf</span> /usr/<span class="keyword">local</span>/redis/etc</span><br></pre></td></tr></table></figure>
<h3 id="启动">启动</h3>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cd</span> bin</span><br><span class="line"><span class="string">./redis-server</span></span><br></pre></td></tr></table></figure>
<p>这是你会发现你的控制台无法再输入命令了，因为你启动了redis，如果想启动了redis还想干其他事，那么需要将redis设置后后台运行</p>
<h3 id="关闭redis服务并编辑刚才的配置文件">关闭redis服务并编辑刚才的配置文件</h3>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">ctrl</span> <span class="string">c</span></span><br><span class="line"><span class="attr">cd</span> <span class="string">etc</span></span><br><span class="line"><span class="attr">vim</span> <span class="string">redis.conf</span></span><br></pre></td></tr></table></figure>
<p>将daemonize设置为yes。 如果找不到daemonize在哪，在命令模式下按&quot;/&quot;输入要查找的字，回车进行查找，&quot;n&quot;继续查找。</p>
<p><strong>注：如果改了之后还是没有反应，那么可以在启动redis时指定配置文件，如：./redis-server ../etc/redis.conf</strong> 然后可以使用netstat -lntp|grep 6379看看6379端口是不是被监听了。6379是redis默认端口。 <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>安装与部署</tag>
      </tags>
  </entry>
  <entry>
    <title>thymeleaf在@{}中无法使用其他服务器链接的问题</title>
    <url>/posts/d0ca1b33.html</url>
    <content><![CDATA[<p>以下是官网原话：</p>
<ul>
<li>Absolute URLs: http://www.thymeleaf.org</li>
<li>Relative URLs, which can be:
<ul>
<li>Page-relative: user/login.html</li>
<li>Context-relative: /itemdetails?id=3 (context name in server will be added automatically)</li>
<li>Server-relative: ~/billing/processInvoice (allows calling URLs in another context (= application) in the same server.</li>
<li>Protocol-relative URLs: //code.jquery.com/jquery-2.0.3.min.js</li>
</ul></li>
</ul>
<p>中文版：</p>
<ul>
<li>绝对网址： http://www.thymeleaf.org</li>
<li>相对URL，可以是：
<ul>
<li>页面相对： user/login.html</li>
<li>与上下文相关:( /itemdetails?id=3服务器中的上下文名称将自动添加）</li>
<li>服务器相对:( ~/billing/processInvoice允许在同一服务器中的另一个上下文（=应用程序）中调用URL。</li>
<li>与协议相关的网址： //code.jquery.com/jquery-2.0.3.min.js <a id="more"></a></li>
</ul></li>
</ul>
<p>它就提供这几种方式，但是我的服务器比如是baidu.com，使用<code>th:href=&quot;@{http://sina.com/index.css}&quot;</code>这样是可以的，但是<code>th:href=&quot;@{${sina_static}/index.css}&quot;</code>这样却不行，也就是说静态资源无法使用变量直接取出来，那么以后改动这些资源将十分麻烦，因为只能写死了。thymeleaf不让动态的获取。</p>
<p>thymeleaf提供的几种方式没有一种可以显示不同服务器的地址。后来发现还有另外一种方式，就是投机取巧的使用url参数。</p>
<p><code>th:href=&quot;@{(由于博客系统原因删除这句话，包括小括号){variable}/index.css(variable=${value})}&quot;</code>这样即可。 <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title>bootstrap-switch常用操作/属性</title>
    <url>/posts/ee9ad51.html</url>
    <content><![CDATA[<h3 id="引入cssjs">引入css、js</h3>
<p><a href="http://www.bootcss.com/p/bootstrap-switch/" target="_blank" rel="noopener">bootstrap-switch中文官网</a></p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&lt;link <span class="attribute">rel</span>=<span class="string">"stylesheet"</span> <span class="attribute">href</span>=<span class="string">"<span class="variable">$&#123;CONTEXT &#125;</span>/css/bootstrap-switch.min.css"</span>&gt;</span><br><span class="line">&lt;script <span class="attribute">src</span>=<span class="string">"<span class="variable">$&#123;CONTEXT &#125;</span>/js/bootstrap/bootstrap-switch.min.js"</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<p><strong>注：</strong>貌似还有一个叫做bootstrapSwitch.js的插件，不要引入错了。</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">div</span> <span class="built_in">class</span>=<span class="string">"input-group"</span>&gt;</span><br><span class="line">&lt;label <span class="keyword">for</span>=<span class="string">"open"</span>&gt;操作&amp;nbsp;&lt;/label&gt;</span><br><span class="line">&lt;input <span class="built_in">id</span>=<span class="string">"open"</span> checked type=<span class="string">"checkbox"</span> data-<span class="keyword">on</span>-<span class="built_in">text</span>=<span class="string">"开"</span> data-off-<span class="built_in">text</span>=<span class="string">"关"</span> data-<span class="keyword">on</span>-color=<span class="string">"success"</span> /&gt;</span><br><span class="line">&lt;/<span class="keyword">div</span>&gt;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h3 id="常用属性">常用属性</h3>
<ul>
<li>data-on-text=&quot;开&quot; data-off-text=&quot;关&quot;，代表开启/关闭时按钮上的文字。</li>
<li>checked代表默认选中，不填代表不选中。</li>
<li>data-on-color=&quot;success&quot;，代表选中时的颜色。</li>
</ul>
<h3 id="常用操作">常用操作</h3>
<ul>
<li>$('#open').bootstrapSwitch();，开始自动生成一个按钮。注：#open是input的id。</li>
<li>$('#open').on('switchChange.bootstrapSwitch', function (event,state) { }，switch触发的事件，所以不用自己再写click事件了。注：state代表按钮当前选中状态。</li>
<li>$('#toggle-state-switch').bootstrapSwitch('toggleState');，来回切换。</li>
<li>$('#toggle-state-switch').bootstrapSwitch('setState', false);，设置按钮状态，false代表未选中。</li>
</ul>
<p>另外不要写官网上的那个格式，官网上的格式是误导人的，它那个写法：把input放在div里，然后div加一个switch的class，这样其实是代表按钮自动生成后的dom节点。所以按照我这个写就行了。</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>front-end</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>bootstrap-switch</tag>
      </tags>
  </entry>
  <entry>
    <title>基于shiro的单点退出功能</title>
    <url>/posts/8e550cc0.html</url>
    <content><![CDATA[<p><strong>2019.01.24更新：发现其他sso系统的实现思路跟我的不一样，我也不知道这样对不对，但是功能是能实现的。</strong></p>
<hr />
<p>由于非单点登录系统在检测用户是否已经单点退出时有点复杂。分两种情况：</p>
<ol type="1">
<li>在每次访问链接时，重定向到单点登录系统进行验证，这是可以做到的，但是用户体验差（这样做或许也可以）。</li>
<li>发送一个http请求，这样可以在用户不知情的情况下进行验证，但是发起http请求，请求的用于不再是当前用户了，即session 不是同一个了。</li>
</ol>
<p>而shiro需要获取subject才能退出登录（我找了很久没有找到其他的办法），所以需要做一个折中的方法，在单点退出的过滤器那，设置session过期，session失效，然后在authc过滤器，判断当前session是否失效，如果失效则执行退出。 <a id="more"></a> 2018-5-4更新：</p>
<p>最终实现：其他系统发出退出登录请求，upms接收到直接将该用户注销，同时全局session从redis中自动删除，并且在删除之前写入一个名为logout的属性，设置为true（由于session瞬间被删除了，但是并没有多余，因为以后可能加入某些机制，使得session过一会才被删除，所以有必要提前做好防患）。</p>
<p>由于upms系统中退出登录，但是没有办法通知其他子系统，所以只能被迫让其他子系统自己来得到通知。具体实现如下：</p>
<ol type="1">
<li>用户在登录时，会在全局session中添加一个属性名为logout，设置为false。</li>
<li>这样当用户在子系统退出后，当前子系统是知道用户已经退出。</li>
<li>但是其他子系统并不知情，所以用户再次访问当前子系统是直接跳转到登录页面。</li>
<li>而当用户访问其他子系统时，子系统需要先跳转到upms系统进行查看，该用户是否退出登录。</li>
<li>规则很简单，upms只需要判断logout属性是否为空或者是否为false即可。</li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title>solr使用自动建议搜索出现No suggester named default was configured</title>
    <url>/posts/b7d5457b.html</url>
    <content><![CDATA[<p>solr的默认配置文件中，有一个路径为/suggest的requestHandler，它里面没有配置suggest.dictionary，这个意思就是建议的字典。而默认值可能就是default，所以出现这个错误，只需要配置一下字典就行了。我碰到的时候我也想不明白，用全文搜索都没搜到default。</p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/b093167a98b9425ca7318393fb6ed37a.PNG" title="solr配置" alt="solr配置" /> <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>error</tag>
        <tag>印象笔记上的博文</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title>Solr中文分词以及拼写纠错</title>
    <url>/posts/cc8c1050.html</url>
    <content><![CDATA[<p>由于在更改配置文件后，重启tomcat，solr的web页面可以直接看到变化，所以我都懒得使用dataimport了。</p>
<p>我之前一直配置中文分词以及拼写纠错失败，我把配置中默认查询字段就改了一个名字，把text改为spell，每一处都替换掉，居然会产生不一样的结果。我搞了一个多小时，发现怎么换都是这样，前后结果完全不同。要么可以分词要么可以拼写纠错，二者没有同时出现过。最后要睡觉的时候，dataimport了一下。发现居然可以了。</p>
<p>我猜测可能在建立索引时把text作为键，于是我更改了text的名字，自然是无法查询到任何东西。</p>
<a id="more"></a>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title>二、将mysql的数据导入到solr中</title>
    <url>/posts/6290f446.html</url>
    <content><![CDATA[<h3 id="一solr部署于tomcat">一、solr部署于tomcat</h3>
<p><a href="https://yan624.github.io/一、solr部署于tomcat">上一篇</a></p>
<h3 id="二将mysql的数据导入到solr中">二、将mysql的数据导入到solr中</h3>
<p>tomcat同级目录中的solr被称为solr_home，tomcat的webapps文件夹中的solr是solr的web工程</p>
<p>将从apache上下下来的solr<font color="red">根</font>文件夹中的/contrib和/dist，复制到solr_home的lib文件夹中，如果没有这个文件夹可以自己建一个。如下图: <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/1375f60bca34409d952810bc12beb13c.PNG" title="solr lib" alt="solr lib" /></p>
<p>这两个文件夹中全是jar包。现在只是复制过来了，solr还不能用它们，所以需要配置一下。solr_home中应该有一个collection1文件夹，这是solr的一个示例，如果不放心可以拷贝一份，改一个名字。注意如果拷贝了一份，需要进入你拷贝的这份文件夹，找到core.properties，将里面的name属性改为你的文件夹名字。</p>
<p>我复制了一份，取名为order，如下图： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/a193f1c3fea84613b0b048c0791dd1b2.PNG" title="solr官方示例" alt="solr官方示例" /></p>
<p>进入order文件夹，里面有一个conf文件夹，再进入，找到solrconfig.xml文件，打开编辑。前几十行很多注释，往下大概80行的样子，有几个lib标签，这些标签就是代表导入之前的jar包。但是我们的路径发生了改变，所以这里需要配置一下。 <a id="more"></a> <figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/contrib/dataimporthandler/lib"</span> <span class="attribute">regex</span>=<span class="string">".*\.jar"</span> /&gt;</span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/dist/"</span> <span class="attribute">regex</span>=<span class="string">"solr-dataimporthandler-\d.*\.jar"</span> /&gt;</span><br><span class="line">   </span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/contrib/extraction/lib"</span> <span class="attribute">regex</span>=<span class="string">".*\.jar"</span> /&gt;</span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/dist/"</span> <span class="attribute">regex</span>=<span class="string">"solr-cell-\d.*\.jar"</span> /&gt;</span><br><span class="line"></span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/contrib/clustering/lib/"</span> <span class="attribute">regex</span>=<span class="string">".*\.jar"</span> /&gt;</span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/dist/"</span> <span class="attribute">regex</span>=<span class="string">"solr-clustering-\d.*\.jar"</span> /&gt;</span><br><span class="line"></span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/contrib/langid/lib/"</span> <span class="attribute">regex</span>=<span class="string">".*\.jar"</span> /&gt;</span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/dist/"</span> <span class="attribute">regex</span>=<span class="string">"solr-langid-\d.*\.jar"</span> /&gt;</span><br><span class="line"></span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/contrib/velocity/lib"</span> <span class="attribute">regex</span>=<span class="string">".*\.jar"</span> /&gt;</span><br><span class="line">&lt;lib <span class="attribute">dir</span>=<span class="string">"../lib/dist/"</span> <span class="attribute">regex</span>=<span class="string">"solr-velocity-\d.*\.jar"</span> /&gt;</span><br></pre></td></tr></table></figure></p>
<p>lib标签dir属性的根目录位于conf文件夹的同级目录。需要注意的是前两个标签，不出意外的话，这两行你们是没有的，这里需要加上这两行。因为它们关系到导入数据。</p>
<p>还是在这个文件中，往下拉，大概找到requestHandler标签，其实不找到也行，但是为将相同的标签放在一起便于管理，所以需要找到并在其中一个位置加上下面的代码： <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">requestHandler</span> <span class="attr">name</span>=<span class="string">"/dataimport"</span> <span class="attr">class</span>=<span class="string">"solr.DataImportHandler"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lst</span> <span class="attr">name</span>=<span class="string">"defaults"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">str</span> <span class="attr">name</span>=<span class="string">"config"</span>&gt;</span>data-config.xml<span class="tag">&lt;/<span class="name">str</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">lst</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">requestHandler</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>这个就是代表了一个请求路径，看英文名代表了数据导入。这里需要注意一点，class是solr.DataImportHandler，而不是其它的，我就是因为懒得自己写，顺手改了一个注释掉的标签，然后忘记改class属性，导致数据一直导入失败。里面的config标签就是代表了数据的配置。接下来需要配置这份文件。</p>
<p>与solrconfig.xml同级目录中<font color="red">新建</font>一个（如果不存在这个文件的话）data-config.xml。配置如下： <figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">&lt;dataConfig&gt;</span><br><span class="line">    &lt;dataSource <span class="keyword">type</span>="JdbcDataSource"</span><br><span class="line">        driver="com.mysql.jdbc.Driver" url="jdbc:mysql://localhost:3306/order"</span><br><span class="line">        <span class="keyword">user</span>="root" <span class="keyword">password</span>="password" batchSize="-1" /&gt;</span><br><span class="line">    &lt;document&gt;</span><br><span class="line">        &lt;entity <span class="type">name</span>="tb_businessman" query="select * from tb_businessman"&gt;</span><br><span class="line">            &lt;field column="businessman_id" <span class="type">name</span>="businessman_id" /&gt;</span><br><span class="line">            &lt;field column="businessman_name" nam="businessman_name" /&gt;</span><br><span class="line">            &lt;field column="introduction" <span class="type">name</span>="introduction" /&gt;</span><br><span class="line">            &lt;field column="business_hours" <span class="type">name</span>="business_hours" /&gt;</span><br><span class="line">            &lt;field column="start_price" <span class="type">name</span>="start_price" /&gt;</span><br><span class="line">            &lt;field column="lunch_box_fee" <span class="type">name</span>="lunch_box_fee" /&gt;</span><br><span class="line">            &lt;field column="merchant_store_thumbnail" <span class="type">name</span>="merchant_store_thumbnail" /&gt;</span><br><span class="line">            &lt;field column="monthly_sales" <span class="type">name</span>="monthly_sales" /&gt;</span><br><span class="line">            &lt;field column="average_score" <span class="type">name</span>="average_score" /&gt;</span><br><span class="line">            &lt;field column="is_open" <span class="type">name</span>="is_open" /&gt;</span><br><span class="line">            &lt;field column="QR_code" <span class="type">name</span>="QR_code" /&gt;</span><br><span class="line">        &lt;/entity&gt;</span><br><span class="line">    &lt;/document&gt;</span><br><span class="line">&lt;/dataConfig&gt;</span><br></pre></td></tr></table></figure></p>
<p>dataSource不做讲解，document中的entity标签的name属性指的是类似于一个id，代表在solr的web应用的网页里面的一个select的一个option（目前我是这么理解的）。query就是查数据。column就是数据库列名，name是接下来配置的。</p>
<p>接下来配置最后一步，schema.xml文件，也是在conf目录下。里面solr已经配置很多了，所以看起来很麻烦。找到fields标签，这个标签下面就是配置各个字段，就是上面说的name。其中 <figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"_version_"</span> <span class="attribute">type</span>=<span class="string">"long"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line"></span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"_root_"</span> <span class="attribute">type</span>=<span class="string">"string"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"false"</span>/&gt;</span><br></pre></td></tr></table></figure></p>
<p>这两个不要删，然后把fields下的所有标签全删了，改成如下： <figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"businessman_id"</span> <span class="attribute">type</span>=<span class="string">"string"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span> <span class="attribute">required</span>=<span class="string">"true"</span> <span class="attribute">multiValued</span>=<span class="string">"false"</span> /&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"businessman_name"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span> <span class="attribute">multiValued</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"introduction"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"business_hours"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"start_price"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"lunch_box_fee"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"merchant_store_thumbnail"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"monthly_sales"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"average_score"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"is_open"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"QR_code"</span> <span class="attribute">type</span>=<span class="string">"string"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span> <span class="attribute">multiValued</span>=<span class="string">"true"</span>/&gt;</span><br><span class="line">&lt;field <span class="attribute">name</span>=<span class="string">"text"</span> <span class="attribute">type</span>=<span class="string">"text_cn"</span> <span class="attribute">indexed</span>=<span class="string">"true"</span> <span class="attribute">stored</span>=<span class="string">"true"</span> <span class="attribute">multiValued</span>=<span class="string">"true"</span>/&gt;</span><br></pre></td></tr></table></figure></p>
<p>篇幅有限，不做太多解释，接下来，在fields标签下一个标签应该是 <code>&lt;uniqueKey&gt;</code>，把里面的值，改为你的id，我的是businessman_id。注意上面的text_cn这是某个solr的域类型，现在是初步测试，就不写这个了，可以缓存solr已经配置好的text_general，这样虽然我们的数据是中文的，但是完全可以进行简单的处理了。</p>
<p>最后还需要一个mysql的jar包，把它放到WEB-INF的lib目录下，就可以启动tomcat访问了。如下图，进行导入数据，点击菜单栏中Query进行查询。（注：4,5两步中间需要等一会，不要马上点，如果成功了，“显示”那会出现绿色字体。）Query中其他参数可自行学习。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/0820f706eae3497599ffd4d1b6783ab2.PNG" title="步骤" alt="步骤" /> <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title>一、solr部署于tomcat</title>
    <url>/posts/e82845bf.html</url>
    <content><![CDATA[<h3 id="一solr部署于tomcat">一、solr部署于tomcat</h3>
<p>solr版本：solr-4.7.1 操作时间：2018-4-11 tomcat版本：tomcat9</p>
<p>由于《solr实战》是用solr4.*，所以我就下了一个版本4的。但是其实已经出到版本7了。 下载地址：http://archive.apache.org/dist/lucene/solr/4.7.1/</p>
<p>我是先照着《solr实战》中基础部分，在jetty中练习了大概一两个小时再移到tomcat中玩的，如果以前没玩过solr建议先知道哪些文档有哪些作用，再移到tomcat。因为移到tomcat和直接在jetty中玩，文件路径有点不一样，而且配置也有点不一样。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/b0e4d6cd5265431fae04c44c4debf8a1.PNG" title="solr文件路径" alt="solr文件路径" /></p>
<ol type="1">
<li>将我上图中选中的solr文件夹移动到tomat<font color="red">同级</font>目录下（或者其他目录，这个路径问题是可以自己配置的，下面会说。），该文件夹被称呼为solr_home。 <a id="more"></a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/22852cec88614c66ad0613cf657d6dda.PNG" title="solr home" alt="solr home" /></li>
<li>然后将第一个图中<font color="red">webapps文件夹</font>中的一个名为solr.war的war包，移动到<font color="red">tomcat中的webapps文件夹</font>中，就是部署war包。</li>
<li>启动tomcat，让tomcat解压war包。这时webapps下多了一个名为solr文件夹（与上面的solr_home不一样），它的WEB-INF/lib下有很多jar包，但是还是缺少了一些。还是第一个图，进入lib文件夹，里面会有一个ext文件夹把里面的jar包全部复制到tomcat的solr项目的lib文件夹中。这样就差不多完成了。最后结果如下图。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/0dca7561a59340c2b3b404508487c60e.PNG" title="tomcat中最后结果" alt="tomcat中最后结果" /></li>
<li>然后之前说solr_home放在了tomcat同级目录下，而solr这个项目并不能自己发现这个solr_home，所以需要配置一下。进入tomcat中的solr项目更改WEB-INF文件夹中的web.xml文件。用ctrl+f的快捷键搜索一下env-entry这个标签。更改为：</li>
</ol>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">&lt;env-<span class="built_in">entry</span>&gt;</span><br><span class="line">    &lt;env-<span class="built_in">entry</span>-<span class="keyword">name</span>&gt;solr/home&lt;/env-<span class="built_in">entry</span>-<span class="keyword">name</span>&gt;</span><br><span class="line">    &lt;env-<span class="built_in">entry</span>-<span class="keyword">value</span>&gt;D:\tomcat\solr&lt;/env-<span class="built_in">entry</span>-<span class="keyword">value</span>&gt;</span><br><span class="line">    &lt;env-<span class="built_in">entry</span>-<span class="keyword">type</span>&gt;java.lang.String&lt;/env-<span class="built_in">entry</span>-<span class="keyword">type</span>&gt;</span><br><span class="line">&lt;/env-<span class="built_in">entry</span>&gt;</span><br></pre></td></tr></table></figure>
<p>注意其中env-entry-value是我solr_home的绝对路径。这样solr项目就可以找到solr_home了。 这个时候启动tomcat应该就可以访问了。项目地址是<code>http://localhost:8080/solr</code>，到现在只是完成了部署，下篇介绍如何导入mysql中的数据。</p>
<h3 id="二将mysql的数据导入到solr中">二、将mysql的数据导入到solr中</h3>
<p><a href="https://yan624.github.io/二、将mysql的数据导入到solr中">下一篇</a> <!-- more --></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>学习笔记</tag>
        <tag>安装与部署</tag>
      </tags>
  </entry>
  <entry>
    <title>访问browse页面solr出现lazy loading error</title>
    <url>/posts/746d3828.html</url>
    <content><![CDATA[<p>如图 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/4494aa77feea482388e892e7e6793b8a.PNG" title="lazy loading error" alt="lazy loading error" /></p>
<p>如果你将下载下来的solr自己部署到tomcat下，然后启动无异常，但是访问browse路径下时，出现该异常。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/c84bd8f2e8b1496284c705b515bbc522.PNG" title="solr配置" alt="solr配置" /></p>
<p>看选中的那行，参数名wt它的值时velocity，意识是让solr返回以velocity模版引擎构建的页面。而velocity实际上也是一个配置。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/b1c20a04a208423ba9a5cb73aef2caf2.PNG" title="solr velocity配置" alt="solr velocity配置" /></p>
<p>同一份配置文件，往最下面拉，看见这个配置，原因是没有这个类，<code>class=&quot;solr.VelocityResponseWriter&quot;</code>，这里有问题。所以只需要导入该包，或者直接在访问browse时跟一个参数，wt=xml或者wt=json等等。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>solr</tag>
      </tags>
  </entry>
  <entry>
    <title>thymeleaf遍历列表出现的问题</title>
    <url>/posts/198ecd00.html</url>
    <content><![CDATA[<p>今天做一个功能，找了好久，也看了thymeleaf的官网好久，发现th遍历集合居然不能根据索引获取对象。还要后台自己整理结构，真的麻烦。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>吐槽</tag>
        <tag>thymeleaf</tag>
      </tags>
  </entry>
  <entry>
    <title>swagger的初步运用</title>
    <url>/posts/b982c2af.html</url>
    <content><![CDATA[<p>网上的介绍很多，我主要描述网上不常见的：<code>@ApiImplicitParam</code>。</p>
<p>这个注解有一个属性：paramType。它的有效值仅有5中，分别为：path，query，form，body，header。</p>
<p>但是这几个值，我感觉用起来特别麻烦。</p>
<h3 id="path配合pathvariable">path（配合@PathVariable）</h3>
<p>这是最简单的，如/user/{userId}，如果使用这种形式，就可以使用path；</p>
<h3 id="query配合requestparam">query（配合@RequestParam）</h3>
<p>这个我认为是有bug的，如果在swagger2的配置中这样写： <a id="more"></a> <figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="constructor">Docket(DocumentationType.SWAGGER_2)</span></span><br><span class="line">    .api<span class="constructor">Info(<span class="params">new</span> ApiInfoBuilder()</span></span><br><span class="line">        .title(<span class="string">"订餐系统_接口文档"</span>)</span><br><span class="line">        .description(<span class="string">"描述：用于订餐管理系统其他模块的数据调用"</span>)</span><br><span class="line">        .version(<span class="string">"版本号:1.0"</span>)</span><br><span class="line">        .build<span class="literal">()</span></span><br><span class="line">    )</span><br><span class="line">    .select<span class="literal">()</span></span><br><span class="line">    .apis(<span class="module-access"><span class="module"><span class="identifier">RequestHandlerSelectors</span>.</span></span>any<span class="literal">()</span>)</span><br><span class="line">    .paths(<span class="module-access"><span class="module"><span class="identifier">PathSelectors</span>.</span></span>any<span class="literal">()</span>)</span><br><span class="line">    .build<span class="literal">()</span></span><br><span class="line">    .path<span class="constructor">Mapping(<span class="string">"/"</span>)</span></span><br><span class="line">    .direct<span class="constructor">ModelSubstitute(LocalDate.<span class="params">class</span>, String.<span class="params">class</span>)</span></span><br><span class="line">    .generic<span class="constructor">ModelSubstitutes(ResponseEntity.<span class="params">class</span>)</span></span><br><span class="line">    .use<span class="constructor">DefaultResponseMessages(<span class="params">false</span>)</span></span><br><span class="line">    .enable<span class="constructor">UrlTemplating(<span class="params">true</span>)</span></span><br></pre></td></tr></table></figure></p>
<p>看最后一个方法，这就代表你的文档最后生成是这样的： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/ee28b7c4e8f84f33938d2d2c1deced0a.PNG" title="swagger post的接口样例截图" alt="swagger post的接口样例截图" /></p>
<p>我为什么要说有bug？这看起来很美好，但是当你在网站上测试时，如下 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/737c0b56dad0405cb8a5b0e330ee8380.PNG" title="url模板bug" alt="url模板bug" /></p>
<p>swagger提供了，在网站上直接测试的功能，但是请看黄色部分，/modify-password后面跟了什么，看起来那只是说明用的{?newPassword...}，直接加在了链接上，导致报了404，找不到该url。</p>
<p>就这玩意搞了我好几个小时，后来还是无意中发现的。但是如果把那个方法删了那么就会变成下面的样子。 <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/e98acd4958754ee5b5876623b758a493.PNG" title="正常的post请求url模板" alt="正常的post请求url模板" /></p>
<p>这样就是正常的，就是普通的get请求，但是这里注意一点，post请求就不要用query了，因为它是直接在url后跟参数的。说是post其实被它改成了get（ps：仅在网页上测试时很坑爹，如果只是给其他开发者使用，那是无所谓的，顶多不要在线测试这项功能）。</p>
<h3 id="form">form</h3>
<p>这个也很坑爹，我也是后来发现的。常见的表单提交，可以f12看到是Query String Parameters，但是这个使用了坑爹的Request Plyload（并没有说它不好）。哪坑爹呢？后台的controller方法里我试了无数个注解，无数个方法接受不到值，要么是null，要么http错误。</p>
<p>我最会想到了，也是因为前段时间正好用过---》我看到swagger在网页上提示是formData，玩过前端的人应该知道js有一个对象叫做：FormData（感兴趣的自己百度）。坑爹的就在这，FormData是用来提交二进制数据的（我是这么理解的），比如一张图片，一份文件。所以我抱着尝试的心态，在Controller的方法中加入了一个参数MultipartFile对象，尼玛，居然正常接收到了参数。</p>
<p>综上，如果用了form，想使用在线测试功能，就加个MultipartFile参数。</p>
<h3 id="body">body</h3>
<p>这个还行，因为如果使用了这个swagger会提交json数据（但是不知道是字符串还是对象，初步估计应该是对象），所以如果使用body，那么@ApiImplicitParam就不用写很多了，比如说，你想接受用户的账号（account），密码（password），那么不需要这样写： <figure class="highlight less"><table><tr><td class="code"><pre><span class="line"><span class="variable">@ApiImplicitParams</span>(</span><br><span class="line">    &#123;<span class="variable">@ApiImplicitParam</span>(name=<span class="string">"account"</span>,value=<span class="string">"账号"</span>,dataType=<span class="string">"String"</span>, paramType = <span class="string">"body"</span>), </span><br><span class="line">    <span class="variable">@ApiImplicitParam</span>(name=<span class="string">"password"</span>,value=<span class="string">"密码"</span>,dataType=<span class="string">"String"</span>, paramType = <span class="string">"body"</span>)&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>只需要这样：<code>@ApiImplicitParam(name=&quot;user&quot;,value=&quot;用户信息&quot;,dataType=&quot;User&quot;, paramType = &quot;body&quot;)</code></p>
<p>就可以了，User就是实体类，在网页上显示就是这样： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/327d110778174272982d99f219254f7e.PNG" title="swagger中将参数类型设置body后的结果" alt="swagger中将参数类型设置body后的结果" /></p>
<p>它会让你提交json数据，只有body会让你提交json数据，很好区分。</p>
<p>但是我为什么要说它坑爹。因为swagger吧User的所有字段都放进去了，虽然可以一个个删掉，但是每次浏览网页都要做一遍，麻烦死了。所以需要使用如下方法： <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/b9b79737da504931b2a940c1a201330f.PNG" title="用户实体类" alt="用户实体类" /></p>
<p>设置为只读，这样就不会在网页上显示了，我们可以把除了account（图中的tel）和password的字段全部设置为只读。这里放心我测试过了，只读只是在网页看不见，其他的功能暂时没有受到影响。 <strong>注：</strong>@RequestBody 和 @ModelAttribute不能一起用</p>
<p><strong>更新：</strong>今天测试的时候发现，如果其他客户端使用代码的方式调用会出现不小的问题。这里把我解决的部分写出：content-type必须设置为“application/json”，传递参数时，不需要写键，只需要传一个json字符串即可，并且json字符串必须使用双引号，而不能是单引号（测试于fastxml jackson）。</p>
<p>我列出我的代码（使用RestTemplate） <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/ebcbfdb2368e43be85252b69a65dce96.PNG" title="使用body的问题" alt="使用body的问题" /></p>
<h3 id="header">header</h3>
<p>没有用过，但是是配合@RequestHeader用的</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>swagger</tag>
      </tags>
  </entry>
  <entry>
    <title>shiro角色和权限的用法</title>
    <url>/posts/9c1e4a2f.html</url>
    <content><![CDATA[<h3 id="shiro通配符的理解">shiro通配符的理解</h3>
<p>shiro提供通配符，例如<code>*:*:*</code>的形式 意味着：第一部分代表一个域，第二部分代表操作，第三部分代表实例。 举个例子，现在有一个权限管理系统，称为<code>:upms</code>，可以写出权限<code>upms:update:coment</code>,这个权限值代表可以在upms这个域中对coment进行update操作。但是也不要思维定死，“域就是一个系统”。 再比如说一个权限值<code>upms:update:user</code>,代表可以更新一个用户的信息，这里的域的确是upms，但是并不是所有的用户都用这个域（事实上也不能用）。比如普通的用户也有权限更新自己的信息，那么可以再创建一个权限值比如“user:update:15900000000”,意味着一个用户可以更新15900000000这个账号的信息。</p>
<h3 id="shiro角色和权限的理解">shiro角色和权限的理解</h3>
<p>之前一直想角色和权限的用法差不多，为什么还要分角色和权限？ <a id="more"></a> 然后看了<a href="http://shiro.apache.org/permissions.html" target="_blank" rel="noopener">shiro官网的文档</a>貌似懂了一些。 官网说shiro一共有三种权限粒度，分为：资源级别，实例级别，属性级别（ <a href="http://shiro.apache.org/java-authorization-guide.html#levels-of-permission-granularity" target="_blank" rel="noopener">这三种粒度的描述页面</a>） 角色可以控制对资源的访问，比如对一个页面的访问。如果程序中已经设置了隐式角色，那么直接使用注解的形式可以很快速的控制这个网页的浏览权限。 而权限是对角色更细粒度的划分。比如现在有一个角色名为“admin”，他拥有对系统中所有权限的CRUD操作，现在需要临时给另外一个很普通的用户（比如只是一个user）查看权限的操作（R）。如果没有shiro提供的权限控制，<font color="red">那么只能给这个用户一个临时的“admin”角色，但是这样他的权限就太大了，因为“admin”是可以查看权限，但是他同样可以删除权限。</font></p>
<p>上述是个人理解。</p>
<p>又看了一遍才看懂了shiro官网的意思。 1. 资源级别指的是一个人可以干什么 2. 实例级别指的是一个人可以对什么干什么 3. 属性级别指的是一个人可以对什么上的什么干什么</p>
<p>以我的博客网站为例，1代表一个人可以管理整个博客后台，2代表一个人可以对博客类别进行某些操作，3代表一个人可以对博客类别的某一个属性（比如博客类别的状态）进行某些操作</p>
<p>2018-3-17更新，红色部分有错误，如果只给一个用户赋予权限而部赋予角色，用户还是访问不了该链接，因为shiro会执行角色过滤器和权限过滤器，所以用户必须同时满足角色和权限的需求。 所以给一个用户赋予临时权限的思路是错的。</p>
<p>2018-3-17再次更新，突然角色这条思路不是全错，因为没有必要为一个链接同时赋予角色和权限，因为一个角色下囊括了多个权限，为何还要多次一举呢？我觉得如果一个链接需要同时赋予角色以及权限，那么肯定是因为该链接非常重要，不允许非该角色的用户操作。 综上，如果一个链接很重要，比如删除整个系统的功能，那么肯定是同时需要角色和权限的，而如果是一个很普通的操作，那么可以只赋予权限，而不赋予角色。</p>
<p>但是权限的细分可以快速的为一个角色增加或删除权限，如给一个角色新增一个权限，那么该角色就可以多访问一个链接。</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>linux安装nginx</title>
    <url>/posts/a5141d63.html</url>
    <content><![CDATA[<p>参照<a href="https://www.linuxidc.com/Linux/2016-08/134110.htm" target="_blank" rel="noopener">Linux中Nginx安装与配置详解</a> 但是出了点小问题，按照步骤往下直到 配置nginx的时候出现了找不到openssl的错误（我的是阿里云的服务器）。 然后自己去下了一个openssl的包去安装死活不行。 最后执行<code>yum -y install openssl openssl-devel</code>就可以了。。 其次该博文中提示需要在某个文件中加入一句话，并重启防火墙，但是这样做我之前安装的tomcat也访问不了了，所以只要把防火墙关了就可以暂时解决了。</p>
<p>注：博文中的方法是为了开启防火墙，并且只运行80端口访问。我的服务器的防火墙不是iptables，而是firewall，所以不应该用博文中的方法，应该为firewall添加允许80端口访问 详见<a href="http://blog.csdn.net/codepen/article/details/52738906" target="_blank" rel="noopener">centos7 Firewall防火墙开启80端口</a> <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>安装与部署</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里云部署javaweb项目</title>
    <url>/posts/a784e2af.html</url>
    <content><![CDATA[<h3 id="配置java运行环境">配置java运行环境</h3>
<h4 id="查看服务器系统版本">查看服务器系统版本</h4>
<p><code>#getconf LONG_BIT</code> &gt;64</p>
<p>一般都是64了吧</p>
<h4 id="下载jdk">下载jdk</h4>
<p>下载地址：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">jdk下载地址</a> 版本：jdk-8u151-linux-x64.tar.gz（我下的版本） 使用WinSCP将jdk移动到linux中（有很多类似的软件，使用起来很简单） 在使用WinSCP连接时，输入公网IP，并输入帐号密码即可，不需要改变端口号。 至于将jdk放在哪个目录，可以看这篇<a href="http://blog.csdn.net/ubuntu64fan/article/details/8289335" target="_blank" rel="noopener">Linux下JDK到底应该安装在哪儿</a> 我选择放在/usr/local/java下</p>
<h4 id="查看当前系统是否有jdk">查看当前系统是否有JDK</h4>
<p>使用rpm -qa |grep jdk 如果有就移除 <a id="more"></a></p>
<h4 id="解压jdk">解压JDK</h4>
<p><code>tar zxvf 文件名</code></p>
<h4 id="配置java环境">配置java环境</h4>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="comment">#vim /etc/profile       </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/java/jdk1.8.0_91   </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar   </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$JAVA_HOME/bin   </span><br><span class="line"><span class="builtin-name">export</span> JAVA_HOME CLASSPATH PATH</span><br></pre></td></tr></table></figure>
<p>按esc-&gt;输入“:wq”退出</p>
<h4 id="查看java版本检验是否成功">查看java版本，检验是否成功</h4>
<p>在此之前先运行source /etc/profile命令，或者重启机器 重启命令sudo shutdown -r now 不出意外就可以了</p>
<hr />
<p><strong>java运行环境到此配置成功，接下来安装、配置tomcat</strong> ***</p>
<h3 id="下载tomcat">下载tomcat</h3>
<p><a href="http://tomcat.apache.org/" target="_blank" rel="noopener">tomcat官网</a> 我下载的是<a href="https://tomcat.apache.org/download-90.cgi" target="_blank" rel="noopener">tomcat9</a></p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/d6a2325465794dd88baf548bc89131a0.PNG" title="tomcat官网截图" alt="tomcat官网截图" /><figcaption>tomcat官网截图</figcaption>
</figure>
<p>选择tar.gz即可，后面括号里的按了貌似没反应（我不知道干嘛用的=.=） 还是使用WinSCP，将tomcat放到/usr/local/tomcat下</p>
<h3 id="解压tomcat">解压tomcat</h3>
<p><code>tar -zxvf apache-tomcat-9.0.2.tar.gz</code> 之后就是跟在windows系统下一样部署web项目，具体我也在摸索.....=.=</p>
<h3 id="配置完成后依然无法访问">配置完成后依然无法访问</h3>
<p>如果无法通过8080访问，其他原因暂且不说（如防火墙，8080被占用），有一个阿里云的问题，需要配置安全组</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/4b0bf9c8aa524d1f8bcf85b5506d1433.PNG" title="阿里云安全组" alt="阿里云安全组" /><figcaption>阿里云安全组</figcaption>
</figure>
<p>如上图端口并没有配置8080，而tomcat默认端口号是8080，所以无法访问到，点击“添加安全组规则”添加即可。</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/8ae0fd824bc0431499b37a9fd4e7c0f3.PNG" title="添加安全组" alt="添加安全组" /><figcaption>添加安全组</figcaption>
</figure>
<p>如上图所示，添加成功。 手太快了，无法对比，之前无法访问的网页忘记截图了，但是我截了访问成功的图片。这里可以看到可以通过公网ip访问了。</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/898416f96b5643de87e73a3579aba6ec.PNG" title="成功访问tomcat主页" alt="成功访问tomcat主页" /><figcaption>成功访问tomcat主页</figcaption>
</figure>
<h3 id="创建数据库">创建数据库</h3>
<p><embed src="http://docs-aliyun.cn-hangzhou.oss.aliyun-inc.com/assets/attach/52685/cn_zh/1496913639790/%E6%96%B0%E6%89%8B%E5%85%A5%E9%97%A8_%E4%BA%91%E6%95%B0%E6%8D%AE%E5%BA%93MySQL%E7%89%88_V2.pdf" /> 这篇讲的很详细</p>
<h3 id="使用navicat连接">使用navicat连接</h3>
<p><a href="https://help.aliyun.com/knowledge_detail/37855.html?spm=5176.11065259.1996646101.searchclickresult.7755a429KB6TbE" target="_blank" rel="noopener">Navicat for SQL Server 连接 RDS For SQL Server 数据库</a> 这篇用sql server连得，但是也差不多。 只要复制mysql的外网连接地址去连就行了。</p>
<figure>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/8db46e497396457e970db85ff37b756e.PNG" title="navicat链接成功" alt="navicat链接成功" /><figcaption>navicat链接成功</figcaption>
</figure>
<h3 id="在阿里云控制台登录数据库">在阿里云控制台登录数据库</h3>
<p>https://help.aliyun.com/document_detail/26138.html?spm=5176.7741843.2.4.m1jXSQ 这篇文章讲的很简单。</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>安装与部署</tag>
      </tags>
  </entry>
  <entry>
    <title>关于shiro的session总结</title>
    <url>/posts/33360a81.html</url>
    <content><![CDATA[<ul>
<li>关闭浏览器，使用shiro记住我功能时，session失效，即重新打开浏览器需要重新登录。其实并没有失效，而是再次打开浏览器时，shiro又重新创建了一个session，所以导致之前的session与现在的session不一致。所以造成了session失效的假象.</li>
<li>使用浏览器，在地址栏输入访问的链接但是不按回车时（意思就是只在地址栏输入一个链接不访问网页），系统会产生一个session，但是马上（一秒不到）自动删掉。</li>
<li>使用RememberMe时，断开会话后会重新生成一个session，并且sessionId以及里面原来保存的值全都没有了，但是不需要重新登录（此适用于user级别的过滤链）。</li>
<li>使用RememberMe时，断开会话后会重新生成一个session，并且sessionId以及里面原来保存的值全都没有了，需要重新登录，但是由于是重新登录，本质上session中的值是没有的，实质上登陆一次后又在session中存入了所有属性。（此适用于authc级别的过滤链）</li>
<li>可以看到断开会话后会重新产生一个session，所以之前的session没用了，但是没有自动删掉。而由于user级别的用户不需要重新登录，session中的值全没了（比如用户个人信息：头像等），所以网页中呈现出来肯定很怪。可以创建一个filter将之前会话的值全部复制到当前session中，然后清除之前的session（由于authc级别是不需要复制的，所以只需要清除之前的session即可，但是因为保不准用户在操作时，session中会存入一些其他的值，所以最好也复制一遍）。 <a id="more"></a></li>
</ul>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title>在shiro的realm中注入service引发的惨案</title>
    <url>/posts/fba51c50.html</url>
    <content><![CDATA[<p><strong><em>2019.01.24更新，由于发现了mybatis-plus插件已经实现了我要实现的功能，我自己写的肯定没别人研发的框架写得好，所以此方法已经废弃。</em></strong> ****</p>
<p>环境介绍一下：由于service层的代码重复太多，于是我想直接把一些重复的代码抽出来。</p>
<p>比如说这个方法，它可以实现根据条件查询，框架是mybatis。而注入的mapper是有spring提供的方法获取到的，问题就出在这里了。 <figure class="highlight monkey"><table><tr><td class="code"><pre><span class="line">@SuppressWarnings(<span class="string">"unchecked"</span>)</span><br><span class="line">@Override</span><br><span class="line"><span class="keyword">public</span> List&lt;Record&gt; selectByExample(Example example) &#123;</span><br><span class="line">    <span class="class"><span class="keyword">Class</span>&lt;? <span class="keyword">extends</span> <span class="title">Object</span>&gt; <span class="title">mapperClazz</span> = <span class="title">mapper</span>.<span class="title">getClass</span>();</span></span><br><span class="line">    List&lt;Record&gt; res = <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="function"><span class="keyword">Method</span> <span class="title">method</span> =</span> mapperClazz.getDeclaredMethod(<span class="string">"selectByExample"</span>, example.getClass());</span><br><span class="line">        res = (List&lt;Record&gt;) <span class="function"><span class="keyword">method</span>.<span class="title">invoke</span>(</span>mapper, example);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalArgumentException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (NoSuchMethodException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SecurityException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> <a id="more"></a> 这个方法获取到了mapper的类型，即CLass对象。</p>
<figure class="highlight kotlin"><table><tr><td class="code"><pre><span class="line"><span class="meta">@SuppressWarnings(<span class="meta-string">"unchecked"</span>)</span></span><br><span class="line"><span class="keyword">public</span> Class&lt;Mapper&gt; getMapperType() &#123;</span><br><span class="line">    ParameterizedType genericSuperclass = (ParameterizedType) <span class="keyword">this</span>.getClass().getGenericSuperclass();</span><br><span class="line">    <span class="keyword">return</span> (Class&lt;Mapper&gt;) genericSuperclass.getActualTypeArguments()[<span class="number">2</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里使用了我自定义的SpringContextUtil类获取了mapper这个bean。注意我这里使用了构造器初始化，问题就出在这里。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">public <span class="constructor">BaseServiceImpl()</span> &#123;</span><br><span class="line">    Class&lt;Mapper&gt; mapperType = get<span class="constructor">MapperType()</span>;</span><br><span class="line">    this.mapper = (Mapper) <span class="module-access"><span class="module"><span class="identifier">SpringContextUtil</span>.</span></span>get<span class="constructor">Bean(<span class="params">mapperType</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBean()方法就不提供了，可以自行百度。主要是这个类SpringContextUtil。</p>
<p>要想使用spring提供的以java代码方法获取bean有5种方式（大致差不多，我是用了第四种）：实现ApplicationContextAware接口。只需要在实现类中定义private static ApplicationContext applicationContext;变量，再设置set方法，即可使用这个对象获取到bean。</p>
<p>到这里一切都没问题，可以当启动tomcat时，问题出来了。</p>
<p>它报了一个异常，必须初始化applicationContext。我纳闷了，我之前在Controller层注入service对象用的好好的，为什么在shiro的realm中注入就出事了？</p>
<p>我看了我的applicationContext.xml文件，我是这么写的：</p>
<figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">import</span> resource=<span class="string">"classpath:springContextConfig.xml"</span> /&gt;</span><br><span class="line">&lt;<span class="keyword">import</span> resource=<span class="string">"classpath:spring/upms-dao.xml"</span> /&gt;</span><br><span class="line">&lt;<span class="keyword">import</span> resource=<span class="string">"classpath:spring/upms-service.xml"</span> /&gt;</span><br><span class="line">&lt;<span class="keyword">import</span> resource=<span class="string">"classpath:spring/upms-tx.xml"</span> /&gt;</span><br><span class="line">&lt;<span class="keyword">import</span> resource=<span class="string">"classpath:shiro/shiro.xml"</span> /&gt;</span><br></pre></td></tr></table></figure>
<p>然后看了web.xml文件</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">&lt;context-<span class="built_in">param</span>&gt;</span><br><span class="line">	&lt;<span class="built_in">param</span>-name&gt;contextConfigLocation&lt;/<span class="built_in">param</span>-name&gt;</span><br><span class="line">	&lt;<span class="built_in">param</span>-<span class="built_in">value</span>&gt;classpath:applicationContext.xml&lt;/<span class="built_in">param</span>-<span class="built_in">value</span>&gt;</span><br><span class="line">&lt;/context-<span class="built_in">param</span>&gt;</span><br></pre></td></tr></table></figure>
<p>好像稍微有点头绪了。我在初始化spring上下文的时候，直接初始化了shiro.xml，这没问题。但是在applicationContext.xml中第一行的<code>&lt;import resource=&quot;classpath:springContextConfig.xml&quot; /&gt;</code>里面注册了SPringContextUtil这个工具类。（这个工具类不会一下子注册进去成为bean，它会在spring上下文初始化完毕之后才行）。</p>
<p>所以我需要在realm中注册AdminService-----&gt;AdminService继承了BaseServiceImpl-----&gt;BaseServiceImpl在构造器中使用了applicationContext.getBean()。这个步骤在spring上下文初始化还没完成的时候执行，但是你要想使用applicationContext，spring上下文必须初始化完毕，所以冲突了。</p>
<p>那我就想直接把shiro.xml托到DispatcherServlet里面初始化就完事了。因为在DispatcherServlet加载的配置文件中，我扫描了Controller层，而在Controller层使用是没问题的（我之前还不懂的时候就这么做的，没报异常）。然后我这么做了，但是又报异常了-----&gt;No Bean Named &quot;shiroFilter&quot;。这不坑爹吗？</p>
<p>我先缕一缕，<code>&lt;context-param&gt;</code>最先执行，其次是<code>&lt;filter&gt;</code>，最后是<code>&lt;servlet&gt;</code>（不一定完全正确，但是可以这么理解）。所以说shiro.xml放在DispatcherServlet中不行！因为filter比servlet先执行，它必须要shiro.xml中的bean。所以怎么办？我必须把shiro.xml放在context-param和filter的中间。这根本不可能（起码我做不到）。</p>
<p>后来我想到了懒加载（我印象中有听说过这个概念），我一百度还真有。那我应该把懒加载放在哪个bean上呢？我决定放在AdminService上。但是没用，因为Realm这个类不能懒加载，因为它马上就被初始化了。而realm中注入了AdminService，所以即使是懒加载也没屌用。</p>
<p>最后终于解决了。</p>
<p>既然你要初始化bean，要用构造器，我就把调用applicationContext的代码不放在构造器里。我写了一个initMapper方法。</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">@Override</span><br><span class="line">public void init<span class="constructor">Mapper()</span> &#123;</span><br><span class="line">    Class&lt;Mapper&gt; mapperType = get<span class="constructor">MapperType()</span>;</span><br><span class="line">    this.mapper = (Mapper) <span class="module-access"><span class="module"><span class="identifier">SpringContextUtil</span>.</span></span>get<span class="constructor">Bean(<span class="params">mapperType</span>)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意@Override注解。那么现在问题就是，怎么调用这个方法。经过度娘之后，终于解决了。贴上类，我就不解释了。附上链接https://www.cnblogs.com/rollenholt/p/3612440.html</p>
<figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">public <span class="keyword">class</span> MapperInit implements ApplicationListener&lt;ContextRefreshedEvent&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void on<span class="constructor">ApplicationEvent(ContextRefreshedEvent <span class="params">event</span>)</span> &#123;</span><br><span class="line">        <span class="comment">//下面的方法执行就行了，这个方法会执行两次，我们不需要这么做</span></span><br><span class="line">    &#125;</span><br><span class="line">       </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 需要执行的逻辑代码，当spring容器初始化完成后就会执行该方法。</span></span><br><span class="line"><span class="comment">     * 由于加了@PostConstruct注解所以这个方法跟上面的onApplicationEvent一样。</span></span><br><span class="line"><span class="comment">     * 但是这个方法只会在root application context环境中执行，不会在 projectName-servlet context中执行</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    @<span class="constructor">SuppressWarnings(<span class="string">"rawtypes"</span>)</span></span><br><span class="line">    @PostConstruct</span><br><span class="line">    <span class="keyword">private</span> void init<span class="constructor">Mapper()</span> &#123;</span><br><span class="line">        Map&lt;String, BaseService&gt; beansOfType = <span class="module-access"><span class="module"><span class="identifier">SpringContextUtil</span>.</span></span>get<span class="constructor">ApplicationContext()</span>.get<span class="constructor">BeansOfType(BaseService.<span class="params">class</span>)</span>;</span><br><span class="line">        for(Map.Entry&lt;String, BaseService&gt; entrySet : beansOfType.entry<span class="constructor">Set()</span>) &#123;</span><br><span class="line">            BaseService service = entrySet.get<span class="constructor">Value()</span>;</span><br><span class="line">            service.init<span class="constructor">Mapper()</span>;</span><br><span class="line">            <span class="module-access"><span class="module"><span class="identifier">System</span>.</span></span>out.println(service);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title>vo,dto,do,po的理解</title>
    <url>/posts/73327597.html</url>
    <content><![CDATA[<ul>
<li>po:持久化对象，没啥好说的，数据库里一张表对应一个po。</li>
<li>vo:视图对象，是指某个指定页面的所有数据，注意是<font color="red">所有数据</font>。</li>
<li>dto:跟vo差不多，甚至可以代替vo，但是二者理论上是不一样的。vo用于数据显示，dto用于数据传输(展示层与业务层之间)。如性别在数据库里用01表示，在传输时dto直接定义Integer，但是在展示时总不能展示0和1，并且男女也有不同称谓(帅哥美女，先生女士等等)，所以需要另建一个vo用于处理这些逻辑。但是如果没有特殊需求，其实vo就是dto，dto是将业务层数据传输出去，在视图层展示时将以数字表示的性别转换为文字。如果客户端没有要求，那么不传输出数字，直接写上男女也没问题，如果确是有要求，在业务层就不能传出文字，而只能传出数字了。</li>
<li>do:无法里给 <a id="more"></a> 以上出自:<a href="https://www.cnblogs.com/qixuejia/p/4390086.html" target="_blank" rel="noopener">博客园博主</a> <img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/e3592ba9de284f128b9183a2434ae018.jpg" title="领域模型" alt="领域模型" /> <!-- more --></li>
</ul>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>印象笔记上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>js一些常用的属性和函数</title>
    <url>/posts/8abb4fb3.html</url>
    <content><![CDATA[<p>由于老是忘记js和jq的函数，这里记一下。</p>
<h3 id="javascript">javascript</h3>
<ol type="1">
<li>string.replace(//, &quot;&quot;)：第一个参数是正则，表达式在//两个之间写，第二个参数是需要替换成什么。</li>
<li>string.substr()：用法和一样</li>
<li>new Date(date).toLocaleString()：将毫秒数转成本地的时间，如中国：2017/9/4 下午9:42:41</li>
<li>(a/b).toFixed(2)：相除保留两位小数，如700/100等于7.00。要不然就是只等于7（java里整数相除只得到整数部分） <a id="more"></a></li>
</ol>
<h3 id="jquery">Jquery</h3>
<ol type="1">
<li>$(&quot;#id&quot;).attr()：为一个节点添加属性，一个属性:attr(&quot;name&quot;, &quot;file&quot;)。多个属性:attr({&quot;name&quot;:&quot;file&quot;, &quot;type&quot;,&quot;button&quot;})</li>
<li>$(&quot;#id&quot;).remove()：移除节点</li>
<li>$(&quot;#id&quot;).removeAttr(&quot;&quot;)：移除一个节点的属性</li>
<li>$(&quot;#id&quot;).children(&quot;:first&quot;)：一个节点的子节点</li>
<li><span class="math inline">\((&quot;#id&quot;).offset()：一个节点离网页顶部的top值和left值，不是离浏览器的top值和left值（以整个网页的高度做计算）。\)</span>(&quot;#id&quot;).offset().top代表节点的top值，left值同理。</li>
<li>滚动监听 <figure class="highlight arcade"><table><tr><td class="code"><pre><span class="line">$(<span class="string">"body,html"</span>).animate(&#123;</span><br><span class="line">	scrollTop:scroll_offset.top <span class="comment">//让body的scrollTop等于pos的top，就实现了滚动</span></span><br><span class="line">&#125;,<span class="number">0</span>);</span><br></pre></td></tr></table></figure></li>
<li>window.location.search：获得当前url，如：http://localhost:8080/contextpath/index.html</li>
<li><span class="math inline">\(.parseJSON(string)：将一个字符串转为json对象，但是不要在用ajax的时候，data:\)</span>.parseJSON(string)这样用，我搞了2个小时，没查出错，原来是这里错了。 string json = '{&quot;comment&quot;:&quot;abcdrf&quot;,&quot;name&quot;:&quot;xiaowang&quot;}'; 我在用<span class="math inline">\(.ajax()的时候，把data赋值\)</span>.parseJSON(json)，出错了！！！data:json。后台接受的很成功。 但是后台传来一个json字符串，用这个方法转成json对象，可以直接通过.取值挺方便的。</li>
<li>new FormData().append()：使用 FormData对象获取到form中的数据后，可以继续append自己想要添加的数据。 <!-- more --></li>
</ol>
]]></content>
      <categories>
        <category>coding</category>
        <category>front-end</category>
      </categories>
      <tags>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>再探String</title>
    <url>/posts/d0357408.html</url>
    <content><![CDATA[<p>估计是最终版了。</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="keyword">String</span> s1 = <span class="keyword">new</span> <span class="keyword">String</span>(<span class="string">"张三"</span>);</span><br><span class="line"><span class="keyword">String</span> s2 = <span class="keyword">new</span> <span class="keyword">String</span>(<span class="string">"张三"</span>);</span><br><span class="line"><span class="keyword">String</span> s3 = <span class="string">"张三"</span>;</span><br><span class="line"><span class="keyword">String</span> s4 = <span class="string">"张三"</span>;</span><br></pre></td></tr></table></figure>
<p>我们都知道<code>String s3 = &quot;张三&quot;;</code>这句代码的&quot;张三&quot;字符串位 于常量池中，而s3==s4这种明显就是小儿科，true！ 我们来解析一下<code>String s3 = &quot;张三&quot;;</code>这句代码。 1. 首先s3进入栈中，&quot;张三&quot;进入常量池中，&quot;张三&quot;返回一个地址，s3拿到这个地址，所以我们就可以拿着这个地址做一些事情。这应该都很熟悉了，那么问题来了：“String s1 = new String(&quot;张三&quot;);”这句代码是怎么执行的？ <a id="more"></a> 2. 首先我们要知道一个定义：成员变量和局部变量。 s3是一个局部变量，当然是相对来说，比如说上面的4句代码都位于一个方法中，那么s3是一个局部变量。</p>
<ol start="3" type="1">
<li>接下来我们解析<code>String s1 = new String(&quot;张三&quot;);</code>这句代码。 s1还是一个局部变量所以进入栈中，new String会在堆中创建一个String实例对象（OK很简单），那么这个 &quot;张三&quot;怎么办？注意了！String对象是如何存储字符串的？实际上就是一个char数组（同时也解释了一个中文可以用一个char来存储），所以&quot;张三&quot;在String中实际上是这样的：value[0]='张'，value[1]=&quot;三&quot;。 这个value是一个char数组，而它优势String的成员变量也就是说，value这个变量不会进入栈，而是跟着String在堆内存中（实际上不是，我先打个比喻）。 String对象的构造器还没完！它还会初始化一个hash码，这个是String自己初始化的，不用你来控制，所以hash码这个变量也是跟着String进入堆中。</li>
</ol>
<p>现在我们来缕一缕-------&gt;String在堆中开辟一个空间，这个空间里有value数组，hash变量（其他的我就不说了，我上面也说过了，实际上value并不在String中）。</p>
<p>知道上面的一切之后，就可以分析了。</p>
<p>是不是&quot;张三&quot;这种形式的写法，字符串就进入了常量池？比如：<code>String s1 = &quot;张三&quot;;String s1 = new String(&quot;张三&quot;);StringBuilder s3 = new StringBuilder(&quot;张三&quot;);StringBuffer s4 = new StringBuffer(&quot;张三&quot;);</code></p>
<p>其实我们有办法做到，观察是否进入了。 但是之前先考虑，<code>String s1 = new String(&quot;张三&quot;);</code>和<code>String s3 = &quot;张三&quot;;</code>这两个&quot;张三&quot;是同一个字符串吗？ 其实看我上面的某些描述，可能也推测出来了，这两个&quot;张三&quot;就是同一个（指同一个地址）。下面讲如何做到观察是否为同一个。</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">String <span class="built_in">s1</span> = new String(<span class="string">"abc"</span>)<span class="comment">;</span></span><br><span class="line">String <span class="built_in">s2</span> = new String(<span class="string">"abc"</span>)<span class="comment">;</span></span><br><span class="line">Class&lt;?&gt; clazz1 = <span class="built_in">s1</span>.getClass()<span class="comment">;</span></span><br><span class="line">Class&lt;?&gt; clazz2 = <span class="built_in">s2</span>.getClass()<span class="comment">;</span></span><br><span class="line">Field declaredField1 = clazz1.getDeclaredField(<span class="string">"value"</span>)<span class="comment">;</span></span><br><span class="line">Field declaredField2 = clazz2.getDeclaredField(<span class="string">"value"</span>)<span class="comment">;</span></span><br><span class="line">declaredField1.setAccessible(true)<span class="comment">;</span></span><br><span class="line">declaredField2.setAccessible(true)<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField1.get(<span class="built_in">s1</span>) == declaredField2.get(<span class="built_in">s2</span>))<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField1.get(<span class="built_in">s1</span>))<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField2.get(<span class="built_in">s2</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>上面的代码结果如何，显然已经解释的很清楚了。</p>
<p>解</p>
<p>首先&quot;张三&quot;实际上是一个char数组，而它是String的成员变量，所以它硬该在堆内存中，但是事实是在常量池。 常量池：看名字就知道是存常量的。 在网络上的熏陶，我们知道String name = &quot;李四&quot;；&quot;李四&quot;在常量池，所以name是一个常量（无语ing，别被带偏了，我在今天之前也是这么认为的）。 被final修饰的才是常量。现在你们大概猜出什么了。去看String的源码吧，看看value这个成员变量的前面是用什么修饰的！！！自己去看才会记忆深刻，我就不贴源码了。</p>
<p>还没完 是不是&quot;张三&quot;这种形式的写法，字符串就进入了常量池？ 我之前问了这个问题。答：不是。 StringBuilder name1 = new StringBuilder(&quot;张三&quot;); String name2 = &quot;张三&quot;; 这时候又不一样了。 这两个&quot;张三&quot;不是同一个（也就是说地址不一样）。话不多说上代码。</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">String <span class="built_in">s1</span> = new String(<span class="string">"abc"</span>)<span class="comment">;</span></span><br><span class="line">StringBuilder <span class="built_in">s2</span> = new StringBuilder(<span class="string">"abc"</span>)<span class="comment">;</span></span><br><span class="line">Class&lt;?&gt; clazz1 = <span class="built_in">s1</span>.getClass()<span class="comment">;</span></span><br><span class="line">Class&lt;?&gt; clazz2 = <span class="built_in">s2</span>.getClass()<span class="comment">;</span></span><br><span class="line">clazz2 = clazz2.getSuperclass()<span class="comment">;</span></span><br><span class="line">Field declaredField1 = clazz1.getDeclaredField(<span class="string">"value"</span>)<span class="comment">;</span></span><br><span class="line">Field declaredField2 = clazz2.getDeclaredField(<span class="string">"value"</span>)<span class="comment">;</span></span><br><span class="line">declaredField1.setAccessible(true)<span class="comment">;</span></span><br><span class="line">declaredField2.setAccessible(true)<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField1.get(<span class="built_in">s1</span>) == declaredField2.get(<span class="built_in">s2</span>))<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField1.get(<span class="built_in">s1</span>))<span class="comment">;</span></span><br><span class="line">System.out.println(declaredField2.get(<span class="built_in">s2</span>))<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>上面的结果有没有出乎意料？地址打印出来都不一样。你们也猜到了什么吧。 去看StringBuilder的源码吧。StringBuffer同理。 注：StringBuilder中没有value，但是它的父类AbstractStringBuilder有，去看看value前面是什么修饰的。</p>
<hr />
<p>2018.9.6更新 java1.7之后貌似有很大变化。上面的理论可能不太适用</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>解决li标签使用inline-block时产生的4px</title>
    <url>/posts/9bf9a2db.html</url>
    <content><![CDATA[<p>完美兼容的方法</p>
<p>父元素（比如ul）设置font-size:0;</p>
<p>使用letter-spacing:-Npx;</p>
<p>li标签重新设置字体大小</p>
<p>原文出处：解决inline-block出现的间隙 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>front-end</category>
      </categories>
      <tags>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>理解接口和抽象类</title>
    <url>/posts/4a3c1668.html</url>
    <content><![CDATA[<p>这篇只是自学java基础时的个人理解而已。</p>
<p>初学abstract和interface时会感到很疑惑，明明这两个没有具体实现的方法，为什么还要继承或者实现他们呢？明明可以自己在自己编写的类中写一个方法，而不去继承或实现。现在看来大概是因为一种规范，也是为了让别人更好的看懂，如果自己写方法，自己去用，当然不需要多此一举。如果编写一个Run的接口，让别人去用，别人一看就知道这个接口是用来让某种东西跑起来。 - 抽象类 它只有声明，而没有具体的实现。抽象方法必须加上abstract关键字。如果一个类含有抽象方法即这个类是抽象类，但是抽象类也可以不含有抽象方法，不过这样定义一个抽象类就毫无意义。 抽象类中也可以拥有成员变量和普通的成员变量。 抽象类与普通类主要有三种区别： 1. 抽象方法必须为public或者protected，缺省情况下为public 2. 抽象类不能被用来创建对象 3. 如果继承一个抽象类则必须实现它的抽象方法，如果不实现则必须将这个方法也加上abstract。 <a id="more"></a> - 接口 在软件工程中，接口泛指供别人调用的方法或者函数。它是对行为的抽象。 接口可以含有变量和方法，但是它们都会被自动加上public static final关键字，如果没有加上，系统会自动添加。 一个类可以实现多个接口。 接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法； - 区别 抽象类是“是不是”的关系，定义一个animal类，再定义一个Dog类，animals extends Dog，是一种“是不是”的关系，即狗是不是动物。 接口是“有没有”的关系，定义一个interface Eat，实现它，Dog implements Eat，即Dog类实现Eat接口，狗有没有吃这种功能。 具体内容引自 http://www.cnblogs.com/dolphin0520/p/3811437.html 这篇只是为了帮助自己理解二者的区别。</p>
<!-- more -->
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>自动装箱和自动拆箱功能</title>
    <url>/posts/ae310f85.html</url>
    <content><![CDATA[<p><code>Integer a = new Integer(1000);</code> 在jdk5.0之后走了自动装箱功能 <code>Integer a = 1000;</code>即与上面的等式相同。 在编译阶段，编译器帮助我们改进代码，将<code>Integer a = new Integer(1000);</code> 自动改为<code>Integer a = 1000;</code></p>
<p><code>int c = new Integer(1500);</code>进行自动拆箱。 编译器将上述代码自动改为<code>int c = new Integer(1500).intValue();</code></p>
<p>但是在–128到127之间的数依然会当做基本数据类型处理。 <figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">Integer <span class="built_in">a1</span>=<span class="number">100</span><span class="comment">;</span></span><br><span class="line">Integer <span class="built_in">a2</span>=<span class="number">100</span><span class="comment">;</span></span><br></pre></td></tr></table></figure></p>
<p>a1==a2返回的照理说应该是false，但是在处理时，它只是基本数据类型，所以返回true。 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>StringBuilder和StringBuffer的区别</title>
    <url>/posts/e8a4cb6f.html</url>
    <content><![CDATA[<p>StringBuilder线程不安全，效率高。 DtringBuffer线程安全，效率低。 都是可变字符序列。 <code>StringBuilder s = new StringBuilder()</code>字符数组长度初始化为16 <code>StringBuilder s = new StringBuilder(32)</code>字符数组长度初始化为32 其中的append方法最终返回this，可以实现方法链，<code>s.append(&quot;ab&quot;).append(&quot;cd&quot;)</code></p>
<figure class="highlight isbl"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">StringBuilder</span>(<span class="variable">String</span> <span class="variable">s</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">	<span class="function"><span class="title">super</span>(<span class="variable">s</span>.length() + <span class="number">16</span>);</span></span><br><span class="line"><span class="function">	<span class="title">append</span>(<span class="variable">s</span>);</span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure>
<p>StringBuilder类的其中一个构造器，建立一个初始化内容的长度加上16的数组 如果传入的一个数组比初始化的大，则会进行数组扩容。 新容量 = 旧容量 * 2+2 <a id="more"></a></p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>区分“==”和equals</title>
    <url>/posts/52188101.html</url>
    <content><![CDATA[<p>比如</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line"><span class="keyword">String</span> s1=<span class="keyword">new</span> <span class="keyword">String</span>(<span class="string">"abc"</span>);</span><br><span class="line"><span class="keyword">String</span> s2=<span class="keyword">new</span> <span class="keyword">String</span>(<span class="string">"abc"</span>);</span><br></pre></td></tr></table></figure>
<p>s1==s2返回的是faluse，因为s1指向的是String类的value数组，而s2指向的是另一个String类的value数组，对象不同。 而s1.equals(s2)返回true。因为eauals比较的是内容，即value数组。 <a id="more"></a> <figure class="highlight armasm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">String </span><span class="built_in">s3</span>=<span class="string">"abc"</span><span class="comment">;</span></span><br><span class="line"><span class="keyword">String </span><span class="built_in">s4</span>=<span class="string">"abc"</span><span class="comment">;</span></span><br></pre></td></tr></table></figure> 这个初始化的，s3==s4和s3.equals(s4)返回的都是true，因为s3和s4指向的都是方法区的常量池</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
  <entry>
    <title>new String(abc)与String s=abc的区别</title>
    <url>/posts/e9e64e00.html</url>
    <content><![CDATA[<p>String类是不可变字符序列。 比如<code>String s=&quot;abc&quot;;</code> 原理是将字符串&quot;abc&quot;存入value数组，而value数组是final，所以value数组是不能改变的，但是String产生的s对象，s这个指针是可变的。 局部变量s在栈中产生，指向在堆(方法区的常量池)中的&quot;abc&quot;,然后如果想在字符串后面添加字符，则会诞生一个新的字符串(比如&quot;abcd&quot;)，然后将s指针指向&quot;abcd&quot;。 而<code>String s=new String(&quot;abc&quot;);</code> 同理s产生在栈中，字符串&quot;abc&quot;产生在堆(方法区的常量池)中，但是s不直接指向&quot;abc&quot;。 new String在堆中产生一个对象，由常量池中的&quot;abc&quot;对它进行初始化，而s对象指向的是new String这个对象。 s指向String，String指向&quot;abc&quot;。 <a id="more"></a></p>
<p>总结:new String()比String多创建了一个对象，浪费内存。 用<code>String s=new String()</code>创建了在栈中的s对象以及String类对象。 用String s仅仅创建了s对象</p>
]]></content>
      <categories>
        <category>coding</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>新浪博客上的博文</tag>
      </tags>
  </entry>
</search>
