<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/5.12.1/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yan624.github.io","root":"/","scheme":"Pisces","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering&amp;emsp;&amp;emsp;本文将多领域 DST 视为问答问题，被称为 Dialogue State Tracking via Question Answering（DSTQA）。在 DSTQA 之中，每一轮生成一个问题，">
<meta name="keywords" content="4me,DST">
<meta property="og:type" content="article">
<meta property="og:title" content="DST论文笔记（？-2019）">
<meta property="og:url" content="http://yan624.github.io/·论文笔记/dilogue/task-oriented/DST论文笔记（？-2019）.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering&amp;emsp;&amp;emsp;本文将多领域 DST 视为问答问题，被称为 Dialogue State Tracking via Question Answering（DSTQA）。在 DSTQA 之中，每一轮生成一个问题，">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2020-05-06T05:30:50.094Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DST论文笔记（？-2019）">
<meta name="twitter:description" content="Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering&amp;emsp;&amp;emsp;本文将多领域 DST 视为问答问题，被称为 Dialogue State Tracking via Question Answering（DSTQA）。在 DSTQA 之中，每一轮生成一个问题，">

<link rel="canonical" href="http://yan624.github.io/·论文笔记/dilogue/task-oriented/DST论文笔记（？-2019）.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>
<!--图片缩放插件样式-->
<link rel="stylesheet" href="/lib/zoomify/zoomify.min.css" />
<!--阿里云矢量库样式-->
<link rel="stylesheet" href="//at.alicdn.com/t/font_1717154_621sfmh583s.css" />

  <title>DST论文笔记（？-2019） | 博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">低阶炼金术士<br />虚体训练师</p>
  </div>

  <div class="site-nav-right"></div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档<span class="badge">155</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-常用链接">

    <a href="/常用链接" rel="section"><i class="fas fa-fw fa-bookmark"></i>常用链接</a>

  </li>
        <li class="menu-item menu-item-时间线">

    <a href="/categories/timeline/" rel="section"><i class="iconfont icon-timeline"></i>时间线</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签<span class="badge">91</span></a>

  </li>
        
            
  <li class="menu-item menu-item-博客分类">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>博客分类</a>

  </li>


      
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    
    	
    		<link rel="stylesheet" type="text/css" href="/lib/spop/spop.min.css">
        <script type="text/javascript" src="/lib/spop/spop.min.js"></script>
        <!--判断此文是否为特殊的文章-->
        <script>
          var templateSentence = '这是条不可能出现的弹窗提示。';
          if('4me' == '学习笔记')
            templateSentence = '<h4 class="spop-title">注意</h4>此文仅为博主的学习笔记，并非教学，其中可能含有理论错误。';
          else if('4me' == '4me')
            templateSentence = '<h4 class="spop-title">注意</h4>此文仅供个人查阅，对于他人没什么太大的价值。';
          spop({
            template: templateSentence,
            group: 'tips',
            position  : 'bottom-center',
            style: 'success',
            autoclose: 5500,
            onOpen: function () {
              //这里设置灰色背景色
            },
            onClose: function() {
              //这里可以取消背景色
              spop({
                template: 'ε = = (づ′▽`)づ',
                group: 'tips',
                position  : 'bottom-center',
                style: 'success',
                autoclose: 1500
              });
            }
          });
        </script>
    	
    
    	
    

    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/·论文笔记/dilogue/task-oriented/DST论文笔记（？-2019）.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          DST论文笔记（？-2019）
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-03-30 09:58:31" itemprop="dateCreated datePublished" datetime="2020-03-30T09:58:31+08:00">2020-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-05-06 13:30:50" itemprop="dateModified" datetime="2020-05-06T13:30:50+08:00">2020-05-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/paper/" itemprop="url" rel="index">
                    <span itemprop="name">paper</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>20 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="Multi-domain-Dialogue-State-Tracking-as-Dynamic-Knowledge-Graph-Enhanced-Question-Answering"><a href="#Multi-domain-Dialogue-State-Tracking-as-Dynamic-Knowledge-Graph-Enhanced-Question-Answering" class="headerlink" title="Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering"></a>Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering</h1><p>&emsp;&emsp;本文将多领域 DST 视为问答问题，被称为 <em>Dialogue State Tracking via Question Answering</em>（<strong>DSTQA</strong>）。在 DSTQA 之中，每一轮生成一个问题，询问域槽对的槽值，因此可以很自然地将其扩展到未知领域，槽位和槽值。此外，我们使用一个<strong>动态变化的知识图谱</strong>，以清楚地学习槽值对之间的关系。</p>
<ul>
<li>公式阐述：在多领域 DST 问题中，有 <script type="math/tex">M</script> 个领域 <script type="math/tex">D=\{d_1, d_2, \cdots, d_M\}</script>。每个领域 <script type="math/tex">d \in D</script> 有 <script type="math/tex">N^d</script> 个槽位 <script type="math/tex">S^d=\{s^d_1, s^d_2, \cdots, s^d_{N^d}\}</script>。每个槽位 <script type="math/tex">s \in S^d</script> 有 <script type="math/tex">K^s</script> 个可能的值 <script type="math/tex">V^s=\{v^s_1, v^s_2, \cdots, v^s_{K^s}\}</script>。对话 <script type="math/tex">X</script> 定义为 <script type="math/tex">X = \{U^a_1, U^u_1, U^a_2, U^u_2, \cdots, U^a_T, U^u_T\}</script>。</li>
</ul>
<a id="more"></a>
<h1 id="Find-or-Classify-Dual-Strategy-for-Slot-Value-Predictions-on-Multi-Domain-Dialog-State-Tracking"><a href="#Find-or-Classify-Dual-Strategy-for-Slot-Value-Predictions-on-Multi-Domain-Dialog-State-Tracking" class="headerlink" title="Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking"></a>Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking</h1><p>&emsp;&emsp;<strong>作者：Zhang et al., 2019。</strong><br>&emsp;&emsp;现存的 DST 方法分为两种类型：picklist-based 和 span-based。<strong>picklist-based</strong> 方法在预定义本体的条件下，为每个槽位上潜在的槽值执行分类任务。但是它在工业环境下，是不切实际的，因为很难获得对本体的完全访问。<strong>span-based</strong> 方法在对话上下文中，通过寻找一个文本跨度（text spans），为每个槽位跟踪槽值。然而，由于槽值的多样性，很难在对话上下文中找到一个合适的字符串。为了解决这一问题，通过借鉴前两者方法的优点，本文提出 <strong>Dual Strategy for DST (DS-DST)</strong>。</p>
<ul>
<li>本文的做法：将域槽对视为 picklist-based 槽位或者 span-based 槽位，决定域槽对类别归属的方法是凭借人类启发（human heuristics）。<ul>
<li>例如在订酒店的场景下，请求一个停车位通常只有“yes”或者“no”的回复，所以将此类槽位视为 picklist-based 槽位。鉴于用户停留的天数是无限的，并且可以在上下文中找到，所以将其视为 span-based 槽位。</li>
</ul>
</li>
<li>DS-DST：令 <script type="math/tex">X = \{(U^{sys}_1, U^{usr}_1), \cdots, (U^{sys}_T, U^{usr}_T)\}</script> 代表系统语句 <script type="math/tex">U^{sys}_t</script> 和 用户语句 <script type="math/tex">U^{usr}_t</script> 的集合（<script type="math/tex">1 \le t \le T</script>），在给定 T 轮对话的情况下。令 N 个可能的域槽对表示为 <script type="math/tex">S = \{S_1, \cdots, S_N\}</script>，其中，<strong>每个域槽对都有 n 个符号</strong>。<br>DST 是追踪整个对上的状态，因此每一轮，我们都需要在上下文 <script type="math/tex">X_t = \{(U^{sys}_1, U^{usr}_1), \cdots, (U^{sys}_t, U^{usr}_t)\}</script> 中预测<strong>每个</strong>域槽对 S 的槽值，<strong>其中 <script type="math/tex">X_t</script> 拥有 m 个符号</strong>。我们假定 span-based 槽位在 S 中有 M 个，picklist-based 槽位有 <code>N-M</code> 个。每个 picklist-based 槽位有 C 个可能的槽值，即 <script type="math/tex">V_1, \cdots, V_C</script>，其中 C 是 picklist 的容量，<strong>每个槽值有 c 个符号</strong>。<br>我们首先使用 <strong>BERT</strong> 编码对话上下文 <script type="math/tex">X_t</script> 的信息，编码时还考虑了 S 中每个域槽对，以此获取基于域槽对信息的上下文表征。然后使用 <strong>slot gate</strong> 处理特殊类型的槽值。对于 span-based 槽位，使用 <strong>two-way 线性映射</strong>以找到文本跨度。对于 picklist-based 槽位，我们基于上下文表征从 picklist 中选择可信的槽值。<ul>
<li><strong>Slot-Context Encoder</strong>：对于第 j 个域槽对以及 t 时的对话上下文，我们使用 BERT 进行编码，将二者拼接，然后获取表征：<script type="math/tex; mode=display">R_{tj} = BERT([CLS] \oplus S_j \oplus [SEP] \oplus X_t) \tag{1}</script>其中 <code>[CLS]</code> 是一个特殊符号，每个样本之前都应该有它，<code>[SEP]</code> 是一个特殊的分割符。公式 1 中的输出可拆解为 <script type="math/tex">R_{tj} = [r^{CLS}_{tj}, r^1_{tj}, \cdots, r^k_{tj}]</script>，其中 <script type="math/tex">r^{CLS}_{tj}</script> 代表 K 个输入的聚合表征（<strong>博主注</strong>：这个只是一个定义而已），<script type="math/tex">r^k_{tj}</script> 就是普通的符号表征。</li>
<li><strong>Slot-Gate Classification</strong>：多领域对话中有非常多的域槽对，很不容易判断一个域槽对是否出现在每一轮的对话中。总的来说，在 t 轮，我们让分类器在 <code>{none, dontcare, prediction}</code> 中做出决策。<code>none</code> 代表没有提及，<code>dontcare</code> 代表对于某槽位用户可以接受任何槽值，<code>prediction</code> 代表应该由模型处理。我们在 slot-gate classification 中利用 <script type="math/tex">r^{CLS}_{tj}</script>，t 轮中第 j 个域槽对的概率由如下公式计算：<script type="math/tex; mode=display">P^{gate}_{tj} = softmax(W_{gate} \cdot (r^{CLS}_{tj})^T + b_{gate}) \tag{2}</script>此分类器的 loss 函数为：<script type="math/tex; mode=display">\mathcal{L}_{gate} = \sum^T_{t=1} \sum^N_{j=1} -log(P^{gate}_{tj} \cdot (y^{gate}_{tj})^T) \tag{3}</script>其中 <script type="math/tex">y^{gate}_{tj}</script> 是第 t 轮第 j 个域槽对的 one-hot 标签。</li>
<li><strong>Span-Based Slot-Value Prediction</strong>：计算 start 和 end 位置的向量：<script type="math/tex; mode=display">[\alpha^{start}_{tj}, \alpha^{end}_{tj}] = W_{span} \cdot ([r^1_{tj}, \cdots, r^k_{tj}])^T +b_{span} \tag{4}</script>那么，start 的概率可以使用公式：<script type="math/tex">P^{start}_{tj} = \frac{e^{\alpha^{start}_{tj} \cdot r^i_{tj}}}{\sum_k \alpha^{start}_{tj} \cdot r^k_{tj}}</script> 得到（<strong>博主注</strong>：这应该是 softmax，所以他可能漏了个 e，正确共识我认为是这样的：<script type="math/tex">P^{start}_{tj} = \frac{e^{\alpha^{start}_{tj} \cdot r^i_{tj}}}{\sum_k e^{\alpha^{start}_{tj} \cdot r^k_{tj}}}</script>），因此此模型的 loss 为（end 类似，不再赘述）：<script type="math/tex; mode=display">\mathcal{L}_{start} = \sum^T_{t=1} \sum^M_{j=1} -log(P^{start}_{tj} \cdot (y^{start}_{tj})^T) \tag{5}</script></li>
<li><strong>Picklist-Based Slot-Value Prediction</strong>：首先获得候选值的聚合表征<script type="math/tex; mode=display">Y_j = BERT([CLS] \oplus V_j \oplus [SEP]) \tag{6}</script>（余下略，写起来太麻烦了）</li>
<li><strong>Training Objective</strong>：<script type="math/tex">\mathcal{L}_{total} = \mathcal{L}_{sg} + \mathcal{L}_{span} + \mathcal{L}_{picklist} \tag{9}</script></li>
</ul>
</li>
</ul>
<h1 id="Transferable-Multi-Domain-State-Generator-for-Task-Oriented-Dialogue-Systems"><a href="#Transferable-Multi-Domain-State-Generator-for-Task-Oriented-Dialogue-Systems" class="headerlink" title="Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems"></a>Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</h1><blockquote class="blockquote-center"><p><a href="https://yan624.github.io/·论文笔记/dilogue/task-oriented/61. Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems.html">论文笔记</a></p>
</blockquote>
<p>&emsp;&emsp;<strong>作者：Wu, Chien-Sheng et al., 2019。</strong></p>
<h1 id="Global-Locally-Self-Attentive-Dialogue-State-Tracker"><a href="#Global-Locally-Self-Attentive-Dialogue-State-Tracker" class="headerlink" title="Global-Locally Self-Attentive Dialogue State Tracker"></a>Global-Locally Self-Attentive Dialogue State Tracker</h1><p>&emsp;&emsp;<strong>作者：Zhong et al. 2018。</strong></p>
<ul>
<li>引言<ul>
<li>在 DST 中，state 通常由一系列的 <strong>requests</strong> 和 <strong>joint goals</strong> 组成。</li>
<li>DST 中的一个重要问题是，现存的方法没有解决<strong>对低频槽值的提取</strong>。这是因为任务导向的对话系统涵盖了巨大的状态空间，许多槽值对组成的状态在训练集中很少出现。尽管用户一轮对话指定一个低频槽值对的概率很小，但是他们在整个对话中指定一个的概率很大。</li>
<li>本文提出 <strong>G</strong>lobal-<strong>L</strong>ocally Self-<strong>A</strong>ttentive <strong>D</strong>ialogue State Tracker(GLAD) 。相比于先前的工作， GLAD 独立地估计每一个槽值，使用 global modules 在估计器之间为每一个槽位共享参数，使用 local modules 学习特定槽位的表征。</li>
</ul>
</li>
<li>GLAD：GLAD 对每对槽值使用了一个估计器，将多元状态分类分解为一系列的二元分类问题，以此跟新状态。<ul>
<li><strong>Global-Locally Self-Attentive Encoder</strong>：每个状态都由一系列的槽值对组成，它们中有许多都是低频的，这会造成误差在多轮对话中累积。为了解决这一问题，使用 global module 对每个槽位进行参数共享，使用 local module 学习特定槽位的特征。使 n 代表序列长度， <script type="math/tex">d_{emb}</script> 为词向量维度，<script type="math/tex">X \in \mathbb{R}^{n \times d_{emb}}</script> 为序列中所有单词的词向量矩阵。我们使用 Bi-LSTM 产生 X <strong>全局编码</strong> <script type="math/tex">H^g</script>，其中 <script type="math/tex">d_{rnn}</script> 代表 LSTM 隐藏状态的维度。以同样的方法产生 X 的<strong>局部编码</strong> <script type="math/tex">H^s</script>，这考虑的是槽位 s。然后二者通过一个混合函数产生一个 X 的 <strong>global-local 编码</strong> H，其中 <script type="math/tex">\beta^s</script> 是一个特定于槽位 s 的 01 之间的可学习参数。公式如下所示：<script type="math/tex; mode=display">
\begin{align}
  H^g & = biLSTM^g(X) \in \mathbb{R}^{n \times d_{rnn}} \tag{1} \\
  H^s & = biLSTM^s(X) \in \mathbb{R}^{n \times d_{rnn}} \tag{2} \\
  H & = \beta^s H^s + (1 - \beta^s)H^g \in \mathbb{R}^{n \times d_{rnn}} \tag{3} \\
\end{align}</script>接下来计算 H 的 global-local self-attention context <script type="math/tex">c</script>。self-attention（或称 intra-attention） 是一种计算变长序列长下文摘要的好方法。对于第 i 个元素 <script type="math/tex">H_i</script>，我们计算全局自注意力分数标量 <script type="math/tex">a^g_i</script>，之后通过 softmax 将所有元素归一化，global self-attention context（下称<strong>全局自注意力上下文</strong>）<script type="math/tex">c^g</script> 就通过加权和计算出来了。 local self-attention context（下称<strong>局部自注意力上下文</strong>）<script type="math/tex">c^s</script> 同理。而 global-local self-attention context <script type="math/tex">c</script> 是它们的混合。计算公式如下所示：<script type="math/tex; mode=display">
\begin{align}
  a^g_i & = W^g H_i + b^g \in \mathbb{R} \tag{4} \\
  p^g & = softmax(a^g) \in \mathbb{R}^n \tag{5} \\
  c^g & = \sum_i p^g_i H_i \in \mathbb{R}^{d_{rnn}} \tag{6} \\
  a^s_i & = W^s H_i + b^s \in \mathbb{R} \tag{7} \\
  p^s & = softmax(a^s) \in \mathbb{R}^n \tag{8} \\
  c^s & = \sum_i p^s_i H_i \in \mathbb{R}^{d_{rnn}} \tag{9} \\
  c & = \beta^s c^s + (1 - \beta^s) c^g \in \mathbb{R}^{d_{rnn}} \tag{10}
\end{align}</script>为了便于说明，我们定义了函数 <code>encode(X)</code>，它将序列 X 映射为编码 H 和自注意力上下文 c：<script type="math/tex; mode=display">encode: X \to H, c \tag{11}</script></li>
<li><strong>Encoding module</strong>：定义好 global-locally self-attentive encoder 之后，我们可以构建用户语句、上一轮系统动作和槽值对的表征了。使 <script type="math/tex">U</script> 代表用户语句的嵌入，<script type="math/tex">A_j</script> 代表上一轮系统的第 j 个动作（例：request(price range)），<script type="math/tex">V</script> 代表槽值对（例：food=french）。所以我们有公式：<script type="math/tex; mode=display">
\begin{align}
  H^{utt}, c^{utt} & = encode(U) \tag{12} \\
  H^{act}_j, C^{act}_j & = encode(A_j) \tag{13} \\
  H^{val}, c^{val} & = encode(V) \tag{14} \\
\end{align}</script></li>
<li><strong>Scoring module</strong>：该组件，直观来说，我们可以通过检查两个输入，判断用户是否表达出了槽值对。第一个输入是用户语句，用户直接陈述<strong>目标与请求</strong>。做法是判断用户是否指定了某个槽值对。考虑用户语句 <script type="math/tex">H^{utt}</script>，槽值对 <script type="math/tex">c^{val}</script>，最后使用 resulting attention context <script type="math/tex">q^{utt}</script> 计算槽值对的分数，其中 m 代表用户语句中单词数量，分数 <script type="math/tex">y^{utt}</script> 代表用户表达槽值对的程度。公式如下所示：<script type="math/tex; mode=display">
\begin{align}
  a^{utt}_i & = (H^{utt}_i)^T c^{val} \in \mathbb{R} \tag{15} \\
  p^{utt} & = softmax(a^{utt}) \in \mathbb{R}^m \tag{16} \\
  q^{utt} & = \sum_i p^{utt}_i H^{utt}_i \in \mathbb{R}^{d_{rnn}} \tag{17} \\
  y^{utt} & = W q^{utt} + b \in \mathbb{R} \tag{18} \\
\end{align}</script>第二个输入是前一轮系统动作。这在用户没有提供信息，但是提到先前系统动作时很有效。如：在系统询问“你喜欢在市中心的酒店吗”，用户回答“喜欢”。为了处理这种情况，考虑动作表征 <script type="math/tex">C^{act} = [C^{act}_1, \cdots, C^{act}_l]</script> 以及用户语句上下文 <script type="math/tex">c^{utt}</script>，<script type="math/tex">l</script> 是动作数量，然后使用 <script type="math/tex">q^{act}</script> 和 <script type="math/tex">c^{val}</script> 之间的相似度来衡量槽值对：<script type="math/tex; mode=display">
\begin{align}
  a^{act}_j & = (C^{act}_j)^T c^{utt} \in \mathbb{R} \tag{19} \\
  p^{act} & = softmax(a^{act}) \in \mathbb{R}^{l+1} \tag{20} \\
  q^{act} & = \sum_i p^{act}_j C^{act}_j \in \mathbb{R}^{d_{rnn}} \tag{21} \\
  y^{act} & = (q^{act})^T c^{val} \in \mathbb{R} \tag{22} \\
\end{align}</script>除了真实的动作，我们还引入了哨兵动作以忽略上一轮的系统动作。<script type="math/tex">y^{act}</script> 代表上一轮动作表达了某个槽值的程度。最后的 y 使用二者的加权和，使用 sigmoid 函数归一化，w 是可学习参数。<script type="math/tex; mode=display">y = \sigma(y^{utt} + w y^{act}) \in \mathbb{R} \tag{23}</script></li>
</ul>
</li>
<li>总结：<strong>虽然文中没有明确指出，但是 global Bi-LSTM 应该是所有的槽位共享一个模型，而 local Bi-LSTM 应该指的是对于每一个槽位都训练一个模型。最后从文中的实验结果发现，似乎 global 组件对于 request 的实验结果毫无影响？？？</strong></li>
</ul>
<h1 id="Scalable-multi-domain-dialogue-state-tracking"><a href="#Scalable-multi-domain-dialogue-state-tracking" class="headerlink" title="Scalable multi-domain dialogue state tracking"></a>Scalable multi-domain dialogue state tracking</h1><p>&emsp;&emsp;<strong>作者：Rastogi A et al., 2017。</strong></p>
<ul>
<li>引言<ul>
<li><strong>相关工作</strong>：在有些方法中，本体为一个任务定义了一组槽位，这些槽位又关联了一组槽值。还有些方法使用本体中的条目去探测用户语句中潜在的槽值对（如 Henderson et al., 2014d）。</li>
<li><strong>缺陷与本文方法</strong>：<em>事实上，定义本体是困难且不切实际的，一个槽位所拥有的槽值是无穷无尽的，这使得灵活性成为了一个重大的问题。此外使用深度学习来表示槽位/槽值无法处理在训练期间从未见过的实体，使得很难与动态变化的数据库进行交互。</em>所以我们的论文提出：<ol>
<li>用一个巨大的或者无限的潜在值（possible values）集合表示槽位</li>
<li>为了给用户语句中的槽位打标签，我们使用了 <strong>multi-domain LU</strong> 模型</li>
<li>SLU 的输出被用于 delexicalize 用户语句，由 DST 处理并进行特征提取</li>
<li>然后通过集成一个独立的 candidate 生成步骤，使用 local conversation context 也有可能是外部的知识源（而不是本体）来估计一组<strong>候选槽值对</strong>（slot-value candidates）。DST 仅操作这些候选者，从而产生一种能够扩展到大且丰富的数据集的方法<ul>
<li>此方法可以被扩展到其他大型数据集是因为：候选槽值对的产生依赖于上下文或者外部知识源，而不是预定义的本体。</li>
</ul>
</li>
<li>此外这个新颖的 DST 框架提取的一系列特征，其独立于槽值对集合<ul>
<li>为了捕获语句中的长期依赖，使用 Bi-GRU 来表示输入语句，扩展了前人工作的 DNN，CNN</li>
</ul>
</li>
<li>共享一个领域但不同槽位之间的参数，并将参数迁移到从未见过的数据集或领域中。这样就不需要为每个领域中的每个 slot 类型训练模型，并有助于快速向领域中添加新 slot。</li>
</ol>
</li>
</ul>
</li>
<li>dialogue sate<ul>
<li><strong>Candidate Set</strong>：令 <script type="math/tex">C^t_s</script> 代表领域 D 中，第 t 轮对话，槽位 s 的候选集。对话初始，对于每个槽位，<script type="math/tex">C^0_s</script> 都是空的。令 <script type="math/tex">|C^t_s| \le K</script> 以限制候选集的上限（博主吐槽：这跟前人的工作有锤子区别，不还是假定槽值已知）。<script type="math/tex">C^t_s</script> 由用户语句，前一轮的系统语句以及先前的候选集初始化，初始化的内容来自 LU 模块，一般 K 取 7。如果初始化完毕后，候选集溢出，则根据分数排序，并从后往前开始删除候选值；<br>有两点需要说明：<strong>1）</strong>初始化步骤很容易拓展到诸如 ASR 或者来自后端（API）的响应；<strong>2）</strong>候选集的最大容量必须最够大以确保可能的值不会被冲洗掉。</li>
<li><strong>State Representation</strong>：在第 t 轮上使用 <script type="math/tex">{V'}^t_s = C^t_s \cup \{\delta_s, \phi_s\}</script> 限制分布的大小，以此代替 <script type="math/tex">V_s</script> 上的分布。<script type="math/tex">V_s</script> 代表槽位 s 所有可能的值，<script type="math/tex">C^t_s</script> 表示第 t 轮，槽位 s 生成的候选值，<script type="math/tex">\delta_s, \phi_s</script> 分别表示 don’t care（即对于槽位 s，用户不关心值是什么）和 null value（即用户所表达的语句中不包含任何槽位 s）。这样表示会更好，因为对话中未被提到的槽值，它们的概率只会接近 0。<br>为了保持分布的大小，在 <script type="math/tex">{V'}^t_s</script> 加入了 <script type="math/tex">K - |C^t_s|</script> 个 <code>PAD</code> 符号，使其为一个定值 <code>K + 2</code>。此外，对于大多数槽位， <script type="math/tex">|{V'}_s| = K + 2 \ll |V_s|</script>。</li>
</ul>
</li>
<li>dialogue state tracking<ul>
<li><strong>Model Description</strong>：是一个辨别式模型，用每个槽位的候选值集合作为输入，并更新候选值的分数。它也可识别 <script type="math/tex">\delta_s</script> 或 <script type="math/tex">\phi_s</script>。<br>在用户轮数 t，DST 使用前一轮的候选集合 <script type="math/tex">C^{t-1}_s</script> 及其分数，最近的用户/系统语句和它们的对话状态，去提取语句相关（<script type="math/tex">r^t_{utt}</script>），槽相关（<script type="math/tex">r^t_{slot}(s)</script>），候选值相关（<script type="math/tex">r^t_{cand}(c^t_{s,i})</script>）的特征。候选集 <script type="math/tex">\alpha \in {V'}^t_s = C^t_s \cap \{\delta_s, \phi_s\}</script> 的分数 <script type="math/tex">p^t_{\alpha}</script> <strong>更新公式</strong>如下所示，其中 <script type="math/tex">\oplus</script> 代表向量拼接，图 2 描述了模型的架构：<script type="math/tex; mode=display">
\begin{align}
  g^t_s & = r^t_{utt} \oplus r^t_{slot}(s) \\
  f^t_{c_{s,i}} & = g^t_s \oplus r^t_{cand}(c^t_{s,i}) \\
  l^t_{\phi_s} & = l_{\phi_s} \\
  l^t_{c_{s,i}} & = W^s_2 \cdot \sigma(W^s_1 \cdot f^t_{c_{s,i}} + b^s_1) + b^s_2 \tag{1} \\
  l^t_{\delta_s} & = W^s_4 \cdot \sigma(W^s_3 \cdot g^t_s + b^s_3) + b^s_4 \tag{2} \\
  p^t_{\alpha} & = \frac{\exp(l^t_{\alpha})}{\exp(l^t_{\phi_s}) + \exp(l^t_{\delta_s}) + \Sigma_i \exp(l^t_{c_{s,i}})} \tag{3} \\
\end{align}</script>其中 <script type="math/tex">l_{\phi_s}, W^s_k, b^s_k</script> 都是可训练的模型参数，接下来描述特征 <script type="math/tex">r^t_{utt}, r^t_{slot}(s), r^t_{cand}(c^t_{s,i})</script> 是如何背计算出来的。</li>
<li><strong>Feature Extraction</strong>：使用一个特殊的符号替换所有的槽值，这些槽值由 SLU 模块识别出来，<strong>所以并不需要知道槽位关联的所有槽值或是人工构建的词表</strong>。需要注意的是只替换槽值，并不替换槽位。最后使用一个两层 Bi-GRU 处理被 delexicalisation 的语句。<br>除了为槽位的所有槽值打上标签之外，SLU 还预测用户语句对应的动作，如 <code>affirm, negate(time)</code> 等。<br>此外对于系统的语句也是类似操作。<ul>
<li>语句特征：<script type="math/tex">r^t_{utt} = c^t \oplus a^t_u \oplus {c'}^t \oplus {a'}^t_u</script>，其中 <script type="math/tex">c^t</script> 代表语句的表征，来自 Bi-GRU 的隐藏状态；<script type="math/tex">a^t_u</script> 代表动作表征，由 SLU 模块产生；<script type="math/tex">{c'}^t</script> 和 <script type="math/tex">{a'}^t_u</script> 表示用户语句之前的系统语句所对应的特征。</li>
<li>槽特征：<script type="math/tex">r^t_{slot}(s) = a^t_u(s) \oplus {a'}^t_s(s) \oplus p^{t-1}_{\delta_s} \oplus p^{t-1}_{\phi_s}</script>，其中 <script type="math/tex">p^{t-1}_{\delta_s}</script> 和 <script type="math/tex">p^{t-1}_{\phi_s}</script> 代表特殊值 <code>dontcare</code> 和 <code>null</code> 在前一轮 DST 输出中的分数；<script type="math/tex">a^t_s(s)</script> 是带参对话动作的二维向量，如 <code>request(s), deny(s)</code>；<script type="math/tex">{a'}^t_s</script> 是系统动作对应的二维向量。</li>
<li>候选值特征：</li>
</ul>
</li>
</ul>
</li>
<li>参数共享以及迁移学习：上式中，候选值评分函数的参数 <script type="math/tex">l_{\phi_s}, W^t_k, W^s_k, 1 \le k \le 4</script>，每个槽位都会定义一组，但是 GUR 的参数是为一个领域定义的。这些参数的维度不依赖槽位和领域，这得以参数共享或者在跨领域迁移。</li>
</ul>
<h1 id="Neural-Belief-Tracker-Data-Driven-Dialogue-State-Tracking"><a href="#Neural-Belief-Tracker-Data-Driven-Dialogue-State-Tracking" class="headerlink" title="Neural Belief Tracker: Data-Driven Dialogue State Tracking"></a>Neural Belief Tracker: Data-Driven Dialogue State Tracking</h1><blockquote class="blockquote-center"><p><a href="https://yan624.github.io/·论文笔记/dilogue/task-oriented/57. Neural Belief Tracker：Data-Driven Dialogue State Tracking.html">论文笔记</a></p>
</blockquote>
<p>&emsp;&emsp;<strong>作者：Mrkšić N et al., 2016。</strong></p>
<h1 id="Incremental-LSTM-based-dialog-state-tracker"><a href="#Incremental-LSTM-based-dialog-state-tracker" class="headerlink" title="Incremental LSTM-based dialog state tracker"></a>Incremental LSTM-based dialog state tracker</h1><p>&emsp;&emsp;<strong>作者：Zilka and Jurcicek, 2015。</strong></p>
<ul>
<li>此论文是作者同年发表的论文的扩展，他们将论文中的状态跟踪器称为 LecTrack。<strong>它能一个接一个地处理单词，这其实是 RNN 的特性，也是论文名中“Incremental”的起因。</strong></li>
<li>本文定义：在第 t 轮，对话状态 <script type="math/tex">s_t \in C_1 \times \cdots \times C_k</script> 为一个向量，包含 k 个元素，有时候在文献中它们被称为槽位（slot）。每个 <script type="math/tex">c_i \in C_i = \{v_1, \cdots, v_{n_i}\}</script> 包含 <script type="math/tex">n_i</script> 个槽值，并且我们假设各成分（slot）之间是独立的，则：<script type="math/tex; mode=display">P(s_t | w_1, \cdots, w_t) = \prod_i p(c_i | w_1, \cdots, w_t; \theta)</script></li>
<li>LSTM dialogue state tracker<ul>
<li><strong>model</strong>：使用 LSTM 提取语句信息，但是做了小小的改动，将输入门的 sigmoid 函数换做了 tanh。公式如下所示：<script type="math/tex; mode=display">
\begin{align}
  u & = NN(a, r) \\
  q_t & = Enc(u, q_{t-1}) \\
  p_t & = C(h_t) \\
\end{align}</script>其中单词 a 与其 ASR 置信度分数 r 的联合表征为 u，LSTM decoder 使用 u 以及前一时间步的隐藏状态 <script type="math/tex">q_{t-1} = (c_{t-1}, h_{t-1})</script> 计算出当前隐藏状态 <script type="math/tex">q_t</script>，C 代表 softmax 层，将隐藏状态映射为各个可能值的分布。<br>注意，虽然论文中没有明确写出，但是对于最后一个公式 <script type="math/tex">p_t = C(h_t)</script>，它可能需要<strong>为每一个槽位都设计一个函数</strong>。这个公式应该是这样的：<script type="math/tex">p^j_t = C(h_t), \forall j \in 1, \cdots, k</script>，j 代表槽位索引，t 代表单词在句子中的索引。</li>
<li><strong>Improvements</strong>：1）包括了 ASR 置信度分数；2）将训练集中的 Transcriptions 加入训练；3）多个模型取均值；4）低频词抽象化</li>
</ul>
</li>
<li>模型流程（个人向）：输入每个单词，输出对应的隐藏状态。隐藏状态经过一个函数输出槽值的分布，这个函数是特定于槽位的。也就是说每个槽位都有一个独一无二的函数，在生成槽值时，只需要遍历所有槽位的函数，然后将隐藏状态传入每一个函数，就可以得到每个槽位对应的槽值分布。</li>
</ul>
<h1 id="Word-Based-Dialog-State-Tracking-with-Recurrent-Neural-Networks"><a href="#Word-Based-Dialog-State-Tracking-with-Recurrent-Neural-Networks" class="headerlink" title="Word-Based Dialog State Tracking with Recurrent Neural Networks"></a>Word-Based Dialog State Tracking with Recurrent Neural Networks</h1><div class="note warning">
            <p>&emsp;&emsp;之前的论文大都是使用 SLU 的结果作为输入，这篇论文则直接使用 ASR 的结果作为输入。由于我看的论文不是很多，对于这篇论文，我不敢说是首创，但是应该有渐隐之色。这样的做法是，消除了 ASR 到 SLU 的误差 [<a href="https://www.cnblogs.com/jiangxinyang/p/10794364.html" target="_blank" rel="noopener">4</a>]。</p>
          </div>
<p>&emsp;&emsp;<strong>作者：Henderson et al., 2014d</strong>。<br>&emsp;&emsp;近来 DST 领域的辨别式方法已经展示出了超于传统的生成式方法的性能。本文提出 word-based DST，直接从 ASR 结果映射到对话状态。使用 RNN 结构，有能力泛化到未见的对话状态假设，只需要一点特征工程。<br>&emsp;&emsp;通常，DST 假定 SLU 将 ASR 的假设映射为一系列的语义假设，本论文直接将 ASR 的假设映射为对话中某轮的对话状态，省略了中间 SLU 的处理步骤。这避免了显式语义表征的需要以及在 SLU 阶段可能的信息误差。<br>&emsp;&emsp;与用户交流时，统计对话系统必须维护一个潜在的对话状态的分布，这个步骤被称为 DST。这个分布有时候也被称作 belief state （<strong>划重点要考</strong>），直接决定了系统的决策。<br>&emsp;&emsp;<em>介绍了一堆 14 年前的做法以及区别。</em><br>&emsp;&emsp;<strong>Feature Representation</strong>(1-2)/<strong>Generalisation to Unseen States</strong>(3)：</p>
<ol>
<li>如图 1 所示，从 ASR 的 N-best 列表中提取出 n-gram 特征，即为每个假设计算 uni-/bi-/tri-gram。然后用 N-best 列表的概率计算加权和求得到单个向量。如果出现了相同的项，把对应的概率相加即可。</li>
<li><strong>此领域的 dialogue acts 由形如 acttype(slot=value) 的一系列 act 成分组成，其中 slot=value 是可选的</strong>。n-gram 正是提取自这些成分，如：<code>&#39;acttype&#39;, &#39;slot&#39;, &#39;value&#39;, &#39;acttype slot&#39;, &#39;slot value&#39;</code> 和 <code>&#39;acttype slot value&#39;</code> 或者对于 <code>acttype()</code> 只有 <code>&#39;acttype&#39;</code>。处理方法与 1 类似，只是它们的权重都置为 1</li>
<li>处理未在训练集出现的状态（如一种食物类型）的方法是：使用 ‘tagged’ 方法，即忽略特定的槽值，将其替换为类似 <code>&lt;value&gt;</code> 的标签。如图 1 所示，<script type="math/tex">f_s, f_v</script> 来自未标过的 <script type="math/tex">f</script>。</li>
</ol>
<p>&emsp;&emsp;<strong>Model Definition</strong>：</p>
<ol>
<li>RNN 拥有一个内部的记忆 <script type="math/tex">m \in \mathbb{R}^{N_{mem}}</script>。如果对于槽位 s 有 N 个槽值，那么概率分布输出 <script type="math/tex">p \in \mathbb{R}^{N+1}</script>，其中最后一个成分 <script type="math/tex">P|_N</script> 代表 None。图 2 解释了 p 和 m 在某一轮中是如何被更新为 p’ 和 m’ 的。</li>
<li>神经网络的一部分结构用于学习将 untagged input, memory, previous state 映射为向量 <script type="math/tex">h \in \mathbb{R}^N</script>，它将直接参与 <script type="math/tex">p'</script> 的计算。公式为：<script type="math/tex">h=NNet(f \oplus p \oplus m) \in \mathbb{R}^N</script>。（<strong>博主注</strong>：h 学习将 lexical n-grams 映射为特定的槽值对，<strong>此步可能对 domain-independent 具有一定的影响</strong>，故<a href="https://arxiv.xilesou.top/pdf/1506.07190.pdf" target="_blank" rel="noopener">此论文</a>移除了这部分的网络）</li>
<li>本文 <script type="math/tex">NNet(\cdot)</script> 均代表激活函数为 sigmoid 的隐藏层</li>
<li>其次，由于 h 的计算需要使用训练集中每一个槽值的样本，所以泛化性并不好。<strong>通过 g</strong>，采用 tagged feature 作为输入，<strong>可能可以提高泛化性</strong>。对于一个槽位的槽值 v，计算公式为：<script type="math/tex">g|_v = NNet(f \oplus f_s \oplus f_v \oplus \{p|_v, P|_N\} \oplus m) \in \mathbb{R}</script>。此结构的网络能够处理未见或者不频繁的 dailogue state</li>
<li><strong>博主注</strong>：不同的槽位拥有不同模型，即其中的每个 p 都不同</li>
<li>new belief <script type="math/tex">p'</script> 的更新公式为：<script type="math/tex">p' = softmax([h+g] \oplus \{B\}) \in \mathbb{R}^{N+1}</script>，其中 B 是 RNN 的一个参数，有助于 None 的假设的估计</li>
<li>最后 memory 的更新公式为：<script type="math/tex">m' = \sigma(W_{m0}f + W_{m1}m) \in \mathbb{R}^{N_{mem}}</script>，其中 <script type="math/tex">W_{mi}</script> 是 RNN 的参数</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/4me/" rel="tag"># 4me</a>
              <a href="/tags/DST/" rel="tag"># DST</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/assorted/win10下安装NVIDIA CUDA.html" rel="prev" title="win10下安装NVIDIA CUDA">
      <i class="fa fa-chevron-left"></i> win10下安装NVIDIA CUDA
    </a></div>
      <div class="post-nav-item">
    <a href="/·论文笔记/dilogue/task-oriented/SLU论文笔记（？-2019）.html" rel="next" title="SLU论文笔记（？-2019）">
      SLU论文笔记（？-2019） <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Multi-domain-Dialogue-State-Tracking-as-Dynamic-Knowledge-Graph-Enhanced-Question-Answering"><span class="nav-number">1.</span> <span class="nav-text">Multi-domain Dialogue State Tracking as Dynamic Knowledge Graph Enhanced Question Answering</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Find-or-Classify-Dual-Strategy-for-Slot-Value-Predictions-on-Multi-Domain-Dialog-State-Tracking"><span class="nav-number">2.</span> <span class="nav-text">Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transferable-Multi-Domain-State-Generator-for-Task-Oriented-Dialogue-Systems"><span class="nav-number">3.</span> <span class="nav-text">Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Global-Locally-Self-Attentive-Dialogue-State-Tracker"><span class="nav-number">4.</span> <span class="nav-text">Global-Locally Self-Attentive Dialogue State Tracker</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scalable-multi-domain-dialogue-state-tracking"><span class="nav-number">5.</span> <span class="nav-text">Scalable multi-domain dialogue state tracking</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Belief-Tracker-Data-Driven-Dialogue-State-Tracking"><span class="nav-number">6.</span> <span class="nav-text">Neural Belief Tracker: Data-Driven Dialogue State Tracking</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Incremental-LSTM-based-dialog-state-tracker"><span class="nav-number">7.</span> <span class="nav-text">Incremental LSTM-based dialog state tracker</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Word-Based-Dialog-State-Tracking-with-Recurrent-Neural-Networks"><span class="nav-number">8.</span> <span class="nav-text">Word-Based Dialog State Tracking with Recurrent Neural Networks</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="朱冲䶮"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">朱冲䶮</p>
  <div class="site-description" itemprop="description">记录学习问题，积累做的 leetcode 题目</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">155</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">91</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
      <!-- 不蒜子/busuanzi -->
      <div class="site-state-item site-state-posts">
      	<span class="site-state-item-count">183.2k</span>
      	<span class="site-state-item-name">总字数</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/zhu-yu-er-85" title="zhihu → https://www.zhihu.com/people/zhu-yu-er-85" rel="noopener" target="_blank"><i class="fab fa-zhihu"></i>zhihu</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:897538633@qq.com" title="E-Mail → mailto:897538633@qq.com" rel="noopener" target="_blank"><i class="fas fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/yan624" title="GitHub → https://github.com/yan624" rel="noopener" target="_blank"><i class="fab fa-fw fa-github"></i>GitHub</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://huaguoguo.gitee.io" title="http://huaguoguo.gitee.io" rel="noopener" target="_blank">葬爱丶华少的天下</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://lzh0928.gitee.io/" title="https://lzh0928.gitee.io/" rel="noopener" target="_blank">Mr.Liu</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">朱冲䶮</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.7.1
  </div><script src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script>
<script src="/lib/my-utils.js"></script>
<!--图片缩放插件-->
<script src="/lib/zoomify/zoomify.min.js"></script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- 背景插件 -->
<script src="https://cdn.bootcss.com/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
<!-- 背景图片 -->
<script>
	function generateBG(count){
		var bg_prefix = '/images/background/';
		var bg =new Array();
		for(var i = 0; i < count; i++){
			bg[i] = bg_prefix + i + '.jpg';
		}
		bg.shuffle();
		return bg;
	}
	$("body").backstretch(generateBG(11), {
		duration:90000,//1min半一换
		fade: 1500
	});
</script>
<!-- 图片缩放 -->
<script>
$('.content img').zoomify({duration: 500, });
$('.content img').on('zoom-in.zoomify', function () {
	$('.sidebar').css('display', 'none');
});
$('.content img').on('zoom-out-complete.zoomify', function () {
	$('.sidebar').css('display', '');
});
</script>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>












  

  

  
  <script src="//cdn.jsdelivr.net/npm/quicklink@1/dist/quicklink.umd.js"></script>
  <script>
      window.addEventListener('load', () => {
      quicklink({
        timeout: 3000,
        priority: true,
        ignores: [uri => uri.includes('#'),uri => uri == 'http://yan624.github.io/·论文笔记/dilogue/task-oriented/DST论文笔记（？-2019）.html',]
      });
      });
  </script>
<!-- calendar widget -->


</body>
</html>
