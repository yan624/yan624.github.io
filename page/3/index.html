<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">




  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2">























  

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/5.8.1/css/all.min.css">

<link rel="stylesheet" href="/css/main.css?v=6.7.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.7.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.7.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.7.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '6.7.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":true},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  


<!--图片缩放插件样式-->
<link rel="stylesheet" href="/lib/zoomify/zoomify.min.css">

  <meta name="description" content="记录学习问题，积累做的 leetcode 题目">
<meta name="keywords" content="博客，java，javaWeb，NLP，python，机器学习，深度学习">
<meta property="og:type" content="website">
<meta property="og:title" content="博客">
<meta property="og:url" content="http://yan624.github.io/page/3/index.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="记录学习问题，积累做的 leetcode 题目">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="博客">
<meta name="twitter:description" content="记录学习问题，积累做的 leetcode 题目">






  <link rel="canonical" href="http://yan624.github.io/page/3/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN">
	<!--加载flower canvas-->
<script>
var pathname = window.location.pathname;
if(pathname == '/flower.html'){
	var body =  document.getElementsByTagName('body')[0];
	var canvas = document.createElement("canvas")
	canvas.setAttribute('id', 'sakura')
	// '<canvas id="sakura"></canvas>'
	body.appendChild(canvas)
}
</script>
  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">低阶炼金术士</p>
      
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
    
      
    

    
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-常用链接">

    
    
    
      
    

    
      
    

    <a href="/常用链接" rel="section"><i class="menu-item-icon fas fa-fw fa-bookmark"></i> <br>常用链接</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签<span class="badge">17</span></a>

  </li>
        
        
        
          
            
            
            
              
              

  
  
    
  
  <li class="menu-item menu-item-categories">

    
    
    
      
    

    
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类<span class="badge">22</span></a>

  </li>


            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
            
            
            
          
        
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档<span class="badge">110</span></a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/论文/20、Open Question Answering with Weakly supervised Embedding Models.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/论文/20、Open Question Answering with Weakly supervised Embedding Models.html" class="post-title-link" itemprop="url">论文笔记：Open Question Answering with Weakly supervised Embedding Models</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-05 10:54:15" itemprop="dateCreated datePublished" datetime="2019-07-05T10:54:15+08:00">2019-07-05</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-16 12:32:12" itemprop="dateModified" datetime="2019-07-16T12:32:12+08:00">2019-07-16</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/" itemprop="url" rel="index"><span itemprop="name">assorted</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="论文概要"><a href="#论文概要" class="headerlink" title="论文概要"></a>论文概要</h1><p>&emsp;&emsp;<a href="https://arxiv.org/pdf/1404.4326" target="_blank" rel="noopener">论文地址</a>，论文发表于 2014 年。<br>&emsp;&emsp;建立一个能够回答任何问题的计算机是人工智能的一个长期目标。这一领域一个重要的发展时大规模知识库的建立，如 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.538.7139&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Freebase</a> 和 <a href="https://content.iospress.com/download/semantic-web/sw134?id=semantic-web%2Fsw134" target="_blank" rel="noopener">DBPedia</a>，它们存储了大量的通用信息。它们由三元组的形式构成一个数据库，通过各种关系和格式连接成实体对。那么回答问题被定义为<strong>给定一个用自然语言表达的查询语句</strong>（一个查询语句的例子：中国的首都在哪？）<strong>从知识库中检索正确的实体或实体集的任务</strong>。<br>&emsp;&emsp;最近，通过将问题映射为<strong>逻辑形式</strong>或者类似<strong>数据库查询</strong>的方法取得了可喜的进展。虽然这种方法可能有效，但是缺点是要采用大量的人为标记的数据或者需要工作人员定义词汇表和语法。<br>&emsp;&emsp;本文采用一种激进的学习方式，将问题映射为向量（无法人为解释）的特征表示。并且将重点放在回答一些基于比较宽泛的主题的简单事实性问题。这项任务的难点来自词汇的多样性，而不是句法的复杂性。<br>&emsp;&emsp;该方法采用随机梯度下降，然后使用 fine-tuning 进行训练。经验表明该模型能够捕获一些有意义的信号，且这是唯一一种能够在弱标记数据上训练的方法。</p>
<h1 id="文章内容介绍"><a href="#文章内容介绍" class="headerlink" title="文章内容介绍"></a>文章内容介绍</h1><ol>
<li>Section 2：讨论了之前的工作；</li>
<li>Section 3：介绍了开放域问答的问题；</li>
<li>Section 4：给出了模型；</li>
<li>Section 5：实验结果。</li>
</ol>
<h1 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h1><ol>
<li>大规模的问答历史悠久，主要由 TREC tracks（<a href="https://arxiv.org/pdf/cs/0110053.pdf" target="_blank" rel="noopener">Voorhees 2000</a>） 发起，这是第一个成功地<strong>将问题转换为查询</strong>的问答系统。将问题转换为查询之后，又<strong>将查询提供给 web 搜索引擎</strong>，然后<strong>从返回的页面或片段中取出答案</strong>（<a href="http://aiweb.cs.washington.edu/research/projects/ai3/mulder/mulder-www10.pdf" target="_blank" rel="noopener">Kwok 2001</a>, <a href="https://www.aaai.org/Papers/Symposia/Spring/2002/SS-02-06/SS02-06-002.pdf" target="_blank" rel="noopener">Banko 2002</a>）。这种方法需要大量的人工操作来处理查询，然后解析和搜索结果。</li>
<li>大型 KBs 的出现，改变了上述状况，但是也带来巨大的挑战。语言的多样性以及 KBs 规模的庞大，使得需要通过监督学习来处理大量的<strong>带标签</strong>的数据。最早的方法是基于手写模板的 KBs 开放问答，然而对于日新月异 KBs（增加/删除三元组和实体） 还不够健壮。</li>
<li>后来尝试使用较少的监督情况下学习 KBs 和自然语言之间的联系，但是这项工作实际上在解决<strong>信息提取</strong>的问题（16，11,14,19）。</li>
<li>近年来，有一种基于语义解析器（6,3,12）的新的问答系统被提出，它只具有少量标记数据。但仍需要耗费大量精力去仔细设计词汇，语法和知识库。</li>
<li>所以本文（2014 年）提出了基于嵌入式的问答模型。据我们所知，这是以前从未尝试过的。</li>
</ol>
<h1 id="开放域问答"><a href="#开放域问答" class="headerlink" title="开放域问答"></a>开放域问答</h1><p>&emsp;&emsp;本文使用 <a href="https://www.aclweb.org/anthology/P13-1158" target="_blank" rel="noopener">Fader 2013</a> 的问答框架，并使用了相同的数据。</p>
<h2 id="任务定义"><a href="#任务定义" class="headerlink" title="任务定义"></a>任务定义</h2><p>&emsp;&emsp;我们将回答问题的任务看作为：给定一个问题 q，对应的答案由 KB 中的三元组 t 给出。这意味着我们的问题由<strong>一组三元组 t</strong> 提供对问题及其答案的解释，例如：</p>
<blockquote>
<p>q: What environment does a dodo live in?（渡渡鸟生活在什么样的环境中？）<br>t: (dodo.e, live-in.r, makassar.e)<br>q: What are the symbols for Hannukah?（光明节的象征是什么？）<br>t: (menorah.e, be-for.r, hannukah.e)<br>q: What is a laser used for?（极光可以用来做什么？）<br>t: (hologram.e,be-produce-with.r,laser.e)</p>
</blockquote>
<p>&emsp;&emsp;这里每个问题我们只给出一个 t，但是实际上它可以有很多，所以上文说是一组三元组。本文其余部分，<strong>使用 <script type="math/tex">\kappa</script>（读作 kappa） 代表 KB ，使用 <script type="math/tex">\epsilon</script> 代表 KB 中的实体或者关系。问题的词表用 V 表示，<script type="math/tex">n_V</script> <script type="math/tex">n_{\epsilon}</script>分别表示 V 和 <script type="math/tex">\epsilon</script> 的大小</strong>。<br>&emsp;&emsp;我们的模型在于<strong>函数 S(·)</strong>，它可以为 question-answer triple pairs (q,t) 打分。因此，找到问题 q 的 top-ranked 的答案 <script type="math/tex">\hat{t}</script>(q) 直接由以下公式得出：</p>
<script type="math/tex; mode=display">
\hat{t}(q) = arg \max_{t' \in \kappa}S(q, t')</script><p>&emsp;&emsp;为了处理多个答案，我们将结果呈现为排完序的列表并对其评分，而不是直接采用最前面的预测结果。<br>&emsp;&emsp;使用评分函数可以直接查询 KB，而不需要在<strong>语义分析系统</strong>中一样为问题定义一个中间的结构化逻辑表示。我们的目标是学习 S(·)，余下将讲述用于训练的数据的创建步骤。</p>
<h2 id="用于训练的数据"><a href="#用于训练的数据" class="headerlink" title="用于训练的数据"></a>用于训练的数据</h2><h1 id="Embedding-based-model"><a href="#Embedding-based-model" class="headerlink" title="Embedding-based model"></a>Embedding-based model</h1><p>&emsp;&emsp;使用了符号的嵌入表示（2019 年了，应该谁都知道了，不做解释）。</p>
<h2 id="Question-KB-Triple-Scoring"><a href="#Question-KB-Triple-Scoring" class="headerlink" title="Question-KB Triple Scoring"></a>Question-KB Triple Scoring</h2><p>&emsp;&emsp;我们的框架关注的是函数 S(q,t) 的学习，该函数的目的是对一个<strong>问题 q</strong> 和 一个<strong>来自 <script type="math/tex">\kappa</script> 的三元组 t</strong> 进行打分。该评分方法受到了先前工作 labeling images withwords 的启发（<a href="https://link.springer.com/content/pdf/10.1007/s10994-010-5198-3.pdf" target="_blank" rel="noopener">Weston 2013</a>），我们采用该方法将图片和标签替换成了问题和三元组。直观来讲就是：<br>有点难翻译，故给出原文：</p>
<blockquote>
<p>&emsp;&emsp;Intuitively, it consists of projecting questions, treated as a bag of words(and possibly n-grams as well), on the one hand, and triples on the other hand,into a shared embedding space and then computing a similarity measure (the dot  product  in  this  paper)  between  both  projections.<br>&emsp;&emsp;大致意思，将问题和三元组使用词袋模型（也可以是 n-gram 模型）投射到共享的嵌入空间，然后计算二者的相似度（本文使用点积的方式）。</p>
</blockquote>
<p>&emsp;&emsp;那么评分函数为:</p>
<script type="math/tex; mode=display">
S(q,t) = f(q)^Tg(t)</script><p>&emsp;&emsp;<strong>其中 f(·) 将问题中的单词映射到 <script type="math/tex">\mathbb{R}^{\kappa}</script>，<script type="math/tex">f(q) = V^T \Theta(q)</script>。V 是关于 <script type="math/tex">\mathbb{R}^{n_v \times \kappa}</script> 包含所有词嵌入 v 的矩阵。<script type="math/tex">\Theta(q)</script>是 q（<script type="math/tex">\in \{0,1\}^{n_v}</script>） 的二进制（稀疏）表示。同样，g(·) 将 KB 三元组中的实体和关系映射到 <script type="math/tex">\mathbb{R}^{\kappa}</script>，<script type="math/tex">g(t) = W^T\Psi(t)</script>，W 是关于 <script type="math/tex">\mathbb{R}^{n_e \times \kappa}</script> 包含所有实体和关系的嵌入 w 的矩阵，<script type="math/tex">\Psi(t)</script> 是 t（<script type="math/tex">\in \{0,1\}^{n_e}</script>） 的二进制（稀疏）表示。</strong><br><div class="note info">
            <p>&emsp;&emsp;注：上一段太长了，解释一下。f(q) 就是词向量，g(t) 就是实体和关系的向量（下一段原文写到 g(t) 是将三元组中的嵌入全部相加）。</p>
          </div></p>
<p>&emsp;&emsp;将单词表示为词袋模型似乎有一点局限性，但是由于我们特定的设置，语法都很简单，因此含有的信息十分有限，所以词袋模型应该也能带来不错的性能。当然也有反例，比如 <em>What are cats afraid of ?vs.What are afraid of cats ?</em> 这将会有不同的答案。不过这种情况十分罕见。未来考虑将 parse tree features 或者 semantic role labels 作为输入放入嵌入模型中。<br>&emsp;&emsp;与以前的工作（<a href="https://arxiv.org/pdf/1307.7973" target="_blank" rel="noopener">Weston 2013</a>）不同的是，在我们的模型中，实体出现三元组的不同侧面（左右侧）时，实体并非拥有相同的嵌入。KB 中的关系并不是对称的，所以会出现三元组中左侧和右侧的实体是不同的情况。<strong>由于 g(·) 是将三元组中的所有成分相加，所以每一个实体我们都需要两个嵌入</strong>。<br>&emsp;&emsp;这样就可以很容易地对任何三元组进行评分：</p>
<script type="math/tex; mode=display">
\hat{t}(q) = arg \max_{t' \in \kappa}S(q, t') = arg \max_{t' \in \kappa}(f(q)^Tg(t'))</script><p>&emsp;&emsp;接下来花了好几段讲怎么训练。</p>
<h2 id="Fine-tuning-the-Similarity-between-Embeddings"><a href="#Fine-tuning-the-Similarity-between-Embeddings" class="headerlink" title="Fine-tuning the Similarity between Embeddings"></a>Fine-tuning the Similarity between Embeddings</h2><p>&emsp;&emsp;由于受到数据大小的限制，需要使用微调来改进性能。</p>
<h1 id="论文总结"><a href="#论文总结" class="headerlink" title="论文总结"></a>论文总结</h1><p>&emsp;&emsp;通读论文之后还是有点搞不清论文是怎么训练的，后来看了一下 CCF ADL100 刘康老师的 PPT ，感觉有点理解了，以下是训练步骤：</p>
<ol>
<li>输入自然语言表达的问题，比如：姚明的老婆的是哪里人？</li>
<li>使用 entity linking（论文中貌似没有这步，我在看 PPT 时也是一知半解，好在前几天我刚好在一篇论文中看到了这个 entity linking！<a href="http:s//yan624.github.io/论文/19、Semantic Parsing via Staged Query Graph Generation：Question Answering with Knowledge Base.html#链接主题实体" target="_blank" rel="noopener">博客地址</a>，entity linking 源于<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）找到 main entity，main entity 周围的 entity 均是候选 entity。如下图，姚明是 main entity，姚明周围的实体都算作候选 entity，比如叶莉、火箭队、上海等。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/论文笔记：Open Question Answering with Weakly supervised Embedding Models/姚明的老婆是谁的知识图谱的子图.jpg" alt="姚明的老婆是谁的知识图谱的子图"></li>
<li>计算问题和候选 entity 的相似度，其中问题由词向量表示，候选 entity 是一个三元组的形式，难以直接用词向量表示，方法是将三元组中的三个对象分别用词向量表示，然后将三个词向量相加。这样就得到了问题的词向量和 entity 的词向量，点乘获得相似度。</li>
<li>由于候选 entity 不一定只有一个，所以可以获得多个相似度。进行排序即可获得最相似的候选 entity。</li>
</ol>
<div class="note danger">
            <p>&emsp;&emsp;以上的训练步骤并不是论文中的训练步骤，只是我为了给自己加深映像写的，具体的训练步骤在原论文第 4 节，具体在 4.1。</p>
          </div>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/论文/20、Open Question Answering with Weakly supervised Embedding Models.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/论文/19、Semantic Parsing via Staged Query Graph Generation：Question Answering with Knowledge Base.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/论文/19、Semantic Parsing via Staged Query Graph Generation：Question Answering with Knowledge Base.html" class="post-title-link" itemprop="url">论文笔记：Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-03 10:11:46" itemprop="dateCreated datePublished" datetime="2019-07-03T10:11:46+08:00">2019-07-03</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-16 12:32:38" itemprop="dateModified" datetime="2019-07-16T12:32:38+08:00">2019-07-16</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/" itemprop="url" rel="index"><span itemprop="name">assorted</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>&emsp;&emsp;此论文为 2015 年的论文。<br>&emsp;&emsp;本文会出现一个名为<strong>谓语序列（predicate sequence）</strong>的名词，论文中没有详细说明。但是估计就是：一个实体至另一个实体的有向路径上的所有谓语的连接形式。如下文第一张图 Family Guy-&gt;cvt1-&gt;Mila Kunis 的谓语序列就是 cast-actor。</p>
<h1 id="论文概要"><a href="#论文概要" class="headerlink" title="论文概要"></a>论文概要</h1><p>&emsp;&emsp;<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ACL15-STAGG.pdf" target="_blank" rel="noopener">论文地址</a><br>&emsp;&emsp;节选自摘要部分：</p>
<blockquote>
<p>&emsp;&emsp;论文提出了一个基于知识库问答的新的语义解析（semantic parsing）框架。首先定义一个类似于知识库的<strong>子图（subgraph）</strong>的查询图（query graph），可以直接映射到一个语义的逻辑形式（如<script type="math/tex">\lambda</script>-calculus）。所以<strong>语义分析简化为查询图的生成</strong>，并将其表示为一个阶段性搜索问题。然后通过使用先进的实体链接系统（<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）以及深度卷积网络来实现问题与谓语序列之间的匹配。在 WEBQUESTIONS 的数据集上，F1 指标达到了 52.5% 的水平，高于以前的方法。</p>
</blockquote>
<p>&emsp;&emsp;以下大型知识库已经成为支持开放领域问答的重要资源：</p>
<ul>
<li>DBPedia</li>
<li>Freebase</li>
</ul>
<p>&emsp;&emsp;最先进的 KB-QA 方法都是基于<strong>语义解析</strong>的，在语义解析中一个问题或者一种表达被映射到它具有一定意义的表示上（如逻辑形式，具体来说可以是 <script type="math/tex">\lambda</script>-calculus），即将自然语言映射为表达式，然后被翻译为一个 <strong>KB 查询</strong>。最后，只需要执行查询就可以检索问题的答案。<strong>但是大多数<u>传统的</u>语义解析方法在很大程度上都<u>脱离</u>知识库</strong>。由于没有前人的贡献累积，因此 QA 问题面临着一系列的挑战。例如：</p>
<ul>
<li>当在逻辑形式中使用与知识库中的谓语不同的谓语时，可能需要用到本体匹配（ontology matching）的问题（Kwiatkowski et al., 2013）。</li>
<li>即使表示语言与知识库的模式接近，从知识库中的大量词汇表中寻找正确的谓语与语句的描述相关联仍然是一个难题（Berant and Liang, 2014）。</li>
</ul>
<p>&emsp;&emsp;由（Yao and Van Durme, 2014; Bao etal., 2014）的启发，该论文提出了一个语义解析框架，定义一个查询图可以直接地映射到由 <script type="math/tex">\lambda</script>-calculus 表达的逻辑形式。从语义上来讲，与 <script type="math/tex">\lambda</script>-DCS（Liang, 2013）十分接近。将解析行为分为 3 步：</p>
<ol>
<li>定位问题中的主题实体；</li>
<li>找到回答与主题实体之间的主要关联；</li>
<li>（通过额外的约束扩大查询图，约束即回答需要附加的额外属性，如最早时间等）或者（答案与其他实体之间的关联）。</li>
</ol>
<p>&emsp;&emsp;至此将一个语义解析问题划分成了一系列的子问题。例如 entity linking 和 relation matching。</p>
<h2 id="文章内容介绍"><a href="#文章内容介绍" class="headerlink" title="文章内容介绍"></a>文章内容介绍</h2><ol>
<li>Sec. 2: 介绍了图知识库（估计就是知识图谱）的概念和查询图的设计；</li>
<li>Sec. 3: 介绍了基于搜索方法的查询图生成；</li>
<li>Sec. 4: 实验结果；</li>
<li>Sec. 5: 论文中的方法和其他相关工作的比较；</li>
<li>Sec. 6: 总结。</li>
</ol>
<h1 id="Knowledge-Base"><a href="#Knowledge-Base" class="headerlink" title="Knowledge Base"></a>Knowledge Base</h1><p>&emsp;&emsp;论文中的知识库 K 是一个包含主语、谓语、宾语的三元组（e1, p, e2）的集合，其中 e1 和 e2<script type="math/tex">\in</script>E，是一个实体。p<script type="math/tex">\in</script>P，是一个谓语。这种形式的知识库通常称为知识图谱。每一个实体是一个节点，两个相关联的实体由谓语标记的有向边连接，边的方向是从主语实体到宾语实体。如下图就是一个 Freebase 的子图：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/Freebase subgraph of Family Guy.jpg" alt="Freebase subgraph of Family Guy"></p>
<div class="note info">
            <p>&emsp;&emsp;Freebase 中有一个叫 <a href="https://developers.google.com/freebase/guide/basic_concepts#cvts" target="_blank" rel="noopener">CVT</a>（此链接需要翻墙访问） 的特殊实体类型，它不是一个真正的实体，而是用于收集事件或特殊的关联的多个字段。</p>
          </div>
<h1 id="Query-graph"><a href="#Query-graph" class="headerlink" title="Query graph"></a>Query graph</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>&emsp;&emsp;给定一个知识图谱。执行逻辑形式的查询等价于寻找一个子图，该子图的表现形式可以映射到查询动作。之后解析绑定的变量。<br><div class="note warning">
            <p>&emsp;&emsp;接下来，以实体这个属性来表示真实世界的实体和 CVT 实体以及日期或高度等属性，这些实体之间的区别对于论文中的方法来说并不重要。</p>
          </div><br>&emsp;&emsp;就像知识图谱一样，查询图中的相关节点也是通过有向边连接，并用 K 中的谓语标记。查询图由四中类型的节点组成：</p>
<ol>
<li>grounded entity：圆角矩形表示。grounded entity 是在知识库 K 中已存的实体。</li>
<li>existential variable：圆形表示。existential variable 是 un-grounded entity。</li>
<li>lambda variable：阴影圆形表示。lambda variable 是 un-grounded entity。尤其，该论文表示希望<strong>检索</strong>能够映射到 lambda variable 的所有实体<strong>作为</strong>最终答案。其也被称为<strong>answer 节点</strong>。</li>
<li>aggregation function：菱形表示。aggregation function 被用于操作特定的实体，该实体通常具有一些数值属性。</li>
</ol>
<p>&emsp;&emsp;下图展示了一个查询图：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/Query graph that represents the question “Who first voiced Meg on Family Guy？”.jpg" alt="Query graph that represents the question “Who first voiced Meg on Family Guy？”"></p>
<p>&emsp;&emsp;上图是“谁第一次为 Family Guy 中的 Meg 配音？”的问题。MegGriffin 和 FamilyGuy 由圆角矩形表示，圆圈节点 y 表示应该存在一个实体来描述扮演关系，比如角色、演员和开始饰演此角色的时间。阴影圆圈节点也被称为 <strong>answer 节点</strong>。菱形节点 argmin 限制答案必须是扮演此角色的最早的演员。同样不含聚合函数的<script type="math/tex">\lambda-calculus</script>逻辑形式查询为<script type="math/tex">\lambda x.\exists y.cast(FamilyGuy,y) \Lambda actor(y,x) \Lambda character(y,MegGriffin)</script>。在使用聚合函数之前，对 K 运行此查询图会匹配 LaceyChabert 以及 MilaKunis，请看第一张图。但是只有 LaceyChabert 是正确答案，因为是她最早开始扮演这个角色。<br><div class="note info">
            <p>查询图的设计灵感来源于（Reddyet al., 2014），但是他的查询图是从问题的 CCG 解析中映射出来的，在映射到子图前还需要进一步的转换。从语义上来说，该论文的查询图更像简单的 <script type="math/tex">\lambda-DCS</script>。</p>
          </div></p>
<h2 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h2><p>&emsp;&emsp;<strong>首先</strong>树图（tree graph）的根由一个实体节点组成，称为主题实体（topic entity）。<strong>其次</strong>，只有一个 lambda 变量 x 作为答案节点，从根到 x 有一个定向路径，其中含有 0 个或多个 existential variables。论文中将此路径称为图的核心推理链，因为它描述了答案和主题实体之间的主要关系。这个链除了根节点外只有变量节点。<strong>最后</strong>，可以将 0 个或多个实体或者聚合函数节点附加到每个变量节点，包括 answer 节点。例如，上图 Family Guy 是根，而 Family Guy-&gt;y-&gt;x 是核心推理链，分支 y-&gt;MegGriffin 阐述了角色，而 y-&gt;argmin 限制答案必须是该角色最早的参与者。<br>&emsp;&emsp;定义状态（state）集合<script type="math/tex">S = \{\phi, S_e, S_p, S_c\}</script>，其中每个状态可以是一个空的图（<script type="math/tex">\phi</script>），一个主题实体的单节点图（<script type="math/tex">S_e</script>），一个核心推理链（<script type="math/tex">S_p</script>）或者带有额外约束的更复杂的查询图（<script type="math/tex">S_c</script>）。<br>&emsp;&emsp;定义动作（action）集合<script type="math/tex">A = \{A_e, A_p, A_c, A_a\}</script>，其中<script type="math/tex">A_e</script>选取实体节点，<script type="math/tex">A_p</script>确定核心推理链，<script type="math/tex">A_c</script>和<script type="math/tex">A_a</script>分别约束和聚合节点。<br>&emsp;&emsp;给出一个示例<script type="math/tex">q_{ex}</script> = “Who first voiced Meg of Family Guy?”。</p>
<h3 id="链接主题实体"><a href="#链接主题实体" class="headerlink" title="链接主题实体"></a>链接主题实体</h3><p>&emsp;&emsp;从初始状态<script type="math/tex">S_0</script>开始，正确的操作是创建一个与给定问题中的主题实体相对应单节点图。例如，<script type="math/tex">q_{ex}</script>中可能的主题实体是 Family Guy 和 MegGriffin，如下图所示。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/Two possible topic entity linking actionsapplied to an empty graph, for question “Who firstvoiced[Meg]on[Family Guy]？”.jpg" alt="Two possible topic entity linking actionsapplied to an empty graph, for question “Who firstvoiced[Meg]on[Family Guy]？”"></p>
<p>&emsp;&emsp;使用的<strong>实体链接系统</strong>是专为短且有噪声的文本设计的，源于（<a href="https://arxiv.org/pdf/1609.08075.pdf" target="_blank" rel="noopener">Yang and Chang, 2015</a>）。具体不做赘述，详情可参考相关论文。</p>
<h3 id="确定核心推理链"><a href="#确定核心推理链" class="headerlink" title="确定核心推理链"></a>确定核心推理链</h3><p>&emsp;&emsp;给定与主题实体 e 对应的单节点图的状态 s，扩展该图的正确操作是确定核心推理链，即主题实体和答案之间的关系。下图展示了扩展<script type="math/tex">s_1</script>中的单节点图的三个可能的链。具体做法是，当中间的 existential variable 链接 CVT 时，探索长度为 2 的所有路径，如果没有链接，则探索长度为 1 的路径。<br><div class="note primary">
            <p>&emsp;&emsp;本节主要描述了如何确定核心推理链，不过上文一段先描述了如何确定候选的核心推理链。具体做法上一段也已经给出，但是由于原论文讲的也有点不清楚，此处加以说明，以下只是推测。</p><ol><li>扩展主题节点 Family Guy 的三个可能的核心推理链，应该是从知识库 K 中入手。请看第一张图，它是知识库 K 中的一张子图。从 Family Guy 中开始可以看到有三条边，两条边上是 cast，一条边上是 writer。由于两条边相同，于是就融为了一条推理链。至于最后一条推理链的谓语是 genre，可能是第一张图的子图中没有标出造成的。总而言之，那三条推理链就是从知识库 K 中获取。</li><li>existential variable 即 y，lambda variable 即 x。可以把知识库 K 中的 CVT 节点看作是 y，答案看作是 x。</li></ol>
          </div><br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/Candidate core inferential chains start from the entity FamilyGuy.jpg" alt="Candidate core inferential chains start from the entity FamilyGuy"></p>
<p>&emsp;&emsp;这样做的目的是将自然表达映射到正确的谓语序列上。对于问题“Who first voiced Meg on [Family Guy]?”，需要衡量的是在{cast-actor, writer-start, genre}中每个序列（<em>注：这个元组就是上图的三个候选核心推理链上的谓语</em>）正确捕捉 Family Guy 和 Who 之间关系的可能性。因此将这个问题简化为使用神经网络测量语义相似度。</p>
<h4 id="Deep-Convolutional-Neural-Networks"><a href="#Deep-Convolutional-Neural-Networks" class="headerlink" title="Deep Convolutional Neural Networks"></a>Deep Convolutional Neural Networks</h4><p>&emsp;&emsp;虽然是陈述一个相同的问题，但是以语义等价的方式来重新表达该问题仍旧拥有巨大的多样性。并且还存在自然语言表达与知识库中的谓语不匹配的情况。<strong>为了处理上述两个问题</strong>，论文建议使用 Siamese neural networks（<a href="http://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf" target="_blank" rel="noopener">Bromley et al., 1993</a>）来识别核心推理链（暹（xiān）罗神经网络，也可以叫连体神经网络。看见这个中文就很好理解了。Siamese neural networks 可以进行语义相似度分析，QA 的匹配等操作。详情可以先看看<a href="https://www.jianshu.com/p/92d7f6eaacf5" target="_blank" rel="noopener">这篇</a>博客）。注：由于上图可以得知一个问题可以获得几个候选得到核心推理链，这就是因为语言的多样性造成的，所以需要一个方法来识别一条最核心的推理链。<br>&emsp;&emsp;例如，将一个问题映射到一种<strong>模式</strong>上，方法是将实体替换为通用符号 &lt;e&gt;，然后将其与<strong>候选链</strong>比较。比如问题“who first voiced meg on &lt;e&gt;”和 cast-actor。该模型由两个神经网络组成，一个处理<strong>模式</strong>，一个处理<strong>核心推理链</strong>（这个模型说白了就是 Siamese neural networks）。两个神经网络都映射到 k 维向量作为网络的输出，最后使用距离函数（如余弦相似度）计算语义相似度。<br><div class="note info">
            <p>&emsp;&emsp;该论文处理<strong>匹配问题</strong>使用了 CNN 模型。你可能会有点疑惑<strong>匹配问题</strong>是什么问题，前面压根就没提到过。是的，论文里也没说过，我只能猜测，这里的 CNN 其实就是上述模型的两个神经网络的具体实现。处理模型和处理核心推理链可能都用了 CNN 模型。另外论文中也没有说如何将核心推理链送入 CNN 中。论文中倒是稍微提了一下如何将问题送入 CNN 中，使用 word hashing 技术（<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf" target="_blank" rel="noopener">Huang et al., 2013</a>）。</p>
          </div><br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/CNN架构.jpg" alt="CNN架构"></p>
<h3 id="增加约束和聚合函数"><a href="#增加约束和聚合函数" class="headerlink" title="增加约束和聚合函数"></a>增加约束和聚合函数</h3><h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><p>&emsp;&emsp;<strong>Topic Entity</strong>：由实体链接系统返回的分数直接作为特征。<br>&emsp;&emsp;<strong>Core Inferential Chain</strong>：使用不同的 CNN 模型的相似度分数来衡量核心推理链的质量，以下为 3 个模型。</p>
<ul>
<li><strong>PatChain</strong>：比较模式和谓语序列。</li>
<li><strong>QuesEP</strong>：将主题实体的名称与谓语序列拼接完成之后，将其与原问题比较。</li>
<li><strong>ClueWeb</strong>：使用 ClueWeb 语料库的 Freebase 注释训练 ClueWeb 模型</li>
</ul>
<p>&emsp;&emsp;<strong>Constraints &amp; Aggregations</strong>：当查询图中有约束节点，使用一些简单的特征来检查问题中是否存在单词可以与约束实体或者属性相关联。相似地，也可以使用一些预定义的关键字，比如“first”、“current”或者“latest”作为 argmin 节点的特征。<br>&emsp;&emsp;<strong>Overall</strong>：回答节点的个数和总节点个数也都作为特征。<br>&emsp;&emsp;比如下图，（1）属于 Topic Entity，（2）（3）（4）属于 Core Inferential Chain，（5）（6）（7）属于 Constraints &amp; Aggregations，（8）（9）属于 Overall：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/Semantic Parsing via Staged Query Graph Generation Question Answering with Knowledge Base/特征举例.jpg" alt="特征举例"></p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>&emsp;&emsp;使用 WEBQUESTIONS 数据集，评价指标有：precision，recall 和 F1。其中 F1 的平均值作为主要的评价指标。</p>
<h1 id="其他参考资料"><a href="#其他参考资料" class="headerlink" title="其他参考资料"></a>其他参考资料</h1><p>&emsp;&emsp;在浏览此篇论文时，发现还有其他人也看过这篇论文并且留下了笔记（中文）。<br>&emsp;&emsp;<a href="https://bigquant.com/community/t/topic/121147" target="_blank" rel="noopener">笔记1</a><br>&emsp;&emsp;<a href="https://blog.csdn.net/qq_32782771/article/details/82773048" target="_blank" rel="noopener">笔记2</a><br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/论文/19、Semantic Parsing via Staged Query Graph Generation：Question Answering with Knowledge Base.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/在hexo中添加绘制流程图及其他图的功能.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/在hexo中添加绘制流程图及其他图的功能.html" class="post-title-link" itemprop="url">在hexo中添加绘制流程图及其他图的功能</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-01 15:28:27 / 修改时间：15:45:51" itemprop="dateCreated datePublished" datetime="2019-07-01T15:28:27+08:00">2019-07-01</time>
            

            
              

              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/" itemprop="url" rel="index"><span itemprop="name">assorted</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/hexo/" itemprop="url" rel="index"><span itemprop="name">hexo</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>hexo 本身不支持绘制流程图，但是可以使用以下命令安装插件来实现此功能。<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --<span class="built_in">save</span> hexo-<span class="built_in">filter</span>-flowchart</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/bubkoo/hexo-filter-flowchart" target="_blank" rel="noopener">插件地址</a><br>语法可以<a href="https://cloud.tencent.com/developer/article/1142260" target="_blank" rel="noopener">在这</a>找<br>一个简单的例子<br>(`乘3)flow<br>st=&gt;start: Start|past:&gt;<a href="http://www.google.com[blank" target="_blank" rel="noopener">http://www.google.com[blank</a>]<br>e=&gt;end: End:&gt;<a href="http://www.google.com" target="_blank" rel="noopener">http://www.google.com</a><br>op1=&gt;operation: My Operation|past<br>op2=&gt;operation: Stuff|current<br>sub1=&gt;subroutine: My Subroutine|invalid<br>cond=&gt;condition: Yes<br>or No?|approved:&gt;<a href="http://www.google.com" target="_blank" rel="noopener">http://www.google.com</a><br>c2=&gt;condition: Good idea|rejected<br>io=&gt;inputoutput: catch something…|request</p>
<p>st-&gt;op1(right)-&gt;cond<br>cond(yes, right)-&gt;c2<br>cond(no)-&gt;sub1(left)-&gt;op1<br>c2(yes)-&gt;io-&gt;e<br>c2(no)-&gt;op2-&gt;e<br>(`乘3)<br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/在hexo中添加绘制流程图及其他图的功能.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/学习笔记/机器学习算法（七）：K-NN.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/学习笔记/机器学习算法（七）：K-NN.html" class="post-title-link" itemprop="url">机器学习算法（七）：K-NN</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-07-01 15:14:48" itemprop="dateCreated datePublished" datetime="2019-07-01T15:14:48+08:00">2019-07-01</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-06 13:10:25" itemprop="dateModified" datetime="2019-07-06T13:10:25+08:00">2019-07-06</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/ml/" itemprop="url" rel="index"><span itemprop="name">ml</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><blockquote>
<p>K-NN 算法采用测量不同特征值之间的距离的方法进行分类。<br>工作原理：<br>存在一个<strong>样本数据集</strong>，也称作训练样本集，并且样本集中每个数据都存在标签。输入<strong>没有标签的新数据</strong>后，将<strong>新数据</strong>的每个特征与<strong>样本集</strong>中的数据对应特征进行比较，然后算法提取样本集中特征最相似的数据（最邻近）的分类<strong>标签</strong>。一般来说，只选择样本数据集中前 k 个最相似的数据，这就是 k-NN 算法中 k 的出处，通常 k 是不大于 20 的整数。<br>最后选择在 k 个最相似的数据中出现次数最多的分类，作为新数据的分类。</p>
</blockquote>
<div id="flowchart-0" class="flow-chart"></div>

<p>简单来说，K-NN 算法使用了一种计算特征之间的距离的公式，然后选择距离前 k 近的数据，获取这些数据的标签。通过一个简单的统计，获取这 k 项数据中最多的类别。最后我们将新数据看作是这个类别。</p>
<h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">()</span>:</span></span><br><span class="line">    group = np.array([[<span class="number">1.0</span>, <span class="number">1.1</span>], [<span class="number">1.0</span>, <span class="number">1.0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0.1</span>]])</span><br><span class="line">    labels = [<span class="string">'A'</span>, <span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>]</span><br><span class="line">    <span class="keyword">return</span> group, labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(input, dataset, labels, k)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    K-NN 分类</span></span><br><span class="line"><span class="string">    :param input: 输入数据，即待分类的数据</span></span><br><span class="line"><span class="string">    :param dataset: 训练数据集</span></span><br><span class="line"><span class="string">    :param labels: dataset 对应的标签</span></span><br><span class="line"><span class="string">    :param k: 显而易见</span></span><br><span class="line"><span class="string">    :return: input 的类别</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 计算特征之间的距离，只是一个很简单的算法</span></span><br><span class="line">    <span class="comment"># 先算差，再平方，然后将一个项数据的所有特征累加，最后开方</span></span><br><span class="line">    all_distances = np.sqrt(np.sum(np.power((input - dataset), <span class="number">2</span>), <span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 对距离进行逆序排序</span></span><br><span class="line">    sorted_distance_indices = all_distances.argsort()</span><br><span class="line">    <span class="comment"># 对类别进行计数</span></span><br><span class="line">    class_count = &#123;&#125;</span><br><span class="line">    <span class="comment"># 选取前 k 项数据</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        <span class="comment"># 第 i 项数据的标签</span></span><br><span class="line">        label = labels[sorted_distance_indices[i]]</span><br><span class="line">        <span class="comment"># 标签存在则加 1，不存在就默认是 0 再加 1</span></span><br><span class="line">        class_count[label] = class_count.get(label, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 根据标签的数量排序</span></span><br><span class="line">    sorted_class_count = sorted(class_count.items(), key=operator.itemgetter(<span class="number">1</span>), reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sorted_class_count[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    X, Y = create_dataset()</span><br><span class="line">    res = classify([<span class="number">0</span>, <span class="number">0</span>], X, Y, <span class="number">3</span>)</span><br><span class="line">    print(res)</span><br></pre></td></tr></table></figure>
<h2 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h2><p>由于有些数据范围波动较大，可以进行均值归一化处理。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>引用《机器学习实战》中的应用。</p>
<ol>
<li>可以分类电影的类别，已知数据：打斗镜头、接吻镜头、<strong>电影的类别</strong>。如果给定一部新电影，则可以根据该电影的打斗镜头、接吻镜头来计算此部电影属于哪种类别。</li>
<li>改进约会网站配对效果。已知数据：每年获得的飞行常客里程数、玩视频游戏所耗时间百分比、每周消费的冰淇淋公升数、<strong>用户交往对象的类别</strong>。其中<strong>用户交往对象的类别</strong>指：<ul>
<li>不喜欢的人</li>
<li>魅力一般的人</li>
<li>极具魅力的人<br>则可以输入一个新的约会对象的数据，从而判断此人属于哪种类别，如果属于不喜欢的人的类别，那么用户可以提前得知，并且决定不去约会。</li>
</ul>
</li>
<li>甚至可以识别手写数字。将图片转换成 0 1 表示，即数字部分用 1 表示，其他部分用 0 表示。组成一个 32 x 32 数字矩阵，然后将矩阵转换为 1 x 1024 的向量。其中的每一维度的值可以看作为一个特征。算法类似。</li>
</ol>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/学习笔记/机器学习算法（七）：K-NN.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/2019-CCF会议总结.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2019-CCF会议总结.html" class="post-title-link" itemprop="url">2019 CCF会议总结</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-27 21:33:09" itemprop="dateCreated datePublished" datetime="2019-06-27T21:33:09+08:00">2019-06-27</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-29 13:00:38" itemprop="dateModified" datetime="2019-06-29T13:00:38+08:00">2019-06-29</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/" itemprop="url" rel="index"><span itemprop="name">assorted</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/assorted/conference/" itemprop="url" rel="index"><span itemprop="name">conference</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="问答系统"><a href="#问答系统" class="headerlink" title="问答系统"></a>问答系统</h1><h2 id="知识图谱问答系统概述"><a href="#知识图谱问答系统概述" class="headerlink" title="知识图谱问答系统概述"></a>知识图谱问答系统概述</h2><p>现在的<strong>搜索引擎</strong>工作流程是输入要搜索的内容，搜索引擎返回一大堆内容，供你自己选择。<br><strong>问答系统</strong>是下一代的搜索引擎的基本形态。</p>
<blockquote>
<p>以直接而准确的方式回答用户自然语言提问的自动问答系统将构成下一代搜索引擎的基本形态。</p>
</blockquote>
<p>下图展示问答系统在近几十年的发展历史。</p>
<ol>
<li>1960 年的问答系统属于专家系统（模版系统）</li>
<li>1990 - 2000 年的问答系统属于基于信息检索的 QA 系统</li>
<li>2000 - 2010 年的问答系统属于社区 QA 系统</li>
<li>2011 年之后的问答系统属于基于知识图谱的 QA 系统</li>
</ol>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/问答系统的历史.jpg" alt="问答系统的历史"></p>
<h2 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h2><p>问答系统的分类（或者说三个阶段）：</p>
<ol>
<li>IR-based QA：基于<strong>关键词匹配 + 信息抽取</strong>，任然是基于<strong>浅层语义分析</strong></li>
<li>Community QA：依赖于网民贡献，问答过程任然依赖于<strong>关键词检索技术</strong></li>
<li>KB-based QA：Knowledge Base，例如：WolfframAlpha</li>
</ol>
<p>根据问答形式分类：</p>
<ol>
<li>一问一答：字面意思，也是演讲的主题</li>
<li>交互式问答：就是进行连续的复杂的问答</li>
<li>阅读理解</li>
</ol>
<div class="note warning">
            <p>KB-QA 现在只能解决事实性的问题，无法解决：</p><ol><li>怎么去天安门</li><li>西红柿炒鸡蛋怎么做等提问</li></ol><p>某公司（在会议上没听清，可能是一个公司）只有 5% 的问题能用 KB-QA 解决。</p>
          </div>
<h2 id="什么是知识图谱"><a href="#什么是知识图谱" class="headerlink" title="什么是知识图谱"></a>什么是知识图谱</h2><h3 id="一个简单的例子"><a href="#一个简单的例子" class="headerlink" title="一个简单的例子"></a>一个简单的例子</h3><p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/知识图谱示例.jpg" alt="知识图谱示例"></p>
<h3 id="知识图谱基本架构"><a href="#知识图谱基本架构" class="headerlink" title="知识图谱基本架构"></a>知识图谱基本架构</h3><p>图中三元组中的 Ent1、Ent2 等指的是 entity。entity 可以在架构中选取，比如将 concept 作为 entity 或者将 instance 作为 entity。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/知识图谱基本架构.jpg" alt="知识图谱基本架构"></p>
<h3 id="运用知识图谱问答"><a href="#运用知识图谱问答" class="headerlink" title="运用知识图谱问答"></a>运用知识图谱问答</h3><p>语义如何表示是其中的一个问题：</p>
<ol>
<li>使用符号表示的形式（传统方法）</li>
<li>使用分布式表示方法</li>
</ol>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/运用知识图谱问答.jpg" alt="运用知识图谱问答"></p>
<h3 id="知识图谱问答的两类方法（根据技术路线分）"><a href="#知识图谱问答的两类方法（根据技术路线分）" class="headerlink" title="知识图谱问答的两类方法（根据技术路线分）"></a>知识图谱问答的两类方法（根据技术路线分）</h3><ol>
<li>语义解析(Semantic Parsing)：问句转换成形式化的查询语句，进行结构化查询得到答案</li>
<li>语义检索（Answer Retrieval &amp; Ranking）：简单的搜索得到候选答案，利用问句和候选答案的匹配程度(特征)抽取答案</li>
</ol>
<h2 id="公开的评测数据集"><a href="#公开的评测数据集" class="headerlink" title="公开的评测数据集"></a>公开的评测数据集</h2><p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/公开的评测数据集.jpg" alt="公开的评测数据集"><br>例如：</p>
<script type="math/tex; mode=display">
    \text{图数据结构}
    \begin{cases}
        QALD \\
        WebQuestions \\
        Simple Question\\
    \end{cases}\\
    \text{表数据结构}
    \begin{cases}
        WikiSQL & \text{一个表} \\
        Spider & \text{多个表} \\
    \end{cases}</script><h2 id="知识图谱问答基于的几种方法"><a href="#知识图谱问答基于的几种方法" class="headerlink" title="知识图谱问答基于的几种方法"></a>知识图谱问答基于的几种方法</h2><ol>
<li>基于符号语义解析的知识图谱问答<ul>
<li>语义表示（lambda 验算，DCS Tree）</li>
<li>语义解析方法（CCG）<ul>
<li>还有许多语义解析方法，略</li>
</ul>
</li>
</ul>
</li>
<li>基于语义检索的知识图谱问答<ul>
<li>基于显示特征的知识检索</li>
<li>基于端到端的知识图谱问答</li>
</ul>
</li>
<li>基于神经符号计算的知识图谱问答<ul>
<li>基于序列学习的解析方法</li>
<li>基于动作序列的解析方法</li>
<li>基于对战神经网络的端到端问答方法</li>
</ul>
</li>
</ol>
<h3 id="基于符号语义解析的知识图谱问答"><a href="#基于符号语义解析的知识图谱问答" class="headerlink" title="基于符号语义解析的知识图谱问答"></a>基于符号语义解析的知识图谱问答</h3><p>两种技术的具体实现过程略过，对比如下图：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/Lambda演算vs.DCSTree.jpg" alt="Lambda演算vs.DCSTree"></p>
<h3 id="基于语义检索的知识图谱问答"><a href="#基于语义检索的知识图谱问答" class="headerlink" title="基于语义检索的知识图谱问答"></a>基于语义检索的知识图谱问答</h3><ul>
<li>基于显示特征的知识检索<ul>
<li>关键词检索</li>
<li>文本蕴含推理</li>
<li>逻辑表达式</li>
<li><div class="note primary">
            <p>给出了许多研究进展。</p>
          </div></li>
</ul>
</li>
<li>基于端到端的知识图谱问答<ul>
<li>LSTM</li>
<li>Attention Model</li>
<li>Memory Network</li>
<li><div class="note primary">
            <p>其中有部分问题：</p><ol><li>如何学习？<ul><li>RNN</li><li>CNN</li><li>Transformer</li></ul></li><li>问句如何表示？<ul><li>取所有词向量的平均值</li><li>关注答案不同的部分，问句的表示应该问句的不同部分</li><li>等</li></ul></li><li><strong>考虑多维度的相似度</strong><ul><li>从多个角度计算问句和知识的语义匹配（语义相似度）</li><li>问句如何表示？</li><li>依据问答特点，考虑答案不同维度的信息</li></ul></li></ol><p>PPT 中给出了许多研究进展，包括最基本的做法。</p>
          </div>
<img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/基于语义检索的知识图谱问答.jpg" alt="基于语义检索的知识图谱问答"></li>
</ul>
</li>
</ul>
<h3 id="基于神经符号计算的知识图谱问答"><a href="#基于神经符号计算的知识图谱问答" class="headerlink" title="基于神经符号计算的知识图谱问答"></a>基于神经符号计算的知识图谱问答</h3><p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/符号语义解析vs.深度学习.jpg" alt="符号语义解析vs.深度学习"></p>
<ul>
<li><p>基于序列学习的解析方法</p>
<ul>
<li>seq2seq<ul>
<li>RNN-based</li>
<li>with Attention</li>
</ul>
</li>
<li><p>基于序列学习的神经符号计算</p>
<div class="note primary">
            <p>就是运用<strong>基于符号语义解析的知识图谱问答</strong>的原理，让神经网络生成这些符号，而不是生成文字。</p>
          </div>
<blockquote>
<p>基于序列学习的方法将问句和答案的逻辑表达式看作为两个序列</p>
<ul>
<li>使用序列转换的神经网络模型（如 Seq2Seq）来建模</li>
<li>神经网络生成的逻辑表达式可能不合语法规范</li>
</ul>
</blockquote>
<ul>
<li>Seq2Tree</li>
</ul>
</li>
</ul>
</li>
<li>基于动作序列的解析方法<ul>
<li>Seq2Action</li>
</ul>
</li>
<li>基于对战神经网络的端到端问答方法</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>限定域的深度问答的准确度比较高，开放域的深度问答的准确度还是处于较低的水平。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/深度问答的性能.jpg" alt="深度问答的性能"></p>
<h1 id="对话系统"><a href="#对话系统" class="headerlink" title="对话系统"></a>对话系统</h1><p>对话系统也可以直白的称为聊天机器人。<br>目前 54% 的用户会使用闲聊（开放域对话）功能。26% 的用户会选择使用某些功能性功能，比如查出行路线、查天气等。其余小部分用户使用其他的功能。<br>目前大部分的聊天机器人都基于<strong>微软小冰</strong>。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/各种聊天机器人.jpg" alt="各种聊天机器人"></p>
<p>聊天机器人一共分为两种：</p>
<ol>
<li>检索式</li>
<li>生成式</li>
</ol>
<h2 id="Response-Selection-for-Retrieval-based-Chatbots"><a href="#Response-Selection-for-Retrieval-based-Chatbots" class="headerlink" title="Response Selection for Retrieval-based Chatbots"></a>Response Selection for Retrieval-based Chatbots</h2><p>检索式又分为单轮和多轮。<br>单轮不考虑回复历史。下图展示了一个单轮回复的场景，用户提出一个问题，机器人需要在一堆回复中检索出一个最有可能的结果来对用户进行回复。多轮回复与单轮类似，只不过多轮需要考虑上下文的对话。最后也是选择一个最优可能的结果进行回复。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复.jpg" alt="检索式单轮回复"></p>
<div class="note info">
            <p>&emsp;&emsp;对于单轮：<br>&emsp;&emsp;回复不只回复 Top1 的候选回复，而是要训练一个 classifier，从而随机地返回一个回复。因为如果回复总是为同一个，用户可能会感觉很无聊。<br>&emsp;&emsp;对于多轮：<br>&emsp;&emsp;有一些挑战：</p><ul><li>A hierarchical data structure<ul><li>Words -&gt; utterances -&gt; session</li></ul></li><li>Information redundancy<ul><li>Not all words and utterances are useful for response selection</li></ul></li><li>Logics<ul><li>Order of utterances matters in response selection</li><li>Long-term dependencies among words and utterances</li><li>Constraints to proper responses</li></ul></li></ul>
          </div>
<p>下面是检索式单轮回复系统架构图和多轮回复系统架构图的对比。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复架构图.jpg" alt="检索式单轮回复架构图"></p>
<p><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式多轮回复架构图.jpg" alt="检索式多轮回复架构图"></p>
<h3 id="单轮回复中使用的模型"><a href="#单轮回复中使用的模型" class="headerlink" title="单轮回复中使用的模型"></a>单轮回复中使用的模型</h3><p>一共有两种框架，分别为：Framework I 和 Framework II。<br><strong>Framework I 和 Framework II 的区别是</strong>：</p>
<ol>
<li>Framework I 是将句子表示为向量，Framework II 将字表示为向量。</li>
</ol>
<p><strong>Framework I 和 Framework II 的比较：</strong></p>
<ul>
<li>Efficacy（功效）：<ol>
<li>一般来讲，在外界公布出的数据集上，Framework II 模型比 Framework I 模型更好。因为在 Framework II 中的 interaction 充分保留了一个 message-response pair 中的匹配信息。</li>
</ol>
</li>
<li>Efficiency（效率）：<ol>
<li>由于过多的 interaction，Framework II 的模型普遍比 Framework I 的模型在计算上代价更大。</li>
<li>由于可以预先计算 messages and responses 的表示并将它们以索引形式存储。所以当对线上响应时间有严格要求时， Framework I 的模型更可取。</li>
</ol>
</li>
</ul>
<p>下图是 Framework I 的架构，其中最下层的 sentence embedding layer 大概就是词向量，然后需要经过一个 Representation function（这个 function 下面会给出架构）。最后将已经经过 Representation function 转换后的 q 和 r 送入 Matching layer，该层有一个 Matching function（这个 function 下面也会给出架构）。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复的 Framework I.jpg" alt="检索式单轮回复的 Framework I"></p>
<p>下图是 Representation funtion 的结构：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复的 Framework I 的 Representation funtion.jpg" alt="检索式单轮回复的 Framework I 的 Representation funtion"></p>
<p>下图是 Matching funtion 的结构：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复的 Framework I 的 Matching funtion.jpg" alt="检索式单轮回复的 Framework I 的 Matching funtion"></p>
<p><strong><em>有一些特殊的模型：Arc-I，Attentive LSTM 等</em></strong></p>
<p>Framework II 的架构与 Framework I 类似，只是多了一个 Interaction Function。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复的 Framework II.jpg" alt="检索式单轮回复的 Framework II"></p>
<p>Interaction 由两种形式：<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/2019 CCF会议总结/检索式单轮回复的 Framework II 中 Interaction 的两种类型.jpg" alt="检索式单轮回复的 Framework II 中 Interaction 的两种类型"></p>
<p><strong><em>有一些特殊的模型：Match Pyramid，Match LSTM 等</em></strong></p>
<p>PPT 中有数据集。以及很多 reference。</p>
<h3 id="多轮回复中使用的模型"><a href="#多轮回复中使用的模型" class="headerlink" title="多轮回复中使用的模型"></a>多轮回复中使用的模型</h3><p>&emsp;&emsp;对于多轮回复也有两种框架，分别为：Framework I 和 Framework II。<br>&emsp;&emsp;具体的架构略。PPT 里都有。</p>
<h1 id="技术总结"><a href="#技术总结" class="headerlink" title="技术总结"></a>技术总结</h1><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/2019-CCF会议总结.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/机器学习中优化算法以及各种函数的选择.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/机器学习中优化算法以及各种函数的选择.html" class="post-title-link" itemprop="url">机器学习中优化算法以及各种函数的选择</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-04 21:19:56 / 修改时间：21:33:18" itemprop="dateCreated datePublished" datetime="2019-06-04T21:19:56+08:00">2019-06-04</time>
            

            
              

              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/ml/" itemprop="url" rel="index"><span itemprop="name">ml</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><p>大部分梯度下降算法已经记录在<a href="https://yan624.github.io/学习笔记/对神经网络整体的理解.html#Mini-batch梯度下降">笔记</a>中。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>算法</th>
<th>选择</th>
</tr>
</thead>
<tbody>
<tr>
<td>SGD</td>
<td></td>
</tr>
<tr>
<td>Adagrad</td>
<td>有优化过的 RMSprop 算法</td>
</tr>
<tr>
<td>Momentum</td>
<td></td>
</tr>
<tr>
<td>RMSprop</td>
<td>我的理解是 RMSprop 算法也算是在累计梯度。所以我感觉使用 RMSprop 和使用 Adam（是 Momentum 和 RMSprop 结合体） 差不多。但是吴恩达老师指出 Adam 比单独两个 Momentum 和 RMSprop 效果好。请看<a href="https://yan624.github.io/学习笔记/对神经网络整体的理解.html#优化算法总结">优化算法总结</a>。</td>
</tr>
<tr>
<td>Adam</td>
<td></td>
</tr>
</tbody>
</table>
</div>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/机器学习中优化算法以及各种函数的选择.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/Dissecting-BERT-Part-1：-The-Encoder（BERT解析）.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/Dissecting-BERT-Part-1：-The-Encoder（BERT解析）.html" class="post-title-link" itemprop="url">Dissecting BERT Part 1： The Encoder（BERT解析）</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-25 11:47:18" itemprop="dateCreated datePublished" datetime="2019-05-25T11:47:18+08:00">2019-05-25</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-04 13:22:19" itemprop="dateModified" datetime="2019-06-04T13:22:19+08:00">2019-06-04</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/dl/" itemprop="url" rel="index"><span itemprop="name">dl</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      
        <div class="post-gallery" itemscope="" itemtype="http://schema.org/ImageGallery">
          
          
            <div class="post-gallery-row">
              <a class="post-gallery-img fancybox" href="https://cdn-images-1.medium.com/max/800/1*SdiFbDnvGZWRUhev7ynU9Q.jpeg" rel="gallery_cjy6v9bnu0007yw801jzv0700" itemscope="" itemtype="http://schema.org/ImageObject" itemprop="url">
                <img src="https://cdn-images-1.medium.com/max/800/1*SdiFbDnvGZWRUhev7ynU9Q.jpeg" itemprop="contentUrl">
              </a>
            
          

          
          </div>
        </div>
      

      
        
          <p><a href="">原文</a></p>
<h1 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h1><p>在开始之前，我们先定义一些将会贯穿全文的符号：</p>
<blockquote>
<p>emb_dim: Dimension of the token embeddings.<br>input_length: Length of the input sequence (the same in all sequences in a specific batch due to padding).<br>hidden_dim: Size of the Feed-Forward network’s hidden layer.<br>vocab_size: Amount of words in the vocabulary (derived from the corpus).</p>
</blockquote>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><strong>BERT</strong> 中使用的 <strong>Encoder</strong> 是基于注意力机制的架构，被用于 NLP 领域之中，一年之前 Encoder 在论文 <strong>Attention Is All You Need</strong> 中被提出。该论文介绍了一种被称为 <strong>Transformer</strong> 的架构，共由两部分组成，分别为 <strong>Encoder</strong> 和 <strong>Decoder</strong> 。因为 <strong>BERT</strong> 只使用了 <strong>Encoder</strong> ，所以我们在这篇博客中只解释 Encoder（如果你想要了解 <strong>Decoder</strong> 以及它是如何与 <strong>Encoder</strong> 集成的，<a href="https://medium.com/dissecting-bert/transformer-architecture-where-the-encoder-comes-from-3b86f66b0e5f" target="_blank" rel="noopener">这里</a>我们写了一篇单独的博客）。<br>自从年初</p>
<h1 id="Information-Flow"><a href="#Information-Flow" class="headerlink" title="Information Flow"></a>Information Flow</h1><p>通过架构的数据流如下所示：</p>
<ol>
<li>该模型将每个标记表示为<em>emb_dim</em>大小的向量。</li>
</ol>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/Dissecting-BERT-Part-1：-The-Encoder（BERT解析）.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/zcy/深度学习算法（三）：LSTM.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/zcy/深度学习算法（三）：LSTM.html" class="post-title-link" itemprop="url">深度学习算法（三）：LSTM</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-23 17:07:17" itemprop="dateCreated datePublished" datetime="2019-05-23T17:07:17+08:00">2019-05-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-14 13:24:03" itemprop="dateModified" datetime="2019-07-14T13:24:03+08:00">2019-07-14</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/dl/" itemprop="url" rel="index"><span itemprop="name">dl</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <p>略，详见<a href="https://yan624.github.io/学习笔记/吴恩达李宏毅综合学习笔记：RNN入门.html#长短期记忆——Long-Short-term-Memory-LSTM">博客</a><br>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/zcy/深度学习算法（三）：LSTM.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </p></div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/zcy/深度学习算法（二）：simple-RNN.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/zcy/深度学习算法（二）：simple-RNN.html" class="post-title-link" itemprop="url">深度学习算法（二）：simple RNN</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-23 15:48:00" itemprop="dateCreated datePublished" datetime="2019-05-23T15:48:00+08:00">2019-05-23</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-07-10 16:35:25" itemprop="dateModified" datetime="2019-07-10T16:35:25+08:00">2019-07-10</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/dl/" itemprop="url" rel="index"><span itemprop="name">dl</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><a href="https://github.com/yan624/machine_learning_algorithms/tree/master/simple_recurrent_neural_network" target="_blank" rel="noopener">github地址</a><br>simple RNN只实现了正向传播，反向传播没有实现。是因为simple RNN有梯度消失的问题，索性直接不写了。下一节直接写LSTM。</p>
<h1 id="simple-RNN和simple-NN的对比"><a href="#simple-RNN和simple-NN的对比" class="headerlink" title="simple RNN和simple NN的对比"></a>simple RNN和simple NN的对比</h1><p>本来觉得simple RNN挺简单的，只不过是simple NN的扩展，区别无非是将simple NN的神经元换成一个RNN cell。但是实际上没那么简单，特别是加上将数据向量化后计算。感觉简直和simple NN是两种架构。</p>
<h2 id="input"><a href="#input" class="headerlink" title="input"></a>input</h2><p>下图是一个simple NN的架构，其中的一层也叫做全连接层。所以也叫做前馈神经网络。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/带参数的前馈神经网络模版.svg" alt="带参数的前馈神经网络模版"><br>网络中输入的x是一个纯数字，而不是向量。如果输入的是向量，就代表一次输入了多条样本。总的来说，一条样本向量化为：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}
    x_1\\
    x_2\\
    x_3\\
\end{pmatrix}</script><p>多条样本向量化为：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}
    x_1 & x_4\\
    x_2 & x_5\\
    x_3 & x_6\\
\end{pmatrix}</script><p>但是在simple <strong>R</strong>NN中，因为RNN可以用做自然语言处理，在NLP领域一个数据就是一个单词或者一个词组，我们需要先将词组用数字表示，但是一个字只用一个数表示显然是不现实的。我们通常使用词向量（word vector）表示，所以问题就来了。如果我用simple NN来做自然语言处理，我该怎么处理这些数据。<br>我需要输入这句话——我 是 一名 学生。将其用变量一一对应：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}
    x_1 = \text{我}\\
    x_2 = \text{是}\\
    x_3 = \text{一名}\\
    x_4 = \text{学生}\\
\end{pmatrix}</script><p>如果再输入一句话——今天 天气 好像 不错。将其用变量一一对应：</p>
<script type="math/tex; mode=display">
\begin{pmatrix}
    x_1 = \text{我} & x_5 = \text{今天}\\
    x_2 = \text{是} & x_6 = \text{天气}\\
    x_3 = \text{一名} & x_7 = \text{好像}\\
    x_4 = \text{学生} & x_8 = \text{不错}\\
\end{pmatrix}</script><p>这样会出现<strong>极大的问题</strong>，即文字无法进行数学运算。所以需要将文字转为词向量。但是问题是我如何在一个神经元输入一个向量？我如果输入多条样本，那么我整个输入值x就会变成<strong>3维的矩阵</strong>。simple NN显然是处理不了的。所以有个折中的方法，即将每个词的词向量加起来除以词的个数。即：</p>
<script type="math/tex; mode=display">
\frac{(v_{\text{我}} + v_{\text{是}} + v_{\text{一名}} + v_{\text{学生}})}{4} =  v_{\text{我是一名学生}}</script><p>其中v代表某个词对应的词向量。这样就将4个向量合并成一个向量了。然后simple NN就可以处理了。<br>但是这样处理肯定太勉强了，所以就出现了simple RNN，它可以处理上述这种问题。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/吴恩达深度学习与李宏毅深度学习学习笔记：RNN序列模型/吴恩达深度学习中的RNN示意图.jpg" alt="吴恩达深度学习中的RNN示意图"><br>上图就是一个simple <strong>R</strong>NN架构，看起来跟simple NN不一样。但是其实你只要将图片往右旋转90度，就一样了。还有一点不太一样，就是simple <strong>R</strong>NN中的一个神经元跟simple NN中的一层神经元一样。<br><div class="note info">
            <p>simple <strong>R</strong>NN其实就是simple NN的神经元被替换成了simple <strong>R</strong>NN的神经元。而simple <strong>R</strong>NN的一个神经元本身里面还有多个单元，图上就是一个神经元里有4个单元。<br>所以simple <strong>R</strong>NN的神经元可以被叫做记忆细胞。<br>如果重新描述一遍就是simple <strong>R</strong>NN其实就是simple NN的神经元被替换成了simple <strong>R</strong>NN的记忆细胞。<br>而simple <strong>R</strong>NN的记忆细胞里面有多个神经元用来处理进行向量计算。</p>
          </div></p>
<h2 id="simple-RNN的另一个输入值a"><a href="#simple-RNN的另一个输入值a" class="headerlink" title="simple RNN的另一个输入值a"></a>simple RNN的另一个输入值a</h2><p>下图是simple RNN的一个记忆细胞。由于其概念大都需要数值来演示，但是大量的数值难以书写，并且用语言实在难以描述。所以以下均使用一个矩阵的字母表示来演示。<br>此处会有几个问题：</p>
<ol>
<li>乍一看很简单，但是在实现代码的时候，脑子会转不过来。<strong>因为你碰到的是向量化后的运算</strong>。所以你对各个W，b，A以及X的形状难以确定。不信就自己写一下代码，如果你以前没写过simple RNN的代码，肯定要在确定形状这卡至少一个小时。</li>
<li>A的形状尤其难确定，会一时之间绕不过来。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/simple%20rnn%20cell.png" alt="simple rnn cell"></li>
</ol>
<h3 id="以一个记忆细胞为例"><a href="#以一个记忆细胞为例" class="headerlink" title="以一个记忆细胞为例"></a>以一个记忆细胞为例</h3><p>设词向量的维度为300，一个记忆细胞的units为32——keras代码表示：simpleRNN(32)，并且进行的是18元分类问题。</p>
<h4 id="以一个样本为例"><a href="#以一个样本为例" class="headerlink" title="以一个样本为例"></a>以一个样本为例</h4><p>，输入样本数为1。<br>则运算过程为：</p>
<script type="math/tex; mode=display">
\begin{align}
    A\_next & = tanh(Wx_{32, 300} * X_{300, 1} + Wa_{32, 32} * A\_prev_{32, 1} + ba_{32, 1})\\
    y & = softmax(Wy_{18, 32} * A\_next + by_{18, 1})
\end{align}</script><p>(数字, 数字) 的表示形式是在线性代数里表示形式，这样看起来方便点。第一个数字表示行，第二个数字表示列。tanh和softmax就不解释了。<br>我依次解释：</p>
<ol>
<li>权重值Wx比较好理解，由于输入值X是一个 (300, 1) 的矩阵（也可以叫向量）。Wx为 (32, 300) 是因为记忆细胞的一个单元为32，并且词的特征为300。如果将一个记忆细胞看作是一个隐藏层，那么神经元个数就是32，300就代表前一层的输入。</li>
<li>权重值Wa为什么是 (32, 32) ?由于a实际上就是激活值，激活值我们可以通过w * x计算得到。显然结果是 (32, 1) ，那么权重值Wa的第二个参数就可以确定大小了（矩阵相乘，第一个矩阵的第二维和第二个矩阵的第一维必须一样），权重值Wa的第一个参数实际上跟权重值Wx一样，都是units。</li>
<li>Wy为什么是 (18, 32) ?18是因为这是一个18元分类问题，32是因为A的第一维是32。</li>
</ol>
<p>其中最难确定的就是Wa的形状。经过上面推导就可以知道了，第一维代表units，第二维代表需要与A的第一维，即为A的第一维的大小。</p>
<h4 id="以128个样本为例"><a href="#以128个样本为例" class="headerlink" title="以128个样本为例"></a>以128个样本为例</h4><p>如果上面没懂可以再看一遍多个样本</p>
<script type="math/tex; mode=display">
\begin{align}
    A\_next & = tanh(Wx_{32, 300} * X_{300, 128} + Wa_{32, 32} * A\_prev_{32, 128} + ba_{32, 1})\\
    y & = softmax(Wy_{18, 32} * A\_next + by_{18, 1})
\end{align}</script><p>说白了A其实激活值，看起来比较晕是因为多了一个初始的A0，实际上A0就是激活值，只不过需要初始化一下，它的形状就是激活值的形状。</p>
<h3 id="以多个记忆细胞为例"><a href="#以多个记忆细胞为例" class="headerlink" title="以多个记忆细胞为例"></a>以多个记忆细胞为例</h3><p>过程就是上面的过程，唯一有区别的是输入值X。因为有了多个记忆细胞，所以X变成了3维，第3维就是timestep——时间步。<br>但是其实计算，跟上面一模一样，假设现在有6个时间步。伪代码如下：<br><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">fun</span> <span class="title">rnn_cell</span><span class="params">(A_prev, Xt, parameters)</span></span>:</span><br><span class="line">	<span class="keyword">do</span>上面的操作</span><br><span class="line"></span><br><span class="line">timesteps = <span class="number">6</span></span><br><span class="line">X = rand((<span class="number">300</span>, <span class="number">128</span>, timesteps))</span><br><span class="line">A0 = rand((<span class="number">32</span>, <span class="number">128</span>))</span><br><span class="line">parameters = 初始化所有参数</span><br><span class="line"><span class="keyword">for</span> ts <span class="keyword">in</span> range(timesteps):</span><br><span class="line">	rnn_cell(A0, X[:, :, ts], parameters)</span><br></pre></td></tr></table></figure></p>
<p>其实就是遍历每一个时间步而已。<br><img src="https://blog-content-1256924128.cos.ap-shanghai.myqcloud.com/RNN.png" alt="RNN"></p>
<h1 id="simple-RNN-的缺陷"><a href="#simple-RNN-的缺陷" class="headerlink" title="simple-RNN 的缺陷"></a>simple-RNN 的缺陷</h1><p>RNN一个最大的缺陷就是梯度消失与梯度爆炸问题，由于这一缺陷，使得RNN在长文本中难以训练，这才诞生了LSTM及各种变体，来源于<a href="https://zhuanlan.zhihu.com/p/44163528" target="_blank" rel="noopener">专栏</a>。梯度消失的原因：参考<a href="https://zhuanlan.zhihu.com/p/28687529" target="_blank" rel="noopener">专栏</a></p>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/zcy/深度学习算法（二）：simple-RNN.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yan624.github.io/学习笔记/2017CS224n学习笔记.html">
    

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="朱冲䶮">
      <meta itemprop="description" content="记录学习问题，积累做的 leetcode 题目">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="博客">
    </span>

    
      <header class="post-header">
				
				
	

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/学习笔记/2017CS224n学习笔记.html" class="post-title-link" itemprop="url">2017CS224n学习笔记</a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-05-20 10:51:09" itemprop="dateCreated datePublished" datetime="2019-05-20T10:51:09+08:00">2019-05-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-04 13:19:05" itemprop="dateModified" datetime="2019-06-04T13:19:05+08:00">2019-06-04</time>
              
            
          </span>
          
          
          	
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/AI/dl/" itemprop="url" rel="index"><span itemprop="name">dl</span></a></span>

                
                
              
            </span>
          
          
          <!--不蒜子计数-->
          <span id="busuanzi_container_site_uv">
<span class="post-meta-divider">|</span>
	浏览量：<span id="busuanzi_value_site_uv"></span>人次
</span>
				
          
            
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          <h1 id="词向量表示：word2vec"><a href="#词向量表示：word2vec" class="headerlink" title="词向量表示：word2vec"></a>词向量表示：word2vec</h1>
          <!--noindex-->
          
            <div class="post-button text-center">
              <a class="btn" href="/学习笔记/2017CS224n学习笔记.html#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          
          <!--/noindex-->
        
      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="朱冲䶮">
            
              <p class="site-author-name" itemprop="name">朱冲䶮</p>
              <p class="site-description motion-element" itemprop="description">记录学习问题，积累做的 leetcode 题目</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">110</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">22</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">17</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
            <br>
						<!--同个ip访问本站页面次数-->
						<div class="site-state-item site-state-posts" style="border-left:none;">
								<span class="site-state-item-count" id="busuanzi_value_site_pv"></span>
								<span class="site-state-item-name">浏览量</span>
						</div>
						<!--不同ip访问本站次数-->
						<div class="site-state-item site-state-posts">
								<span class="site-state-item-count" id="busuanzi_value_site_uv"></span>
								<span class="site-state-item-name">访客量</span>
						</div>
						<div class="site-state-item site-state-posts">
								<span class="site-state-item-count">83.4k</span>
								<span class="site-state-item-name">总字数</span>
						</div>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:897538633@qq.com" title="E-Mail &rarr; mailto:897538633@qq.com" rel="noopener" target="_blank"><i class="fas fa-fw fa-envelope"></i>E-Mail</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/yan624" title="GitHub &rarr; https://github.com/yan624" rel="noopener" target="_blank"><i class="fab fa-fw fa-github"></i>GitHub</a>
                </span>
              
            </div>
          

          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://huaguoguo.gitee.io" title="http://huaguoguo.gitee.io" rel="noopener" target="_blank">葬爱丶华少的天下</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://lzh0928.gitee.io/" title="https://lzh0928.gitee.io/" rel="noopener" target="_blank">Mr.Liu</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </div>

      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">朱冲䶮</span>

  

  
</div>


  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v6.7.0</div>




        








        
      </div>
    </footer>

    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=6.7.0"></script>

  <script src="/js/src/motion.js?v=6.7.0"></script>



  
  


  <script src="/js/src/affix.js?v=6.7.0"></script>

  <script src="/js/src/schemes/pisces.js?v=6.7.0"></script>



  

  


  <script src="/js/src/bootstrap.js?v=6.7.0"></script>



  



  





  

  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  


  

  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function(i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap');
      $(e).after($wrap);
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function(e) {
        var code = $(this).parent().find('.code').find('.line').map(function(i, e) {
          return $(e).text();
        }).toArray().join('\n');
        var ta = document.createElement('textarea');
        var range = document.createRange(); //For Chrome
        var sel = window.getSelection(); //For Chrome
        var yPosition = window.pageYOffset || document.documentElement.scrollTop;
        ta.style.top = yPosition + 'px'; //Prevent page scroll
        ta.style.position = 'absolute';
        ta.style.opacity = '0';
        ta.value = code;
        ta.textContent = code; //For FireFox
        ta.contentEditable = true;
        ta.readOnly = false;
        document.body.appendChild(ta);
        range.selectNode(ta);
        sel.removeAllRanges();
        sel.addRange(range);
        ta.setSelectionRange(0, code.length);
        var result = document.execCommand('copy');
        
          if (result) $(this).text('复制成功');
          else $(this).text('复制失败');
        
        ta.blur(); //For iOS
        $(this).blur();
      })).on('mouseleave', function(e) {
        var $b = $(this).find('.copy-btn');
        setTimeout(function() {
          $b.text('复制');
        }, 300);
      }).append(e);
    })
  </script>


  

	<script src="/lib/my-utils.js"></script>
<!--图片缩放插件-->
<script src="/lib/zoomify/zoomify.min.js"></script>
<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!--不蒜子统计-->
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-backstretch/2.0.4/jquery.backstretch.min.js"></script>
<!-- 背景图片 -->
<script>
	function generateBG(count){
		var bg_prefix = '/images/background/';
		var bg =new Array();
		for(var i = 0; i < count; i++){
			bg[i] = bg_prefix + i + '.jpg';
		}
		bg.shuffle();
		return bg;
	}
	$("body").backstretch(generateBG(5), { 
		duration:60000,//1min一换
		fade: 1500 
	});
	$('#content img').zoomify({duration: 500, });
	$('#content img').on('zoom-in.zoomify', function () {
		$('#sidebar').css('display', 'none');
	});
	$('#content img').on('zoom-out-complete.zoomify', function () {
		$('#sidebar').css('display', '');
	});
</script>
	

</body>
</html>
